{"meta":{"title":"灵魂都失控","subtitle":"","description":"","author":"Icey Liu","url":"https://tlylft.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2019-11-23T07:02:17.249Z","updated":"2019-11-23T07:02:17.249Z","comments":false,"path":"/404.html","permalink":"https://tlylft.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2019-11-23T07:02:17.250Z","updated":"2019-11-23T07:02:17.250Z","comments":false,"path":"about/index.html","permalink":"https://tlylft.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"Repositories","date":"2019-11-23T07:02:17.251Z","updated":"2019-11-23T07:02:17.251Z","comments":false,"path":"repository/index.html","permalink":"https://tlylft.github.io/repository/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-11-23T07:02:17.251Z","updated":"2019-11-23T07:02:17.251Z","comments":false,"path":"categories/index.html","permalink":"https://tlylft.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-11-23T07:02:17.252Z","updated":"2019-11-23T07:02:17.252Z","comments":false,"path":"tags/index.html","permalink":"https://tlylft.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"【transformer】 03-GPT1/2/3 微调到prompt","slug":"NLP/transformer/GPT","date":"2023-08-13T13:12:24.000Z","updated":"2023-08-14T02:58:58.268Z","comments":true,"path":"NLP/transformer/GPT/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/GPT/","excerpt":"","text":"GPT1： 生成式的预训练2018预训练(单向Transformer) + Fine-tuningGPT是“Generative Pre-Training”的简称，从名字看其含义是指的生成式的预训练。GPT提出两阶段训练方式，第一个阶段是利用语言模型进行预训练，第二阶段通过Fine-tuning的模式解决下游任务 预训练过程 从ELMO中优化：特征抽取器使用Transformer解码器，将输入序列编码为固定长度的向量。 使用单向语言模型：ELMO在做语言模型预训练的时候，预测单词可以同时使用上文和下文，用的双向LSTM结构，而GPT则只采用单词的上文来进行单词预测，而抛开了下文。说人话，就是让你根据提示造句，从左到右，是单向的 关于为啥使用单向的说明，需要再详细看一下 第二阶段：下游任务 ??? 什么是结构改造？ GPT2:初步具备小样本学习上的潜能 GPT3增大参数量： 成为1750亿的大语言模型 为什么通过提示可以不微调？few-shot: 通过上下文学习学到了一种隐士微调，学习到了映射的分布。 3.5加强代码推理能力： 使用github的代码库作为训练数据本质是三个阶段都是在做微调继续增强代码训练增加指令微调： 借鉴instructGPTRHLF强化学习 指令微调Google论文：《FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS》","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"},{"name":"transformer","slug":"LLM/transformer","permalink":"https://tlylft.github.io/categories/LLM/transformer/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"强化学习（2）-马尔科夫决策过程MDP","slug":"reinforcement_learning/02_rf_mdp","date":"2023-08-09T09:13:54.000Z","updated":"2023-08-10T08:44:41.707Z","comments":true,"path":"reinforcement_learning/02_rf_mdp/","link":"","permalink":"https://tlylft.github.io/reinforcement_learning/02_rf_mdp/","excerpt":"","text":"强化学习极简入门1.2：https://blog.csdn.net/v_JULY_v/article/details/128965854 1. 马尔科夫决策过程（MDP）RL其实是一个马尔可夫决策过程(Markov decision process，MDP)，而为说清楚MDP，得先从随机过程、马尔可夫过程(Markov process，简称MP)开始讲起，故为考虑逻辑清晰，我们还是把整个继承/脉络梳理下。 概念理解顺序：马尔科夫过程 -&gt; 马尔科夫奖励() -&gt; 马尔科夫决策过程（MDP） 1.1. MDP的前置知识：随机过程、马尔可夫过程随机过程核心：状态转移矩阵，表示当前状态下执行下一动作的概率，也是需要学习的参数？ 马尔可夫奖励(MRP)在马尔可夫过程的基础上加入奖励函数R和折扣因子\\gamma，就可以得到马尔可夫奖励过程(Markov reward process，MRP) 奖励函数，某个状态s的奖励R(s)，是指转移到该状态s时可以获得奖励的期望，有$R(s) = E[R_{t+1}|S_t = s]$注意，有的书上奖励函数和下面回报公式中的R_{t+1}的下标t+1写为t，其实严格来说，先有t时刻的状态/动作之后才有t+1时刻的奖励，但应用中两种下标法又都存在，读者注意辨别 在实际中，奖励可以分为即时奖励和持久奖励。持久奖励是当前动作对未来n步影响的收益，这个收益可以用小于1的折扣因子的n次方* 未来产生的即时奖励 求和获得，因为一个状态可以得到的奖励是持久的，所有奖励的衰减之和称为回报，可用G表示当下即时奖励和所有持久奖励等一切奖励的加权和(考虑到一般越往后某个状态给的回报率越低，也即奖励因子或折扣因子越小，用\\gamma表示)，从而有$Gt=R_{t+1}+γ⋅R_{t+2}+γ^2⋅R_{t+3}+γ^3⋅R_{t+4}+⋯=R_{t+1}+γ(R_{t+2}+γ⋅R_{t+3}+γ^2⋅R_{t+4}+⋯)=R_{t+1}+γG_{t+1}$ 通过奖励计算回报引入概率，推导过程忽略就是所谓的贝尔曼方程(bellman equation),hu$V(s)=R(s)+γ∑s′∈SP(s′|s)V(s′)$马尔可夫决策过程(MDP)：马尔可夫奖励(MRP) + 智能体动作因素 aa动作价值函数状态价值函数","categories":[{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"强化学习（3）-RLHF基于人类反馈的强化学习","slug":"reinforcement_learning/03_rf_rlhf","date":"2023-08-09T09:13:54.000Z","updated":"2023-08-10T00:49:44.092Z","comments":true,"path":"reinforcement_learning/03_rf_rlhf/","link":"","permalink":"https://tlylft.github.io/reinforcement_learning/03_rf_rlhf/","excerpt":"","text":"简单介绍：ChatGPT狂飙：强化学习RLHF与PPO！【ChatGPT】原理第02篇LLM大型语言模型如何进行微调？ RLHF强化学习代码解读 背景finetuning 20B LLM, 微调大语言模型超过200亿参数的模型是非常困难的，需要大量的语料，否则参数调不动起不到效果，于是提出了RLHF(Reinforcement Learning Human Feedback)强化学习的微调方式，强化学习通过人类反馈来训练大语言模型，从而提高大语言模型的性能。 实际上，RLHF(Reinforcement Learning with Human Feedback)这一概念最早被定义为基于人类反馈的强化学习，它最早是在2008年《TAMER：Training an Agent Manually via Evaluative Reinforcement》一文中被提及的.在2017年前后，深度强化学习(Deep Reinforcement Learning)逐渐发展并流行起来，如你所见，2017年6月由OpenAI联合Google DeepMind一块推出：基于人类偏好的深度强化学习《Deep Reinforcement Learning from Human Preferences》，也简称RLHF huggingface 提供了trl开源库，实现微调大语言模型的方式。https://github.com/lvwerra/trl/tree/main/examples 实现方式简单说明：首先，得到一个预训练语言模型的输出结果，然后，通过人类反馈对模型打分，将对输出结果的评分作为reward，来训练一个RL模型，得到新的模型参数。 也可以通过这种方式做指令微调，根据不同的指令设置不同的reward.","categories":[{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"LLM（4）-chatGLM-清华","slug":"LLM/04_chatGLM","date":"2023-08-09T06:40:59.000Z","updated":"2023-08-10T09:29:41.415Z","comments":true,"path":"LLM/04_chatGLM/","link":"","permalink":"https://tlylft.github.io/LLM/04_chatGLM/","excerpt":"","text":"https://github.com/mymusise/ChatGLM-Tuning","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"redis","slug":"tools/redis","date":"2023-07-19T00:21:34.000Z","updated":"2023-07-24T07:34:41.016Z","comments":true,"path":"tools/redis/","link":"","permalink":"https://tlylft.github.io/tools/redis/","excerpt":"","text":"linux 安装： https://blog.csdn.net/qq_39187538/article/details/126485922 1. 下载安装12345678910# 下载yum install -y wgetwget https:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-7.0.2.tar.gz# 默认安装到了&#x2F;usr&#x2F;local&#x2F;bin&#x2F;目录，但是我想自定义安装到&#x2F;data&#x2F;software&#x2F;#解压tar -zxf redis-7.0.2.tar.gz -C &#x2F;data&#x2F;software&#x2F;#编译make#安装make install PREFIX&#x3D;&#x2F;data&#x2F;software&#x2F; 添加环境变量12345vi ~.&#x2F;bashrcREDIS_HOME&#x3D;&#x2F;data&#x2F;software&#x2F;PATH&#x3D;$PATH:$REDIS_HOME&#x2F;bin#配置生效source ~&#x2F;.bash_profile 启动和停止1234#实际是去找&#x2F;data&#x2F;software&#x2F;redis-7.0.2&#x2F;bin的这个启动语句,并使用redis配置文件redis-server &#x2F;data&#x2F;software&#x2F;redis-7.0.2&#x2F;redis.conf#&#x2F;data&#x2F;software&#x2F;redis-7.0.2&#x2F;bin的这个预计进行停止redis-cli shutdown redis.conf文件说明123456789#设置后台启动，如果不是后台启动，每次推出redis就关闭了daemonize yes#开启密码保护，注释则不需要密码requirepass 密码#设置端口号port 端口号#允许访问的ip，改为0.0.0.0就是所有ip均可bind 127.0.0.1 -::1bind 0.0.0.0","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"}]},{"title":"LLM（2）-Instruct GPT","slug":"LLM/02_instruct_gpt","date":"2023-06-21T01:38:32.000Z","updated":"2023-08-10T12:22:57.896Z","comments":true,"path":"LLM/02_instruct_gpt/","link":"","permalink":"https://tlylft.github.io/LLM/02_instruct_gpt/","excerpt":"","text":"Training language models to follow instructions with human feedback 1.基于GPT-3作为底层模型进行微调 SFT 人类反馈 RM 优化参数 PPO 大模型的问题instruct的意义实现方式：1.基于GPT-3作为底层模型进行微调 SFT 人类反馈 RM 优化参数 PPO 效果展示说明PPO1.3B比SFT175B效果还要好 数据集模型RM loss将奖励的差异作为交叉熵损失函数，使模型更能学习到好和坏的差异。且尽量最大化差异，如选择评分8.5和4分的模型进行学习，而不是8.5和8分的数据（容易引起模型混淆） RL-PPO 最大化收益 KL散度 限制新学习的πRL强化策略 和初始的模型生成策略πSFT之间的差距不要太大， 偏置项","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"LLM（5）-LLaMA","slug":"LLM/05_LLaMA","date":"2023-05-31T09:11:11.000Z","updated":"2023-08-10T09:30:14.851Z","comments":true,"path":"LLM/05_LLaMA/","link":"","permalink":"https://tlylft.github.io/LLM/05_LLaMA/","excerpt":"","text":"LLaMA发展详解：https://agi-sphere.com/llama-models/Paper: LLaMA: Open and Efficient Foundation Language Modelsmeta AI blog: https://ai.facebook.com/blog/large-language-model-llama-meta-ai/ 1. LLaMA目标LLaMA 的目标是为有限的推理预算构建性能最佳的模型，例如，可以使用小于 10GB 的 VRAM 在 NVIDIA 3090 上运行。 2. LLaMA变体发展development:| Model | Size | Training data ||——————————-|——————-|————-|| LLaMA (base model) | 7B, 13B, 33B, 65B | Various || Alpaca | 7B, 13B | 52k GPT-3 instructions || Vicuna | 7B, 13B | 70k ChatGPT conversations || Koala-distill | 7B, 13B | 117k cleaned ChatGPT conversations || GPT4-x-Alpaca | 13B | 20k GPT4 instructions || WizardML | 7B | 70k instructions synthesized with ChatGPT/GPT-3|| OpenAssistant LLaMA | 13B, 30B | 600k human interactions (OpenAssistant Conversations) | 3. LLaMA模型架构LLaMA是一种类似于GPT的transformer模型，优化以下结构： Normalize the input of each transformer sub-layer to improve training stability.对每个transformer子层的输入进行Normalize，以提高训练稳定性。 Use SwiGLU instead of ReLU to improve performance.使用 SwiGLU 而不是 ReLU 来提高性能。 Use rotary embedding instead of absolute positioning to improve performance.使用rotary embedding而不是absolute positioning来提高性能。 Parameters Layers Attention heads Embedding dimension 7B 6.7B 32 32 4,096 13B 13B 40 40 5,120 33B 33B 60 52 6,656 65B 65B 80 64 8,192 训练数据1.4T token:主要包括: 维基百科、github, 科学数据，科学和工程的高质量问答，CommonCrawl清洗后的数据。分词器使用SentencePiece进行字节对编码。detail: English CommonCrawl (67%): Removed non-English text and duplicated content. Only includes pages used as references in Wikipedia. C4 (15%): A cleaned version of CommonCrawl. The same filters were applied. Github (4.5%): Public GitHub dataset available on Google BigQuery. Wikipedia (4.5%): From June-August 2022 period covering 20 languages. Gutenberg and Books3 (4.5%): Both are book datasets. ArXiv (45%): Scientific data. StackExchange (2%): High-quality Q&amp;As covering science and engineering topics.","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"xgboost回归预测","slug":"machine_learning/time_series/xgboost_regression","date":"2023-05-26T12:53:14.000Z","updated":"2023-06-26T08:44:13.121Z","comments":true,"path":"machine_learning/time_series/xgboost_regression/","link":"","permalink":"https://tlylft.github.io/machine_learning/time_series/xgboost_regression/","excerpt":"","text":"api文档： https://xgboost.readthedocs.io/en/stable/python/index.html 原理解释：https://baijiahao.baidu.com/s?id=1665813533927052719&amp;wfr=spider&amp;for=pc说清楚的原理：https://www.cnblogs.com/mantch/p/11164221.htmlhttps://github.com/NLP-LOVE/ML-NLP/blob/master/Machine%20Learning/3.3%20XGBoost/3.3%20XGBoost.md 1. introXGBoost是陈天奇等人开发的一个开源机器学习项目，高效地实现了GBDT算法并进行了算法和工程上的许多改进，被广泛应用在Kaggle竞赛及其他许多机器学习竞赛中并取得了不错的成绩。XgBoost是梯度提升树GBDT（Gradient Boosting Decision Tree）算法的一种变体，能够更快的、更高效率的训练模型。它将多个决策树集成在一起，以提高预测准确性。XgBoost在气量预测中的应用比较广泛，主要是因为它能够处理大规模、高维度的数据集，并且能够在较短时间内生成高质量的预测模型。例如，在天然气供应链中，XgBoost可以被用于预测气量需求，提前做好供应准备。 1.1. regression tree 1.2. XGBoost与GBDT有什么不同除了算法上与传统的GBDT有一些不同外，XGBoost还在工程实现上做了大量的优化。总的来说，两者之间的区别和联系可以总结成以下几个方面。 GBDT是机器学习算法，XGBoost是该算法的工程实现。在使用CART作为基分类器时，XGBoost显式地加入了正则项来控制模 型的复杂度，有利于防止过拟合，从而提高模型的泛化能力。GBDT在模型训练时只使用了代价函数的一阶导数信息，XGBoost对代 价函数进行二阶泰勒展开，可以同时使用一阶和二阶导数。传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类 器，比如线性分类器。传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机 森林相似的策略，支持对数据进行采样。传统的GBDT没有设计对缺失值进行处理，XGBoost能够自动学习出缺 失值的处理策略。 1.3. 为什么XGBoost要用泰勒展开，优势在哪里？XGBoost使用了一阶和二阶偏导, 二阶导数有利于梯度下降的更快更准. 使用泰勒展开取得函数做自变量的二阶导数形式, 可以在不选定损失函数具体形式的情况下, 仅仅依靠输入数据的值就可以进行叶子分裂优化计算, 本质上也就把损失函数的选取和模型算法优化/参数选择分开了. 这种去耦合增加了XGBoost的适用性, 使得它按需选取损失函数, 可以用于分类, 也可以用于回归。 线性树结构的劣势2. model 添加树，不断地进行特征分裂来生长一棵树，每次添加一个树，其实是学习一个新函数f(x)，去拟合上次预测的残差。 训练完成得到k棵树，我们要预测一个样本的分数，其实就是根据这个样本的特征，在每棵树中会落到对应的一个叶子节点，每个叶子节点就对应一个分数 需要将每棵树对应的分数加起来就是该样本的预测值。 2.1. 举例：预测不同人游戏的喜好程度，考虑到年轻和年老相比，年轻更可能喜欢电子游戏，以及男性和女性相比，男性更喜欢电子游戏，故先根据年龄大小区分小孩和大人，然后再通过性别区分开是男是女，逐一给各人在电子游戏喜好程度上打分，如下图所示。就这样，训练出了2棵树tree1和tree2，类似之前gbdt的原理，两棵树的结论累加起来便是最终的结论，所以小孩的预测分数就是两棵树中小孩所落到的结点的分数相加：2 + 0.9 = 2.9。爷爷的预测分数同理：-1 + （-0.9）= -1.9。具体如下图所示：这跟上文介绍的GBDT乃异曲同工，事实上，如果不考虑工程实现、解决问题上的一些差异，XGBoost与GBDT比较大的不同就是目标函数的定义。XGBoost的目标函数如下图所示： 3. Multiple Outputs并行多模型运算分类：https://xgboost.readthedocs.io/en/stable/tutorials/multioutput.html回归：https://xgboost.readthedocs.io/en/stable/python/examples/multioutput_regression.html#sphx-glr-python-examples-multioutput-regression-py","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"},{"name":"time series","slug":"machine-learning/time-series","permalink":"https://tlylft.github.io/categories/machine-learning/time-series/"}],"tags":[{"name":"time series","slug":"time-series","permalink":"https://tlylft.github.io/tags/time-series/"}]},{"title":"Neural Prophet","slug":"machine_learning/time_series/nerualprophet","date":"2023-05-26T12:39:59.000Z","updated":"2023-06-26T08:35:15.993Z","comments":true,"path":"machine_learning/time_series/nerualprophet/","link":"","permalink":"https://tlylft.github.io/machine_learning/time_series/nerualprophet/","excerpt":"","text":"github: https://github.com/ourownstory/neural_prophet官方教程：https://neuralprophet.com/tutorials/tutorial01.html introNeuralProphet是Facebook Research开发的一种新型时间序列预测模型，它是Prophet的升级版。它建立在PyTorch之上，并受到Facebook Prophet和AR-Net库的极大启发。NeuralProphet将Prophet里的模型结构改成了神经网络的形式，从而提高了模型的有效性和灵活性。相比于Prophet，NeuralProphet更能适应非线性的时间序列问题，比如气量预测中存在的带噪声的时间序列。它可以根据数据自动优化模型参数，提升预测的准确性。 Neural Prophet vs. prophet功能改进：1） 一次可以预测未来多步2） 模型结构改成了神经网络的形式，提高了模型的有效性和灵活性3） 加入历史时间t预测值的自回归效应（如：参考历史多日的气量）4） 加入历史时间t外生变量的回归效应（如：参考历史多日的温度）5） 加入未来时间t外生变量的回归效应（如：预测多日的温度） 根据NeuralProphet的文档，增加的技术点： 使用PyTorch的Gradient Descent进行优化，使建模过程比Prophet快得多 使用AR-Net建模时间序列自相关（也称为序列相关） 自定义损失和指标 具有前馈神经网络的可配置非线性层 区别： 不支持再训练，可以直接传入历史数据和未来特征进行预测。原理 原理参考：1.In-Depth Understanding of NeuralProphet through a Complete Example2.时间序列论文: NeuralProphet: Explainable Forecasting at Scale3.NeuralProphet模型概述:详细公式 yˆt = T(t) + S(t) + E(t) + F(t) + A(t) + L(t)T(t) = 时间 t 的趋势S(t) = 时间 t 的季节性影响E(t) = 时间 t 的事件和假日效应F(t) = 未来已知外生变量在时间 t 的回归效应A(t) = 基于过去观察的时间 t 的自回归效应L(t) = t 时刻外生变量滞后观测的回归效应详细公式参考3中链接 预测梳理 数据准备ds y event1 event2 regression_1 future_regresssion_1","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"},{"name":"time series","slug":"machine-learning/time-series","permalink":"https://tlylft.github.io/categories/machine-learning/time-series/"}],"tags":[{"name":"time series","slug":"time-series","permalink":"https://tlylft.github.io/tags/time-series/"}]},{"title":"LLM（1）-大语言模型简介","slug":"LLM/01_intro","date":"2023-05-16T00:52:19.000Z","updated":"2023-08-10T13:49:32.556Z","comments":true,"path":"LLM/01_intro/","link":"","permalink":"https://tlylft.github.io/LLM/01_intro/","excerpt":"","text":"大模型选型的一点思考ChatGPT技术原理解析：从RL之PPO算法、RLHF到GPT4、instructGPT 1. LLM大语言模型（LLM）是指使用大量文本数据训练的深度学习模型，可以生成自然语言文本或理解语言文本的含义。大语言模型可以处理多种自然语言任务，如文本分类、问答、对话等，是通向人工智能的一条重要途径。 现在是2023年5月，截止目前，网络上已经开源了众多的LLM，如何用较低的成本，判断LLM的基础性能，选到适合自己任务的LLM，成为一个关键。 2. 模型发展历史 时间 公司 模型 描述 2017 微积分、概率统计、最优化、策略梯度、TRPO算法(2015年提出) 2017年6月 OpenAI联合DeepMind RLHF Deep Reinforcement Learning from Human Preferences，即基于人类偏好的深度强化学习 2017年6月 Transformer self-attention 2017年7月 OpenAI PPO算法 TRPO算法的改进 2018 Google BERT 2018.07 OpenAI GPT(Generative Pre-trained Transformer) 基于Transformer-Decoder的Masked Self-Attention 2019.02 OpenAI GPT2 融合prompt learning的GPT2，prompt learning的意义在于不用微调也能做任务 2019年10月 Google T5(transfer text to text transformer) 基于transformer的encoder-decoder架构，区别于BERT的编码器架构与GPT的解码器架构 2020年05月 OpenAI GPT3.0 参数规模到了1750亿，终于真正做到预训练之后不用再微调模式，通过In-context learning(简称ICL)开启prompt新范式 2021年7月 OpenAI Codex 通过对GPT3进行大量的代码训练迭代而出Codex，从而具备代码/推理能力 159G的python代码微调 2021年9月 Google FLAN 基于指令微调技术Instruction Fine-Tuning (IFT)的大模型 2021年第四季度 OpenAI GPT3.5 更大的数据量+context learning，用2021年之前的数据进行的训练 2022年1月 Google CoT 研究者提出的思维链技术(Chain of Thought，简称CoT) ，模仿推理能力 2022年3月 OpenAI instructGPT GPT3 + instruction tuning + RLHF + PPO 2022年11月 OpenAI- ChatGPT 语言模型层面的核心架构是GPT3.5(基于Transformer-Decoder的Masked Self-Attention且融合了Codex的代码/推理能力、instruction tuning等技术) + RLHF + PPO3 2022年1月 Google LaMDA 发布LaMDA论文『 LaMDA: Language Models for Dialog Applications』 2022年4月 Google PaLM 提出PaLM: Scaling Language Modeling with Pathways，5400亿参数 2022年10月 Google Flan-T5 提出Flan-T5 23年3月6日 Google PaLM-E 提出多模态LLM模型 2023.02.24 Facebook Meta llama 基础模型 2023.03.15 OpenAI GPT4.0 增加了多模态(支持图片的输入形式) 2023.03.16 百度 文心一言 2023.03.17 微软 Microsoft 365 Copilot 集成GPT4的能力，实现自动化办公 2023.03.22 Google Bard 2023.03.23 Github Copilot X 2023.03.24 OpenAI - 插件功能，赋予chatgpt使用工具、联网、运算的能力 2.1. GPT3：In-context learning正式开启prompt新范式(小样本学习) GPT3在0样本、单样本、小样本下的突出能力GPT3简单来说，就是参数规模大(有钱)、训练数据规模大(多金)、效果出奇好，具体而言为形象描述，举一个GPT3在0样本、单样本、少量样本下的机器翻译使用范例，如下图 2.2. Prompt技术的升级与创新：指令微调技术(IFT)与思维链技术(CoT)OpenAI的GPT3虽然不再微调模型(pre-training + prompt)，但Google依然坚持预训练 + 微调的模式Google提出FLAN大模型：基于指令微调技术Instruction Fine-Tuning (IFT)基于思维链(Chain-of-thought)技术下的prompt 因此导致后续OpenAI的chatgpt不得不关注再次关注微调技术，也转向指令微调 3. 开源模型 截止至2023/06/08 https://huaweidevelopers.csdn.net/64c1290ebfca273ff3548e81.html time model github owner language desc LLaMA 代码 meta 英 在模型参数量降低的同时，增加训练的数据量，这样可以保证模型的效果。LLaMA完全是在公共开源预训练数据上训练。并且取得相当不错的效果，LaMA-13B在绝大部分的benchmarks上超越了GPT-3(175 B)，并且LLaMA-65B的效果能够和最好的大模型，Chinchilla-70B以及PaLM-540B相比。 [Chinchilla] xxx xxx xxx chatGLM-6B 代码 清华 中英 ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。 ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。 Alpaca 代码 斯坦福 英 一个遵循指令的LLaMA模型 PandaLLM 代码 xxx 中英 海外中文开源大语言模型：Panda 系列语言模型目前基于 Llama-7B, -13B, -33B, -65B 进行中文领域上的持续预训练, 使用了接近 15M 条数据, 并针对推理能力在中文 benchmark 上进行了评测, 希望能够为中文自然语言处理领域提供具有泛用性的通用基础工具. [GPT4ALL] 代码 xxx xxx 可在cpu上运行的开源LLM DoctorGLM (MedicalGPT-zh v2) 代码 huggingface xxx 中英医疗 基于 ChatGLM-6B的中文问诊模型 MedicalGPT-zh v1 代码 xxx 中英医疗 基于ChatGLM-6B LoRA 16-bit指令微调的中文医疗通用模型。基于共计28科室的中文医疗共识与临床指南文本，我们生成医疗知识覆盖面更全，回答内容更加精准的高质量指令数据集。以此提高模型在医疗领域的知识与对话能力。 [Cornucopia-LLaMA-Fin-Chinese] 代码 xxx 中文金融 基于中文金融知识的LLaMA微调模型：经过中文金融知识指令精调/指令微调(Instruct-tuning) 的LLaMA-7B模型。通过中文金融公开数据+爬取的金融数据构建指令数据集，并在此基础上对LLaMA进行了指令微调，提高了 LLaMA 在金融领域的问答效果。 [minGPT] 代码 xxx xxx xxx [InstructGLM] 代码 xxx 中英指令 基于ChatGLM-6B+LoRA在指令数据集上进行微调。 [FastChat] 代码 xxx xxx xxx [Luotuo-Chinese-LLM] 代码 商汤&amp;华中师范 中文 开源中文大语言模型 [CamelBell-Chinese-LoRA] 代码 商汤&amp;华中师范 中文 开源中文大语言模型 [alpaca-lora] 代码 xxx xxx xxx 2023.06 chatGLM2 代码 huggingface 清华 中英 1.基座模型升级，性能更强大 2. 支持8K-32k的上下文 3. 推理性能提升了42% baichuan 代码 xxx xxx xxx LLama-2 代码 xxx xxx xxx 代码 xxx xxx xxx 代码 xxx xxx xxx 4. 多模态4.1. LLaVA4.2. MiniGPT-44.3. KOSMOS-1 微软《Language Is Not All You Need: Aligning Perception with Language Models》论文地址：https://arxiv.org/pdf/2302.14045.pdf 项目地址：https://github.com/microsoft/unilmhttps://www.thepaper.cn/newsDetail_forward_22122932?commTag=true 4.4. X-LLM 中文多模态大模型简介：中文多模态大模型力作，中科院发布多模态 ChatGPT，图片、语言、视频都可以 Chat来源：中科院 X-LLMPaper: X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages主页：https://x-llm.github.io/思路： 假设“GPT-4 的多模态能力来源于其更先进，更大的语音模型，即 GPT-4 是用语言的形式表达出了其他模态的内容” 这个假设也就是讲，需要将多模态的数据“对齐”到语言数据之中，然后再投入大模型以获得多模态能力， 在这个假设的基础上，作者提出了 X2L 接口，其中 X 意味着多模态数据，而 L 则表示语言，X2L 接口即将多个单模态编码器与一个大规模语言模型（LLM）进行对齐。其中，图像接口 I2L 采用 BLIP-2 中的 Q-Former，视频接口 V2L 复用图像接口的参数，但是考虑了编码后的视频特征，语言接口 S2L 采用 CIF 与 Transformer 结构将语音转换为语言。整个 X-LLM 的训练包含三个阶段，分别是（1）转换多模态信息；（2）将 X2L 对齐到 LLM；（3）将多模态数据整合到 LLM 中。 5. 主流模型参数性能对比1B = 10亿 model Parameters Layers Attention heads Embedding dimension gpu train data transformer - - 8 8*64=512 - GPT-1 1.17亿 - - - - GPT-2 1.5B - - - - GPT-3 175B 96 96 96*128=12888 - 45T LLaMA 7B 6.7B 32 32 4,096 - LLaMA 13B 13B 40 40 5,120 1 V100 LLaMA 33B 33B 60 52 6,656 LLaMA 65B 65B 80 64 8,192 chatgpt 可能175B - - - 5个80GB的A100加载 baidu文心 2600亿 - - - - GPT-4 100000B - - - - KOSMOS-1（微软多模态） 1.6B - - - - 6. 影响LLM性能的主要因素openAI 论文：Scaling Laws for Neural Language ModelsOpenAI的论文Scaling Laws中列举了影响模型性能最大的三个因素：计算量、数据集大小、模型参数量。也就是说，当其他因素不成为瓶颈时，计算量、数据集大小、模型参数量这3个因素中的单个因素指数增加时，loss会线性的下降。同时，DeepMind的研究也得出来和OpenAI类似的结论。那么我们可以基本确定，如果一个模型在这3个方面，均做的不错，那么将会是一个很好的备选。模型参数量是我们最容易注意到的，一般而言，LLM也只在训练数据上训练1个epoch（如果还有算力，其实可以扩更多的新数据），那么，数据集的大小就是很关键的参数。训练OPT-175B的Susan Zhang在Stanford分享的时候，也提到了，如果能够重新再来一次，她会选择much much more data。可见数据量的重要性。 了解到Scaling Laws之后，为了降低模型的推理成本，可以在模型参数量降低的同时，增加训练的数据量，这样可以保证模型的效果。Chinchilla和LLaMA就是这样的思路。 除了以上的因素之外，还有一个比较大的影响因素就是数据质量。 7. 一些概念7.1. 预训练和微调的区别直观体现在数据集体量， 很大规模的训练集训练出的模型可称为预训练模型。预训练： 首先在一个大规模的数据集上训练一个深度学习模型，例如使用自监督学习或者无监督学习算法进行预训练；微调： 使用目标任务的训练集对预训练模型进行微调。通常，只有预训练模型中的一部分层被微调，例如只微调模型的最后几层或者某些中间层。在微调过程中，通过反向传播算法对模型进行优化，使得模型在目标任务上表现更好；也可进行参数全量微调。评估： 使用目标任务的测试集对微调后的模型进行评估，得到模型在目标任务上的性能指标。 7.2. instruct和promot的区别指令微调是什么","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"LLM（3）- chatgpt","slug":"LLM/03_chatgpt","date":"2023-05-16T00:52:19.000Z","updated":"2023-08-10T09:30:33.201Z","comments":true,"path":"LLM/03_chatgpt/","link":"","permalink":"https://tlylft.github.io/LLM/03_chatgpt/","excerpt":"","text":"https://github.com/shizhediao/ChatGPTPapersCSDN Blogs：https://blog.csdn.net/ganxiwu9686Zhihu Column: https://zhuanlan.zhihu.com/p/58108759 类chatgpt模型openAI: gpt3.0openAI: gpt3.5 更大的数据量+context learning， 用2021年之前的数据进行的训练复旦：Moss 2023.03.15 google AI2023.03.15 openAI gpt4.02023.03.16 百度 文心一言2023.03.16 微软 Copilot2023.03.22 google bardd2023.03.22 github Copilot X2023.03.23 openAI 插件功能，赋予chatgpt使用工具、联网、运算的能力 chatGPT基本概念chat Generative Pre-trained Transformer 动机 之前的大规模模型(bert,bass)在输出方面和人类真实想要的结果往往无法很好对齐。 ChatGPT的一个主要训练方法是在GPT3的基础之上，通过人类提供反馈的强化学习(Reinforcement Learning from Human Feedback（RLHF）)，来让模型的输出逼近人类的意图。需要人工标注问答对的评分。 更加聚焦在人类的意图 他在很多任务上的表现效果都很好，同时他也会去拒绝用户提出的一些不合理，不合宜的请求。能够通过交互式的方式来逼近真实想要的结果。可以进一步对我们领域做一些数据增强的工作发展路线instructGPT(基于提示学习的一系列模型)：通过设定prompt的模板，让模型输出模板的结果，而不需要进行参数的再学习，但要求设计出一套合理适用的模板，模板设计不好对输出结果有很大的影响，主要研究如何构造更好的模板让大模型进行理解。如： “这个电影剧情紧凑，非常感人” -&gt; 情感正向。 之前通过做意图训练和学习，但是prompt是让预训练模型输出完型填空：“这个电影剧情紧凑，非常感人，以上评述是说这是一个__电影” —&gt; 好GPT3.5(大规模预训练语言模型)，参数量超1750亿。高校、小公司做不起来。成本太高。结合prompt learning去做。ChatGPT模型(高质量数据标注和反馈学习)， 专注于1. 如何用高质量数据对大规模模型进行微调 2. 如何结合人类反馈用强化学习逼近人类意图。ChatGPT模型高质量数据标注以及反馈学习技术手段引入“人工标注数据+强化学习” gpt用自回归的方式（transformer decoder）生成，侧重于做生成任务，bert用自编码的方式（transformer encoder）生成,侧重于做理解性任务step1： 收集高质量的数据，有监督微调语言模型为了让GPT 3.5初步具备理解指令中蕴含的意图，首先会从测试用户提交的prompt(就是指令或问题)中随机抽取一批，靠专业的标注人员，给出指定prompt的高质量答案，然后用这些人工标注好的数据来Fine-tune GPT 3.5模型 step2: 训练回报模型（Reward Model,RM） 随机抽样一批用户提交的prompt(大部分和第一阶段的相同)，使用第一阶段Fine-tune好的冷启动模型，对于每个prompt，由冷启动模型生成K个不同的回答，于是模型产生出了,….数据 标注人员对K个结果按照很多标准（上面提到的相关性、富含信息性、有害信息等诸多标准）综合考虑进行排序打分 step3: 利用上一阶段学好的RM模型，靠RM打分结果来更新预训练模型参数 从用户提交的prompt里随机采样一批新的命令（指的是和第一第二阶段不同的新的prompt，相当于测试数据） 再使用PPO算法微调模型的参数 重复step2 和 step 3，反复迭代 在一轮session对话中，会倾向于取悦用户的意图，如果反复强调1+1=3，模型会逐步接受，同意1+1=3，但释放对话后重新发起，它仍会返回1+1=2？ 为什么 存在的问题和可能的原因（局限性）缺点以下的内容主要是来自于推特的一些失败案例，大致可以分成9类+Other 推理 Reasoning： 空间推理（相对位置，导航等）物理推理和时间推理（时间发生先后顺序，事件持续时间）和心理推理（关于人物的行为或者心里要素）存在问题 逻辑 Logic: 偏向于需要三段论、演绎、归纳，逐渐得到结论的过程 Math and Arithmetic：大数相乘，求根，计算能力(尤其是分数)，以及无理数的加减法存在问题 Factual Errors：有些简单的通过搜索引擎很容易找到答案，但是他会回答错误，数据基于2021年之前有关，而且基于概率计算，极大可能在编造事实。 Bias and Discrimination：种族偏见 Wit and Humor：没有幽默特性，但可以生成幽默的句子 Coding：可以提供一些功能性代码，但不能解决复杂的编程、以及复杂代码的debug Syntactic Structure, Spelling, and Grammar：大部分可以解决，以字符为级别的往往回答错误，缺少字符集语义表示 Self Awareness：伦理问题，无自我意识 可能的原因 缺乏世界模型——像ChatGPT这样的模型没有“世界模型”，因为它们对物理和社会世界没有全面的理解，也没有能力推理不同概念和实体之间的关系。他们只能根据从训练数据中学习到的模式生成文本。 缺乏检索模型——像ChatGPT这样的模型不具备从外部存储器或数据库检索信息的能力。这意味着他们可能无法准确回忆事实。（对一些历史事件回答错误）目前和Biying的结合已经能做了。但是下架了说明还有一些问题。 缺少字符级嵌入——许多像ChatGPT这样的模型都没有使用字符级嵌入进行训练。这可能会导致词汇表外的单词和拼写错误，以及对单词中不同字符之间的关系缺乏理解。（使用的词向量表示） 生成一些取悦人类的话术，无法评判生成数据的准确性意义chatgpt的成功，证明了大模型技术路线的正确性。意味着AI从之前大数据统计分类的阶段，走向类人逻辑沟通极端。应用场景文本分类/情感分析序列标注：POS， 命名实体识别， 语义标注句子关系判断：Entailment/QA/自然语言推理生成式任务(机器翻译/文本摘要/ 智能问答）其他应用：修复代码，写规划规模训练数据：45TB使用 https://openai.com/gpt-3.5-turbo模型 1000token(请求和返回) 0.0002美元 new bing输入：2000字符指令：简洁明了，明确目的 区分gpt3.5和4.0问：鲁迅为什么暴打周树人？3.5：#@￥I#$(#的理由4.0：鲁迅和周树人是一个人问：树上9只鸟，打掉一只，还剩几只？3.5:8只4.0: 0只，其他被吓跑了 微调微调： 1w句子左右 未来展望","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"LLM（6）-BARD","slug":"LLM/06_bard","date":"2023-05-16T00:52:19.000Z","updated":"2023-08-10T12:24:19.042Z","comments":true,"path":"LLM/06_bard/","link":"","permalink":"https://tlylft.github.io/LLM/06_bard/","excerpt":"","text":"bard.google.com 优点： 联网，时效性强，依靠强大的Google搜索引擎，bard能够搜索到实时的信息，例如今天的新闻、今天的比赛比分等 谷歌希望将Bard打造成谷歌全家桶的入口，因此可以方便地通过Bard和谷歌搜索、谷歌地图、gmail邮件等谷歌全家桶联动使用，提高各个工具的使用效率。 响应速度惊艳，而且同时可以提供三个答案以供选择，还有导出结果等功能，使用更加方便快捷 缺点： 目前还不支持中文提问，只支持英语、日文、韩文，但谷歌表示会在之后的版本中支持中文。","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"LLM（7）-大模型微调技术","slug":"LLM/07_finetuning","date":"2023-05-16T00:52:19.000Z","updated":"2023-08-11T09:25:04.929Z","comments":true,"path":"LLM/07_finetuning/","link":"","permalink":"https://tlylft.github.io/LLM/07_finetuning/","excerpt":"","text":"参考文献：ChatGPT微调技术框架-完美Clone ChatGPT背后的技术 根据instructGPT论文和ChatGPT的技术报告，背后的微调技术逐步挖掘出来，大致分为：SFT；ReWard模型训练；RLHF（PPO）三个阶段。思考：是否可以在第一阶段之前，补充一个PT预训练微调。 1. 可微调阶段 1.1. stage1: SFTSFT（supervised-fintuning），使用instruction datasets数据进行监督微调 1.2. stage2: Reward Model训练奖励模型，它通过对于同一个 prompt 的不同输出进行人工排序，得到对应分数，监督训练奖励模型。 1.3. stage3: RLHF(Reinforcement Learning from Human Feedback)这个部分是Openai， ChatGPT和GPT4作为核心的部分,该训练流程基于PPO（Proximal Policy Optimization，近端策略优化）算法来进行优化。RLHF也是目前为止常用的、最为复杂的基于强化学习的大语言模型微调方法。 2. 微调框架和流程2.1. 模型选择根据业务场景和算例条件，选择合适的底座参数模型 微调和高效微调微调， Fine-Tuning，一般指全参数的微调 (全量微调)，指是一类较早诞生的微调方法，全参数微调需要消耗大量的算力，实际使用起来并不方便，因此不久之后又诞生了只围绕部分参数进行微调的高效微调方法;不能适用于大模型敏捷开发。高效微调，State-of-the-art Parameter-Efficient Fine-Tuning (SOTA PEFT)，特指部分参数的微调方法，这种方法算力功耗比更高，也是目前最为常见的微调方法;除此之外，Fine-Tuning也可以代指全部微调方法，同时OpenAl中模型微调API的名称也是Fine-Tuning，实际也是PEFT 2.2. pipeline训练 ColossalAI初步打造全流程雏形根据底层技术优化很好的把三个阶段训练进行了串联，实现微调的高效性。体验基于Meta LLAM 7B 微调后模型效果，中文的效果不行（可能是meta llama底座对中文不是非常友好，单纯微调中文英文的可以基于GLM模型来微调）注： 一些介绍：0门槛克隆ChatGPT方案再升级，开源模型完整复现 似乎只是基于LLaMA DeepSpeed Chat 一些介绍：DeepSpeed-Chat：最强ChatGPT训练框架，一键完成RLHF训练 似乎只是gpt-2这种，但github上有chatglm相关的 目前整个开源社区还没有其他能够在一个框架上面训练如上的三个阶段的流程化训练，大家都是分阶段独立训练 2.2.1. stage1: SFTSFT（supervised-fintuning），使用instruction datasets数据进行监督微调数据集：instruct:xxxoutput: xxxx微调方式： 全量微调 Freeze lora P-Tuning Prefix Tuning PromptTuning AdaLora 开源框架：peft: 支持多个模型，如：GPT-2，LLaMA, ChatGLMChatGLM-Finetuning: 支持chatGLM 2.2.2. stage2: Reward Model &amp; stage 3: RLHF数据集：微调方式： 开源框架：TRL: 支持Reward模型训练和PPO优化过程DeepSpeed Chat： 微软开源提供的最好的RLHF流程 3. SFT微调方法参考文章： 人工智能大语言模型微调技术：SFT、LoRA、Freeze 监督微调方法随着技术的发展，涌现出越来越多的大语言模型，且模型参数越来越多，比如 GPT3 已经达到 1750 亿的参数量，传统的监督微调方法已经不再能适用现阶段的大语言模型。为了解决微调参数量太多的问题，同时也要保证微调效果，急需研发出参数高效的微调方法（Parameter Efficient Fine Tuning, PEFT） 3.1. LoRA一句话： 冻结预训练参数，微调新增层结构，大大减少训练参数量。LoRA（Low-Rank Adaptation of Large Language Models），直译为大语言模型的低阶自适应。背景：随着大语言模型的发展，模型的参数量越来越大，比如 GPT-3 参数量已经高达 1750 亿，因此，微调所有模型参数变得不可行。LoRA 微调方法由微软提出，通过只微调新增参数的方式，大大减少了下游任务的可训练参数数量。原理简述：基于大模型的内在低秩特性，增加旁路矩阵来模拟全参数微调;LoRA 的基本原理是冻结预训练好的模型权重参数，在冻结原模型参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。由于这些新增参数数量较少，这样不仅 finetune 的成本显著下降，还能获得和全模型参数参与微调类似的效果。在大语言模型微调的过程中，LoRA 冻结了预先训练好的模型权重，并将可训练的秩的分解矩阵注入到 Transformer 体系结构的每一层。例如，对于预训练的权重矩阵W0，可以让其更新受到用低秩分解表示后者的约束：优势： 预训练模型参数可以被共享，用于为不同的任务构建许多小的 LoRA 模块。冻结共享模型，并通过替换矩阵 A 和 B 可以有效地切换任务，从而显著降低存储需求和多个任务切换的成本。当使用自适应优化器时，由于不需要计算梯度以及保存太多模型参数，LoRA 使得微调效果更好，并将微调的硬件门槛降低了 3 倍。 低秩分解采用线性设计的方式使得在部署时能够将可训练的参数矩阵与冻结的参数矩阵合并，与完全微调的方法相比，不引入推理延迟。 LoRA 与其它多种微调方法不冲突，可以与其它微调方法相结合，比如将要介绍的前缀调优方法等。 在图像生成任务中diffusion model进行微调，表现惊艳。3.2. Prefix-tuningPrefix-tuning（ Optimizing Continuous Prompts for Generation）基于提示词前缀优化的微调方法。由斯坦福大学提出。原理简述：在原始模型基础上，增加一个可被训练的Embedding层，用于给提示词增加前缀，从而让模型更好的理解提示词意图并在训练过程中不断优化这些参数。在模型中加入 prefix，即连续的特定任务向量，微调时只优化这一小段参数。优势：既能够在模型结构上增加一些新的灵活性，又能够在模型使用上提供一种自动的、能够改进模型表现的天天机创3.3. P-tuning/Prompt tuning v1P-tuning v1 微调方法由谷歌提出的轻量级优化方法原理简述：无需调整模型参数，在已有参数中，选择一部分参数作为可学习参数，用于创建每个Prompt的前缀，从而帮助模型更好地理解和处理特定的任务。不同于Prefix方法，Prompt Tuning训练得到的前缀是具备可解释性的我们可以通过查看这些前缀，来查看模型是如何帮我们优化prompt的。类似于自动化提示工程的工具。将Prompt 加入到微调过程中，只对 Prompt 部分的参数进行训练，而语言模型的参数固定不变。 优势：该方法在参数规模非常大的模型微调时效果很好，当参数规模达100亿时和全量微调效果一致;不足：P-tuning v1 微调方法缺少普遍性。实验表明，对于那些较小的模型，P-tuning v1 方法和全参数微调方法的表现有很大差异，效果很差。同时，P-tuning v1 缺少跨任务的通用性，在序列标注任务中的有效性没有得到验证。序列标注需要预测一连串的标签，而且大都是无实际意义的标签，对于 P-tuning v1 微调方法极具挑战。此外，当模型层数很深时，微调时模型的稳定性难以保证。模型层数越深，第一层输入的 prompt 对后面的影响难以预估。 3.4. P-tuning v2P-tuning v2 微调方法是 P-tuning v1 微调方法的改进版，同时借鉴了 prefix-tuning 微调的方法。与 P-tuning v1 微调方法相比，P-tuning v2 微调方法采用了 prefix-tuning 的做法，在输入前面的每一层都加入可微调的参数。在 prefix 部分，每一层的 transformer 的 embedding 输入都需要被微调，而 P-tuning v1 只在第一层进行微调。同时，对于 prefix 部分，每一层 transformer 的输入不是从上一层输出，而是随机初始化的 embedding 作为输入。 此外，P-Tuning v2 还包括以下改进： 移除 Reparamerization 加速训练方式；采用多任务学习优化：基于多任务数据集的 Prompt 进行预训练，然后再适配的下游任务。舍弃词汇 Mapping 的 Verbalizer 的使用，重新利用 [CLS] 和字符标签，跟传统微调方法一样利用 cls 或者 token 的输出做自然语言理解，以增强通用性，可以适配到序列标注任务。优点： P-tuning v2 微调方法解决了 P-tuning v1 方法的缺陷，是一种参数高效的大语言模型微调方法。 P-tuning v2 微调方法仅精调 0.1% 参数量（固定 LM 参数），在各个参数规模语言模型上，均取得和 - Fine-tuning 相比肩的性能，解决了 P-tuning v1 在参数量不够多的模型中微调效果很差的问题。如下图所示（横坐标表示模型参数量，纵坐标表示微调效果）： 将 Prompt tuning 技术首次拓展至序列标注等复杂的 NLU 任务上，而 P-tuning v1 在此任务上无法运作。 非常适合GLM这种双向预训练大模型微调3.5. freezeFreeze 方法，即参数冻结，对原始模型部分参数进行冻结操作，仅训练部分参数，以达到在单卡或不进行 TP 或 PP 操作，就可以对大模型进行训练。在语言模型模型微调中，Freeze 微调方法仅微调 Transformer 后几层的全连接层参数，而冻结其它所有参数优点：大量减少了大语言模型的微调参数，是一种参数高效的微调方法；由于只需微调高层特征，加快了模型的收敛，节约了微调的时间；最大程度地保留了大语言模型预训练所学习到的语言的 “共性”，可解释性较强。","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"prophet","slug":"machine_learning/time_series/prophet","date":"2023-05-04T00:40:23.000Z","updated":"2023-06-26T08:28:41.315Z","comments":true,"path":"machine_learning/time_series/prophet/","link":"","permalink":"https://tlylft.github.io/machine_learning/time_series/prophet/","excerpt":"","text":"1. what is prophetgithub链接官方文档Prophet是Facebook数据科学团队于2017年发布的开源预测软件包，其内容发表在《Forecasting at scale》论文中。目前可以通过Python和R进行实现，该模型可以通过简单的参数配置，实现高精准的时间序列预测。 2. Prophet适用场景预测模型均有其适用的场景，Prophet也不例外，只有在合适的场景下，才能发挥模型本身的威力，具体适用场景如下： 训练数据：拥有至少一个完整周期的数据，让模型完整学习规律。 数据趋势：数据有一定正常的周期效应，例如：周末效应、季节效应等。 跳变情况：明确可能发生跳变的时间点及窗口期，例如：双十一、国庆节等。 缺失值符合预期：历史数据的缺失值和异常值保持在合理范围内。 3. 模型使用QuickStart3.1. 环境配置python 3.7+pip install prophet 3.2. 训练数据格式 DS Y 2007-12-10 9.590761 2007-12-11 8.519590 2007-12-12 8.183677 2007-12-13 8.072467 2007-12-14 7.893572 3.3. 快速调用12345678910111213141516import pandas as pdfrom prophet import Prophetdf &#x3D; pd.read_csv(&#39;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;facebook&#x2F;prophet&#x2F;main&#x2F;examples&#x2F;example_wp_log_peyton_manning.csv&#39;)df.head()# 训练m &#x3D; Prophet()m.fit(df)# 生成预测数据future &#x3D; m.make_future_dataframe(periods&#x3D;365) # 包含训练数据的和未来365天的预测日期future.tail()# 对上面训练+预测数据进行预测拟合forecast &#x3D; m.predict(future) # 可以返回一个Prophet.Forecast对象或者对象的历forecast[[&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;]].tail()# 画图fig1 &#x3D; m.plot(forecast)fig2 &#x3D; m.plot_components(forecast) 4. 模型原理详解简单来说，Prophet 把时序分为四个部分，认为任意时刻的值，就是这四个部分相加的结果。这四个部分分别是： 趋势成分g(t)：时序最内核的一个增长趋势，可设定线性或非线性增长 季节性成分s(t)：使用傅里叶级数拟合时序中跟时间强烈相关、周期性上升下降的成分 节假日影响h(t)：时序中非周期性出现的影响，将过去、将来相同的节假日设置成一个虚拟变量，并拟合该变量的相关性 误差项：不可预测的假设为正态分布的误差部分 对于上面第二个相乘的形式，当考虑对数时，也转换为四部分相加的形式，所以两种形式都可以作为可加模型进行讨论。各部分公式详解1各部分公式详解2 5. 模型应用调优技巧趋势项调优 6. 推理速度优化refer:https://towardsdatascience.com/how-to-run-facebook-prophet-predict-x100-faster-cce0282ca77d prophet推理速度时间大概为1.15 s ± 55.9 ms per loop，比训练的时间还长，不符合通常模型的常规情况。通过翻阅源码debug， 发现在predict过程中，Prophet’s uncertainty占据了大部分的预测时间，这个步骤主要是确定预测的不确定范围。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"},{"name":"time series","slug":"machine-learning/time-series","permalink":"https://tlylft.github.io/categories/machine-learning/time-series/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"charles 抓包工具","slug":"crawler/charles","date":"2023-04-17T12:54:58.000Z","updated":"2023-08-11T09:11:12.641Z","comments":true,"path":"crawler/charles/","link":"","permalink":"https://tlylft.github.io/crawler/charles/","excerpt":"","text":"charles 中文乱码问题 proxy配置 手机代理：下载夜游模拟器，设置网络无线代理为windows的ip地址。 打开浏览器： charles.pro/ssl 下载证书，在手机设置，从sd卡安装，安装刚下载的证书在浏览器设置，—隐私和安全—显示安全警告（不勾选）","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://tlylft.github.io/categories/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://tlylft.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"爬虫加密算法","slug":"crawler/encryption","date":"2023-04-17T12:54:58.000Z","updated":"2023-08-11T09:11:06.013Z","comments":true,"path":"crawler/encryption/","link":"","permalink":"https://tlylft.github.io/crawler/encryption/","excerpt":"","text":"这个网站可以查看很多加密算法的结果：https://spidertools.cn/#/crypto base64是一种编码，不算加密，一般末尾会有个等号123456 u pASCII码对应16进制数据 7 5 7 0转换成2进制 0111 0101 0111 0000按6位重组数据 011101 010111 0000(00 000000) 不足六位进行补00 再补六个0转换成10进制 29 23 A &#x3D; 补位为等号最终结果 dXA&#x3D; md5信息摘要算法，可用于文本表示， 可以产出一个128位（16字节）的散列值，表示为16进制是32位。123import hashlibdef md5_test(text): result = hashlib.md5(text.encode('utf-8').hexdigest()) SHA-1sha-1通常长度为16进制是40位sha-224通常长度为16进制是56位sha-256通常长度为16进制是64位sha-384通常长度为16进制是96位sha-512通常长度为16进制是128位12345import hashlibdef SHA_test(text): result = hashlib.sha1(text.encode('utf-8').hexdigest()) result = hashlib.sha224(text.encode('utf-8').hexdigest()) result = hashlib.sha246(text.encode('utf-8').hexdigest())","categories":[{"name":"爬虫","slug":"爬虫","permalink":"https://tlylft.github.io/categories/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://tlylft.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"python迭代器和生成器","slug":"python/python/python_iter","date":"2023-03-30T09:03:48.000Z","updated":"2023-03-31T01:09:47.116Z","comments":true,"path":"python/python/python_iter/","link":"","permalink":"https://tlylft.github.io/python/python/python_iter/","excerpt":"","text":"什么是可迭代对象元组、列表、字典、集合、字符串 nums = [11, 22, 33] for num in nums: print(num) 判断可迭代对象for 循环测试123num &#x3D; 3.14# for i in num:# print(i) 2. 使用Iterable类进行迭代对象的判断1234567from collections.abc import Iterablestr_data &#x3D; &#39;abc&#39;# 判断浮点类型的实例对象是否是Iterable类的子类print(isinstance(num, Iterable))print(isinstance(str_data, Iterable)) 迭代器迭代对象不一定是迭代器，迭代对象可用迭代器加载1234567891011121314from collections.abc import Iterator, Iterablenums &#x3D; [11, 22, 33, 44]# num是一个可迭代对象print(isinstance(nums, Iterable))# 但不是一个迭代器print(isinstance(nums, Iterator))# 可以创建一个迭代器对象的nums_iter &#x3D; iter(nums)print(isinstance(nums_iter, Iterator)) # Trueprint(isinstance(nums_iter, Iterable)) # True 自定义一个迭代器1234567891011121314151617181920212223242526272829303132333435363738394041424344class StuSystem(object): &quot;&quot;&quot; 学生管理系统 &quot;&quot;&quot; def __init__(self): self.index &#x3D; 0 self.student_name &#x3D; [] def add(self): &quot;&quot;&quot; 添加一个新的学生 :return: &quot;&quot;&quot; name &#x3D; input(&quot;请输入新学生的姓名:&quot;) # tel &#x3D; input(&quot;请输入新学生的手机号:&quot;) # address &#x3D; input(&quot;请输入新学生的住址:&quot;) new_stu &#x3D; dict() new_stu[&quot;name&quot;] &#x3D; name # new_stu[&quot;tel&quot;] &#x3D; tel # new_stu[&quot;address&quot;] &#x3D; address self.student_name.append(new_stu) def __iter__(self): return self def __next__(self): if self.index &lt; len(self.student_name): item &#x3D; self.student_name[self.index] self.index +&#x3D; 1 return item else: raise StopIterationstu_sys &#x3D; StuSystem()stu_sys.add(&#39;1&#39;)stu_sys.add(&#39;2&#39;)stu_sys.add(&#39;3&#39;)for item in stu_sys: print(item)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"arima模型","slug":"machine_learning/time_series/arima","date":"2023-03-17T02:13:48.000Z","updated":"2023-03-22T00:19:05.339Z","comments":true,"path":"machine_learning/time_series/arima/","link":"","permalink":"https://tlylft.github.io/machine_learning/time_series/arima/","excerpt":"","text":"https://blog.csdn.net/lam_yx/article/details/107887284 adf平稳性检验：https://blog.csdn.net/FrankieHello/article/details/86766625/ I 差分： 是前一个减去后一个的值，通过差分实现平稳化，一般不超过两阶，时序输入：15-50个预测输出：1-15个 step1: 要求序列满足平稳性，查看ADF结果分析t值，分析是否可以显著拒绝序列不平稳的假设（p&lt;0.05或0.01)Step2: 查看差分前后数据对比图，判斯是否平稳（上下幅度不大），同时对时间序列进行偏自相关分析、自相关分析，根据截尾情况估算其 p、q 值。Step3:ARIMA 模型要求时间序列数据具备纯随机性，即模型残差为白噪声，查看模型检验表，根据 Q 统计量的p 值对模型白噪声进行检验，也可以结合信息准则 AIC和 BIC值进行分析《越低越好》，也可通过 ACF/PACF 图进行分析Step4: 根据模型参数表，出模型公式Step5: 结合时间序列分析图进行分析，得到向后预测的阶数结果","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"},{"name":"time series","slug":"machine-learning/time-series","permalink":"https://tlylft.github.io/categories/machine-learning/time-series/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"刷题题库","slug":"leecode/interview","date":"2023-02-20T01:08:45.000Z","updated":"2023-08-11T08:02:35.823Z","comments":true,"path":"leecode/interview/","link":"","permalink":"https://tlylft.github.io/leecode/interview/","excerpt":"","text":"本文列举了一些刷题和知识点的资源： 一、编程题 Leecode网站 二、算法知识 机器学习、NLP相关： https://github.com/nosuggest/Reflection_Summary","categories":[{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/categories/Leecode/"}],"tags":[{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/tags/Leecode/"}]},{"title":"强化学习（1）-强化学习概念","slug":"reinforcement_learning/01_rf_intro","date":"2023-02-16T00:29:53.000Z","updated":"2023-08-10T01:53:53.089Z","comments":true,"path":"reinforcement_learning/01_rf_intro/","link":"","permalink":"https://tlylft.github.io/reinforcement_learning/01_rf_intro/","excerpt":"","text":"1. 什么是强化学习强化学习，是在于环境的互动中为了达成一个目标进行的学习过程。 所谓强化学习(Reinforcement Learning，简称RL)，是指基于智能体在复杂、不确定的环境中最大化它能获得的奖励，从而达到自主决策的目的。流程：依据策略执行动作-感知状态-得到奖励 1.1. 基本结构总的而言，Agent依据策略决策从而执行动作action，然后通过感知环境Environment从而获取环境的状态state，进而，最后得到奖励reward(以便下次再到相同状态时能采取更优的动作)，然后再继续按此流程“依据策略执行动作-感知状态—得到奖励”循环进行。 agent在environment中，观察到环境的state，选择做出的action，每个action对应得到的正向或负向的reward，agent的goal是学习reward或goal高的action。以alphago为例： 第一层：基本元素： Agent：主体、智能体一般译为智能体，就是我们要训练的模型，类似玩超级玛丽的时候操纵马里奥做出相应的动作，而这个马里奥就是Agent environment: 环境它是提供reward的某个对象，它可以是AlphaGo中的人类棋手，也可以是自动驾驶中的人类驾驶员，甚至可以是某些游戏AI里的游戏规则 goal：目标 —赢得比赛 第二层结构：主要元素 state： 状态，环境的state可以理解成环境的状态，简称状态 action： 行动， 会影响环境。 —落子的位置玩超级玛丽的时候你会控制马里奥做三个动作，即向左走、向右走和向上跳，而马里奥做的这三个动作就是action reward: 奖励，action的奖励这个奖赏可以类比为在明确目标的情况下，接近目标意味着做得好则奖，远离目标意味着做的不好则惩，最终达到收益/奖励最大化，且这个奖励是强化学习的核心 奖励是及时的反馈，而目标是长远的结果。 第三层结构：核心元素 policy:策略在某一状态下应该采取怎样的行动，一个策略函数 value: 价值 state value 状态价值函数 输入状态，输出实数，表示预期得到的所有奖励之和 state-action value 状态-行动价值函数 在特定状态下，采取某种行动所具有的价值 学习的是一个好的价值函数，决定了一个好的策略状态价值函数决定了策略 1.2. 特点Trial and error 试错,在不断的尝试中学习难点：delayed reward 延迟奖励，一个行动可能没有奖励，但最终通过他获胜，是有价值的action affect 核心问题，行为影响后续的状态，需要行为探索世界，exploration vs. exploitation 与监督学习的区别：监督学习是每一步都向一个老师学习概率，强化学习是通过经验学习，自己通过不断试错来学习。需要大量的训练。 训练数据中没有标签，只有奖励函数 训练数据不是现成给定的，而是由行为获得 监督学习中输入是独立分布的，即各项数据之间没有关联;RL现在的行为不仅影响后续训练数据的获得，也影响奖励函数的取值 训练目的:构建状态-&gt;行为的函数 监督学习如果做了比较坏的选择则会立刻反馈给算法RL的结果反馈有延时，有时候可能需要走了很多步以后才知道之前某步的选择是好还是坏 ML: 学习一个函数：input-&gt; obsevation learning -&gt; func(obsevation) output-&gt; action 1.3. 应用领域： 围棋：alphago 玩游戏: gym, Universe 直升机 机器人 无人驾驶 文本生成（对话）:chatgpt1.4. 算法分类RL为得到最优策略从而获取最大化奖励，有以下两大类方法： 基于值函数的方法通过价值选行为，如：Q-learning, Sarsa, Deep Q Network，学习一个评判器,适合离散的环境下，比如围棋和某些游戏领域。 基于策略的方法一般先进行策略评估，即对当前已经搜索到的策略函数进行估值，得到估值后，进行策略改进，不断重复这两步直至策略收敛，直接训练行为策略，比如策略梯度法(policy gradient，简称PG)，适合连续动作的场景，比如机器人控制领域 结合以上两种方式：actor+critic架构Actor-Criti(一般被翻译为演员-评论家算法)，Actor学习参数化的策略即策略函数，Criti学习值函数用来评估状态-动作对，不过，Actor-Criti本质上是属于基于策略的算法，毕竟算法的目标是优化一个带参数的策略，只是会额外学习价值函数，从而帮助策略函数更好的学习 想象环境未来会发生的状况并从中学习： Model based RL， 棋类游戏比较多，游戏场景比较少用到，因为游戏场景未来的发生情况不好穷举。 2. 实例Alpha GO: policy-based+value-based + model-based原理 = 深度 + 强化 2.1. 围棋agent: 下棋的人 environment：对手、棋盘 goal：赢得游戏state：棋盘上棋子的分布情况 action：落子行为 reward: 一个好的学习模型，除非赢，奖励应该为0，如果以吃子作为奖励，不一定能赢state-1: empty board 有361个可采取的行动对应361个 state-action value, reward之和为状态价值action-1: star pointreward-1:0 2.2. chatbot3. 参考资料Textbook: Reinforcement Learning: An introductionhttps://webdocs.cs.ualberta.ca/~sutton/book/the-book.htmlLectures of David Silver","categories":[{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"dataframe转换操作","slug":"python/pandas/pandas-transform","date":"2023-01-20T13:29:08.000Z","updated":"2023-02-20T00:53:33.519Z","comments":true,"path":"python/pandas/pandas-transform/","link":"","permalink":"https://tlylft.github.io/python/pandas/pandas-transform/","excerpt":"","text":"transform()只针对某一列进行运算 agg()apply()python中pandas操作apply返回多列的实现 不同点：1.apply()里面可以跟自定义的函数，包括简单的求和函数以及复杂的特征间的差值函数等，但是agg()做不到 2.agg() / transform()方法可以反射调用（str调用）‘sum‘、’max’、’min’、’count‘等方法，形如agg(‘sum’)。apply不能直接使用，而可以用自定义函数+列特征的方法调用。 3.transform() 里面不能跟自定义的特征交互函数，因为transform是真针对每一元素（即每一列特征操作）进行计算 计算速度：https://www.cnblogs.com/wqbin/p/12806161.htmlagg()+python内置方法的计算速度最快，其次是transform()+python内置方法。而 transform() 方法+自定义函数 的组合方法最慢，需要避免使用！ python自带的stats统计模块在pandas结构中的计算也非常慢，也需要避免使用！","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"pandas","slug":"python/pandas","permalink":"https://tlylft.github.io/categories/python/pandas/"}],"tags":[{"name":"pandas","slug":"pandas","permalink":"https://tlylft.github.io/tags/pandas/"}]},{"title":"联邦学习","slug":"deep_learning/fed","date":"2023-01-20T13:24:11.000Z","updated":"2023-01-20T13:24:48.942Z","comments":true,"path":"deep_learning/fed/","link":"","permalink":"https://tlylft.github.io/deep_learning/fed/","excerpt":"","text":"书宝梳理论文：https://github.com/jacks-tang/Federated_Learning_Time_Series_Park","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"PCL基础","slug":"cv/pointcloud/PCL","date":"2022-11-18T05:43:05.000Z","updated":"2022-11-18T13:19:08.343Z","comments":true,"path":"cv/pointcloud/PCL/","link":"","permalink":"https://tlylft.github.io/cv/pointcloud/PCL/","excerpt":"","text":"官网： https://pointclouds.orgGithub: https://github.com/PointCloudLibrary/pcl教程： https://pcl.readthedocs.io/en/latest文档： http://pointclouds.org/documentation博客： https://zhuanlan.zhihu.com/p/268524083 PCL架构图","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"pointcloud","slug":"cv/pointcloud","permalink":"https://tlylft.github.io/categories/cv/pointcloud/"}],"tags":[{"name":"pointcloud","slug":"pointcloud","permalink":"https://tlylft.github.io/tags/pointcloud/"}]},{"title":"MoCo","slug":"cv/moco","date":"2022-06-13T03:03:10.000Z","updated":"2022-06-16T11:18:40.456Z","comments":true,"path":"cv/moco/","link":"","permalink":"https://tlylft.github.io/cv/moco/","excerpt":"","text":"https://arxiv.org/pdf/1911.05722.pdfhttps://github.com/facebookresearch/moco对比学习： 动量对比学习做无监督的表征学习Self-Supervised Learning 超详细解读 (目录)https://zhuanlan.zhihu.com/p/381354026Self-Supervised Learning 超详细解读 (四)：MoCo系列解读 (1)https://zhuanlan.zhihu.com/p/382763210自监督学习修炼之MoCov1与MoCov2https://zhuanlan.zhihu.com/p/265786990","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"【3D图像】 点云数据","slug":"cv/pointcloud/point_data","date":"2022-06-08T03:06:01.000Z","updated":"2022-08-15T00:15:51.238Z","comments":true,"path":"cv/pointcloud/point_data/","link":"","permalink":"https://tlylft.github.io/cv/pointcloud/point_data/","excerpt":"","text":"https://www.shuangyi-tech.com/news_161.html 1. 三维视觉背景三维视觉技术发展，得益于广泛的应用。尤其是最近看到的智能无人系统，智能无人系统包括无人车、无人机以及机器人，还有AR、VR方面，也是得益于三维视觉的发展。这些应用一方面得益于三维视觉，一方面也推动了三维视觉技术的发展。具体来讲，三维视觉得益于三维数据获取的快速发展，首先是各种各样的传感器，最初普通用户不太能够拥有这些设备。越早期设备越大，由原本在飞机上应用的激光雷达，到车上，到小型三维扫描仪，再到手机，比如苹果好多手机厂商都在推深度相机。所以，这给已有或者未来获取三维数据，带来了更大的可能。 1.1. 研究内容三维视觉涉及的研究内容，主要包括三维感知、位姿感知、三维建模、三维理解，甚至还有三维认知的方面。 1.2. 发展现状产业界：无人车、机器人方向领域的发展，是非常迅速的。传感器： 奥比中光， 图漾科技算法：商汤科技，zong mu, altizure学术界：也是非常活跃，有一个标志性的会议叫三维视觉国际会议（3DV），目前已经举办了六届，参与者都是国际上在视觉和图形方向比较先进的实验室。近年三维视觉论文所占比例逐年上升。 1.3. 挑战新问题的大量出现统一学术社区的缺乏 2. 三维视觉表示三维图像是在二维彩色图像的基础上又多了一个维度，即深度（Depth，D），可用一个很直观的公式表示为： 三维图像 = 普通的 RGB 三通道彩色图像 + Depth Map。表示方式： 深度图像（depth images） 点云 网格（meshes） 体积网格（volumetric grids） 2.1. RGB-DRGB-D 是广泛使用的 3D 格式，其图像每个像素都有四个属性：即红（R）、绿（G）、蓝（B）和深度（D）。 在一般的基于像素的图像中，我们可以通过（x，y）坐标定位任何像素，分别获得三种颜色属性（R，G，B）。而在 RGB-D 图像中，每个（x，y）坐标将对应于四个属性（深度 D，R，G，B）。 2.2. 点云https://zhuanlan.zhihu.com/p/344635951点云是某个坐标系下的点的数据集。获取： 点云不是通过普通的相机拍摄得到的，一般是通过三维成像传感器获得，比如双目相机、三维扫描仪、RGB-D 相机等。内容： 根据激光测量原理得到的点云，包括三维坐标（XYZ）和激光反射强度（Intensity） 有序点云：一般由深度图还原的点云，有序点云按照图方阵一行一行的，从左上角到右下角排列，当然其中有一些无效点因为。有序点云按顺序排列，可以很容易的找到它的相邻点信息。有序点云在某些处理的时候还是很便利的，但是很多情况下是无法获取有序点云的。 无序点云：无序点云就是其中的点的集合，点排列之间没有任何顺序，点的顺序交换后没有任何影响。是比较普遍的点云形式，有序点云也可看做无序点云来处理。 存储格式： 主要包括：pts、LAS、PCD、.xyz 和. pcap 等 pts 点云文件格式是最简便的点云格式，直接按 XYZ 顺序存储点云数据， 可以是整型或者浮点型。 LAS 是激光雷达数据（LiDAR），存储格式比 pts 复杂，旨在提供一种开放的格式标准，允许不同的硬件和软件提供商输出可互操作的统一格式。其中 C：class(所属类)，F：flight(航线号)，T：time(GPS 时间)，I：intensity(回波强度)，R：return(第几次回波)，N：number of return(回波次数)，A：scan angle(扫描角)，RGB：red green blue(RGB 颜色值)。-xyz 一种文本格式，前面 3 个数字表示点坐标，后面 3 个数字是点的法向量，数字间以空格分隔。 优点： 点云表示保留了三维空间中原始的几何信息，不进行离散化 Las点云数据数据格式介绍https://blog.csdn.net/baidu_41612192/article/details/124230091LAS1.0版标准格式是由美国摄影测量与遥感协会（ASPRS）在2003年发布的，经过改进目前已有1.0、1.1、1.2、1.3、1.4，5种版本。python相关包：https://blog.csdn.net/weixin_43779943/article/details/98637017laspy, pylas, las, pylidar","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"pointcloud","slug":"cv/pointcloud","permalink":"https://tlylft.github.io/categories/cv/pointcloud/"}],"tags":[{"name":"pointcloud","slug":"pointcloud","permalink":"https://tlylft.github.io/tags/pointcloud/"}]},{"title":"【mmsegmentation】06-可视化","slug":"cv/segmentation/mmsegmentation_06_visual","date":"2022-06-06T09:24:58.000Z","updated":"2022-06-08T03:05:35.457Z","comments":true,"path":"cv/segmentation/mmsegmentation_06_visual/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/mmsegmentation_06_visual/","excerpt":"","text":"tools/analyze_logs.pyjson_logs: 包含指标的日志文件，可以是一个列表keys: 指标的名称，可以是一个列表 12345678python tools/analyze_logs.py work_dirs/upernet_swin_tiny_patch4_window7_512x512_160k_weldcircle2_pretrain_224x224_1k/epoch600.jsonwork_dirs/upernet_swin_tiny_patch4_window7_512x512_160k_weldcircle2_pretrain_224x224_defect/epoch600.json--legendmIoU_without_defect_pretrainmIoU_with_defect_pretrain--outoutput/plt/circle.png","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"matplotlib 基础 （一）","slug":"python/matplotlib/matplotlib_basic","date":"2022-06-06T09:07:46.000Z","updated":"2022-06-06T09:22:42.456Z","comments":true,"path":"python/matplotlib/matplotlib_basic/","link":"","permalink":"https://tlylft.github.io/python/matplotlib/matplotlib_basic/","excerpt":"","text":"安装123pip install matplotlibimport matplotlibprint(matplotlib.__version__) 基本用法绘制单、多条线12345678910111213141516import matplotlib.pyplot as pltimport numpy as npxpoints = np.array([0, 6])ypoints = np.array([0, 100])plt.plot(xpoints, ypoints)plt.show()# 画单条线plot([x], y, [fmt], *, data=None, **kwargs)# 画多条线plot([x], y, [fmt], [x2], y2, [fmt2], ..., **kwargs)# 使用红色+号plot(y, 'r+') #不指定x, x会根据 y 的值自动生成# 使用蓝色圆圈plot(y, 'bo') 颜色字符：’b’ 蓝色，’m’ 洋红色，’g’ 绿色，’y’ 黄色，’r’ 红色，’k’ 黑色，’w’ 白色，’c’ 青绿色，’#008000’ RGB 颜色符串。多条曲线不指定颜色时，会自动选择不同颜色。 线型参数：’‐’ 实线，’‐‐’ 破折线，’‐.’ 点划线，’:’ 虚线。 标记字符：’.’ 点标记，’,’ 像素标记(极小点)，’o’ 实心圈标记，’v’ 倒三角标记，’^’ 上三角标记，’&gt;’ 右三角标记，’&lt;’ 左三角标记…等等。 绘制多条线```import matplotlib.pyplot as pltimport numpy as npxpoints = np.array([0, 6])","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"matplotlib","slug":"python/matplotlib","permalink":"https://tlylft.github.io/categories/python/matplotlib/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"MAE CAE","slug":"cv/mae","date":"2022-05-24T02:46:00.000Z","updated":"2022-08-17T12:45:19.241Z","comments":true,"path":"cv/mae/","link":"","permalink":"https://tlylft.github.io/cv/mae/","excerpt":"","text":"MAEhttps://github.com/facebookresearch/mae动机：在nlp中，自监督学习应用比较火，但是在cv中，基本还是用有标号的训练。在将bert拓展到cv领域的过程中，效果没有nlp好。 图片和文本的区别：1) 文本中一个词代表一个语义的单元，含有的语义信息丰富；图片中用patch代表一个语义信息，但一个patch可能包含多个物体或者一个物体的一小部分。cv比nlp的语义单元好还原2) 图片之前使用卷积神经网络，窗口滑动不便于将mask结合起来，（目前不是问题，已经解决）3)4) 解决方法：1) mask掉更多的块，使远距离的块相互关系不显得那么冗余，训练更能关注全局的信息，得到全局图片的重构2) mask更多的块，使编码器减少计算开销 意义：在imageNet数据集上用自编码器学习进行迁移学习，只使用1k的数据，结果和之前有标号的100倍数据训练差不多。 CAEhttps://mp.weixin.qq.com/s/B1-pOt2emoUZHMC9kILJFw来自北京大学、香港大学和百度的研究者们近日提出了一种名为 CAE 的新型 MIM 方法。该方法通过对 “表征学习” 和 “解决前置任务（pretext task）” 这两个功能做完全分离，使得 encoder 学习到更好的表征，从而在下游任务上实现了更好的泛化性能。 introMask Image Modeling (MIM) 方法，在 NLP 领域（例如 BERT）得到了广泛的应用。随着 ViT 的提出和发展，人们也尝试将 MIM 应用到视觉领域并取得了一定进展。在此之前，视觉自监督算法主要沿着 contrastive learning 的思路去设计，而 MIM 无疑打开了新的大门。 MIM 是一种自监督表征学习算法。它的主要思路是：对输入图像进行分块和随机掩码操作，然后对掩码区域做一些预测。预测的目标可以是 Token ID（BEiT），也可以是 RGB 的值（MAE）。通过 MIM，我们希望 encoder 能学习到一个好的表征，从而在下游任务取得良好的泛化性能。 近期 MIM 有两个代表性工作：BEiT 和 MAE。 BEiT 使用一个 encoder 做两件事：(1) 学习一个好的图像表征；(2) 解决 pretext task：预测 masked patch 的 Token ID。encoder 的潜力并没有完全被挖掘，只有部分被用来学习表征。 MAE 使用了 encoder-decoder 架构，encoder 负责对 visible patch 进行表征学习，decoder 将 visible 和 masked patch 的表征（masked patch 使用一个可学习的向量）作为输入，预测 masked patch 的 RGB 值。但是，MAE 在 decoder 中也会对 visible patch 的表征进行改变。与此同时，MAE decoder 利用改变后的可见区域的表征去预测遮挡区域的表征，实际上 decoder 也负责了一部分表征学习的功能。然而，在下游任务中，只有 encoder 中学到的信息能被拿来用，那么即使在 decoder 中进一步学到了更好的表征，也无法利用到下游任务中。 以上两种方法，都没有充分挖掘 encoder 的潜力，限制了预训练学习到的表征质量。 我们最近的工作 “Context Autoencoder for Self-Supervised Representation Learning”，提出了一种新的 MIM 方法 CAE，通过对 “表征学习” 和 “解决 pretext task” 这两个功能做完全分离，使得 encoder 学习到更好的表征，从而在下游任务实现了更好的泛化性能。","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"安卓手机脚本开发","slug":"tools/android_scripts","date":"2022-05-18T03:26:39.000Z","updated":"2022-05-28T04:04:18.159Z","comments":true,"path":"tools/android_scripts/","link":"","permalink":"https://tlylft.github.io/tools/android_scripts/","excerpt":"","text":"工具[adb:调试工具]scrcpy:安卓投屏控制工具Qtscrpy:连接Android设备进行显示和控制安装教程：https://blog.csdn.net/j1451284189/article/details/116053027使用说明：12adb devicesscrcpy qtscrpy: ndkminitouchhttps://blog.csdn.net/Alkaid2000/article/details/12306768012345678910# download ndk and add to system pathndk-build # checkgit clone https:&#x2F;&#x2F;github.com&#x2F;openstf&#x2F;minitouch.gitcd minitouchgit submodule initgit submodule updatendk-build # minitouch目录下会出现两个文件夹pip install pyminitouchadb shell getprop ro.product.cpu.abiadb push minitouch &#x2F;data&#x2F;local&#x2F;tmp","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"}]},{"title":"cv预训练模型","slug":"cv/pretrained_model","date":"2022-05-12T01:48:31.000Z","updated":"2022-05-12T01:51:47.832Z","comments":true,"path":"cv/pretrained_model/","link":"","permalink":"https://tlylft.github.io/cv/pretrained_model/","excerpt":"","text":"https://baijiahao.baidu.com/s?id=1673448659697290799&amp;wfr=spider&amp;for=pc todo:谷歌大脑的研究团队对这个概念进行了扩展，在新论文《Rethinking Pre-training and Self-training》中，不仅讨论了预训练，还研究了自训练，比较了在同一组任务当中自训练与监督预训练、自监督预训练之间的差异。论文地址：https://arxiv.org/abs/2006.06882 作者通过实验得出了以下结论： 1、如果预训练任务和目标任务存在差异，则预训练（包括监督和自监督）可能损害目标任务准确率； 2、自训练适用不同规模数据集和不同强度增强数据的训练； 3、自训练并且可以看作对预训练的补充，联合预训练和自训练可以获得更大的增益 研究动机：1、预训练对训练结果有多大程度的帮助？ 2、什么情况下使用预训练是无效的？ 3、与预训练相比，我们可以使用自训练并获得相似或更好的结果吗？ 4、如果自训练优于预训练（暂做这样的假设），那它在多大的程度上比预训练好？ 5、在什么情况下自训练比预训练更好？ 6、自训练的灵活性和可扩展性如何？ 用预训练模型训练自己的数据集准确率非常低是什么原因呢1、训练原始模型的数据（源域）和 自己的数据集（目标域）不匹配，通常微调fine tuning可缓解，解决的方法有领域自适应等；2、灾难遗忘 (catastrophic forgetting)，指的是模型在新数据集上由于参数更新步伐过大，忘记了之前在旧数据集上学习到的知识，解决的方法一般是在新数据集上用小的学习率慢慢更新。 其实也是要看你训练的数据是不是在ImageNet中有的相关类别数据，如果有的话，这样提取特征的效果会比较好，因为预训练的权重包含了已经有的类别。如果是新的类别的话，需要进行尝试，因为不同预训练权重对于不同的数据训练的效果，或者需要修改的层数也是不同的，需要经过实验来测试，但是其实修改最后一层的效果会稍微好一些，不会将之前的权重破坏掉。建议：修改最后一层，或者最后面在加上一层，放自己的分类数 “只训练vgg19的全连接层参数，前面的卷积层参数都是冻结的 “ 这个是你的前提设置吗？类别多少应该不是影像性能的主要原因，数据分布和数据集质量比较重要。如果是你的前提设置，性能不好可以尝试后面多增加一些层进行训练。如果不是，可以用预训练好的模型当作训练的初始化参数，你继续进行整体模型的重训练。总之，效果还是要你自己动手进行实验验证，别人的经验与你的情况未必是完全一致的。","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"pooling","slug":"deep_learning/pooling","date":"2022-05-06T06:54:35.000Z","updated":"2022-05-06T06:56:26.173Z","comments":true,"path":"deep_learning/pooling/","link":"","permalink":"https://tlylft.github.io/deep_learning/pooling/","excerpt":"","text":"https://www.zhihu.com/question/41948919 Max pooling","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"swin transformer","slug":"cv/swin_transformer","date":"2022-05-06T05:29:36.000Z","updated":"2022-05-12T00:30:23.938Z","comments":true,"path":"cv/swin_transformer/","link":"","permalink":"https://tlylft.github.io/cv/swin_transformer/","excerpt":"","text":"论文：swin transformer论文2：Swin Transformer V2: Scaling Up Capacity and Resolution代码: https://github.com/microsoft/Swin-Transformerswin transformer详解 介绍研发动机： 意义： 实验说明数据集和训练：1) 在ImageNet-1K进行训练2) 在ImageNet-22K进行预训练，在ImageNet-1K进行fine-tuning实验结果： 成果：目标检测的结果，比之前各种结果都高了三四个点 模型结构","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"Vision Transformer","slug":"cv/VIT","date":"2022-05-06T05:28:56.000Z","updated":"2022-05-12T00:30:22.471Z","comments":true,"path":"cv/VIT/","link":"","permalink":"https://tlylft.github.io/cv/VIT/","excerpt":"","text":"《AN IMAGE IS WORTH 16*16 WORDS TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE》 该论文提出的Vision Transformer (ViT)模型是Transformer在CV领域的首次应用。 背景Transformer自提出以来在NLP领域取得了诸多突破，自然就有CV领域的研究人员考虑如何在图片等视觉媒体上应用Transformer。 从深度学习暴发以来，CNN一直是CV领域的主流模型，而且取得了很好的效果。以图像分类为例，以往用卷积神经网络做图像分类时，我们做的事情就是把一张图片送到一个卷积神经网络里，然后可以得到一个概率向量。 对于图像分类任务而言，目前最常用(通用效果较好) 的模型是ResNet，当然可能会做一些子结构的调整，但模型的总体结构还是Residual network。 直到ViT模型出现了，战胜了CNNs(前提条件是有足够大的数据集和足够的算力) Vision Transformer(ViT)的宏观介绍ViT的全称为Vision transformer，是首次将transformer应用到计算机视觉任务中。我们知道，transformer最早是在NLP领域提出的，并且在NLP领域大获成功。transformer在CV领域的探索正是研究界想把transformer在NLP领域的成功借鉴到CV领域。对于图像问题，卷积具有天然的先天优势（inductive bias）：平移等价性（translation equivariance）和局部性（locality）。而transformer虽然不并具备这些优势，但是transformer的核心self-attention的优势不像卷积那样有固定且有限的感受野，self-attention操作可以获得long-range信息（相比之下CNN要通过不断堆积Conv layers来获取更大的感受野），但训练的难度就比CNN要稍大一些。从图中我们可以看到，输入图像被切分为很多子块(patches)，这些patches会送入到linear projection of flattened patches结构做一系列变换。linear projection of flattened patches结构包含两个操作：(1).把每个patch展开成一个向量；(2).做线性映射(linear projection)，实际上就是一个不带激活层的全连接。 经过linear projection of flattened patches结构之后，得到输出多个向量。接着会为每个输出向量配置一个position embedding(位置编码)。这些向量之后会被送到一个叫做transformer encoder的编码器结构中，最终，将输出向量接一个MLP Head(多层感知器)来做图像分类。 拆解ViT模型的各部分组件我们以大小为224*224的输入图像为例，来看看上述流程：l 将划输入图片切分为大小是16x16的小块，共196(14x14)个l 对这么多的patch做embedding，得到196个768向量l 再拼接一个cls tokens，变成197个768向量l 添加位置embedding，还是197个768向量l 上述向量输入到transformer中进行特征提取l 取出最后一层的(CLS位置对应)输出，接1000分类的全连接层 TransformerTransformer结构来自于论文《Attention Is All Yor Need》-2017，在ViT模型中，Transformer encoder就是指Transformer原图中左侧部分其中：Muti-Head：多头自注意力Add &amp; Norm：有点像ResNet中的skip connectionFeed Forward：全连接 PATCH EMBEDDINGS对图像块进行 Embedding的方式非常简单，只需要对每个图像块做一个线性变换，将维度压缩为即可。比如大小为 (3, 224, 224)的图片，切分为 196(14 14) 块大小为 3 16 16 的子图。每个图像块(patch)被展平为维度是3 16 *16 = 768的向量。整张图像经过处理后，我们得到196 个维度为 768的向量，用向量化的方式表示就是(196, 768)的矩阵，如下图所示： 为什么不直接把整张图片送进TRANSFORMER，而是要采用切块的方式？ [CLS]tokenViT模型借鉴BERT增加了一个特殊的class token(类标记位)。transformer的encoder输入是一系列的patch embeddings，输出也是同样长的序列patch features，但是图像分类最后需要获取image feature，简单的策略是采用pooling，比如求patch features的平均来获取image feature，但是ViT并没有采用类似的pooling策略，而是直接增加一个特殊的class token，其最后输出的特征加一个linear classifier就可以实现对图像的分类，所以输入ViT的sequence长度是N+1(N表示图像块的个数)。 class token对应的embedding在训练时随机初始化，然后通过训练得到。以前边的图像为例，[CLS]标记位是一个大小为 (1, 768) 的向量，如下图所示：图像块经过patch embeddings之后，矩阵为 (196, 768)，再添加上CLS标记位后，最终得到的是矩阵大小为： 197x768（196个子图块+1个[CLS]标记位） POSITION EMBEDDING除了patch embeddings，模型还需要另外一个特殊的position embedding。transformer和CNN不同，需要position embedding来编码tokens的位置信息，这主要是因为self-attention是permutation-invariant，即打乱sequence里的tokens的顺序并不会改变结果。如果不给模型提供patch的位置信息，那么模型就需要通过patchs的语义来学习拼图，这就额外增加了学习成本。ViT论文中对比了几种不同的position embedding方案(如下），最后发现如果不提供positional embedding效果会差，但其它各种类型的positional embedding效果都接近，这主要是因为ViT的输入是相对较大的patchs而不是pixels，所以学习位置信息相对容易很多。 (1)无positional embedding(2)1-D positional embedding：把2-D的patchs看成1-D序列(3)2-D positional embedding：考虑patchs的2-D位置（x, y）(4)Relative positional embeddings：patchs的相对位置 transformer原论文中是默认采用固定的positional embedding，但ViT中默认采用学习（训练的）的1-D positional embedding，在输入transformer的encoder之前直接将patch embeddings和positional embedding相加。 ViT模型的实现细节之前我们说，是把输入图像”切”成了子块，用”切”这个词其实并不准确，实际上它和卷积神经网络类似，是一个sliding window一样的处理，有stride(滑动步长)。通过滑动窗口，我们就得到了不同的图像块。这些图像子块实际上是可以有重叠的，但论文中实现代码中用的是没有重叠的，所以可以看作是把图像切成了子块。不过，论文中也有提到：如果计算资源没有问题，patches是可以有重叠的。 输入图像向量化我们会把输入图像里边的每一个图像块展成一个向量，如下图所示：x1一直到x9就是每一个patch对应的向量。得到这些向量之后，我们就会做Linear projection，即线性变换：wx+b，如下图：一直到zn=Wx_n + b,这个wx+b的线性变换其实就是一个全连接的处理，但是这是一个不带激活函数的全连接，而且，另外需要注意的是：每一个输入的向量x，共享同样一组参数。 ViT模型的效果和使用建议","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"torch BN层和LN层","slug":"pytorch/torch_bn","date":"2022-05-06T01:23:44.000Z","updated":"2022-05-06T02:57:19.272Z","comments":true,"path":"pytorch/torch_bn/","link":"","permalink":"https://tlylft.github.io/pytorch/torch_bn/","excerpt":"","text":"https://blog.csdn.net/qq_39777550/article/details/108038677https://blog.csdn.net/u012526436/article/details/86295971 上面第二个讲的详细，还没看！ Batch Normalization目的：使我们的一批(batch)数据 feature map满足均值为0，方差为1的分布规律。 γ和β是对像素在BN的基础上进行的调整，具体数值是模型自己学出来的，初始值是γ=1（调整方差）和β=0（调整均值） 函数参数讲解：1BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) 1.num_features：一般输入参数为batch_sizenum_featuresheight*width，即为其中特征的数量，即为输入BN层的通道数；2.eps：分母中添加的一个值，目的是为了计算的稳定性，默认为：1e-5,避免分母为0；3.momentum：一个用于运行过程中均值和方差的一个估计参数（我的理解是一个稳定系数，类似于SGD中的momentum的系数）；4.affine：当设为true时，会给定可以学习的系数矩阵gamma和beta一般来说pytorch中的模型都是继承nn.Module类的，都有一个属性trainning指定是否是训练状态，训练状态与否将会影响到某些层的参数是否是固定的，比如BN层或者Dropout层。通常用model.train()指定当前模型model为训练状态,model.eval()指定当前模型为测试状态。同时，BN的API中有几个参数需要比较关心的，一个是affine指定是否需要仿射，还有个是track_running_stats指定是否跟踪当前batch的统计特性。容易出现问题也正好是这三个参数：trainning，affine，track_running_stats。其中的affine指定是否需要仿射，也就是是否需要上面算式的第四个，如果affine=False则γ=1,β=0，并且不能学习被更新。一般都会设置成affine=True。trainning和track_running_stats，track_running_stats=True表示跟踪整个训练过程中的batch的统计特性，得到方差和均值，而不只是仅仅依赖与当前输入的batch的统计特性。相反的，如果track_running_stats=False那么就只是计算当前输入的batch的统计特性中的均值和方差了。当在推理阶段的时候，如果track_running_stats=False，此时如果batch_size比较小，那么其统计特性就会和全局统计特性有着较大偏差，可能导致糟糕的效果。如果BatchNorm2d的参数track_running_stats设置False,那么加载预训练后每次模型测试测试集的结果时都不一样；track_running_stats设置为True时，每次得到的结果都一样。running_mean和running_var参数是根据输入的batch的统计特性计算的，严格来说不算是“学习”到的参数，不过对于整个计算是很重要的。BN层中的running_mean和running_var的更新是在forward操作中进行的，而不是在optimizer.step()中进行的，因此如果处于训练中泰，就算不进行手动step()，BN的统计特性也会变化。12345678model.train() #处于训练状态for data , label in self.dataloader: pred =model(data) #在这里会更新model中的BN统计特性参数，running_mean,running_var loss=self.loss(pred,label) #就算不进行下列三行，BN的统计特性参数也会变化 opt.zero_grad() loss.backward() opt.step()这个时候，要用model.eval()转到测试阶段，才能固定住running_mean和running_var，有时候如果是先预训练模型然后加载模型，重新跑测试数据的时候，结果不同，有一点性能上的损失，这个时候基本上是training和track_running_stats设置的不对。如果使用两个模型进行联合训练，为了收敛更容易控制，先预训练好模型model_A，并且model_A内还有若干BN层，后续需要将model_A作为一个inference推理模型和model_B联合训练，此时希望model_A中的BN的统计特性量running_mean和running_var不会乱变化，因此就需要将model_A.eval()设置到测试模型，否则在trainning模式下，就算是不去更新模型的参数，其BN都会变化，这将导致和预期不同的结果。","categories":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/categories/pytorch/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/tags/pytorch/"}]},{"title":"深度学习结构术语","slug":"cv/DL_architucture","date":"2022-04-29T06:24:13.000Z","updated":"2022-04-29T09:17:22.445Z","comments":true,"path":"cv/DL_architucture/","link":"","permalink":"https://tlylft.github.io/cv/DL_architucture/","excerpt":"","text":"https://blog.csdn.net/Dontla/article/details/123272169 backbone主干网络，用来做特征提取的网络，代表网络的一部分，一般是用于前端提取图片信息，生成特征图feature map,供后面的网络使用。在神经网络中，尤其是CV领域，一般先对图像进行特征提取（常见的有vggnet，resnet，谷歌的inception），这一部分是整个CV任务的根基，因为后续的下游任务都是基于提取出来的图像特征去做文章（比如分类，生成等等）。所以将这一部分网络结构称为backbone十分形象，仿佛是一个人站起来的支柱。 bottleneckResNet的核心内容之一，即“Deeper Bottleneck Architectures”（简称DBA），一言概之，bottleneck是一种特殊的残差结构。 结构： block的输入和输出channel_num是一样的， 而在block内部，输入和输出channel_num是小于输入和输出channel_num 的。左图是普通的残差结构，右图是瓶颈结构（通道256-&gt;64-&gt;64&gt;256） 作用：网络的参数减少了很多，深度也加深了，训练也就相对容易一些。 other2.head：head是获取网络输出内容的网络，利用之前提取的特征，head利用这些特征，做出预测。 3.neck:是放在backbone和head之间的，是为了更好的利用backbone提取的特征 5.GAP：在设计的网络中经常能够看到gap这个层，我之前不知道是干啥的，后了解了，就是Global Average Pool全局平均池化，就是将某个通道的特征取平均值，经常使用AdaptativeAvgpoold(1),在pytorch中，这个代表自适应性全局平均池化，说人话就是将某个通道的特征取平均值self.gap = nn.AdaptiveAvgPool2d(1)6.Embedding: 深度学习方法都是利用使用线性和非线性转换对复杂的数据进行自动特征抽取，并将特征表示为“向量”（vector），这一过程一般也称为“嵌入”（embedding）7.用于预训练的任务被称为前置/代理任务(pretext task)，用于微调的任务被称为下游任务(downstream task)8.temperature parameters 在论文中经常能看到这个温度参数的身影，那么他都有什么用处呢？比如经常看到下面这样的式子：里面的beta就是temperature parameter，他在运算的时候起到什么作用呢？是这样的，他可以起到平滑softmax输出结果的作用，举例子如下： 9.热身Warm up。Warm up指的是用一个小的学习率先训练几个epoch，这是因为网络的参数是随机初始化的，一开始就采用较大的学习率容易数值不稳定。 10 end to end 在论文中经常能遇到end to end这样的描述，那么到底什么是端到端呢？其实就是给了一个输入，我们就给出一个输出，不管其中的过程多么复杂，但只要给了一个输入，机会对应一个输出。比如分类问题，你输入了一张图片，肯呢个网络有特征提取，全链接分类，概率计算什么的，但是跳出算法问题，单从结果来看，就是给了一张输入，输出了一个预测结果。End-To-End的方案，即输入一张图，输出最终想要的结果，算法细节和学习过程全部丢给了神经网络。 11 domain adaptation 和domain generalization 域适应和域泛化域适应中，常见的设置是源域D_S完全已知，目标域D_T有或无标签。域适应方法试着将源域知识迁移到目标域。第二种场景可以视为domain generalization域泛化。这种更常见因为将模型应用到完全未知的领域，正因为没有见过，所以没有任何模型更新和微调。这种泛化问题就是一种开集问题，由于所需预测类别较多，所以比较头疼","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"【Unet系列】swin-Unet","slug":"cv/segmentation/unet_05_swinUnet copy","date":"2022-04-28T13:18:32.000Z","updated":"2022-05-12T00:30:24.838Z","comments":true,"path":"cv/segmentation/unet_05_swinUnet copy/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/unet_05_swinUnet%20copy/","excerpt":"","text":"Published: 2021 May论文：https://arxiv.org/abs/2105.05537代码：https://github.com/HuCaoFighting/Swin-Unet 1. introduction问题动机：解决医学图像分析中图像分割问题；现有的U-Net结构设计t在各种医学成像应用中取得了巨大的成功。思路来源：虽然基于CNN的方法在医学图像分割领域取得了优异的性能，但仍不能完全满足医学应用对分割精度的严格要求。由于卷积运算固有的局限性，基于CNN的方法很难学习显式的全局和长期语义信息交互。受Transformer在自然语言处理(NLP)领域的巨大成功的启发，研究人员试图将Transformer引入视觉领域。ViT、DeiT和Swin transformer在图像识别领域的成功证明了transformer在视觉领域的应用潜力。实现方式基于Swin-transformer block构建Unet结构，主要贡献：(1)基于Swin Transformer block，构建了一个具有跳跃连接的对称编码器-解码器体系结构。在编码器中实现了从局部到全局的自注意;在解码器中，将全局特征上采样到输入分辨率，进行相应的像素级分割预测。(2)开发了patch扩展层，无需卷积或插值操作即可实现上采样和特征维数的增加。(3)实验发现跳跃连接对transformer也是有效的，因此最终构建了一个纯基于transformer的u型编解码结构，具有跳跃连接，命名为swin-unet。意义首个基于纯Transformer的U-Net形的医学图像分割网络 2. 算法结构2.1. Swin-Transformer 2021年3月论文：https://arxiv.org/abs/2103.14030源码地址：https://github.com/microsoft/Swin-Transformer参考博客：https://blog.csdn.net/qq_41111734/article/details/116353615预训练权重: swin_small_patch4_window7_224.pth swin transformer(shifted windows Transformer)和resnet一样设计的是一个层次结果很明显的网络，底部的结构处理的数据更多也更局部，顶部的网络处理的数据更少但是语义信息是更加丰富的。不同的是swin主要提取信息的方式是采用transformer，而resnet是卷积核。 在图像分割，让很多人看到了transformer完全替代卷积的可能。而且它的设计思想吸取了resnet的精华，从局部到全局，将transformer设计成逐步扩大感受野的工具。效果说明：在COCO数据集上提升2.6个点(实例分割) 2.7个点（目标检测） 2.1.1. Swin-Transformer网络结构2.1.1.1. Swin vs. VIT1) 像CNN一样，特征层（feature map）更具有层次性（下采样倍率4-&gt; 8-&gt; 16）2) VIT每一层是个整体，并没有进行分割， Swin对窗口进行分割(windows multi-head self attention), 在每个窗口内部进行W-MSA计算，windows之间不进行信息的传递， 减少运算量3) 在更大数据集上做预训练，然后迁移学习，更能够提升效果4) ViT在输入会给embedding进行位置编码。而Swin-T这里则是作为一个可选项（self.ape），Swin-T是在计算Attention的时候做了一个相对位置编码5) ViT会单独加上一个可学习参数，作为分类的token。而Swin-T则是直接做平均，输出分类，有点类似CNN最后的全局平均池化层 2.1.1.2. swin整体框架整体说明：1) 整个模型采取层次化的设计，一共包含4个Stage（四次下采样），每次下采样特征图宽高分辨率缩小两倍（像CNN一样逐层扩大感受野），但通道数增加两倍2) 在每个Stage里，由Patch Merging和多个Block组成。3) 第一次下采样先进行的patch partition + linear embedding, 其他下采样先进行的patch merging, 但其实功能差不多：主要在每个Stage一开始降低图片分辨率4) 而Block具体结构如右图所示，堆叠偶数次（因为是两个模块成对使用），主要是LayerNorm，MLP，Window Attention 和 Shifted Window Attention组成5) 图中没画，分类任务在最后接入layer norm, 全局池化，全连接层，最后输出分类 2.1.2. 步骤说明2.1.2.1. patch partition在输入开始的时候，做了一个patch embedding，将图片切成一个个图块，并嵌入到embedding。上图以单通道为例，我理解这个就是把原始图像中每个4*4*3的区域直接展开成1*1*48的区域，然后做embedding。 有人说也可以用卷积来替代同样的效果，应该也可以，就是理解成两种特征表示，一种是原图特征，一种是卷积后的特征。或者是通过二维卷积层，将stride，kernelsize设置为patch_size大小。设定输出通道来确定嵌入向量的大小。最后将H,W维度展开，并移动到第一维度 2.1.2.2. Patch Merging该模块的作用是在每个Stage开始前做降采样，用于缩小分辨率，调整通道数（高和宽缩减为原来一半，通道数会翻倍），进而形成层次化的设计，形成从一开始的局部信息搜索到全局信息的提取，同时也能节省一定运算量。这个pooling操作与传统卷积里面的pooling也不太一样，它是将特征图先经过一个space to depth变为1/4，通道数变为原来的4倍，再又一个MLP缩减一半。 2.1.2.3. W-MSA self attention: https://arxiv.org/abs/1706.03762https://blog.csdn.net/qq_37541097/article/details/117691873 window attention就是按照一定的尺寸将图像划分为不同的window，每次transformer的attention只在window内部进行计算。目的： 减少计算量缺点：窗口之间无法进行信息交互 2.1.2.4. SW-MSAshift window attention如果只有window attention就会带来每一个像素点的感受野得不到提升的问题，所以它又设计了shift window attention的方法，就是换一下window划分的方式，让每一个像素点做attention计算的window块处于变化之中。那么就起到了提升感受野的作用。目的： 实现不同window之间的信息交互，提升感受野 2.1.2.5. MLP2.1.2.6. Relative Position Bias2.1.2.7. 配置参数2.1.3. 存在问题在同尺寸通计算量的前提下，swin确实效果远好于resnet。但是有几个问题： 预训练受限于shift操作，对不同尺寸的输入要设计不同的网络，而且也要重新开始训练，这是很难接受的。 和Detr一样训练的时候收敛的太慢。我自己有训练了一下最小的swin-tiny版本，大概训练了一百多轮的时候也才到72～73左右。有这方面改进的想法的朋友可以和我交流，整一篇B类应该没问题。 shift操作其实主要是为了提升感受野，不一定用这种方式 虽然在几个常用benchmark上提升明显，但是在某些实际项目的落地中发现可能还不如vit好用，或者需要精细调参，这个在resnet中是不存在的； 整个模型设计，我认为并没有真正从原理上真正解决cnn和vit之间的问题。transformer放在cv两个问题，local feat无法专注，长序列导致显存炸裂。swin采用的local self attention等于是套着cnn的模式到了transformer中，后面接一个shift window，我理想当中应该是采用一种全新的attention设计去解决这两个问题，我甚至有点好奇把local self attention替换一个普通卷积会怎么样。再者就是shift window那一步略显复杂，毕竟simple is best。 计算损耗：显存要求很高。 3. swin-Unet https://aistudio.baidu.com/aistudio/projectdetail/1985598?_=1651631016452 自从 Transformer 被引入计算机视觉以来，催生了大量相关研究与应用。在图像分割方向，涌现了像 SETR 和 TransUNet 等基于 Transformer 的语义分割网络模型。在TransUNet 中，虽然引入了 Transformer 用于 UNet 编码器，但其特点还是 CNN 与 Transformer 的混合编码，解码上也是基于 CNN 的上采样。直观上看，这种混合编码的结构并没有完全发挥出 Transformer 的优势，并且作为 backbone 的 ViT 结构也需要进一步改进。 Swin Transformer 正好作为视觉 Transformer 领域新的backbone。相较于 TransUNet，去掉CNN编码，用 Swin Transformer 来代替原先的 ViT，将 UNet 全部结构都换成 Swin Transformer。 3.1. 网络结构Swin-UNet由Encoder、Bottleneck、Decoder和跳跃连接组成。 编码器部分，输入图像先进行patch partition，每个patch大小为4x4，输入维度为H/4 x W/4 x 48，经过linear embedding和两个Swin Transformer block后特征图尺寸为H/4 x W/4 x C，然后通过patch merging进行下采样，再经过两个Swin Transformer block后特征图尺寸变为H/8 x W/8 x 2C，最后再进行一次同样的下采样操作即可完成编码器的操作。可以看到，Swin-UNet编码器每次按照2倍来缩小patch的数量，然后按照3倍来扩大特征维度的数量。 Bottleneck则是用了两个连续的Swin Transformer block，这里为防止网络太深不能收敛，所以只用了两个block，在Bottleneck中，特征尺寸保持H/32 x W/32 x 8C不变。 然后是解码器部分。Swin-UNet解码器主要由patch expanding来实现上采样，作为一个完全对称的网络结构，解码器也是每次扩大2倍进行上采样，核心模块由Swin Transformer block和patch expanding组成。 最后是跳跃连接。和unet一样。 3.1.1. 跳跃连接","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"},{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"【Unet系列】swin-Unet","slug":"cv/segmentation/unet_05_swinUnet","date":"2022-04-28T13:18:32.000Z","updated":"2022-05-05T05:55:11.259Z","comments":true,"path":"cv/segmentation/unet_05_swinUnet/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/unet_05_swinUnet/","excerpt":"","text":"2. Swin-Transformer 2021年3月论文：https://arxiv.org/abs/2103.14030源码地址：https://github.com/microsoft/Swin-Transformer参考博客：https://blog.csdn.net/qq_41111734/article/details/116353615预训练权重: swin_small_patch4_window7_224.pth swin transformer(shifted windows Transformer)和resnet一样设计的是一个层次结果很明显的网络，底部的结构处理的数据更多也更局部，顶部的网络处理的数据更少但是语义信息是更加丰富的。不同的是swin主要提取信息的方式是采用transformer，而resnet是卷积核。 在图像分割，让很多人看到了transformer完全替代卷积的可能。而且它的设计思想吸取了resnet的精华，从局部到全局，将transformer设计成逐步扩大感受野的工具。效果说明：在COCO数据集上提升2.6个点(实例分割) 2.7个点（目标检测） 2.1. 网络整体框架2.1.1. Swin vs. VIT1) 像CNN一样，特征层（feature map）更具有层次性（下采样倍率4-&gt; 8-&gt; 16）2) VIT每一层是个整体，并没有进行分割， Swin对窗口进行分割(windows multi-head self attention), 在每个窗口内部进行W-MSA计算，windows之间不进行信息的传递， 减少运算量3) 在更大数据集上做预训练，然后迁移学习，更能够提升效果4) ViT在输入会给embedding进行位置编码。而Swin-T这里则是作为一个可选项（self.ape），Swin-T是在计算Attention的时候做了一个相对位置编码5) ViT会单独加上一个可学习参数，作为分类的token。而Swin-T则是直接做平均，输出分类，有点类似CNN最后的全局平均池化层 2.1.2. swin整体框架整体说明：1) 整个模型采取层次化的设计，一共包含4个Stage（四次下采样），每次下采样特征图宽高分辨率缩小两倍（像CNN一样逐层扩大感受野），但通道数增加两倍2) 在每个Stage里，由Patch Merging和多个Block组成。3) 第一次下采样先进行的patch partition + linear embedding, 其他下采样先进行的patch merging, 但其实功能差不多：主要在每个Stage一开始降低图片分辨率4) 而Block具体结构如右图所示，堆叠偶数次（因为是两个模块成对使用），主要是LayerNorm，MLP，Window Attention 和 Shifted Window Attention组成5) 图中没画，分类任务在最后接入layer norm, 全局池化，全连接层，最后输出分类 2.2. 步骤说明2.2.1. patch partition在输入开始的时候，做了一个patch embedding，将图片切成一个个图块，并嵌入到embedding。上图以单通道为例，我理解这个就是把原始图像中每个4*4*3的区域直接展开成1*1*48的区域，然后做embedding。 有人说也可以用卷积来替代同样的效果，应该也可以，就是理解成两种特征表示，一种是原图特征，一种是卷积后的特征。或者是通过二维卷积层，将stride，kernelsize设置为patch_size大小。设定输出通道来确定嵌入向量的大小。最后将H,W维度展开，并移动到第一维度 2.2.2. Patch Merging该模块的作用是在每个Stage开始前做降采样，用于缩小分辨率，调整通道数（高和宽缩减为原来一半，通道数会翻倍），进而形成层次化的设计，形成从一开始的局部信息搜索到全局信息的提取，同时也能节省一定运算量。这个pooling操作与传统卷积里面的pooling也不太一样，它是将特征图先经过一个space to depth变为1/4，通道数变为原来的4倍，再又一个MLP缩减一半。 2.2.3. W-MSA self attention: https://arxiv.org/abs/1706.03762https://blog.csdn.net/qq_37541097/article/details/117691873 window attention就是按照一定的尺寸将图像划分为不同的window，每次transformer的attention只在window内部进行计算。目的： 减少计算量缺点：窗口之间无法进行信息交互 2.2.4. SW-MSAshift window attention如果只有window attention就会带来每一个像素点的感受野得不到提升的问题，所以它又设计了shift window attention的方法，就是换一下window划分的方式，让每一个像素点做attention计算的window块处于变化之中。那么就起到了提升感受野的作用。目的： 实现不同window之间的信息交互，提升感受野 2.2.5. MLP2.2.6. Relative Position Bias2.2.7. 配置参数2.3. 存在问题在同尺寸通计算量的前提下，swin确实效果远好于resnet。但是有几个问题： 预训练受限于shift操作，对不同尺寸的输入要设计不同的网络，而且也要重新开始训练，这是很难接受的。 和Detr一样训练的时候收敛的太慢。我自己有训练了一下最小的swin-tiny版本，大概训练了一百多轮的时候也才到72～73左右。有这方面改进的想法的朋友可以和我交流，整一篇B类应该没问题。 shift操作其实主要是为了提升感受野，不一定用这种方式 虽然在几个常用benchmark上提升明显，但是在某些实际项目的落地中发现可能还不如vit好用，或者需要精细调参，这个在resnet中是不存在的； 整个模型设计，我认为并没有真正从原理上真正解决cnn和vit之间的问题。transformer放在cv两个问题，local feat无法专注，长序列导致显存炸裂。swin采用的local self attention等于是套着cnn的模式到了transformer中，后面接一个shift window，我理想当中应该是采用一种全新的attention设计去解决这两个问题，我甚至有点好奇把local self attention替换一个普通卷积会怎么样。再者就是shift window那一步略显复杂，毕竟simple is best。 计算损耗：显存要求很高。 3. swin-Unet https://aistudio.baidu.com/aistudio/projectdetail/1985598?_=1651631016452 自从 Transformer 被引入计算机视觉以来，催生了大量相关研究与应用。在图像分割方向，涌现了像 SETR 和 TransUNet 等基于 Transformer 的语义分割网络模型。在TransUNet 中，虽然引入了 Transformer 用于 UNet 编码器，但其特点还是 CNN 与 Transformer 的混合编码，解码上也是基于 CNN 的上采样。直观上看，这种混合编码的结构并没有完全发挥出 Transformer 的优势，并且作为 backbone 的 ViT 结构也需要进一步改进。 Swin Transformer 正好作为视觉 Transformer 领域新的backbone。相较于 TransUNet，去掉CNN编码，用 Swin Transformer 来代替原先的 ViT，将 UNet 全部结构都换成 Swin Transformer。 3.1. 网络结构Swin-UNet由Encoder、Bottleneck、Decoder和跳跃连接组成。 编码器部分，输入图像先进行patch partition，每个patch大小为4x4，输入维度为H/4 x W/4 x 48，经过linear embedding和两个Swin Transformer block后特征图尺寸为H/4 x W/4 x C，然后通过patch merging进行下采样，再经过两个Swin Transformer block后特征图尺寸变为H/8 x W/8 x 2C，最后再进行一次同样的下采样操作即可完成编码器的操作。可以看到，Swin-UNet编码器每次按照2倍来缩小patch的数量，然后按照3倍来扩大特征维度的数量。 Bottleneck则是用了两个连续的Swin Transformer block，这里为防止网络太深不能收敛，所以只用了两个block，在Bottleneck中，特征尺寸保持H/32 x W/32 x 8C不变。 然后是解码器部分。Swin-UNet解码器主要由patch expanding来实现上采样，作为一个完全对称的网络结构，解码器也是每次扩大2倍进行上采样，核心模块由Swin Transformer block和patch expanding组成。 最后是跳跃连接。和unet一样。 3.1.1. 跳跃连接","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"},{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"【Unet系列】transUnet","slug":"cv/segmentation/unet_04_transUnet","date":"2022-04-27T00:21:09.000Z","updated":"2022-04-28T13:15:26.783Z","comments":true,"path":"cv/segmentation/unet_04_transUnet/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/unet_04_transUnet/","excerpt":"","text":"论文:TransUnetUNetTransformer 博客：https://blog.csdn.net/zjiafbaodaozmj/article/details/119063094https://blog.csdn.net/weixin_46435936/article/details/121658305TransUNet阅读笔记与训练尝试 我的想法：焊缝缺陷较小，用这种远程关系的模型是否效果不会有很大的提升，理论上不需要建立特别远的远程关系。 backgroudUNet基本是医学图像分割的魔改基础配方。由于卷积网络的内在局部性，卷积网络在远程关系显式建模上存在限制{感觉意思是一张输入图片左上角和右下角信息很难直接卷在一起}，因而在不同病例数据纹理形状大小相对差别较大时效果欠佳。Transformer的结构针对序列处理设计，能一定程度上解决此问题。文章作者将Transformer应用于医学分割问题，结果也不令人满意。大概是因为Transformer将输入数据作为一维序列处理，失去了大量位置信息所致。 Transformer TransUnetUnet与Transformer的结合，把UNet编码器的一部分替换为了Transformer的注意力格式，其中选择了CNN-Transformer组合结构，这样不仅效果更好，也便于利用早期特征。另外将图片打包成小patch之后embeding位置这步是在CNN提取的特征图上做的，不是在原始输入上做的，总的来讲是个比较简单的部分替换式改进。","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"},{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"VGG16","slug":"cv/VGG16","date":"2022-04-25T05:37:59.000Z","updated":"2022-04-25T09:24:12.496Z","comments":true,"path":"cv/VGG16/","link":"","permalink":"https://tlylft.github.io/cv/VGG16/","excerpt":"","text":"IntroductionVGG是Oxford的Visual Geometry Group的团队在ILSVRC 2014上的相关工作。在这项工作中，主要研究卷积网络深度对大规模图像识别准确率的影响。其主要的贡献是对使用非常小的卷积滤波器（3 X 3）的体系架构来增加网络深度进行彻底的评估。实验结果表明将网络的深度提升至16-19个权重层可以实现对现有技术的显著改进。其在2014年的 imageNet 大规模视觉挑战赛（ILSVRC - 2014）中取得亚军。（冠军是 GoogleNet） VGG优势相比于 LeNet 网络，VGG 网络的一个改进点是将大尺寸的卷积核用多个小尺寸的卷积核代替。 比如：VGG使用 2个3X3的卷积核 来代替 5X5的卷积核，3个3X3的卷积核 代替7X7的卷积核。 这样做的好处是： 在保证相同感受野的情况下，多个小卷积层堆积可以提升网络深度，增加特征提取能力（非线性层增加）。 参数更少。比如 1个大小为5的感受野 等价于 2个步长为1，3X3大小的卷积核堆叠。（即1个5X5的卷积核等于2个3X3的卷积核）。而1个5X5卷积核的参数量为 5*5*C^2。而2个3X3卷积核的参数量为 2*3*3*C^2。 很显然，18C^2 &lt; 25C^2。 3X3卷积核更有利于保持图像性质。 注：这里参数量的计算，忽略了偏置。并且假设 输入和输出通道数都为C感受野公式：一个大小为5的感受野，等于2个3X3的卷积核堆叠，具体如下所示： VGG网络结构VGG有两种结构，分别是VGG16和VGG19。通常人们说的VGG是指VGG16（13层卷积层+3层全连接层）。下图展示VGG网络的6中不同结构，VGG16：包含16个隐藏层（13个卷积层+3个全连接层），下图D列。VGG19：包含19个隐藏层（16个卷积层+3个全连接层），下图E列。 可视化：https://dgschwend.github.io/netscope/#/preset/vgg-16 Pretrained model‘vgg11’: ‘https://download.pytorch.org/models/vgg11-bbd30ac9.pth‘,‘vgg13’: ‘https://download.pytorch.org/models/vgg13-c768596a.pth‘,‘vgg16’: ‘https://download.pytorch.org/models/vgg16-397923af.pth‘,‘vgg19’: ‘https://download.pytorch.org/models/vgg19-dcbb9e9d.pth‘,‘vgg11_bn’: ‘https://download.pytorch.org/models/vgg11_bn-6002323d.pth‘,‘vgg13_bn’: ‘https://download.pytorch.org/models/vgg13_bn-abd245e5.pth‘,‘vgg16_bn’: ‘https://download.pytorch.org/models/vgg16_bn-6c64b313.pth‘,‘vgg19_bn’: ‘https://download.pytorch.org/models/vgg19_bn-c79401a0.pth‘ Reference论文：[1] Simonyan K , Zisserman A . Very Deep Convolutional Networks for Large-Scale Image Recognition[J]. Computer Science, 2014. torch代码：https://github.com/KKKSQJ/DeepLearning/tree/master/classification/vggNet 参考：https://zhuanlan.zhihu.com/p/460777014","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"dicom类型图像文件","slug":"cv/dicom_image","date":"2022-04-24T06:03:56.000Z","updated":"2023-08-11T09:31:56.865Z","comments":true,"path":"cv/dicom_image/","link":"","permalink":"https://tlylft.github.io/cv/dicom_image/","excerpt":"","text":"backgroud文件涉及领域： 医学图像 工业数字探测图像 文件结构： 图像信息 图像 Tags 图像通道表示 https://blog.csdn.net/charce_you/article/details/99616021 不同图像格式，每个通道的表示范围有可能不同，常用的范围如下： CV_8U - 8位无符号整数（0..255） CV_8S - 8位有符号整数（-128..127） CV_16U - 16位无符号整数（0..65535） CV_16S - 16位有符号整数（-32768..32767） CV_32S - 32位有符号整数（-2147483648..2147483647） CV_32F - 32位浮点数（-FLT_MAX..FLT_MAX，INF，NAN） CV_64F - 64位浮点数（-DBL_MAX..DBL_MAX，INF，NAN） 图像格式DICOM图像读取解析1pip install pydicomDICONDE VS. DICOM 图像读写工具下面代码针对当前项目的工业管道探伤图像123456789101112131415# pip install pydicomimport pydicom# 图像读取dcm = pydicom.dcmread(file_path)tag1 = dcm.PatientID #读取PatientID 的值img = dcm.pixel_array # 读取图像数组， 默认读取出来是int16类型的np.array## 由于项目的图像数据在存储时是uint16类型，所以需要进行转换img = # 图像展示# 图像写入## 不变大小的转换dcm.PatientID = new_id #改变属性dcm.pixel_array = new_img # 改变图像数组ds.Rows,ds.Columns = data_rotated.shape # 如果改变图像大小，需要修改对应值dcm.save_as(new_file_path)","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"【mmsegmentation】05-mmcv","slug":"cv/segmentation/mmsegmentation_05_mmcv","date":"2022-04-24T05:50:36.000Z","updated":"2022-05-12T01:47:56.508Z","comments":true,"path":"cv/segmentation/mmsegmentation_05_mmcv/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/mmsegmentation_05_mmcv/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/336081587","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"【mmsegmentation】04-schedule配置","slug":"cv/segmentation/mmsegmentation_04_schedule","date":"2022-04-24T05:39:02.000Z","updated":"2022-05-12T01:47:50.935Z","comments":true,"path":"cv/segmentation/mmsegmentation_04_schedule/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/mmsegmentation_04_schedule/","excerpt":"","text":"todo: 补充笔记https://zhuanlan.zhihu.com/p/355272459https://blog.csdn.net/qq_43403200/article/details/121810273 1. backgroundschedule配置基于mmcv Runner核心组件。https://zhuanlan.zhihu.com/p/355272459Runner 是 OpenMMLab 系列框架中训练部分的引擎，重要性不言而喻，其核心功能和特性如下： 负责 OpenMMLab 中所有框架的训练过程调度，是一个基础但功能丰富的类 支持定制工作流以满足训练过程中各状态自由切换，目前支持训练和验证两个工作流 提供了 Epoch 和 Iter 为基础的迭代模式以满足不同场景，例如 MMDetection 默认采用 Epoch (配置文件中相关参数都是以 Epoch 为单位)，而 MMSegmentation 默认采用 Iter (配置文件中相关参数都是以 Iter 为单位) 配合各类 Hook，对外提供了灵活的扩展能力，注入不同类型的 Hook，就可以在训练过程中以一种优雅的方式实现扩展功能 2. schedule config123456789# optimizeroptimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)optimizer_config = dict()# learning policylr_config = dict(policy='poly', power=0.9, min_lr=1e-4, by_epoch=False)# runtime settingsrunner = dict(type='IterBasedRunner', max_iters=80000)checkpoint_config = dict(by_epoch=False, interval=8000)evaluation = dict(interval=8000, metric='mIoU', pre_eval=True) 2.1. optimizertorch.optim下的优化器，可选[SGD, Adam, AdamW, RMSprop, Adamax] 2.2. learning policylr_config： 学习率策略，默认为poly????? 2.3. checkpoint savingby_epoch表示是否按照epoch的方式进行记录，interval表示每多少个周期保存一次输出结果 2.4. workflow 假设只想运行训练工作流，则可以设置 workflow = [(‘train’, 1)]，表示 data_loader 中的数据进行迭代训练 假设想运行训练和验证工作流，则可以设置 workflow = [(‘train’, 3), (‘val’,1)]，表示先训练 3 个 epoch ，然后切换到 val 工作流，运行 1 个 epoch，然后循环，直到训练 epoch 次数达到指定值 工作流设置非常自由，例如你可以先验证再训练 workflow = [(‘val’, 1), (‘train’,1)] 2.5. evaluation表示验证测量，interval表示多少个interval进行一次验证并输出验证结果，默认每8K个iterators进行一次验证；metric表示你使用的验证指标，默认为mIoU。评价指标在mmseg/core/evaluation/metrics.py， 支持[‘mIoU’, ‘mDice’, ‘mFscore’]和aAcc(mPA平均像素准确度，无论是否输入都会输出),想使用多个指标，可以采用传入数组的方式1evaluation = dict(interval=5, metric=['mIoU', 'mDice'], pre_eval=True) 2.6. runner: 整合 runtime settingsmmcv 提供IterBasedRunner和EpochBasedRunner两种迭代模式， 继承BaseRunner 2.6.1. 基于iterationIterBasedRunner 模式没有 epoch 的概念，故 IterBasedRunner 的 run 方法有些许改动 工作流终止条件不再是 epoch，而是 iter Hook 的生命周期方法也不涉及 epoch，全部是 iter 相关方法 虽然本类中不需要 epoch 参数，但是 epoch 参数在很多场景比较有用，故还是需要通过 IterLoader 得到 假设数据长度是 1024，batch=4，那么 dataloader 长度是 1024/4=256, 也就是一个 epoch 是 256 次迭代，在 Iter 训练模式下，计划训练 100000 个迭代，那么实际上运行了 100000//256=39 个 epoch。1runner &#x3D; dict(type&#x3D;&#39;IterBasedRunner&#39;, max_iters&#x3D;300) 2.6.2. 基于epoch1runner &#x3D; dict(type&#x3D;&#39;EpochBasedRunner&#39;, max_epochs&#x3D;300)","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"【mmsegmentation】03-模型配置","slug":"cv/segmentation/mmsegmentation_03_models","date":"2022-04-24T05:37:41.000Z","updated":"2022-05-12T01:47:54.668Z","comments":true,"path":"cv/segmentation/mmsegmentation_03_models/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/mmsegmentation_03_models/","excerpt":"","text":"配置文件对num_classes进行修改decode_head 和 auxiliary_head的num_class 修改为自己的类别+背景数，做最后全连接层 对loss函数进行修改mmseg中的loss函数定义在mmseg/models/losses/_ int _.py下面123456789101112131415# Copyright (c) OpenMMLab. All rights reserved.from .accuracy import Accuracy, accuracyfrom .cross_entropy_loss import (CrossEntropyLoss, binary_cross_entropy, cross_entropy, mask_cross_entropy)from .dice_loss import DiceLossfrom .focal_loss import FocalLossfrom .lovasz_loss import LovaszLossfrom .utils import reduce_loss, weight_reduce_loss, weighted_loss__all__ = [ 'accuracy', 'Accuracy', 'cross_entropy', 'binary_cross_entropy', 'mask_cross_entropy', 'CrossEntropyLoss', 'reduce_loss', 'weight_reduce_loss', 'weighted_loss', 'LovaszLoss', 'DiceLoss', 'FocalLoss'] 模型推理","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"【mmsegmentation】02-数据集配置","slug":"cv/segmentation/mmsegmentation_02_dataset","date":"2022-04-24T05:18:20.000Z","updated":"2022-05-18T13:51:14.838Z","comments":true,"path":"cv/segmentation/mmsegmentation_02_dataset/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/mmsegmentation_02_dataset/","excerpt":"","text":"数据集准备数据集位置（可以自己定义文件目录）：123456data&#x2F;&#123;dataset&#125;-- Images-- Labels-- train.txt-- test.txt-- val.txt 定义数据集加载类1234567891011121314151617181920# location: mmseg/datasets/&#123;dataset&#125;.pyfrom .builder import DATASETSfrom .custom import CustomDatasetfrom .pipelines import LoadNrrdLabels@DATASETS.register_module()class EnnWeldDataset(CustomDataset): # 定义类别名 CLASSES = ('background', 'circle', 'line', 'in_penetration', 'in_fusion') # 定义每个类别的显示颜色 --show result使用 PALETTE = [[0, 0, 0], [128, 64, 128], [244, 35, 232], [70, 70, 70], [102, 102, 156]] # 传递参数可以根据自己的数据集格式需求进行调整，一般不用改变 def __init__(self, **kwargs): super(EnnWeldDataset, self).__init__( # img_suffix='.png', # seg_map_suffix='.png', reduce_zero_label=False, **kwargs) self.gt_seg_map_loader = LoadNrrdLabels() assert self.file_client.exists(self.img_dir) CustomDataset源码中，训练过程中验证集标签的加载写在了这个类里面，没有在pipeline中配置，而且直接默认加载的png格式的图片标签，对nrrd的数据标签不太友好，解决办法： 1) 制作数据集时直接存成图像格式的标签 2）自定义数据类时，继承CustomDataset覆写self.gt_seg_map_loader为自定义的加载标签的组件函数。 test.py时生成验证指标，用到dataset.pre_eval()，这个保证self.gt_seg_map_loader读取的groundtruth是正确的,还有model.inference返回的处理标签是正确的，就不用进行调整。 定义数据加载pipeline组件1234567mmseg&#x2F;datasets&#x2F;pipelines&#x2F;-- __init__.py-- compose.py-- fomatting.py-- loading.py-- transforms.py-- &#123;其它自定义组件文件&#125;.py 数据集配置文件configs/_base_/datasets/{dataset}.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657dataset_type = 'ADE20KDataset' #数据集加载类data_root = 'data/ade/ADEChallengeData2016' # 数据集准备目录# 串联组件流程train_pipeline = [ dict(type='LoadImageFromFile'), dict(type='LoadAnnotations', reduce_zero_label=True), dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)), dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.75), dict(type='RandomFlip', prob=0.5), dict(type='PhotoMetricDistortion'), dict(type='Normalize', **img_norm_cfg), dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255), dict(type='DefaultFormatBundle'), dict(type='Collect', keys=['img', 'gt_semantic_seg']),]test_pipeline = [ dict(type='LoadImageFromFile'), dict( type='MultiScaleFlipAug', img_scale=(2048, 512), # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75], flip=False, transforms=[ dict(type='Resize', keep_ratio=True), dict(type='RandomFlip'), dict(type='Normalize', **img_norm_cfg), dict(type='ImageToTensor', keys=['img']), dict(type='Collect', keys=['img']), ])]# 整合train, val, test数据集类及加载流程data = dict( samples_per_gpu=4, # 每张GPU的样本数，可以简单理解为batch_size workers_per_gpu=4, # 表示多线程数 train=dict( type=dataset_type, data_root=data_root, img_dir='images/training', ann_dir='annotations/training', # 也可以是目录列表 # split = 'train.txt', # 如果图片目录没有划分数据集，而是通过文件指定，可以设置这个参数，data_root的相对路径， 也可以是文件列表 pipeline=train_pipeline), val=dict( type=dataset_type, data_root=data_root, img_dir='images/validation', ann_dir='annotations/validation', # split = 'val.txt', # 如果图片目录没有划分数据集，而是通过文件指定，可以设置这个参数，data_root的相对路径， 也可以是文件列表 pipeline=test_pipeline), test=dict( type=dataset_type, data_root=data_root, img_dir='images/validation', ann_dir='annotations/validation', # split = 'test.txt', # 如果图片目录没有划分数据集，而是通过文件指定，可以设置这个参数，data_root的相对路径， 也可以是文件列表 pipeline=test_pipeline))","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"语义分割","slug":"cv/segmentation/segmentation","date":"2022-04-22T02:46:08.000Z","updated":"2022-05-12T01:47:58.760Z","comments":true,"path":"cv/segmentation/segmentation/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/segmentation/","excerpt":"","text":"主干网络（backbone)：通常是卷积网络的堆叠，来做特征提取，例如 ResNet, HRNet 解码头 (decoder head): 用于语义分割图的解码的组件（得到分割结果） 在语义分割里，一些方法会让解码头组件的学习率大于主干网络的学习率，这样可以获得更好的表现或更快的收敛。 1. 评价指标 evaluate indicatorhttps://blog.csdn.net/qq_36201400/article/details/109180060 Truth:真实标签T0: 真实backgroundT1: 真实目标区域Groud Truth Prediction:预测标签P0: 预测backgroundP1: 预测目标区域 T: 预测正确F：预测错误P：预测为正样本N：预测为负样本TP：表示测试样本中猫能够被准确地预测成猫TN： 表示测试样本中非猫（狗）能够被准确地预测成非猫（狗)FP：表示测试样本中非猫能够被准确地预测成猫FN：表示表示测试样本中猫能够被准确地预测成非猫 PA: Pixel Accuracy 像素准确率准确率（Accuracy）公式：Accuracy = (TP + TN) / (TP + TN + FP + FN)意义：对角线计算。预测结果中正确的占总预测值的比例（对角线元素值的和 / 总元素值的和） CPA: 类别像素准确率精准率（Precision），对应：语义分割的类别像素准确率 CPA公式：Precision = TP / (TP + FP) 或 TN / (TN + FN)意义：竖着计算。预测结果中，某类别预测正确的概率 mPA: Mean pixel Accuracy 平均像素精确度MPA = sum(CPA) / 类别数 1.1. Dice对于分割过程中的评价标准主要采用Dice相似系数(Dice Similariy Coefficient,DSC),Dice系数是一种集合相似度度量指标,通常用于计算两个样本的相似度,值的范围0-1,分割结果最好时值为1 ,最差时值为0(我的理解：大概是交集比并集，但并集不是严格意义的并集，重叠部分也要多算进去)123456789101112def dice_coef(output, target):#output为预测结果 target为真实结果 smooth = 1e-5 #防止0除 if torch.is_tensor(output): output = torch.sigmoid(output).data.cpu().numpy() if torch.is_tensor(target): target = target.data.cpu().numpy() intersection = (output * target).sum() # 默认标签都是1？？？ return (2. * intersection + smooth) / \\ (output.sum() + target.sum() + smooth) 1.2. IOU: Intersection over Union 平均交并比(这个才是交集比并集)IoU分数是对象类别分割问题的标准性能度量。 给定一组图像，IoU测量给出了在该组图像中存在的对象的预测区域和Ground Truth区域之间的相似性，并且由以下等式定义：12345678910111213def iou_score(output, target): smooth = 1e-5 if torch.is_tensor(output): output = torch.sigmoid(output).data.cpu().numpy() if torch.is_tensor(target): target = target.data.cpu().numpy() output_ = output &gt; 0.5 target_ = target &gt; 0.5 intersection = (output_ &amp; target_).sum() union = (output_ | target_).sum() return (intersection + smooth) / (union + smooth) 1.3. TPR:True Positive Rate(真阳性率-召回率)预测正确的样本占总阳性样本（所有实际为True的样本）的比例,越大越好.又称为Sensitivity:灵敏度$TPR = Recall = Sensitivity = {TP\\over TP+FN}$ 1.4. Precision:精确率表示预测为阳性的样本中,预测正确的比例,越大越好$precision = {TP\\over TP+FP}$ 1.5. FPR:False Positive Rate(假阳性率-误报率)预测错误的样本占总负样本（所有实际为false的样本）的比例,越小越好.又称为Sensitivity:灵敏度$FPR = {FP\\over FP+TN}$ 1.6. Hausdorff_95 (95% HD)todo","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"},{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"【mmsegmentation】01-Quick Start","slug":"cv/segmentation/mmsegmentation_01_quick","date":"2022-04-17T12:54:40.000Z","updated":"2022-06-06T09:06:13.475Z","comments":true,"path":"cv/segmentation/mmsegmentation_01_quick/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/mmsegmentation_01_quick/","excerpt":"","text":"https://www.bilibili.com/video/BV1ub4y187DP?p=3 1. backgroudMMSegmentation是一个基于PyTorch的开源语义分割工具箱。它是OpenMMLab项目的一部分。 1.1. OpenMMLab官网：https://openmmlab.com/官方github：https://github.com/open-mmlab官方bilibili: https://space.bilibili.com/1293512903 2. MMSegmentation官方github：https://github.com/open-mmlab/mmsegmentation官方文档：https://mmsegmentation.readthedocs.io/zh_CN/latest/index.html 2.1. 主要特性 统一的基准平台 将各种各样的语义分割算法集成到了一个统一的工具箱，进行基准测试。 模块化设计MMSegmentation 将分割框架解耦成不同的模块组件，通过组合不同的模块组件，用户可以便捷地构建自定义的分割模型。 丰富的即插即用的算法和模型MMSegmentation 支持了众多主流的和最新的检测算法，例如 PSPNet，DeepLabV3，PSANet，DeepLabV3+ 等。 速度快训练速度比其他语义分割代码库更快或者相当。2.2. 模型库支持backbone:123456ResNetResNeXtHRNetResNeStMobileNetV2MobileNetV3 支持算法：12345678910111213141516171819202122FCNPSPNetDeepLabV3PSANetDeepLabV3+UPerNetNonLocal NetEncNetCCNetDANetAPCNetGCNetDMNetANNOCRNetFast-SCNNSemantic FPNPointRendEMANetDNLNetCGNetMixed Precision (FP16) Training 2.3. 安装参考官方GitHub安装流程123456789101112131415161718# 1. 创建环境conda create -n mmseg python=3.7conda activate mmseg# 2. 安装pytorchpip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html# 3. 根据git版本推荐安装mmcv,一般安装full版本# https://mmcv.readthedocs.io/en/latest/get_started/installation.htmlpip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html# 4. 安装mmsegpip install mmsegmentation# 或者需要修改源码git clone https://github.com/open-mmlab/mmsegmentation.gitcd mmsegmentationpip install -e . # 或者 \"python setup.py develop\" cuda10.1环境下安装123456789101112131415161718192021# 1. 创建环境conda create -n mmseg python=3.8conda activate mmseg# 2. 安装pytorch# pip install torch==1.8.1+cu101 torchvision==0.9.1+cu101 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.htmlpip install https://download.pytorch.org/whl/cu101/torchvision-0.8.0-cp38-cp38-linux_x86_64.whlpip install torch==1.7.0+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html# 3. 根据git版本推荐安装mmcv,一般安装full版本# https://mmcv.readthedocs.io/en/latest/get_started/installation.html# pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.1/index.htmlpip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.7.0/index.html# 4. 安装mmseg, 找mmcv版本对应版本# https://github.com/open-mmlab/mmsegmentation/blob/master/docs/zh_cn/get_started.md#installationpip install mmsegmentation# 或者需要修改源码git clone https://github.com/open-mmlab/mmsegmentation.gitcd mmsegmentationpip install -e . # 或者 \"python setup.py develop\"pip install wcwidth==0.2.5 验证1python -c \"import mmsegmentation; print(mmsegmentation.__version__)\" 2.4. demo运行 quick start2.4.1. 数据集准备眼球红血丝demo数据集：CHASE DB12.4.2. 数据转换在mmsegmentation/data下放置或生成对应数据集123456789101112131415python tools&#x2F;convert_datasets&#x2F;chase_db1.py &#x2F;path&#x2F;to&#x2F;CHASEDB1.zip# 将生成数据的目录结构mmsegmentation├── mmseg├── tools├── configs├── data│ ├── CHASE_DB1│ │ ├── images│ │ │ ├── training│ │ │ ├── validation│ │ ├── annotations│ │ │ ├── training│ │ │ ├── validation 2.4.3. 模型训练1python tools&#x2F;train.py configs&#x2F;unet&#x2F;deeplabv3_unet_s5-d16_128x128_40k_chase_db1.py 2.4.4. 模型预测1python tools&#x2F;predict.py configs&#x2F;unet&#x2F;deeplabv3_unet_s5-d16_128x128_40k_chase_db1.py &#x2F;path&#x2F;to&#x2F;model.pth 3. 框架解读todo:!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!https://zhuanlan.zhihu.com/p/411494961 配置文件框架基于配置文件组装，实现对模型训练和预测的全过程。 有4种基本组件类型： 数据集(dataset)，模型(model)，训练策略(schedule)和运行时的默认设置(default runtime)，可以组合配置 在 config/_base_ 文件夹下的组件来构建的配置为 原始配置 (primitive)，所有其他的配置文件都应该继承自这个原始配置文件。这样就能保证配置文件的最大继承深度为 3。 主配置文件命名1&#123;model&#125;_&#123;backbone&#125;_[misc]_[gpu x batch_per_gpu]_&#123;resolution&#125;_&#123;iterations&#125;_&#123;dataset&#125; {model}: 模型种类，例如 psp， deeplabv3 等等 {backbone}: 主干网络种类，例如 r50 (ResNet-50)， x101 (ResNeXt-101) [misc]: 模型中各式各样的设置/插件，例如 dconv， gcb， attention， mstrain [gpu x batch_per_gpu]: GPU数目 和每个 GPU 的样本数， 默认为 8x2 {iterations}: 训练迭代轮数，如160k {dataset}: 数据集，如 cityscapes， voc12aug， ade 3.1. 数据集配置https://github.com/open-mmlab/mmsegmentation/blob/master/docs/zh_cn/dataset_prepare.md 3.2. 模型配置3.3. 模型训练3.3.1. 框架设定标准 默认使用 4 卡分布式训练 ResNet 网络是基于 ResNetV1c 的变种，在这里输入层的 7x7 卷积被 3个 3x3 取代。参考 https://arxiv.org/pdf/1812.01187.pdf 以 torch.cuda.max_memory_allocated() 的最大值作为 GPU 占用率，通常比 nvidia-smi 显示的要少 推理时间：网络 forward 时间+后处理的时间作为推理时间，不包括数据加载的时间 推理模式（两种）：— slide 模式（滑动模式）：测试的配置文件字段 test_cfg 会是 dict(mode=’slide’, crop_size=(769, 769), stride=(513, 513)). 在这个模式下，从原图中裁剪多个小图分别输入网络中进行推理。小图的大小和小图之间的距离由 crop_size 和 stride 决定，重合区域会进行平均— whole 模式 （全图模式）：测试的配置文件字段 test_cfg 会是 dict(mode=’whole’). 在这个模式下，全图会被直接输入到网络中进行推理。 对于 769x769 下训练的模型，我们默认使用 slide 进行推理，其余模型用 whole 进行推理 对于输入大小为 8x+1 （比如769），我们使用 align_corners=True。其余情况，对于输入大小为 8x (比如 512，1024)，我们使用 align_corners=False 3.3.2. 模型训练https://mmsegmentation.readthedocs.io/zh_CN/latest/train.html 可以执行分布式训练和非分布式训练，分别使用 MMDistributedDataParallel 和 MMDataParallel 命令。 所有输出（日志文件和检查点）将保存到工作目录，该目录在config文件中的work_dir指定。 默认情况下，会在一些迭代后在验证集上评估模型，可以通过在训练配置中添加interval参数来更改评估间隔。1evaluation &#x3D; dict(interval&#x3D;4000) # This evaluate the model per 4000 iterations. 3.3.2.1. 单卡GPU训练123456python tools/train.py $&#123;CONFIG_FILE&#125; [可选参数]# 指定GPU --gpu-id 0# 指定保存目录 --work-dir &#123;dir_path&#125; 默认是 ./work_dirs/&#123;cofig_name&#125;# 指定加载检查点 --load-from# --auto-resume python tools/train.py $&#123;CONFIG_FILE&#125; --gpu-id 0 3.3.2.2. 使用 CPU 训练123# 禁用GPUexport CUDA_VISIBLE_DEVICES=-1python tools/train.py $&#123;CONFIG_FILE&#125; [可选参数] 3.3.2.3. 多卡GPU训练1sh tools/dist_train.sh $&#123;CONFIG_FILE&#125; $&#123;GPUS&#125; [可选参数] 3.3.2.4. 在单个机器上启动多个任务3.3.2.5. 使用多台机器训练3.4. 模型测试123456789# 单卡 GPU 测试python tools&#x2F;test.py $&#123;配置文件&#125; $&#123;检查点文件&#125; [--out $&#123;结果文件&#125;] [--eval $&#123;评估指标&#125;] [--show]# CPU: 禁用 GPU 并运行单 GPU 测试脚本export CUDA_VISIBLE_DEVICES&#x3D;-1python tools&#x2F;test.py $&#123;配置文件&#125; $&#123;检查点文件&#125; [--out $&#123;结果文件&#125;] [--eval $&#123;评估指标&#125;] [--show]# 多卡GPU 测试.&#x2F;tools&#x2F;dist_test.sh $&#123;配置文件&#125; $&#123;检查点文件&#125; $&#123;GPU数目&#125; [--out $&#123;结果文件&#125;] [--eval $&#123;评估指标&#125;] RESULT_FILE: pickle 格式的输出结果的文件名，如果不专门指定，结果将不会被专门保存成文件。（MMseg v0.17 之后，args.out 将只会保存评估时的中间结果或者是分割图的保存路径。） EVAL_METRICS: 在结果里将被评估的指标。这主要取决于数据集， mIoU 对于所有数据集都可获得，像 Cityscapes 数据集可以通过 cityscapes 命令来专门评估，就像标准的 mIoU一样。 —show: 如果被指定，分割结果将会在一张图像里画出来并且在另一个窗口展示。它仅仅是用来调试与可视化，并且仅针对单卡 GPU 测试。请确认 GUI 在您的环境里可用，否则您也许会遇到报错 cannot connect to X server —show-dir: 如果被指定，分割结果将会在一张图像里画出来并且保存在指定文件夹里。它仅仅是用来调试与可视化，并且仅针对单卡GPU测试。使用该参数时，您的环境不需要 GUI。 —eval-options: 评估时的可选参数，当设置 efficient_test=True 时，它将会保存中间结果至本地文件里以节约 CPU 内存。请确认您本地硬盘有足够的存储空间（大于20GB）。（MMseg v0.17 之后，efficient_test 不再生效，我们重构了 test api，通过使用一种渐近式的方式来提升评估和保存结果的效率。）","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"unet","slug":"cv/segmentation/unet_01_unet","date":"2022-03-30T02:16:29.000Z","updated":"2022-05-06T05:31:34.144Z","comments":true,"path":"cv/segmentation/unet_01_unet/","link":"","permalink":"https://tlylft.github.io/cv/segmentation/unet_01_unet/","excerpt":"","text":"看一半的视频：https://www.bilibili.com/video/BV1rz4y117rR?p=10&amp;spm_id_from=pageDriverhttps://blog.csdn.net/weixin_44791964/article/details/108866828https://github.com/bubbliiiing/unet-pytorchhttps://github.com/ggyyzm/pytorch_segmentation 重新看：https://www.bilibili.com/video/BV1LT4y1v7CM?p=2&amp;spm_id_from=pageDriver交叉熵损失函数和softmax笔记 结构图核心思想为结合浅层特征与深层特征，共进行四次下采样与四次上采样。观察网络结构图，每层上采样结果都与裁剪后的对应浅层信息拼接起来，再通过卷积后输入下次上采样。","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"},{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"}]},{"title":"yolo项目代码","slug":"cv/yolo_project","date":"2022-03-23T11:54:09.000Z","updated":"2022-08-15T00:15:42.130Z","comments":true,"path":"cv/yolo_project/","link":"","permalink":"https://tlylft.github.io/cv/yolo_project/","excerpt":"","text":"1. 数据集准备 images为图片目录，里面存放相关图片即可。 labels为标签目录，里面存放图片对应的标签信息，格式要求为 image_name.txt yolov3:1234-- images-- labels-- valid_data_path.txt-- train_data_path.txtyolov5:123456-- train -- images -- labels-- valid -- images -- labels 2. 训练部分2.1. 训练参数详解https://blog.csdn.net/it_charge/article/details/119208680https://blog.csdn.net/m0_50294896/article/details/120606979配置文件相关参数：123456data: 数据集配置文件yaml路径，里面包含训练集和验证集的路径和标签cfg: 模型的配置文件，包含各层的结构参数hyp: 超参数配置- masaic: 1.0 大致原理就是将四个图片进行拼接成一张图片(原理解析：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_41011242&#x2F;article&#x2F;details&#x2F;110439183)0.0 关闭马赛克图像增强weights: 指定一个训练好的模型路径训练相关参数：1234567891011device: 训练时使用的设备,i.e. 0 or 0,1,2,3 or cpuepochs: 设置训练的轮数batch-size: 设置一次跑多少的数据输入到网络当中img-size: 分别设置训练集和测试集的大小evolve:生效后对超参数进行净化,作用是寻找最优超参数的方式，方法是利用遗传算法自动搜索超参数。single_cls： 设置为True，则只训练单标签，如果训练集中存在多个物体标签，在dataset初始化时会将所有种类物体标签合并为一个标签0。rect: 默认false, 矩形训练，去除矩形图片转换为416\\*416正方形后padding产生的冗余信息，加速模型推理过程noautoanchor: 设置在目标检测任务中是否采用锚点 &#x2F; 锚框freeze: Freeze layers: backbone&#x3D;10, first3&#x3D;0 1 2加载和保存位置：123456resume: 是否在最近训练的一个模型基础上继续训练nosave: 生效后只保存最后一次 pt 文件noval: 生效后只在最后一次进行测试project: 保存位置的文件夹根目录name: 保存这一次训练的文件夹，最后保存在project&#x2F;name目录下，文件夹名重复会自动后缀+1exist-ok: 如果文件夹已经存在，是否覆盖 3. 预测部分4. 部署调用4.1. model load参数方式参考：Flask部署YOLOv5 4.2. torchscript 转换为torchscript模型1python export.py --weights path&#x2F;to&#x2F;yolov5s.pt --img 640 --batch 1 # export at 640x640 with batch size 1 detector文件","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"【读书笔记】财报","slug":"reading/finance_report","date":"2022-02-16T04:37:12.000Z","updated":"2023-08-10T12:05:15.408Z","comments":true,"path":"reading/finance_report/","link":"","permalink":"https://tlylft.github.io/reading/finance_report/","excerpt":"","text":"财报本身，如书中所说，乃用以反映公司经营状况，其作用有如“战情仪表板”，能将一家公司所有业务活动，依所谓“产、销、人、发、财”之类的功能，予以有条不紊地整合呈现，使经营者对公司繁复多变的活动统筹兼顾，产生企业经营上的“综效”（synergy）。 财报本身不是经营的终点，而是起点。因为真正重要的，乃是这些报表故事背后的策略、愿景、文化和统理这些因素。换句话说，经营者应以财报为起点，探究其背后的来龙去脉，从而思考未来该怎么做，带动公司因应改变、创造商机。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"【CV】02- 图片标注","slug":"cv/cv_image_label","date":"2022-02-16T01:01:52.000Z","updated":"2023-08-11T09:16:14.379Z","comments":true,"path":"cv/cv_image_label/","link":"","permalink":"https://tlylft.github.io/cv/cv_image_label/","excerpt":"","text":"1. labelme 对图像进行多边形，矩形，圆形，多段线，线段，点形式的标注（可用于目标检测，图像分割，等任务）。 对图像进行进行 flag 形式的标注（可用于图像分类 和 清理 任务）。 视频标注 生成 VOC 格式的数据集（for semantic / instance segmentation） 生成 COCO 格式的数据集（for instance segmentation） 1.1. 安装123activate envspip install labelmelabelme 常用命令行参数：12345--flags： comma separated list of flags 或者 file containing flags--labels：comma separated list of labels 或者 file containing labels--nodata：stop storing image data to JSON file--nosortlabels：stop sorting labels--output：指定输出文件夹 1.2. 使用分类标注1labelme &#123;data_dir&#125; --flags flags.txt --nodata目标检测1labelme data_annotated --labels labels.txt --nodata --autosave 2. labelimg123activate envspip install labelimglabelimg 修改保存目录： change save dir设置自动保存： View-&gt;auto save mode快捷键：A/D 上下一张W 绘制矩形框 3. 问题使用问题：labelme/labelimg 不是内部或外部命令，也不是可运行的程序问题解决. 解决方案 重新安装12pip uninstall labelxxxpip install labelxxx 找到labelme的安装目录12cd env_path\\site-package\\labelmepython __main__.py","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"【图像处理】PIL库","slug":"cv/package_PIL","date":"2022-02-11T06:10:48.000Z","updated":"2023-08-11T09:20:41.968Z","comments":true,"path":"cv/package_PIL/","link":"","permalink":"https://tlylft.github.io/cv/package_PIL/","excerpt":"","text":"https://mp.weixin.qq.com/s/NQh4lDQf2NjPUiGnFhZ06A PIL：Python Imaging Library，是Python环境下最受欢迎的图像处理库，木有之一。 安装1pip install pillow 引用12import numpy as np from PIL import Image,ImageFilter,ImageDraw,ImageFont 使用图片读写pillow无论读取什么文件，都是默认RGB?1234567891011# 读取图片img = Image.open(\"./data/abc.jpg\")print(img.format, img.size, img.mode)print(img.info)img# output: JPEG (641, 641) RGB# &#123;'jfif': 257, 'jfif_version': (1, 1), 'dpi': (72, 72), 'jfif_unit': 1, 'jfif_density': (72, 72)&#125;# 保存图片img.save(\"./data/猫咪图片.png\") 图片与array互转12345678910# image -&gt; np.arrayimg = Image.open(\"./data/猫咪图片.jpg\")arr = np.array(img)print(arr.shape, arr.dtype) # output:(641, 641, 3) uint8# np.array -&gt; imagearr = (np.ones((256,256))*np.arange(0,256)).astype(np.uint8)img = Image.fromarray(arr)img base64编码灰度图12img = Image.open(\"./data/猫咪图片.jpg\")img.convert(\"L\") 图片通道分离与合并12345# 分离通道r,g,b = img.split() b # 合并通道Image.merge(mode = \"RGBA\", bands = [r,g,b,r]) 调整图片尺寸12345print(img.size)img_resized = img.resize((300,300))print(img_resized.size)# output: (641, 641)# (300, 300) 截取部分区域123img_croped = img.crop(box = [78,24,455,320]) print(img_croped.size)# output:(377, 296) 图片旋转12#以center为中心逆时针旋转img_rotated = img.rotate(15,center = (0,0)) 图片翻转1234# 左右翻转img_left_right = img.transpose(Image.FLIP_LEFT_RIGHT)# 上下翻转img_top_bottom = img.transpose(Image.FLIP_TOP_BOTTOM) 提取图片边缘1img_edges = img.filter(ImageFilter.FIND_EDGES) 高斯模糊1img_blur = img.filter(ImageFilter.GaussianBlur(radius=3)) 在图片上绘制文字或线条12345678910111213141516171819img = Image.open(\"./data/猫咪图片.jpg\")draw = ImageDraw.Draw(img)## 绘制文字arial = ImageFont.truetype('./data/simsun.ttc', 46)draw.text((250,450),\"敢梭哈吗?\",font =arial, fill=\"white\")## 绘制直线draw.line([0,0,641,641],fill = \"red\",width = 5)## 绘制矩形draw.rectangle([78,24,455,320], fill=None, outline ='lawngreen',width = 5)## 绘制椭圆draw.arc(xy = [78,24,455,320],start = 0,end = 360,fill=\"red\",width=5)## 粘贴其他图片new_img = img.resize((150,150))img.paste(new_img,box = [460,50])","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"【图像处理】opencv库","slug":"cv/package_opencv","date":"2022-02-08T08:45:59.000Z","updated":"2023-08-11T09:20:29.552Z","comments":true,"path":"cv/package_opencv/","link":"","permalink":"https://tlylft.github.io/cv/package_opencv/","excerpt":"","text":"安装 python安装123456# pip install opencv-python# 建议安装3.4.3以下的版本？因为新版本有经典算法进行了收费？ 3.4.2.17# pip install opencv-contrib-python# 算法扩展库# pip install pytesseract 谷歌开源ocr引擎import cv2 报错：ImportError: libSM.so.6: cannot open shared object file: No such file or directory原因：低版本的opencv安装，主要原因时系统缺少libSM.so.6库文件解决： 安装libSM.so.6 或者安装最新版本的opencv 模块介绍三个核心模块：core:highguiimgproc 使用图像读取123img = cv2.imread(file_path)# 如路径中包含中文字符，会读取不进来，可以用下面方式img = cv2.imdecode(np.fromfile(file_path, dtype=np.uint8), -1) cv2.imshow(‘title’,img_arr1) 最小外接最小外接矩形https://zhuanlan.zhihu.com/p/97855964外接圆，外接多边形https://blog.csdn.net/weixin_37763340/article/details/114339621 直线检测https://blog.csdn.net/wenhao_ir/article/details/124636972","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"faster-RCNN","slug":"cv/faster_rcnn","date":"2022-02-08T01:58:43.000Z","updated":"2022-02-09T09:47:14.534Z","comments":true,"path":"cv/faster_rcnn/","link":"","permalink":"https://tlylft.github.io/cv/faster_rcnn/","excerpt":"","text":"1. 网络结构两个阶段： 网络结构： 2. 整体流程介绍https://blog.csdn.net/weixin_44791964/article/details/105739918图片输入：将图片进行resize，短边resize到600的大小，宽高比不变（防止图片失真）对输入进来的图片尺寸没有固定，但是一般会把输入进来的图片短边固定成600，如输入一张1200x1800的图片，会把图片不失真的resize到600x900上。backbone主干网络:主干特征提取网络，将输入进来的图片进行特征提取后的图片特征。一般使用VGG或resnet，还可以使用Xception。Feature Map共享特征层（一堆特征的集合）的shape:38381024，含义：3838的网格，每个网格包含9个先验框，包含是否包含物体的检测信息。region proposal network 建议框网络对输入进来的共享特征层进行33卷积，在对卷积结果进行两次11的卷积，其中一个通道数是18（拆成92）， 另一个卷积通道是36（拆成9*4） 为什么这么拆分？和共享特征层有关，对应feature map的9个先验框，2代表先验框是背景的概率和有物体的概率。4代表先验框的调整参数（表示框位置的4个参数）。 得到建议框，建议框是对画面中物体的粗略筛选，并不十分准确，后面进一步调整。 ROI Pooling：建议框和共享特征层进行结合，传入ROI polling层，利用建议框对共享特征层进行截取，分区域池化resize到一样大小，进行分类（是否包含物体和种类）与回归（物体位置）预测。 模块详解backboneresnet50:ResNet50有两个基本的块，分别名为Conv Block和Identity Block，其中Conv Block输入和输出的维度是不一样的，所以不能连续串联，它的作用是改变网络的维度；Identity Block输入维度和输出维度相同，可以串联，用于加深网络的。这两个都是残差网络结构。Conv Block的结构如下： Identity Block的结构如下： Faster-RCNN的主干特征提取网络部分只包含了长宽压缩了四次的内容，第五次压缩后的内容在ROI中使用。即Faster-RCNN在主干特征提取网络所用的网络层如图所示。以输入的图片为600x600为例，shape变化如下： 3. 代码【代码1】https://github.com/bubbliiiing/faster-rcnn-pytorchpip install torch==1.2.0 torchvision==0.4.0 backbone使用resnet50","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"图像预处理","slug":"cv/cv_preprocess","date":"2022-01-27T06:55:44.000Z","updated":"2023-08-11T09:31:50.270Z","comments":true,"path":"cv/cv_preprocess/","link":"","permalink":"https://tlylft.github.io/cv/cv_preprocess/","excerpt":"","text":"1. 图像预处理1.1. 图像显示与存储原理1.1.1. 图片表示RGB颜色空间 加法混色，三原色越混合越亮 三个通道 Red, Green, Blue 一个点的像素颜色值表示（b,g,r） 取值范围(色彩饱和度) [0, 255], [0, 1] CMYK颜色空间 减法混色，四原色越混合越深 四个通道 Cyan, Magenta, Yellow, Key 一个点的像素颜色值表示（c,m,y,k） 取值范围(色彩饱和度) [0, 255], [0, 1] HSV颜色空间 人类视觉概念，画家配色 三个要素 Hue（色调，颜色种类）, Saturation（饱和度，颜色纯度）, Value（明度，颜色明亮度） 一个点的像素颜色值表示（h,s,v） 取值范围(色彩饱和度) [0, 255], [0, 1]1.1.2. 图片存储原理RGB三通道彩色图图片 -&gt; 3维矩阵(0,255)数据格式：由红绿蓝三通道的(0,255)表示单通道灰度图亮度信息(0,255)Gray = R 0.299 + G 0.587 + B * 0.114 (多种公式都可以表示) 存储格式：bmp，jpg，png，tiff，gif，pcx, tga, exif, fpx, svg, psdl, ccr, pcc, dxf, ufo, eps,ai，raw，WMF，webp等BMP：采用位映射存储格式，不采用其他任何压缩，所占用的空间很大。JPG：最常见的有损压缩格式，能够将图像压缩到很小的空间，压缩比可达10：1到40：1之间。GIF：基于LZW算法的连续色调的无损压缩格式，其压缩率一般在50％左右。PNG：是比较新的图像文件格式，能够提供长度比GIF小30％的无损压缩图像文件。 1.2. 图像增强的目标 改善图像视觉效果 转换为更适合人或机器分析处理的形式 突出对人或机器分析有意义的信息 抑制无用信息，提高图像的使用价值 包括图像锐化、平滑、去噪、灰度调整（对比度增强）空间域处理点运算(HE、CLAHE）、形态学运算(膨胀、腐蚀)、临域运算（卷积、金字塔）频率域处理傅里叶变换、小波变换 1.3. 点运算：基于直方图的对比度增强1.4. 形态学处理1.5. 空间域处理：卷积1.6. 卷积的应用（平滑、边缘检测、锐化等）1.7. 频率域处理：傅里叶变换、小波变换2. 图像特征颜色特征量化颜色直方图、聚类颜色直方图RGB, HSV 几何特征Edge 边缘像素值函数快速变化的区域 -&gt; 一阶导数的极值区域边缘提取： 先高斯去噪，再使用一阶导数获取极值 避免导数对噪声敏感Corner, Blob基于关键点的特征描述子SIFT, SURF, ORB其他特征提取LBP, Gabor代码实战","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"事件抽取论文","slug":"knowledge_graph/kg_ee_paper","date":"2022-01-17T12:56:30.000Z","updated":"2022-01-17T14:04:21.422Z","comments":true,"path":"knowledge_graph/kg_ee_paper/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/kg_ee_paper/","excerpt":"","text":"事件抽取综述（上）NLP 事件抽取综述（中）—— 模型篇超全必读！NLP 事件抽取综述（下） 1.5. 综述论文元事件抽取研究综述, 2019[1]事件抽取是信息抽取领域的一个重要研究方向，在情报收集、知识提取、文档摘要、知识问答等领域有着广泛应用。写了一篇对当前事件抽取领域研究得较多的元事件抽取任务的综述。 首先，简要介绍了元事件和元事件抽取的基本概念，以及元事件抽取的主要实现方法。然后，重点阐述了元事件抽取的主要任务，详细介绍了元事件检测过程，并对其他相关任务进行了概述。最后,总结了元事件抽取面临的问题，在此基础上展望了元事件抽取的发展趋势。 An Overview of Event Extraction from Text, 2019[2]文本挖掘的一个常见应用是事件抽取，它包括推导出与事件相关的特定知识，这些知识重新映射到文本中。事件抽取可处理各种类型的文本，如(在线)新闻消息、博客和手稿。本文献回顾了用于各种事件抽取目的的文本挖掘技术。它提供了关于如何根据用户、可用内容和使用场景选择特定事件抽取技术的一般指南。 A Survey of Event Extraction from Text, 2019[3]事件抽取的任务定义、数据源和性能评估，还为其解决方案方法提供了分类。在每个解决方案组中，提供了最具代表性的方法的详细分析，特别是它们的起源、基础、优势和弱点。最后，对未来的研究方向进行了展望。 A Survey of Textual Event Extraction from Social Networks, 2017[4]过去的十年中，在社交网络上挖掘文本内容以抽取相关数据和有用的知识已成为无所不在的任务。文本挖掘的一种常见应用是事件抽取，它被认为是一个复杂的任务，分为不同难度的多个子任务。 在本文中，对现有的主要文本挖掘技术进行了概述，这些技术可用于许多不同的事件抽取目标。首先，介绍基于统计模型将数据转换为知识的主要数据驱动方法。其次，介绍了基于专家知识的知识驱动方法，通常通过基于模式的方法来抽取知识。然后，介绍结合了数据驱动和知识驱动方法的主要现有混合方法。最后，比较社交网络事件抽取研究，概括了每种提出的方法的主要特征。 A Survey of event extraction methods from text for decision support systems, 2016[5]事件抽取是一种可以追溯到20世纪80年代的专门的信息抽取流程，由于大数据的出现以及文本挖掘和自然语言处理等相关领域的发展，事件抽取技术得到了极大的普及。然而，到目前为止，对这一特殊领域的概述仍然是难以捉摸的。 因此，总结了文本数据的事件抽取技术，划分成数据驱动、知识驱动和混合方法三类，并对这些方法进行了定性评价。此外，还讨论了从文本语料库中抽取事件的常见决策支持应用。最后，对事件抽取系统的评价进行了阐述，并指出了当前的研究问题。 [1] 元事件抽取研究综述, 2019: https://doi.org/10.11896/j.issn.1002-137X.2019.08.002 [2] An Overview of Event Extraction from Text, 2019: http://ceur-ws.org/Vol-779/derive2011_submission_1.pdf [3] A Survey of Event Extraction from Text, 2019: https://doi.org/10.1109/ACCESS.2019.2956831 [4] A Survey of Textual Event Extraction from Social Networks, 2017: http://ceur-ws.org/Vol-1988/LPKM2017_paper_15.pdf [5] A Survey of event extraction methods from text for decision support systems, 2016: https://doi.org/10.1016/j.dss.2016.02.006 2. 事件抽取技术方案2.1. 论文方案2.1.1. Event Extraction via Dynamic Multi-Pooling Convolutional Neural Networks, ACL2015任务：给定候选实体的位置；完成触发词识别，触发词分类，论元识别，论元分类 动机：在于一个句子中可能会有多个事件，如果只用一个池化将导致多个事件的句子级特征没有区别。因此引入动态多池化 主要思想：采用动态多池化的方式，以trigger和candidate作为分隔符[-trigger-candidate-]，将句子池化成三段；动机在于一个句子中可能会有多个事件，如果只用一个池化将导致多个事件的句子级特征没有区别。将任务目标转换成句子分类任务，从而完成任务。 中文论文方案Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial Event Extraction, EMNLP2019 [5]任务: 与其他研究不同，该任务被定义为：事件框架填充：也就是论元检测+识别 不同点有：不需要触发词检测;文档级的抽取;论元有重叠 动机: 解码论元需要一定顺序，先后有关 主要思想:发布数据集，具有特性：arguments-scattering and multi-event,先对事件是否触发进行预测；然后，按照一定顺序先后来分别解码论元 数据集:ten years (2008-2018) Chinese financial announcements：ChFinAnn;","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"}]},{"title":"评论观点抽取","slug":"NLP/info_extract/opinion_extract","date":"2022-01-05T08:02:04.000Z","updated":"2022-01-29T02:06:24.348Z","comments":true,"path":"NLP/info_extract/opinion_extract/","link":"","permalink":"https://tlylft.github.io/NLP/info_extract/opinion_extract/","excerpt":"","text":"【数据集】千言数据集：情感分析【项目】【paddlenlp】千言数据集：情感分析【项目】【paddlenlp】情感分析之评价对象提取（千言数据集）SKEP模型paddle细粒度情感分析和观点提取【PP-MiniLM】paddle小模型+量化策略 简单的解决方案：方案一： 调用了百度AI平台的观点抽取，发现不怎么好用，可能是我所在行业所导致的，有很多大量的专有词汇。 方案二：评论标签化，可以看成noun+adj，也就是名词和描述性词汇的结合。有一个大众的做法，就是通过依存句法分析来进行匹配，然后word2vec向量化+dbscan聚类，就可以做到类似淘宝那种评论观点显示，例子： 输入：服务很到位 依存句法分析输出后：主谓关系：服务，状中结构：很，核心关系：到位 可以看出最终的结合是主谓关系+核心关系，就可以将评论观点抽取出来。不过这种方法问题还是很大，实际运用时，不能单单只靠依存句法分析来处理，会出现很多问题的。 首先得建立独有的词表(跟自己行业有关)，比如名词词表，像我的行业里，独有的有车况，取车，还车，手续之类独有的，描述性词表同理（这个手动去挑选比较好，如果词典比较大，再用代码去挑选）。注意：有些词汇出现的频率非常高，但是其不是名词，也不是形容词的话，这种情况要单独挑选出来处理，以免纰漏。 两个词表建立完以后，可以通过word2vec去将相似的词汇进行聚类统一(实际运用时还不如直接人工简单粗暴的好用)。这两个词表在去结合依存句法分析来进行提取，就会比较准确。 评论最后都抽取完以后，就可以进行统计分析了，或者出于业务角度来进行应用。 SKEP 引入情感先验知识的预训练百度评论观点抽取与情感倾向性分析：https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/sentiment_analysis知乎概述：https://zhuanlan.zhihu.com/p/260676722模型解读：https://www.cnblogs.com/zhang12345/p/15675103.html知乎模型解读：https://zhuanlan.zhihu.com/p/267837817SKEP采用RoBERT作为基线模型，在BERT的预训练过程中加入了情感知识，这样更有利于情感分类任务。 RoBERTa相对于BERT的改进之处如下： （1）去除了BERT中的NSP任务 （2）增加了batch size的大小，并且增加了训练的数据 （3）采用了动态mask的方式 （4）BERT使用的是字符级编码方式，但是RoBERTa使用的是byte-level text encoding","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"信息提取","slug":"NLP/信息提取","permalink":"https://tlylft.github.io/categories/NLP/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"信息提取","slug":"信息提取","permalink":"https://tlylft.github.io/tags/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"}]},{"title":"【CV】01-计算机视觉简介","slug":"cv/cv_intro","date":"2022-01-05T00:25:24.000Z","updated":"2023-08-11T09:15:07.130Z","comments":true,"path":"cv/cv_intro/","link":"","permalink":"https://tlylft.github.io/cv/cv_intro/","excerpt":"","text":"1. 预处理图像预处理图像特征和描述（颜色、形状、纹理） 2. 深度学习任务计算机视觉解决的问题：分类、检测、分割图像分类（卷积神经网络CNN）目标检测（区域卷积神经网络R-CNN）关键点检测语义分割（全卷积神经网络FCN）实例分割 图像描述（迭代神经网络RNN）图像生成（生成对抗网络GAN）图像检索 问题和挑战：视角变化、光照变化， 尺度变化、形态变化、背景干扰、遮挡、同类物品的外观差异 没有深度学习之前，也可以通过一些方法或算法解决图像检测问题 2.1. 目标检测让基础网络具备区域输出能力 发展历史 传统方法：Viola-Jones, HOG+SVM, DPM深度学习第一阶段（两阶段模型）： RCNN-&gt;SPP-Net-&gt;Fast/Faster RCNN深度学习第二阶段（一阶段模型）： YOLO-&gt; SSD-&gt; R-FCN演变目的：检测更快、更准确 传统目标检测方法 vs. 深度学习目标检测方法手动设计特征 -&gt; 深度网络学习特征 （解决鲁棒性）滑动窗口 -&gt; Proposal或者直接回归 （解决效率）传统分类器 -&gt; 深度网络多步骤 -&gt; 端到端准确度和实时性差 -&gt; 准确性和实时性好 算法基本流程深度学习经典目标检测方法有以上两种（单阶段和两阶段），stage的选择通常根据场景来决定： 应用场景人脸识别文字监测商品搜索卫星监测 2.1.1. 传统目标检测方法基于传统手工特征的检测算法时期的代表性算法Viola-Jones采用积分图特征结合Adaboost分类器进行人脸检测等的任务Haar特征抽取训练人脸分类器（Adaboost算法等）候选框采用滑动窗口的策略（窗口大小和步长，造成冗余的候选框造成计算速度下降）HOG+SVM主要用于行人检测，通过对行人目标候选区域提取HOG特征，并结合SVM分类器进行行人检测DPM基于HOG特征的变种，加入了额外的策略，提高了检测精度，非深度学习效果最优的一种，传统目标检测算法的巅峰之作。直接获取31维的特征，避免pcv降维，提高了计算速度 2.1.2. two-stage(两阶段)：机制：利用RPN网络对候选区域进行推荐，做了很多候选集，结果更加精确方法：CNN卷积特征， RCNN, SPP-Net, Fast-RCNN, faster-RCNN和相应的变种, Mask-RCNN框架：Mask-RCNNcons and pros：核心优势：效果不错,适合离线任务缺点： 速度通常较慢(5FPS)，对实时的支持性差流程s 2.1.3. one-stage(一阶段)：方法： YOLO，SSD机制：一层回归任务，回归目标的位置cons and pros：核心优势：回归任务，速度快，适合做实时监测任务缺点： 通常效果相对不太好 2.2. 图片分割机器学习解决的是区域轮廓检测深度学习解决了语义上的分割FCN-&gt;SegNet/DeconvNet-&gt;DeepLab目的：语义推断、分割更精确","categories":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}],"tags":[{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"}]},{"title":"yolo目标检测","slug":"cv/pipline_detect","date":"2022-01-04T04:27:54.000Z","updated":"2022-01-27T13:38:54.000Z","comments":true,"path":"cv/pipline_detect/","link":"","permalink":"https://tlylft.github.io/cv/pipline_detect/","excerpt":"","text":"https://github.com/Charmve/Surface-Defect-Detection/blob/master/ReadmeChinese.md#16MVTec-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"yolo目标检测","slug":"cv/yolo","date":"2022-01-04T04:27:54.000Z","updated":"2022-05-06T05:31:34.150Z","comments":true,"path":"cv/yolo/","link":"","permalink":"https://tlylft.github.io/cv/yolo/","excerpt":"","text":"子豪兄的代码铺子 1. 背景1.1. YOLO:You Only Look Once 一阶段模型 https://pjreddie.com/https://pjreddie.com/yolov1https://appjaflfup94042.h5.xiaoeknow.com/v1/course/text/i_610155dbe4b0bf642fff3021?from_multi_course=1&amp;pro_id=p_60fff9dee4b0a27d0e367e6b&amp;type=2 1.2. 衡量指标1.2.1. FPS: (衡量速度)frames per second 每秒处理的张数，越高表示速度越快 1.2.2. mAP:综合衡量检测效果的指标IOU: intersection over union 交集和并集的比值Precision 和recall设置IoU阈值，大于阈值认为是预测结果正例，小于阈值认为是预测结果负例。在这种规则下，计算预测框的 Precision 和recallmAP: mean average precision将各个IOU阈值对应的precision和recall绘制成一个对应关系曲线图，重复纵坐标对应的presicion取最大值，得到如下左图。map值则考虑到所有阈值情况下的precision和recall，组成的曲线下方/长方形的面积。约接近1效果越好。 2. yolo系列 作者： Joseph Redmon自造：Darknet框架fps: 30fps,实时目标检测 2.1. YOLO V12.1.1. 核心思想1-1. 将图片分为s*s(7*7)个格子grid, 每个格子代表预测框的中心点。1-2. 每个中心点设置b个候选框，用w,h代表可能的候选框长宽。一共是7*7*2=98个预测框。1-3. 取每个点的候选框和真实框IOU最大的候选框，负责预测这个物体，每个grid只检测一个物体，进行物体置信度预测、框位置回归预测。2-1. 对每个候选框是否存在物体进行预测，得到是物体的可能性最大的置信度。2-2. 得到每个gird对应的类别概率3-1. 合并得到解析结果 2.1.2. 网络结构 输入resize固定到448，因为后面存在全连接层，全连接层大小在训练过程中很难改变，虽然说其他相对位置信息会相应resize变化，但v1中还是有些局限了。 中间是20多层卷积层，为了提取图像特征，不详细展开，因为v3中的优化要好很多。 后面回归到1024*1的全连接层，作为提取出的特征 再reshape到 1470*1的全连接层, 是为了得到7*7*30的输出结果。 结果解释：7*7是指将图像分成的49个grid cell。30包含 (B*5+C)【10个位置信息】每个cell对应的B(两)个bounding box*5(每个box包含四个位置参数x1, y1, w1, h1 和一个置信度参数c1) x1, y1, w1, h1 是resize图像后的一个相对位置值，不是绝对坐标【20个类别的条件类别概率】每个cell确定包含物体的情况下每个类别的概率C 2.1.3. 损失函数位置误差w,h开根号是为了更专注于小物体，因为预测框大的物体可以相对不敏感置信度误差分为含有object的误差损失和不含object的误差损失。置信度用当前grid的IOU表示，不含object的损失函数带有一个权重参数，是因为前景的所占比例大。分类误差 2.1.4. 预测阶段：预测流程：得到7*7*30的输出结果。每个cell生成两个置信度最高的预测框，一共是7\\ 7\\2=98个预测框， 每个预测框包含四个边界点坐标信息和一个置信度信息， 还有对应的20个类别信息， 将这些信息进行后处理，就得到了最后的预测结果。 后处理NMS非极大值抑制：设置两个阈值，thread1和thread2， A为框的置信度阈值，B为去重时用到的重叠面积的置信度。 将98个框对应的98个置信度乘以20个类别的条件类别概率，得到20个类别对应的98个框的全概率。 遍历每一个类别的98个预测框，将小于置信度A的框去掉，留下置信度较高的框并排序 去重：留下的框做两两比对，如果IOU值大于阈值B（假设0.5），则认为两框检测到同一物体，删除置信度较低的框。 留下的框可以认为是该类别的检测到的物体目标。soft-NMS2.1.5. 训练阶段损失函数L2的回归问题 存在的问题小物体检测不到：因为框是固定的，长宽比固定，候选框只有两个。重叠物体的多标签难以解决 YOLO-V2改进： batch normalization舍弃dropout, 每个卷积后全部加入batch normalization，提升2%map网络每一层输入都做了归一化，加快收敛 更大分辨率v1训练时24*244， 测试时使用448*448，可能导致模型水土不服，v2在训练时加入了10次448*448的微调，map提升4% 网络结构 结构：DarkNet19,有19个卷积层，5次降采样。 输入：实际输入是416*416（为了保证5次降采样能被32整除，而且最后得到的结果是个奇数大小，方便定位中心点） 取消FC全连层，所有层都是卷积做的，因为全连接层容易过拟合；参数多训练慢；而是使用5次降采样，最后得到13*13的结果 卷积核：所有的卷积大小只有3*3（源于VGG思想，当用一些比较小的参数做卷积核时，参数比较省，感受野比较大，训练的模型比较好）和1*1两种（只改变网络特征图个数，节省了很多参数）。聚类提取先验框yolov1每个grid只有2个先验框，比较少，，参考faster-RCNN 9个，yolov2调整为5个。提取三组相同比例大小的先验框，每组涉及覆盖的分辨率更大一些。使用k-means对标注数据的所有真实框进行聚类。k = 5， 5个候选框，coco数据实验得到的。聚类距离采用没有覆盖的比率来表示，d(box, centroids) = 1 - IOU(box, centroids)实现效果与v1对比： map值下降，recall增加。 因为框数量增加，有些框就是错误的，平均的map值会下降，但是检测到的东西覆盖率更全了，查全率增加。预测偏移量误差的优化，和坐标还原https://www.bilibili.com/video/BV1aa411B7iD?p=16https://www.bilibili.com/video/BV1aa411B7iD?p=17v1中直接预测误差，在网络开始的时候没有做网格限制，前期预测的框容易飘， v2中加入了在grid内偏移的限制，预测在当前grid下的相对位置，防止框飘。 训练过程中的特征融合最后一层的感受野太大了，感受野越大，越容易捕捉大目标的信息，丢失小目标的信息，所以v2中融合了之前的特征，将最后13*13*1024的特征图，与前几层的特征拿过来（如26*26*512的特征图进行拆分成4个13*13*512），进行叠加,得到最后的特征图，13*13*(4*512+1024)。 图像在训练过程中动态变换大小！！！！没太明白！！！！！！！因为原始图片有大有小，但都将图resize到固定大小对大或者小的图片不均衡，所以在训练一定的iterations之后，模型会随机改变输入的图片大小。最小的图像尺寸为320*320最大的图像尺寸为608*608 YOLO-V3改进： 最大改进是网络结构，使其更适合小目标检测 特征更加细致，融入多持续特征图信息预测不同规格的物体 先验框更加丰富，3种scale, 每种3个规格，一共9种 softmax改进，预测多标签任务（多分类改成2分类）多scale方法改进用52大小的特征图（感受野小）预测小目标，13大小的特征图预测大目标。 网络结构Darknet-53, （Restnet残差block?????????）没有池化和全连接层，全部卷积层。之前池化下采样通过stride为2实现。3种scale,更多先验框 再看看 重新记笔记： https://www.bilibili.com/video/BV1aa411B7iD?p=25 softmax YOLO-V5看一半的视频：https://www.bilibili.com/video/BV1oP4y1M7rF?p=7https://www.bilibili.com/video/BV1aa411B7iD?p=29https://www.bilibili.com/video/BV1T3411p7zR?spm_id_from=333.337.search-card.all.clickhttps://blog.csdn.net/qq_37541097/article/details/123594351 https://blog.csdn.net/jiafeier_555/article/details/109052569 自己画的代码流程：https://www.processon.com/diagraming/6241259d1efad40756ca56b1","categories":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"}],"tags":[{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"}]},{"title":"【知识图谱】01-知识图谱简介","slug":"knowledge_graph/kg_intro","date":"2021-12-27T06:16:51.000Z","updated":"2022-01-04T00:56:35.819Z","comments":true,"path":"knowledge_graph/kg_intro/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/kg_intro/","excerpt":"","text":"1. 知识图谱概述1.1. 什么是知识图谱？一种用图模型(probabilistic graphic models)来描述知识和建模世界万物之间的关联关系的技术方法。由节点和边组成。 节点可以是实体，如一个人、一本书，或者是抽象的概念 边可以是实体的属性，或者是实体之间的关系 1.2. 发展历史semantic web(语义网)最初的理想是把基于文本链接的万维网转化成基于实体链接的语义网。 1.3. 知识图谱的价值1.3.1. 场景价值 辅助提升搜索引擎能力传统搜索引擎只能搜索文本，不能搜索实体。语义搜索直接对事物进行搜索， 知识图谱可以提供更多的信息，比如提供实体的分类、属性和关系等。 辅助智能问答 辅助大数据分析 金融风控、资源优化等 辅助语言理解，人机之间的相互理解 辅助设备互联，机器与机器之间的相互理解 1.3.2. 和传统db的区别 规模巨大 知识结构更加复杂 来源更加多样 知识更加异构 具有高度的动态性和时效性 更深层次的推理需求 1.4. 问答领域中的行业现状 阿里巴巴有自己的电商知识图谱，规模达到了百亿级别 IBM Watson 背后依托 DBpedia 和Yago等百科知识库和 WordNet 等语言学知识库实现深度知识问答。 Amazon Alex 主要依靠 True Knowledge 公司积累的知识图谱 度秘、 Siri的进化版 、小爱机器人、天猫精灵背后都有海量知识图谱作为支撑 知识图谱既被用来辅助实现语义解析，也被用来匹配问句实体，还被用来训练、神经网络和排序模型等。 知识图谱是实现人机交互问答中重要的环节模块。 2. 知识图谱系统 2.1. 业务构建流程 模型定义：确定知识表示模型，如有什么实体，有什么关系 知识导入：根据数据来源选择不同的知识获取手段导入知识 知识推理与挖掘：接着综合利用知识推理、知识融合、知识挖掘等技术对构建的知识图谱进行质量提升 知识呈现：后根据场景需求设计不同的知知识访问与呈现方法（语义搜索、问答交互、图谱可视化分析等） 2.2. 技术构建及应用流程数据获取、数据清洗，知识抽取、知识融合和知识加工。其中最主要的步骤是知识抽取。 2.2.1. 知识来源知识源表现形式可以为： 文本数据、结构化数据、语音、图像、流数据等，一般可通过以下途径获取： 互联网爬虫爬取 业务数据库中直接获取 多媒体数据 传感器数据 人工众包 2.2.2. 知识表示用计算机符号描述和表示人脑中的知识。表示不同的知识类型： 词 (Vocabulary) 实体 (Entity) 关系 (Relation) 事件 (Event) 一种复合实体 术语体系 (Taxonomy) 规则 (Rule)2.2.3. 知识抽取文本数据源对于文本数据源，需要综合各种自然语言处理技术，实现从文本中抽取知识。 知识抽取包括三个要素：命名实体识别（NER）、实体关系抽取（RE） 和 属性抽取。其中属性抽取可以使用python爬虫爬取百度百科、维基百科等网站，操作较为简单，因此命名实体识别（NER）和实体关系抽取（RE）是知识抽取中非常重要的部分，同时其作为自然语言处理（NLP）中最遇到的问题一直以来是科研的研究方向之一。 常用算法实体识别：如 CRF, BILSTM-CRF, BERT-CRF等关系抽取：预测两个实体之间的关系。基于特征模板，基于核函数的监督学习，基于远程监督学习，基于深度学习的监督或远程监督方法，如CNN、 MP-CNN 、 MWK-CNN 、 PCNN、 PCNN+ Att 和 MIMLCNN 等 结构化数据对于各种结构化数据，需要将结构化数据定义到本体模型之间的语义映射，再通过编写语义翻译工具实现转化。此外，还需要综合采用实体消歧、数据融合、知识链接等技术，提升数据的规范化水平，增强数据之间的关联。 常用方式 D2R工具：Triplify 、 D2RServer、 OpenLink 、 SparqlMap 、 Ontop 等 物联设备数据对物联设备数据，可以用语义技术对传感器产生的数据进行语义化。 对物联设备进行抽象 定义符合语义标准的数据接口 对传感数据进行语义封装 对传感数据增加上下文语义描述,等。 人工众包 获取高质量知识图谱的重要手段，可以开发针对文本、图像等多种媒体数据的语义标注工具，辅助人工进行知识获取。 2.2.4. 知识融合将多个数据源或知识图谱进行融合，通过构建本体库和规则库，避免表现形式的不同造成合并的冗余。 将多个数据源或知识图谱进行融合，避免表现形式的不同造成合并的冗余，需要处理两个层面的问题: 模式层的融合将新得到的本体融入己有的本体库中, 如：杂货铺新增了水果商品，需要将水果商品类别融入到杂货铺的知识图谱中。 数据层的融合新旧本体的融合，包括实体的指称、属性、 关系以及所属类别等。 考虑同一实体但不同标识的识别（共指消解），需要统一表达方式。 如：新奥和新奥新智 考虑新增实体和关系的识别 考虑同名实体是否表达不同含义(实体消歧)， 如:“我想吃苹果”和“我的手机是苹果的” 关键问题是如何定义实体对象与指称项之间的相似度。常用方法空间向量模型〈词袋模型)、语义模型、社会网络模型、百科知识模型和增量证据模型 2.2.5. 知识存储存储： 基于表结构（mysql, oracle）和基于图结构的存储(neo4j, JanusGraph) 批量导入：初始化导入，效率低增量导入：新增数据建设的实时流 2.2.6. 知识推理意义： 知识图谱推理能用来对知识图谱进行补全和质量检测等。方式： 推理包括逻辑推理和非逻辑推理。逻辑推理包含严格的约束和推理过程；非逻辑推理的推理过程相对模糊。一般采用逻辑推理的推理方式，结果更加透明。 知识图谱的逻辑推理 基于演绎的知识图谱推理Deductive Reasoning，是自上而下的推理（通过规则分析样本）例：给定前提：如果明天是周六，那么不上班。A-&gt; B, B-&gt;C , A-&gt;C技术手段：描述逻辑，Datalog, 产生式规则等实现方法：基于表运算 (Tableaux)的本体推理方法：适用于检查某一本体的可满足性，以及实例检测。基于Datalog逻辑编程的方法：可以根据特定的场景定制规则，以实现用户自定义的推理过程。基于查询重写的方法：重写方法关联起不同的查询语言基于产生式规则的方法:一种前向推理系统,可以按照一定机制执行规则从而达到某些目标 总的来说，在程序代码中定义事实和规则，然后调用推理算法，推理算法会根据规则和事实进行推理，列出所有推理出的新事实，判断推理结果是否正确。 基于归纳的知识图谱推理Inductive Reasoning, 自下而上的推理（通过观察样本总结规则）包括溯因推理和类比推理技术手段：路径推理、表示学习、规则学习、基于时序预测、强化学习的推理等实现方法：基于图结构的推理：Path Ranking Algorithm, 利用了实体节点之间的路径当作特征从而进行链接预测推理（预测每种可能的概率）基于规则学习的推理：通过有效搜索空间，挖掘规则，评估规则成立的置信度基于表示学习的推理：将实体和关系映射到连续的向量空间中，通过训练学习向量表示，自动捕捉、推理需要的特征。 2.2.7. 知识检索与分析知识检索 基于关键词的查询： 构建索引和词/实体映射，也可结合关键词映射做结构化查询，排序 基于分面的搜索：指定领域、类别的特定化查询 基于表示学习的搜索：对查询实体映射在向量空间上查询，蕴含语义表示，提高简单查询的效率 知识图谱的应用大多基于对复杂网络的大规模计算，计算的结果以在线服务或离线结果的形式提供给应用者。 知识分析除简单的检索功能外，还可通过统计计算实现：图特征统计、 关联分析、时序分析、节点分类、异常检测、预测推理等 2.3. 领域知识图谱构建难点 3. 知识图谱的应用3.1. 图谱技术架构此外还有一些算法的技术，可应用在爬虫爬取的非结构化数据转换为结构化的数据。和neo4j推理模型实现推理。 3.2. 问答系统的应用4. 联合学习的相关研究4.1. GNN的联合学习4.2. 去中心化的知识图谱语义网强调知识以分散的方式互联和相互链接，知识的发布者拥有完全控制权。 可参考文献：[1] 知识图谱嵌入的联邦学习：CIKM’21 Federated Knowledge Graphs Embedding[2] OpenKG区块链：构建可信开放的联邦知识图谱平台 5. 相关资源 [1] http://www.freebase.be/[2] magi搜索引擎[3] wikidata[4] OpenKG —中文开放知识图谱[5] OpenBase.AI —中文开放知识图谱","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"}]},{"title":"【Leecode】python位运算","slug":"leecode/bit","date":"2021-12-21T02:53:39.000Z","updated":"2023-08-11T07:52:15.457Z","comments":true,"path":"leecode/bit/","link":"","permalink":"https://tlylft.github.io/leecode/bit/","excerpt":"","text":"https://www.cnblogs.com/nxf-rabbit75/p/10291792.html#auto-id-12 功能 运算 去掉最后k位/ 除以2^k n &gt;&gt; k 最后k位加0/ 乘以2^k n &lt;&lt; k 取最后k位 n &amp; (2^k - 1) 右边第一个1变成0 n &amp; (n - 1) 例题LC191: 返回二进制中1的个数遍历每一位，和00001做与运算，如果结果不为0，则说明该位为1，则计数加1123class Solution: def hammingWeight(self, n: int) -&gt; int: return sum(1 for i in range(32) if n &amp; (1&lt;&lt;i))观察这个运算：n&amp;(n - 1)，其运算结果恰为把 n 的二进制位中的最低位的 1变为 0 之后的结果。 如：6&amp;(6-1) = 4, 6 = (110), 4 = (100)，运算结果 4 即为把 6 的二进制位中的最低位的 1 变为 0 之后的结果。 这样我们可以利用这个位运算的性质加速我们的检查过程，在实际代码中，我们不断让当前的 n 与 n - 1 做与运算，直到 n 变为 0 即可。因为每次运算会使得 n 的最低位的 1 被翻转，因此运算次数就等于n 的二进制位中 1 的个数。 1234567class Solution: def hammingWeight(self, n: int) -&gt; int: ret = 0 while n: n &amp;= n - 1 ret += 1 return ret LC231: 判断一个数是不是2的幂2^0 = 1 000012^1 = 2 000102^2 = 4 001002^3 = 8 010002的幂 只有一个1，其余都是0，所以将最右边的1变为0后，看剩下的数是不是0，如果是0，则是2的幂，否则不是123class Solution: def isPowerOfTwo(self, n: int) -&gt; bool: return n &gt; 0 and (n &amp; (n - 1)) == 0","categories":[{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/categories/Leecode/"}],"tags":[{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/tags/Leecode/"}]},{"title":"并行计算","slug":"deep_learning/paraller_computing","date":"2021-12-14T01:35:23.000Z","updated":"2021-12-27T06:37:06.898Z","comments":true,"path":"deep_learning/paraller_computing/","link":"","permalink":"https://tlylft.github.io/deep_learning/paraller_computing/","excerpt":"","text":"https://www.bilibili.com/video/av78586073 同步梯度下降：mapreduce architecture: client-server communication: massage passing 每个ephoch所有的worker都会计算一遍更新梯度，然后把结果返回给master，master把结果相加或取平均更新到参数中。所有的worker都要等最慢的worker结束，才能继续下一个epoch。 系统：hadoop, spark异步梯度下降：paramerter server architecture: client-server communication: massage passing 所有worker不会有空闲，不需等待其他worker工作结束，直接进行下一个epoch, 但需要保证worker的稳定性，如果有异常worker执行的比较慢，梯度更新会出现问题。 系统：Ray decentralized computing 去中心化计算 architecture: peer-to-peer communication: massage passing parallel computing vs distributed computing分布式计算是并行计算的一种。没什么界限。做机器学习的人认为在同一个机器上的多核计算是并行计算，在不同机器上的计算是分布式计算。 tensorflow并行计算框架MirrowStrategy：适用于一台服务器有多个gpu的情况,类似于mapreduce的机制，是同步梯度下降的策略。 1234567from tensorflow.python.client import device_libprint(device_lib.list_local_devices())from tensorflow import distributestrategy = distribute.MirrowStrategy() # 参数可以指定用哪个gpum = strategy.num_replicas_in_syncprint(m) 梯度更新和同步reduce vs all reduce vs ring all reduce","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[]},{"title":"随机性和数据拟合","slug":"math/random","date":"2021-12-02T05:48:24.000Z","updated":"2021-12-02T09:00:31.507Z","comments":true,"path":"math/random/","link":"","permalink":"https://tlylft.github.io/math/random/","excerpt":"","text":"假如我们认定身高和体重的关系是线性的， 因为随机性导致在坐标表示中图像并不是线性的， 拟合出的曲线就有可能是非线性的曲线，不具备稳定性。从另一方面解释，随机性的产生也代表了影响模型结果的其他未被分析的影响因素。 模型过度的拟合了随机的样本点，就会导致模型的过拟合。模型因为随机的样本点而导致不考虑变量的影响，就会导致模型的欠拟合。","categories":[{"name":"math","slug":"math","permalink":"https://tlylft.github.io/categories/math/"}],"tags":[{"name":"math","slug":"math","permalink":"https://tlylft.github.io/tags/math/"}]},{"title":"支持向量机SVM","slug":"machine_learning/svm","date":"2021-12-02T05:15:05.000Z","updated":"2021-12-02T05:41:43.966Z","comments":true,"path":"machine_learning/svm/","link":"","permalink":"https://tlylft.github.io/machine_learning/svm/","excerpt":"","text":"模型效果棒，数学逻辑超前。解决的问题： 学霸（SVM）考100分是因为试卷上只有100分，你(其他分类模型)考99分是因为你只能考99分。如下图的分类，C1分类器只解决了在训练集上分类准确，而C2分类器更能解决在测试集上分类准确。 线性分类器Hard margin svm 想要模型越准确，就需要上图中决策边界之间的距离最大化，由最大化边界确定出来的决策分界面才能更好的划分类别。 以上介绍的是Hard margin svm pros and conspros: 强分类器，能保证最大化区分两个类别，所以性能优异cons: Hard margin svm ,是svm基础版本，不能处理不用类别相互交融的情况。 soft margin svm在边界区域的选择上，加入容错率，即允许在划分区域有错误数据的情况 非线性分类器为了解决线性不可分的情况，可以引用kernel 将线性不可分的数据，映射到高维可分的平面空间上，然后再进行分类。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"Rasa框架解读（8）- cli命令行模块","slug":"chatbot/rasa_08_cli","date":"2021-11-23T01:20:28.000Z","updated":"2023-08-11T08:42:26.713Z","comments":true,"path":"chatbot/rasa_08_cli/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_08_cli/","excerpt":"","text":"1. 支持的命令命令行界面(CLI)为你提供易于记忆的常见任务命令。 1.1. rasa init使用示例训练数据，action和配置文件创建一个新demo项目1rasa init 1.2. rasa train使用你的NLU数据和故事训练模型，在./model中保存训练的模型1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768usage: rasa train [-h] [-v] [-vv] [--quiet] [--data DATA [DATA ...]] [-c CONFIG] [-d DOMAIN] [--out OUT] [--dry-run] [--augmentation AUGMENTATION] [--debug-plots] [--num-threads NUM_THREADS] [--fixed-model-name FIXED_MODEL_NAME] [--persist-nlu-data] [--force] [--finetune [FINETUNE]] [--epoch-fraction EPOCH_FRACTION] &#123;core,nlu&#125; ...positional arguments: &#123;core,nlu&#125; core Trains a Rasa Core model using your stories. nlu Trains a Rasa NLU model using your NLU data.optional arguments: -h, --help show this help message and exit --data DATA [DATA ...] Paths to the Core and NLU data files. (default:[&#39;data&#39;]) -c CONFIG, --config CONFIG The policy and NLU pipeline configuration of your bot.(default: config.yml) -d DOMAIN, --domain DOMAIN Domain specification. This can be a single YAML file, or a directory that contains several files with domain specifications in it. The content of these files will be read and merged together. (default: domain.yml) --out OUT Directory where your models should be stored. (default: models) --dry-run If enabled, no actual training will be performed. Instead, it will be determined whether a model should be re-trained and this information will be printed as the output. The return code is a 4-bit bitmask that can also be used to determine what exactly needs to be retrained: - 1 means Core needs to be retrained - 2 means NLU needs to be retrained - 4 means responses in the domain should be updated - 8 means the training was forced (--force argument is specified) (default: False) --augmentation AUGMENTATION How much data augmentation to use during training. (default: 50) --debug-plots If enabled, will create plots showing checkpoints and their connections between story blocks in a file called &#96;story_blocks_connections.html&#96;. (default: False) --num-threads NUM_THREADS Maximum amount of threads to use when training. (default: 1) --fixed-model-name FIXED_MODEL_NAME If set, the name of the model file&#x2F;directory will be set to the given name. (default: None) --persist-nlu-data Persist the NLU training data in the saved model. (default: False) --force Force a model training even if the data has not changed. (default: False) --finetune [FINETUNE] Fine-tune a previously trained model. If no model path is provided, Rasa Open Source will try to finetune the latest trained model from the model directory specified via &#39;--out&#39;. (default: None) --epoch-fraction EPOCH_FRACTION Fraction of epochs which are currently specified in the model configuration which should be used when finetuning a model. (default: 1.0)Python Logging Options: -v, --verbose Be verbose. Sets logging level to INFO. (default: None) -vv, --debug Print lots of debugging statements. Sets logging level to DEBUG. (default: None) --quiet Be quiet! Sets logging level to WARNING. (default: None)12rasa train --data bots&#x2F;[bot-name]&#x2F;data -c bots&#x2F;testbot&#x2F;config.yml -d bots&#x2F;[bot-name]&#x2F;domain.yml # 数据和配置加载--out bots&#x2F;[bot-name]&#x2F;models --fixed-model-name [time-stamp] # 模型保存目录和文件名 1.3. rasa interactive启动交互式学习会话，通过聊天创建新的训练数据 1.4. rasa shell加载已训练的模型，并让你在命令行上与助手交谈 1.5. rasa run使用已训练的的模型启动Rasa服务。有关详细信息，请参阅运行服务文档 1.6. rasa run actions使用Rasa SDK启动操作服务 1.7. rasa visualize可视化故事 1.8. rasa test使用你的测试NLU数据和故事测试已训练的Rasa模型 1.9. rasa datarasa data splitnlu 根据指定的百分比执行NLU数据的拆分rasa data convertnlu 在不同格式之间转换NLU训练数据 1.10. rasa x在本地启动Rasa X 1.11. rasa exportExport conversations using an event broker. 1.12. rasa telemetryConfiguration of Rasa Open Source telemetry reporting. rasa -h显示所有可用命令 2. 源码解读123456789101112131415161718192021222324252627282930# rasa.__main__.py # 命令行启动入口，传入参数解析，分发到各个命令模块from rasa.cli import ( data, export, interactive, run, scaffold, shell, telemetry, test, train, visualize, x,)from rasa.cli.arguments.default_arguments import add_logging_optionsfrom rasa.cli.utils import parse_last_positional_argument_as_model_pathfrom rasa.shared.exceptions import RasaExceptionfrom rasa.shared.utils.cli import print_errorscaffold.add_subparser(subparsers, parents=parent_parsers)run.add_subparser(subparsers, parents=parent_parsers)shell.add_subparser(subparsers, parents=parent_parsers)train.add_subparser(subparsers, parents=parent_parsers)interactive.add_subparser(subparsers, parents=parent_parsers)telemetry.add_subparser(subparsers, parents=parent_parsers)test.add_subparser(subparsers, parents=parent_parsers)visualize.add_subparser(subparsers, parents=parent_parsers)data.add_subparser(subparsers, parents=parent_parsers)export.add_subparser(subparsers, parents=parent_parsers)x.add_subparser(subparsers, parents=parent_parsers) 解析到对应模块，就开始调用subparser cli/[模块].py 中func参数对应的函数 父级parser参数，如train,run, test， 会向下调用rasa.api中对应的各模块，传参和命令行参数相同rasa.api再向下调用rasa.model_testing.py rasa.model_training.py rasa.core.run模块123rasa train -&gt; cli&#x2F;train.py. run_training() -&gt; rasa.api.train()rasa run -&gt; cli&#x2F;run.py . run() -&gt; rasa.api.run()rasa test -&gt; cli&#x2F;test.py . test() -&gt; rasa.model_testing.*二级的parser参数，如train nlu ,train core, 会直接调用rasa.model_testing.py rasa.model_training.py rasa.core.run模块","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"Rasa框架解读（7）- 多轮对话core","slug":"chatbot/rasa_07_core","date":"2021-11-22T02:34:13.000Z","updated":"2023-08-11T08:42:30.543Z","comments":true,"path":"chatbot/rasa_07_core/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_07_core/","excerpt":"","text":"https://www.jianshu.com/p/bd1bb573511chttps://zhuanlan.zhihu.com/p/76623359https://zhuanlan.zhihu.com/p/76935986 core 核心流程policy选择embedding PolicyThe Recurrent Embedding Dialogue Policy (REDP)paperThis policy only works with FullDialogueTrackerFeaturizer(state_featurizer).具体结构如下图： FormPolicy（槽填充，重要，比较常用）https://rasa.com/docs/rasa/core/forms/#formsThe FormPolicy is an extension of the MemoizationPolicy which handles the filling of forms. Once a FormAction is called, the FormPolicy will continually predict the FormAction until all required slots in the form are filled. For more information, see Forms.Note that for this story to work, your slots should be unfeaturized. If any of these slots are featurized, your story needs to include slot{} events to show these slots being set. In that case, the easiest way to create valid stories is to use Interactive Learning. KerasPolicy（LSTM）The KerasPolicy uses a neural network implemented in Keras to select the next action. The default architecture is based on an LSTM, but you can override the KerasPolicy.model_architecture method to implement your own architecture. MemoizationPolicy如果与训练数据完全一致则得分为1，否则为0The MemoizationPolicy just memorizes the conversations in your training data. It predicts the next action with confidence 1.0 if this exact conversation exists in the training data, otherwise it predicts None with confidence 0.0. MappingPolicy直接把识别的意图映射到一个具体actionThe MappingPolicy can be used to directly map intents to actions. The mappings are assigned by giving an intent the property triggers, e.g.:intents: - ask_is_bot: triggers: action_is_bot FallbackPolicy识别的置信度得分小于设置的阈值时进行触发的action，可设置nlu和core的阈值The FallbackPolicy invokes a fallback action if the intent recognition has a confidence below nlu_threshold or if none of the dialogue policies predict an action with confidence higher than core_threshold.","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"Rasa框架解读（6）- 自定义NLU","slug":"chatbot/rasa_06_nlu_custom","date":"2021-11-22T02:33:33.000Z","updated":"2023-08-11T08:42:38.878Z","comments":true,"path":"chatbot/rasa_06_nlu_custom/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_06_nlu_custom/","excerpt":"","text":"","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"Rasa框架解读（5）- nlu","slug":"chatbot/rasa_05_nlu_models","date":"2021-11-22T02:33:14.000Z","updated":"2023-08-11T08:42:42.209Z","comments":true,"path":"chatbot/rasa_05_nlu_models/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_05_nlu_models/","excerpt":"","text":"","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"Rasa框架解读（4）- NLU模块","slug":"chatbot/rasa_04_nlu","date":"2021-11-22T02:31:44.000Z","updated":"2023-08-11T08:42:45.517Z","comments":true,"path":"chatbot/rasa_04_nlu/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_04_nlu/","excerpt":"","text":"","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"Rasa框架解读（3）- 语料配置","slug":"chatbot/rasa_03_corpus","date":"2021-11-22T02:31:02.000Z","updated":"2023-08-11T08:42:48.576Z","comments":true,"path":"chatbot/rasa_03_corpus/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_03_corpus/","excerpt":"","text":"","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"bert4keras 框架解读（2）-tokenizer源码解析","slug":"NLP/transformer/bert4keras_code02","date":"2021-11-18T07:01:29.000Z","updated":"2021-12-27T14:16:50.972Z","comments":true,"path":"NLP/transformer/bert4keras_code02/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/bert4keras_code02/","excerpt":"","text":"","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"},{"name":"bert4keras","slug":"bert4keras","permalink":"https://tlylft.github.io/tags/bert4keras/"}]},{"title":"bert4keras 框架解读（3）-model模型加载源码解析","slug":"NLP/transformer/bert4keras_code03","date":"2021-11-18T07:01:29.000Z","updated":"2021-12-27T14:17:09.961Z","comments":true,"path":"NLP/transformer/bert4keras_code03/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/bert4keras_code03/","excerpt":"","text":"基于0.7.7版本 整体模块源码位置： bert4keras/models.py包含的类和函数：1234567891011121314151617# class: 定义了各个支持的模型结构class Transformer(object)class BERT(Transformer)class ALBERT(BERT)class ALBERT_Unshared(BERT)class NEZHA(BERT)class ELECTRA(BERT)class GPT2_MLT(Transformer)class T5_BaseT(Transformer)class T5_Encoder(T5_BaseT)class T5_DecoderT(Transformer)class T5(T5_BaseT)# functions: 加载模型的函数extend_with_language_model() # 最新版本多封装了LM_Mask类做继承extend_with_unified_language_model() # 最新版本多封装了UniLM_Mask类做继承build_transformer_model() 分层解析入口函数 build_transformer_model()12345678def build_transformer_model( config_path=None, checkpoint_path=None, model='bert', application='encoder', return_keras_model=True, **kwargs): 参数说明：model: 模型类型，可选值及对应的模型类为：123456789models &#x3D; &#123; &#39;bert&#39;: BERT, &#39;albert&#39;: ALBERT, &#39;albert_unshared&#39;: ALBERT_Unshared, &#39;nezha&#39;: NEZHA, &#39;electra&#39;: ELECTRA, &#39;gpt2_ml&#39;: GPT2_ML, &#39;t5&#39;: T5,&#125;config_path：选择模型需要的配置文件（对应的文件为json格式）``` bert举例{ “attention_probs_dropout_prob”: 0.1, “directionality”: “bidi”, “hidden_act”: “gelu”, “hidden_dropout_prob”: 0.1, “hidden_size”: 768, “initializer_range”: 0.02, “intermediate_size”: 3072, “max_position_embeddings”: 512, “num_attention_heads”: 12, “num_hidden_layers”: 12, “pooler_fc_size”: 768, “pooler_num_attention_heads”: 12, “pooler_num_fc_layers”: 3, “pooler_size_per_head”: 128, “pooler_type”: “first_token_transform”, “type_vocab_size”: 2, “vocab_size”: 21128}checkpoint_path: 模型的检查点文件","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"},{"name":"bert4keras","slug":"bert4keras","permalink":"https://tlylft.github.io/tags/bert4keras/"}]},{"title":"python装饰器","slug":"python/python/python_decorator","date":"2021-11-17T14:15:47.000Z","updated":"2021-11-17T14:26:11.880Z","comments":true,"path":"python/python/python_decorator/","link":"","permalink":"https://tlylft.github.io/python/python/python_decorator/","excerpt":"","text":"https://mp.weixin.qq.com/s/LxK4q9WYin7pyMviZN8WZA 装饰器(decorator)是一种高级Python语法，也是 Python 函数式编程的一部分。写法是 @xxx，在 Pandas、Django 框架源码里经常能见到，应用非常广泛。虽然不用装饰器也不影响开发，但用了装饰器可以让你的代码“秀”起来，当然装饰器的作用不仅仅是“秀”，更重要的是它可以让你的代码更简洁，可读性更高；业务逻辑解耦，维护更容易。 装饰函数简单用法12345678910111213141516171819def my_decorator(func): def wrapper(*args, **kwargs): print('before') func(*args, **kwargs) print('after') return wrapper@my_decoratordef tu_dou_si(): print('清洗土豆') print('去皮，切丝')tu_dou_si()&gt; output:before清洗土豆去皮，切丝after 参数传递：装饰器参数123456789101112131415def cai_factory(cai_type='清炒'): def my_decorator(func): def wrapper(): func() print(f'&#123;cai_type&#125;') print('出锅') return wrapper return my_decorator@cai_factory('凉拌')def tu_dou_si(): print('清洗土豆') print('去皮，切丝') 被装饰函数不定参数1234567891011121314151617def cai_factory(cai_type='清炒'): def my_decorator(func): def wrapper(*args, **kwargs): func(*args, **kwargs) print(f'&#123;cai_type&#125;') print('出锅') return wrapper return my_decorator@cai_factory()def cai(cai_name, cai_cnt): print(f'清洗&#123;cai_name&#125; &#123;cai_cnt&#125;') print('去皮，切丝')cai('山药', '两个') 装饰类装饰函数定义一个 被装饰的类，然后返回一个装饰类，装饰器可以接受一个参数，这个参数就是被装饰的类。12345678910111213141516171819202122232425def pi_fu(cls): class PiFuClass: def __init__(self, name, pi_fu_name): self.wrapped = cls(name, pi_fu_name) self.pi_fu_name = pi_fu_name def display(self): self.wrapped.display() print(f'展示皮肤&#123;self.pi_fu_name&#125;') return PiFuClass@pi_fuclass YingXiong: def __init__(self, name, pi_fu_name): self.name = name self.pi_fu_name = pi_fu_name def display(self): print(f'展示英雄&#123;self.name&#125;')ya_se = YingXiong('亚瑟', '死亡骑士')ya_se.display()","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"bert4keras 框架解读（1）-介绍和模型加载","slug":"NLP/transformer/bert4keras_code01","date":"2021-11-17T09:12:35.000Z","updated":"2021-11-18T07:49:26.525Z","comments":true,"path":"NLP/transformer/bert4keras_code01/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/bert4keras_code01/","excerpt":"","text":"文档说明：https://bert4keras.spaces.ac.cn/guide/代码地址：https://github.com/bojone/bert4keras 1. 介绍bert4keras是一个基于keras的预训练模型加载框架，目前支持多种预训练模型（BERT、ALBERT、RoBERTa、ALBERT、NEZHA、GPT2、T5等），并支持多种环境（python 2.7、python 3.x）和后端（keras、tf.keras、tf 1.x、tf 2.x）。 源码框架结构：1234567__init__.pybackend.py # 分离后端函数，主要是为了同时兼容原生keras和tf.keraslayers.py # 自定义层models.py # 定义各种bert模型结构， 实现加载模型optimizers.py # 训练的优化器snippets.py # 其他模块工具函数tokenizers.py # 用于处理字词特征转换 2. 环境安装3. 模型加载定义了一个tokenizer，用来将输入的文本转化为id，并将id转化为向量。一个model,用来定义和加载预训练模型 目前支持的模型： Google原版bert: https://github.com/google-research/bert brightmart版roberta: https://github.com/brightmart/roberta_zh 哈工大版roberta: https://github.com/ymcui/Chinese-BERT-wwm Google原版albert[例子]: https://github.com/google-research/ALBERT brightmart版albert: https://github.com/brightmart/albert_zh 转换后的albert: https://github.com/bojone/albert_zh 华为的NEZHA: https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA 自研语言模型: https://github.com/ZhuiyiTechnology/pretrained-models T5模型: https://github.com/google-research/text-to-text-transfer-transformer GPT2_ML: https://github.com/imcaspar/gpt2-ml Google原版ELECTRA: https://github.com/google-research/electra 哈工大版ELECTRA: https://github.com/ymcui/Chinese-ELECTRA CLUE版ELECTRA: https://github.com/CLUEbenchmark/ELECTRA 示例：12345678910from bert4keras.models import build_transformer_modelfrom bert4keras.tokenizers import Tokenizerimport numpy as npconfig_path = 'F:/pretrain_tf/chinese_L-12_H-768_A-12/bert_config.json'checkpoint_path = 'F:/pretrain_tf/chinese_L-12_H-768_A-12/bert_model.ckpt'dict_path = 'F:/pretrain_tf/chinese_L-12_H-768_A-12/vocab.txt'tokenizer = Tokenizer(dict_path, do_lower_case=True) # 建立分词器model = build_transformer_model(config_path, checkpoint_path) # 建立模型，加载权重 3.1. tokenizer3.2. build_transformer_model12345678def build_transformer_model( config_path&#x3D;None, # 模型的配置文件（对应的文件为json格式） checkpoint_path&#x3D;None, # 模型的预训练权重（tensorflow的ckpt格式） model&#x3D;&#39;bert&#39;, # 模型的类型（bert、albert、albert_unshared、nezha、electra、gpt2_ml、t5） application&#x3D;&#39;encoder&#39;, # 模型的用途（encoder、lm、unilm） return_keras_model&#x3D;True, # 返回Keras模型，还是返回bert4keras的模型类 **kwargs # 其他传递参数):","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"},{"name":"bert4keras","slug":"bert4keras","permalink":"https://tlylft.github.io/tags/bert4keras/"}]},{"title":"milvus安装及其python使用教程","slug":"NLP/similarity/milvus","date":"2021-11-17T07:39:19.000Z","updated":"2021-11-17T07:39:45.999Z","comments":true,"path":"NLP/similarity/milvus/","link":"","permalink":"https://tlylft.github.io/NLP/similarity/milvus/","excerpt":"","text":"https://blog.csdn.net/yangschfly/article/details/105292534","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"}],"tags":[{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"}]},{"title":"BERTology实现文本相似度","slug":"NLP/similarity/similarity_bert","date":"2021-11-17T06:00:42.000Z","updated":"2021-11-17T15:03:55.337Z","comments":true,"path":"NLP/similarity/similarity_bert/","link":"","permalink":"https://tlylft.github.io/NLP/similarity/similarity_bert/","excerpt":"","text":"https://mp.weixin.qq.com/s/QvCHBGu3ZjvN_RPQN8zGvg BERT-avgbert-whitening通过whitening降维后提高语义相似性的表达，若是用有监督方式训练的向量，可以不进行lanbda^(1/2)的计算 simbertsimCSEsentence-bert","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"}],"tags":[{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"}]},{"title":"文本相似度工程化","slug":"NLP/similarity/similarity_engineer","date":"2021-11-17T05:51:01.000Z","updated":"2021-11-17T06:00:30.685Z","comments":true,"path":"NLP/similarity/similarity_engineer/","link":"","permalink":"https://tlylft.github.io/NLP/similarity/similarity_engineer/","excerpt":"","text":"查找文本最相似的问题，使用大模型会存在时间和资源消耗，可以考虑 待匹配的文本先计算出向量存储起来 milvus 向量存储数据库 模型蒸馏","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"}],"tags":[{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"}]},{"title":"huggingface transformer实战（1）-完形填空","slug":"NLP/transformer/transformer_demo1_mask","date":"2021-11-12T02:37:45.000Z","updated":"2021-11-12T02:39:59.520Z","comments":true,"path":"NLP/transformer/transformer_demo1_mask/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/transformer_demo1_mask/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import torch from transformers import BertTokenizer, BertForMaskedLM# 加载tokenizer# tokenizer &#x3D; BertTokenizer.from_pretrained(&#39;F:\\\\pretrain\\\\bert-base-uncased&#39;)tokenizer &#x3D; BertTokenizer.from_pretrained(&#39;F:\\\\pretrain\\\\bert-base-chinese&#39;)# 输入文本# text &#x3D; &quot;[CLS] Who is Li Jinhong ? [SEP] Li Jinhong is a programmer [SEP]&quot;# text &#x3D; &quot;[CLS] 谁 是 李 明 [SEP] 李 明 是 个 程 序 员 [SEP]&quot;text &#x3D; &quot;[CLS]谁是李明[SEP]李明是个程序员[SEP]&quot;tokenized_text &#x3D; tokenizer.tokenize(text)print(tokenized_text)masked_index &#x3D; 9 # 掩码一个标记，用&#39; BertForMaskedLM &#39;预测回来tokenized_text[masked_index] &#x3D; &#39;[MASK]&#39;print(tokenized_text)# 将标记转换为词汇表索引indexed_tokens &#x3D; tokenizer.convert_tokens_to_ids(tokenized_text)# 将输入转换为PyTorch张量tokens_tensor &#x3D; torch.tensor([indexed_tokens])# 指定设备device &#x3D; torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)# device &#x3D; torch.device( &quot;cpu&quot;)print(device)# 加载预训练模型 (weights)model &#x3D; BertForMaskedLM.from_pretrained(&#39;F:\\\\pretrain\\\\bert-base-chinese&#39;)model.eval()model.to(device)segments_ids &#x3D; [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]segments_tensors &#x3D; torch.tensor([segments_ids]).to(device)tokens_tensor &#x3D; tokens_tensor.to(device)# 预测所有的tokenswith torch.no_grad(): outputs &#x3D; model(tokens_tensor, token_type_ids&#x3D;segments_tensors)predictions &#x3D; outputs[0] # [1, 14, 21128]# predicted_index &#x3D; torch.argmax(predictions[0, masked_index]).item()# predicted_token &#x3D; tokenizer.convert_ids_to_tokens([predicted_index])[0:5] # 转成单词# print(&#39;Predicted token is:&#39;, predicted_token)scores &#x3D; predictions[0, masked_index].unsqueeze(0)predicted_index &#x3D; torch.argsort(scores,dim&#x3D;1, descending&#x3D;True)predicted_token &#x3D; tokenizer.convert_ids_to_tokens(predicted_index[0])[0:5] # 转成单词print(&#39;Predicted token is:&#39;, predicted_token)","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"huggingface transformer框架解读(3)-tokenizer","slug":"NLP/transformer/transformer_code3_tokenizer","date":"2021-11-12T02:23:18.000Z","updated":"2021-11-16T12:41:34.086Z","comments":true,"path":"NLP/transformer/transformer_code3_tokenizer/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/transformer_code3_tokenizer/","excerpt":"","text":"1. 词表工具Tokenizer在transformer库中 ，提供了一个通用的词表工具Tokenizer,可以实现NLP任务重数据预处理的相关任务。 Normalizer：对输入字符进行规范化转换，如对文本进行大小写转换 PreTokenizer：对输入数据进行预处理，如基于字符、空格的分词 Model： 生成和使用字词的模型，可训练的 Post-Processor： 对分词后的文本进行二次处理，如添加CLS标识 Decoder： 输入向量转换为字符串 Trainer： 训练能力 base类： PreTrainedTokenizer位置： transformers/tokenization_utils.py 特性模型的继承子类：{model_name}Tokenizer位置：transformers/models/{model_name}/tokenization_{model_name}.py 2. 使用说明加载tokenizer:12from transformers import &#123;model_name&#125;Tokenizertokenizer = &#123;model_name&#125;Tokenizer.from_pretrained('&#123;model_name&#125;-base-chinese') 2.1. 一些函数查看tokenizer的词表：12print(tokenizer.vocab)# output:OrderedDict([('[PAD]', 0), ('[unused1]', 1), ...])查看tokenizer的词表大小：12print(len(tokenizer))# output:21128查看tokenizer的特殊符号：123456789101112for token_type in tokenizer.SPECIAL_TOKENS_ATTRIBUTES: token_show = \"tokenizer.\" + token_type token_id = token_show + '_id' print(token_type, eval(token_show)) # print(token_type, eval(token_show), eval(token_id))# output:eos_token None# unk_token [UNK]# sep_token [SEP]# pad_token [PAD]# cls_token [CLS]# mask_token [MASK]# additional_special_tokens []添加特殊词12345678special_tokens_dict = &#123;'additional_special_tokens': ['&lt;HHH&gt;']&#125;num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)print('We have added', num_added_toks, 'tokens')print(tokenizer.additional_special_tokens, tokenizer.additional_special_tokens_ids)test = tokenizer.encode(\"你好&lt;HHH&gt;\")print(tokenizer.convert_ids_to_tokens(test))# output:['你', '好', '&lt;HHH&gt;']使用tokenizer进行分词：1234text = \"我是中国人\"tokenized_text = tokenizer.tokenize(text)print(tokenized_text)# output:['我', '是', '中', '国', '人']转换为词向量id:12345text = \"我是中国人\"tokenized_text = tokenizer.tokenize(text)tokenized_ids = tokenizer.convert_tokens_to_ids(tokenized_text)print(tokenized_ids)#output: [2769, 3221, 704, 1744, 782] 2.2. 使用encoder分词，加特殊字符，转换词向量id ，一个函数全部完成encoder函数定义：12345678910111213\"\"\"def encode(self, text: Union[TextInput, PreTokenizedInput, EncodedInput], #第一个句子 text_pair: Optional[Union[TextInput, PreTokenizedInput, EncodedInput]] = None, # 第二个句子 add_special_tokens: bool = True, # 是否添加特殊词 padding: Union[bool, str, PaddingStrategy] = False, # 是否补全 truncation: Union[bool, str, TruncationStrategy] = False, # 4种策略 1.\"longest_first\" \"only_first\" \"only_second\" \"do_not_truncate\" max_length: Optional[int] = None, # 最大长度 stride: int = 0, return_tensors: Optional[Union[str, TensorType]] = None, # 返回值类型 \"tf\" \"pt\", 默认返回list **kwargs) -&gt; List[int]:\"\"\"使用tokenizer直接进行转换：123456text = \"我是中国人\"tokenized_text = tokenizer.encode(text)print(tokenized_text)print(tokenizer.convert_ids_to_tokens(tokenized_text))# output:[101, 2769, 3221, 704, 1744, 782, 102]# output:['[CLS]', '我', '是', '中', '国', '人', '[SEP]']转换两句话：1234567891011121314151617text1 = \"谁是李明\"text2 = \"李明是个程序员\"# 方式1：学习一下，不用a = tokenizer.encode(text1)b = tokenizer.encode(text2)encoder_result = a+b[1:] # 将第二句的第一个[CLS]去掉print(\"encoder 分词+特殊字符并转换词向量：\\n\", encoder_result)print(tokenizer.convert_ids_to_tokens(encoder_result)) # output:# [101, 6443, 3221, 3330, 3209, 102, 3330, 3209, 3221, 702, 4923, 2415, 1447, 102]# ['[CLS]', '谁', '是', '李', '明', '[SEP]', '李', '明', '是', '个', '程', '序', '员', '[SEP]']# 方式2：test = tokenizer.encode(text1, text2)print(\"test:\", tokenizer.convert_ids_to_tokens(test))# output:# test: ['[CLS]', '谁', '是', '李', '明', '[SEP]', '李', '明', '是', '个', '程', '序', '员', '[SEP]']不加入特殊字符：1234test = tokenizer.encode(text1, text2, add_special_tokens=False)print(\"test:\", tokenizer.convert_ids_to_tokens(test))# output:# test: ['谁', '是', '李', '明', '李', '明', '是', '个', '程', '序', '员']补全句子长度：1234test = tokenizer.encode(text, padding=\"max_length\", max_length=10)print(\"test:\", tokenizer.convert_ids_to_tokens(test))# output:# test: ['[CLS]', '我', '是', '中', '国', '人', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] encoder_plus(): 生成掩码标识，被截断的词等附加信息。1234567test = tokenizer.encode_plus(text1, text2, add_special_tokens=False)print(\"encode_plus:\", test)# output:&#123;# 'input_ids': [6443, 3221, 3330, 3209, 3330, 3209, 3221, 702, 4923, 2415, 1447], # 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],# 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]# &#125;batch_encode_plus(): 批量转换，返回list12test = tokenizer.batch_encode_plus([text1, text2], add_special_tokens=False)print(\"batch_encode_plus:\", test) 3. PreTrainedTokenizer","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"torch embedding层","slug":"pytorch/torch_embedding","date":"2021-11-09T02:45:19.000Z","updated":"2021-11-09T03:03:02.091Z","comments":true,"path":"pytorch/torch_embedding/","link":"","permalink":"https://tlylft.github.io/pytorch/torch_embedding/","excerpt":"","text":"使用自定义一个随机的embbeding层,返回一个embedding实例：1self.emb1 &#x3D; nn.Embedding(vocab_size, embedding_dim)从预训练模型中加载,返回一个embedding实例：12weight &#x3D; torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])self.emb2 &#x3D; nn.Embedding.from_pretrained(weight,freeze&#x3D;True)使用embbedding信息，源码中复写了call函数，可直接调用实例做索引查找：1234# 获取index为1的embedding表示input &#x3D; torch.LongTensor([1])embedding(input)&gt; tensor([[ 4.0000, 5.1000, 6.3000]])transformer中复杂的示例：1234567891011121314151617def get_sinusoid_encoding_table(n_position, d_model): def cal_angle(position, hid_idx): return position &#x2F; np.power(10000, 2 * (hid_idx &#x2F;&#x2F; 2) &#x2F; d_model) def get_posi_angle_vec(position): return [cal_angle(position, hid_j) for hid_j in range(d_model)] sinusoid_table &#x3D; np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)]) sinusoid_table[:, 0::2] &#x3D; np.sin(sinusoid_table[:, 0::2]) # dim 2i sinusoid_table[:, 1::2] &#x3D; np.cos(sinusoid_table[:, 1::2]) # dim 2i+1 return torch.FloatTensor(sinusoid_table)class myModule(nn.Module): def __init__(self): self.src_emb &#x3D; nn.Embedding(src_vocab_size, d_model) self.pos_emb &#x3D; nn.Embedding.from_pretrained(get_sinusoid_encoding_table(src_len+1, d_model),freeze&#x3D;True) def forward(self): dec_outputs &#x3D; self.tgt_emb(dec_inputs) + self.pos_emb(torch.LongTensor([[5,1,2,3,4]])) 源码torch.nn.modules.sparse.pyclass Embedding(Module):","categories":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/categories/pytorch/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/tags/pytorch/"}]},{"title":"DIET模型","slug":"chatbot/rasa_diet","date":"2021-11-04T14:10:43.000Z","updated":"2023-08-11T08:42:21.967Z","comments":true,"path":"chatbot/rasa_diet/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_diet/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/267974856论文youtube讲解","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"开放域问答","slug":"chatbot/open_chat","date":"2021-11-02T01:31:48.000Z","updated":"2023-08-11T08:41:11.458Z","comments":true,"path":"chatbot/open_chat/","link":"","permalink":"https://tlylft.github.io/chatbot/open_chat/","excerpt":"","text":"用户以自然语言的形式提出查询请求，系统直接返回准确、简洁的答案，而非可能包含答案的文档。 事实检索+理解系统。 考察系统的文本匹配、信息抽取能力 结合检索+机器阅读理解，输出准确、简洁的答案现状数据源： 社区问答： 百度知道，贴吧等 文本问答： 阅读理解式，对文章进行理解 现状： 以检索和MRC技术为基本过程 基于模式匹配和NLU 融入阅读理解技术 问题： 对于一些问题，仍然无法返回答案，需要用户眼动搜索 复杂的问题，需要比较或推理的问题，返回错误的结果 应用前景语音助手，智能客服，搜索引擎 实现方法从大量文本中找到答案检索器：对用户输入的问题，检索一系列相关的句子，段落或文档阅读器：通过机器阅读理解的方法从检索的结果中获取答案。 检索器根据给定的query，从大量的数据（几百万）中检索出相关的内容问题：对于深度学习， 数据量过大，效率低，一般采用传统的机器学习方法。常用文本相似度检索的方法： tf-idf bm25 LDA BERT 阅读器理解文本语义，开放域问答中，阅读器通常借鉴MRC技术 依赖于分词、词性标注、NER和预存关系分析等自然语言处理基础工作 可以与机器翻译，情感识别和信息抽取等技术思想互相借鉴 常用机器阅读理解的方法： match-lstm bi-DAF V-NET S-NET BERT —-大范式 BART","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}]},{"title":"Visual Paradigm","slug":"tools/visual_paradigm","date":"2021-11-01T06:39:33.000Z","updated":"2021-11-01T06:59:59.241Z","comments":true,"path":"tools/visual_paradigm/","link":"","permalink":"https://tlylft.github.io/tools/visual_paradigm/","excerpt":"","text":"可以做涉及到技术方案的设计，包括 时序图、集成架构图、逻辑架构图、E-R图 安装下载地址 公司的企业版 转换中文Window&gt;&gt;Application Options&gt;&gt;General&gt;&gt;Appearance，在Installed Use Language中选择English或者Simplified Chinese，之后单击Apply，单击OK，重启软件即完成语言转换，如下图所示。（注：汉语版仍存在一部分英文） 使用ER图","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"},{"name":"vp","slug":"vp","permalink":"https://tlylft.github.io/tags/vp/"}]},{"title":"vue框架安装和使用","slug":"vue/vue_install","date":"2021-11-01T06:39:33.000Z","updated":"2023-08-11T09:35:10.893Z","comments":true,"path":"vue/vue_install/","link":"","permalink":"https://tlylft.github.io/vue/vue_install/","excerpt":"","text":"1. vue3.0安装安装详细说明参考 1.1. node.js官网下载地址12345678910111213141. 查看安装成功node -vnpm -v2. 在我们的安装目录下，创建名为node_cache和node_global的两个文件夹。3. 配置目录npm config set prefix &quot;你的安装目录\\node_global&quot;npm config set cache &quot;你的安装目录\\node_cache&quot;# 配置镜像源npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org# 查看配置npm config list# 配置环境变量local variable path: 将 C:\\Users\\你的用户名\\AppData\\Roaming\\npm修改为&quot;你的安装目录\\node_global&quot;system variable path: 你的安装目录\\node_global\\node_modules 1.2. vue,js1234567891011121314npm install vue -g #这个装的vue 好像是2.6npm install vue-cli -g vue --version如果需要更换vue3，先卸载vue2 node.js 14.0.0以上的npm uninstall vue-cli -g npm install @vue&#x2F;cli -g # vue3用@安装yarn global upgrade --latest @vue&#x2F;cli # 更新版本npm install webpack -gnpm install webpack-cli -gwebpack -vnpm install vue-router -gnpm install yarn -g 2. 运行项目2.1. 项目初始化项目初始化vue create project_namecd project_name 2.2. 示例开源项目vue3vue-next-admincd projectnpm run dev/yarn server 2.3. 问题npm install -g yarn解决python环境2。7问题：yarn config set python E:/Python27/python.exe","categories":[{"name":"前端","slug":"前端","permalink":"https://tlylft.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[]},{"title":"huggingface transformer框架解读(2)-pipline机制","slug":"NLP/transformer/transformer_code2 pipline","date":"2021-10-20T02:34:03.000Z","updated":"2021-11-12T02:36:10.620Z","comments":true,"path":"NLP/transformer/transformer_code2 pipline/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/transformer_code2%20pipline/","excerpt":"","text":"工作原理pipline里定义了模型预编译文件，支持的NLP任务，和每种任务对应的内部调用关系。 pipline类简单调用流程：123class xxxPipline(Pipline): def __call__(): return xxx管道层调用自动模型层12class AutoModelXXX(): xxx自动模型层调用具体模型层1具体的预训练模型加载模型文件 代码解读解读： transformer/piplines/__init__.py task定义定义支持的task列表：key是任务名impl是具体的任务加载的pipline类接口tf是指定tensorflow框架的自动类模型pt是指定pytorch框架的自动类模型default: 需要加载的权重文件1234567891011121314151617SUPPORTED_TASKS &#x3D; &#123; &quot;audio-classification&quot;: &#123; &quot;impl&quot;: AudioClassificationPipeline, &quot;tf&quot;: (), &quot;pt&quot;: (AutoModelForAudioClassification,) if is_torch_available() else (), &quot;default&quot;: &#123;&quot;model&quot;: &#123;&quot;pt&quot;: &quot;superb&#x2F;wav2vec2-base-superb-ks&quot;&#125;&#125;, &#125;, &quot;zero-shot-classification&quot;: &#123; &quot;impl&quot;: ZeroShotClassificationPipeline, &quot;tf&quot;: (TFAutoModelForSequenceClassification,) if is_tf_available() else (), &quot;pt&quot;: (AutoModelForSequenceClassification,) if is_torch_available() else (), &quot;default&quot;: &#123; &quot;model&quot;: &#123;&quot;pt&quot;: &quot;facebook&#x2F;bart-large-mnli&quot;, &quot;tf&quot;: &quot;roberta-large-mnli&quot;&#125;, &quot;config&quot;: &#123;&quot;pt&quot;: &quot;facebook&#x2F;bart-large-mnli&quot;, &quot;tf&quot;: &quot;roberta-large-mnli&quot;&#125;, &quot;tokenizer&quot;: &#123;&quot;pt&quot;: &quot;facebook&#x2F;bart-large-mnli&quot;, &quot;tf&quot;: &quot;roberta-large-mnli&quot;&#125;, &#125;, &#125;, pipline()加载流程1pipline(&quot;&lt;task_name&gt;&quot;,model&#x3D;&quot;&lt;model_name&gt;&quot;) pipline类定义","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"huggingface transformer框架解读(1)-介绍和模型加载","slug":"NLP/transformer/transformer_code1","date":"2021-10-20T02:33:03.000Z","updated":"2021-11-12T03:15:27.898Z","comments":true,"path":"NLP/transformer/transformer_code1/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/transformer_code1/","excerpt":"","text":"参考：huggingface文档 ：https://huggingface.co/transformers/installation.html《基于BERT模型的自然语言处理实战》 李金洪 1. 介绍transformer库包括NLU和NLG两大类任务，超过32个预训练模型，细分为100多种语言版本。transformer3版本之后全面支持TensorFlow和pytorch框架在各种环境下的推理功能。 预训练 微调 导入TensorFlow模型到pytorch swift-coreml-transformers 导入模型转化成iOS系统下使用的终端模型 三层结构分被对应3中应用方式：（1）管道Pipline:高度集成的使用方式，使用简单，灵活度差（2）自动模型 Auto Model（3）具体模型（BERT,XLNet等）：使用复杂，灵活度高 2. 环境安装12345conda create -n bert pyhton&#x3D;3.6pip install tensorflow-gpu&#x3D;2.0.0conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;pytorch&#x2F;conda install pytorch torchvision cudatoolkit&#x3D;10.2pip install transformer 验证1234import torchprint(torch.__version__) # 查看pytorch版本print(&#39;gpu:&#39;,torch.cuda.is_available()) # gpu加速是否可用import tensorflow as tf 3. 模型加载 每个模型需要有三个标准步骤/标准类： configuration、 models和tokenizer。 每个类可以通过from_pretrained()加载预训练的模型或文件 通过两个API串联以上三个环节：pipline():用于在给定任务上快速使用模型Trainer()/TFTrainer(): 快速训练或微调给定模型。 如需自定义/扩展模型库， PyTorch/TensorFlow/Keras 每个框架都提供继承的基类，复写模型加载和保存即可 支持的模型列表： https://huggingface.co/transformers/pretrained_models.html 3.1. 模块介绍3.1.1. configuration存储构建模型所需的所有参数。直接加载预训练模型的时候可以用 3.1.2. models包含30+ torch模型和keras模型， 3.1.3. tokenizer它们存储每个模型的词汇表，并提供用于编码/解码要馈送到模型的令牌嵌入索引列表中的字符串的方法。【详细解析】 3.2. 加载函数介绍3.2.1. pretrained缓存模型当使用from_pretrained()时，缓存位置优先顺序： specify a location with cache_dir=… shell environment variable TRANSFORMERS_CACHE shell environment variable (PYTORCH_TRANSFORMERS_CACHE or PYTORCH_PRETRAINED_BERT_CACHE) default dir: ~/.cache/huggingface/transformers/. 3.2.2. 下载模型使用snapshot_download下载整个仓库使用hf_hub_download下载特定文件 3.2.3. 本地离线模型设置环境变量 TRANSFORMERS_OFFLINE=1加载模型只使用本地文件，不会尝试查找HF_DATASETS_OFFLINE=1加载数据集只使用本地文件，不会尝试查找 3.2.4. 保存模型save_pretrained()允许您在本地保存模型/配置/标记器，以便可以使用 from_pretrained(). 3.3. 加载模型3.3.1. pipline方式【详细模块解析】pipline管道加载情感分析模型：123text &#x3D; &#39;I like this book!&#39;nlp &#x3D; pipeline(&quot;sentiment-analysis&quot;)print(nlp(text))pipline管道加载情感分析模型(指定缓存位置)：123tokenizer &#x3D; DistilBertTokenizer.from_pretrained(&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;,cache_dir &#x3D; &#39;F:\\\\pretrain&#39;)model &#x3D; DistilBertForSequenceClassification.from_pretrained(&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;,cache_dir &#x3D; &#39;F:\\\\pretrain&#39;)print(pipeline(&#39;sentiment-analysis&#39;, model&#x3D;model,tokenizer&#x3D;tokenizer)(text))pipline管道加载指定位置预训练情感分析模型：12tokenizer &#x3D; DistilBertTokenizer.from_pretrained(&quot;F:\\\\pretrain\\\\distilbert-base-uncased-finetuned-sst-2-english&quot;)print(pipeline(&#39;sentiment-analysis&#39;, model&#x3D;&#39;F:\\\\pretrain\\\\distilbert-base-uncased-finetuned-sst-2-english&#39;)(text)) 3.3.2. specificModule3.3.3. autoModule","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"CPU、GPU和TPU","slug":"deep_learning/CPU_GPU_TPU","date":"2021-10-08T06:02:57.000Z","updated":"2021-10-08T06:43:46.055Z","comments":true,"path":"deep_learning/CPU_GPU_TPU/","link":"","permalink":"https://tlylft.github.io/deep_learning/CPU_GPU_TPU/","excerpt":"","text":"为何关注硬件 关注硬件不等于所有都要重新写 加速训练 避免部署出现问题 CPU基础架构core: 做运算register： 寄存器，做临时存储,现在一般x64cache： 缓存，从内存里读数据块，一般有策略会预测下次运算需要的数据，多读一些。cache miss: cache多读了一些数据，当有其他线程需要占用CPU时，缓存会清除掉已有数据刷入新数据，造成CPU在工作中大量时间进行cache读写操作。 在训练时候的注意事项 容器部署时，可能因CPU架构原因，运算速度慢很多（CPU缓存读写策略 因多线程干扰频繁清空与写入） 一般不用 CPU 训练深度学习模型。 很多 if…else 出现时，CPU 会比 GPU 快。 如果需要加速，可以通过 Cython 访问 C++，这在实际业务性应用时很有用。 对于大部分硬件（GPU，TPU，FPGA），CPU会负责数据的读写 -&gt; 在进行训练时， 有时为了加速需要选择更多核的机器。部署避免 避免cache miss 有时需要使用足够多的核来支持读写 GPU两个主要厂商：nvidia amd主流是nvidia,两个系列商用卡P100,p1000，v100, RTX2080Ti被动散热，必须放到服务器里和民用卡geforce系列 基础架构core: 进行并行运算，1080ti分发出3000多核进行运算，但为什么比64核的CPU贵？ 因为它不是独立的核，不能进行独立的计算规则，而是分发给3000多线程做同样的计算规则（都做加法或都做减法），SIMT:single instruction multiple threads GPU的数据读取不能从内存中直接获得，而是通过GPU memory访问CPU memory获得，所以内存读写频繁可能造成GPU计算效率非常低 GPU硬件特点 显存污染 显存独立于内存，GPU 显存定时去CPU memory读取数据，当容器化部署时，可能多个进程读取造成冲突，内存和显存的读取可能会成为问题。 对于显存的处理，multi-stream processer 并不如 CPU 一样强大。 GPU 是非常复杂的处理器。 GPU 训练注意事项 GPU 训练效率可以被 DeepSpeed 显著提升。(优化gpu使用的一个加速包) 很少出现 GPU 多线程训练。 GPU 训练有时可能会被一些其他因素影响，如CPU，GPU 之间沟通速度（多 GPU或多节点）。 传统来说，NLP 的训练一般来说不会耗尽 GPU的资源，但是深度迁移模型出现后， GPU 常常出现算力不足或显存资源不足的情况。 GPU 可处理动态的网络。(虽然效率不如cpu,但可以处理if else)GPU 部署的注意事项 GPU 部署的最大问题：显存污染。（最好1个GPU一个serving） GPU 部署经常被内存与显存之间的带宽影响。（加大CPU核数） 部署时需要对参数做详细调整，最重要参数为 Batch Size。（kafka中间件批处理的batch）","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"CPU、GPU和TPU","slug":"deep_learning/deploy_strategy","date":"2021-10-08T06:02:57.000Z","updated":"2022-08-15T00:15:30.262Z","comments":true,"path":"deep_learning/deploy_strategy/","link":"","permalink":"https://tlylft.github.io/deep_learning/deploy_strategy/","excerpt":"","text":"fp16和fp32，神经网络混合精度训练","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"bert tensorflow 代码解读","slug":"NLP/transformer/bert_tensorflow","date":"2021-10-08T05:48:00.000Z","updated":"2021-10-19T03:13:02.910Z","comments":true,"path":"NLP/transformer/bert_tensorflow/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/bert_tensorflow/","excerpt":"","text":"https://github.com/google-research/bert 运行文件： run_classifier.py","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"深度学习训练过程","slug":"deep_learning/train_process","date":"2021-08-27T04:56:06.000Z","updated":"2021-08-27T04:56:37.780Z","comments":true,"path":"deep_learning/train_process/","link":"","permalink":"https://tlylft.github.io/deep_learning/train_process/","excerpt":"","text":"","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"celery异步","slug":"python/python/python_celery","date":"2021-08-15T11:41:33.000Z","updated":"2022-03-20T13:10:40.651Z","comments":true,"path":"python/python/python_celery/","link":"","permalink":"https://tlylft.github.io/python/python/python_celery/","excerpt":"","text":"github地址: https://github.com/celery/celery官方说明文档：https://docs.celeryq.dev/en/stable/getting-started/first-steps-with-celery.html 1. 安装12pip install celery&#x3D;&#x3D;5.1.2kombu&#x3D;&#x3D;4.6.3 # 解决接收指定队列时进程自动杀死或者连通报错的bug Table empty or key no longer exists 错误 OperationalError(“\\nCannot route message for exchange ‘reply.celery.pidbox’: Table empty or key no longer exists.\\nProbably the key (‘_kombu.binding.reply.celery.pidbox’) has been removed from the Redis database.\\n”,)解决思路： 减低kombu版本到 4.6.3 for windows 启动接收参数错误12pip install eventlet-0.31.1 celery -A commons.config.celery_config worker -l info -P eventlet 2. 使用2.1. demo 启动服务，定义任务task.py 123456789101112131415from celery import Celery #导入Celerybroker = 'redis://:password@10.39.200.102:6379/13' # 设置brokerbackend = 'redis://:password@10.39.200.102:6379/13' # 设置backendcelery_app = Celery('rasa_train_tasks', broker=broker, backend=backend) # 实例化celery# 编写任务@celery_app.taskdef rasa_train(bot_id, port): print(bot_id, port) import time time.sleep(10) return 'success' 启动celery服务—消费者服务 1234567# demo celery -A task worker -l info# windowscelery -A task worker -l info -P eventlet# 目录文件celery -A asy_task.celery_config worker -l info [-P eventlet]celery -A asy_task worker -l info [-P eventlet] output: 12345678[tasks]. commons.config.celery_config.rasa_train[2021-08-15 19:40:01,812: INFO&#x2F;MainProcess] Connected to redis:&#x2F;&#x2F;:**@10.39.200.102:6379&#x2F;13[2021-08-15 19:40:02,009: INFO&#x2F;MainProcess] mingle: searching for neighbors[2021-08-15 19:40:03,361: INFO&#x2F;MainProcess] mingle: all alone[2021-08-15 19:40:03,429: INFO&#x2F;MainProcess] pidbox: Connected to redis:&#x2F;&#x2F;:**@10.39.200.102:6379&#x2F;13.[2021-08-15 19:40:03,474: INFO&#x2F;MainProcess] celery@LAPTOP-14KN9DK3 ready. 测试加入任务— 生产者服务 1234from task import rasa_train#from commons.config.celery_config import rasa_trainprint(rasa_train.delay(1,2)) output: 1234567[2021-08-15 19:40:40,050: INFO&#x2F;MainProcess] Task commons.config.celery_config.rasa_train[34318fce-a8d8-40f2-9b98-3768be29609e] received[2021-08-15 19:40:40,051: WARNING&#x2F;MainProcess] 1[2021-08-15 19:40:40,051: WARNING&#x2F;MainProcess][2021-08-15 19:40:40,051: WARNING&#x2F;MainProcess] 2[2021-08-15 19:40:40,051: WARNING&#x2F;MainProcess][2021-08-15 19:40:50,114: INFO&#x2F;MainProcess] Task commons.config.celery_config.rasa_train[34318fce-a8d8-40f2-9b98-3768be29609e] succeeded in 10.062000000005355s: &#39;success&#39; 2.2. 配置文件celery_config.py配置参数说明 http://docs.jinkan.org/docs/celery/configuration.html#configuration123456789101112131415# coding:utf-8from commons.config.env import configBROKER_URL = 'redis://:&#123;0&#125;@&#123;1&#125;:&#123;2&#125;/&#123;3&#125;'.format(config.REDIS_PW, config.REDIS_HOST, config.REDIS_PORT, config.REDIS_DB)CELERY_RESULT_BACKEND = 'db+mysql+pymysql://&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;/&#123;&#125;?charset=utf8'.format( config.USERNAME, config.PASSWORD, config.HOSTNAME, config.PORT, config.DATABASE)CELERY_TASK_SERIALIZER = 'json'CELERY_RESULT_SERIALIZER = 'json'CELERY_ACCEPT_CONTENT = ['pickle', 'json']CELERY_REDIS_MAX_CONNECTIONS=100CELERY_ACKS_LATE=TrueCELERYD_CONCURRENCY = 1 # # 并发worker数CELERYD_MAX_TASKS_PER_CHILD = 1 # 每个worker最多执行万100个任务就会被销毁，可防止内存泄露# CELERYD_TASK_TIME_LIMIT = 60 # 单个任务的运行时间不超过此值，否则会被SIGKILL 信号杀死celery.py12345from __future__ import absolute_importfrom celery import Celery, platformsplatforms.C_FORCE_ROOT = Truecelery = Celery('asy_app', include=['asy_task.task'])celery.config_from_object('asy_task.celery_config') 队列配置https://www.jianshu.com/p/4d0bbdbc6ade 2.3. 查看命令celery查看查看有多少任务正在运行1celery -A tasks inspect active查看有多少任务接收了但还未运行123celery -A tasks inspect reserved# 统计个数(数量为下面的结果-1)celery -A tasks inspect reserved | wc -l查看有多少worker1234 celery -A tasks statuscelery@itscs-MacBook-Pro.local: OK1 node online.使用flower在线查看flower可以实时监控celery的状态，并且还能修改一些配置（生产环境慎用）。（引）12pip install flowercelery -A tasks flower浏览器打开http://localhost:5555即可看到一个现实celery状态的网页。 使用redis作为broker需要先安装redis环境，使用redis-cli查看。基本就是使用redis指令对存储在redis里的list进行各种操作。查看当前所有队列即查看当前存储的所有的keyredis-cli -h HOST -p PORT -n DB_NUMBER(默认为0) keys *123456 redis-cli -n 1 keys \\* # celery内部用来发送event和管理其他队列的队列1) &quot;_kombu.binding.celery.pidbox&quot;2) &quot;_kombu.binding.celeryev&quot;# 当前的工作队列3) &quot;_kombu.binding.celery&quot; 查看队列长度和信息https://www.jianshu.com/p/b6f08341a3ec","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"python操作ppt","slug":"python/python/python_pptx","date":"2021-06-28T08:57:18.000Z","updated":"2021-07-06T14:38:17.839Z","comments":true,"path":"python/python/python_pptx/","link":"","permalink":"https://tlylft.github.io/python/python/python_pptx/","excerpt":"","text":"1. 安装1pip install python-pptx 2. 模块概念在该模块中，将ppt拆分为了以下多个元素 2.1. presentations表示整个ppt文档，用于打开，创建，保存ppt文档，用法如下12345678910111213from pptx import Presentation# 新建一个展示对象dest &#x3D; Presentation()# 打开一个一个PPTdest &#x3D; Presentation(&#39;test.pptx&#39;)# 保存dest.save(&#39;generate.pptx&#39;)# 画布大小属性dest.slide_heightdest.slide_widthdest.slide_height &#x3D; dest.slide_width &#x3D; 2.2. slides表示ppt文档的每一页，在创建一页ppt时，需要指定对应的布局，在该模块中， 内置了以下9种布局1234567891011121314151617181920&quot;&quot;&quot;1. Title2. Title and Content3. Section Header4. Two Content5. Comparison6. Title Only7. Blank8. Content with Caption9. Picture with Caption&quot;&quot;&quot;from pptx import Presentationdef add_layout_pptx(): dest &#x3D; Presentation() slide_layout &#x3D; dest.slide_layouts # 测试加入页不同的layout, 5为空白模块 # for i in range(len(slide_layout)): # dest.slides.add_slide(dest.slide_layouts[i]) dest.slides.add_slide(dest.slide_layouts[5]) dest.save(&#39;layout_test.pptx&#39;) 2.3. shapesshapes表示容器，在制作ppt时，各种基本元素，比如文本框，表格，图片等都占据了ppt的一个部分，或者矩形区域，或者其他各种自定义的形状。shapes表示所有基本元素的和 2.4. placeholdersshapes表示所有基本元素的总和，而placeholders则表示每一个具体的元素，所以placeholders是shapes的子集， 通过数字下标来访问对应的placeholder 3. 使用https://blog.csdn.net/weixin_42750611/article/details/108029796读取pptx12 创建pptx1234567891011from pptx import Presentationprs &#x3D; Presentation()# 创建一个简单的标题-副标题页title_slide_layout &#x3D; prs.slide_layouts[0]slide &#x3D; prs.slides.add_slide(title_slide_layout)title &#x3D; slide.shapes.titlesubtitle &#x3D; slide.placeholders[1]title.text &#x3D; &quot;Hello, World!&quot;subtitle.text &#x3D; &quot;python-pptx was here!&quot;prs.save(&#39;test.pptx&#39;)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"ppt","slug":"ppt","permalink":"https://tlylft.github.io/tags/ppt/"}]},{"title":"canal","slug":"big_data/mysql/canal","date":"2021-06-27T02:50:47.000Z","updated":"2023-08-11T08:31:41.558Z","comments":true,"path":"big_data/mysql/canal/","link":"","permalink":"https://tlylft.github.io/big_data/mysql/canal/","excerpt":"","text":"原理mysql主备复制原理MySQL的Master实例将数据变更写入二进制日志（binary log，其中记录叫做二进制日志事件binary log events，可以通过show binlog events进行查看）MySQL的Slave实例将master的binary log events拷贝到它的中继日志（relay log）MySQL的Slave实例重放relay log中的事件，将数据变更反映它到自身的数据 canal工作原理Canal模拟MySQL Slave的交互协议，伪装自己为MySQL Slave，向MySQL Master发送dump协议MySQL Master收到dump请求，开始推送binary log给Slave（即Canal）Canal解析binary log对象（原始为byte流），并且可以通过连接器发送到对应的消息队列等中间件中 配置配置方式和坑https://www.bilibili.com/video/BV1Nv41177cA?t=15&amp;p=46坑1：坑2： canal/conf/mq.ymlcanalDestinations -patition 这个值如果报错range[0,1)，应该是设置为0 通过配置不同的canal启用不用的mysql.slaveId， 在这个canal下配置自己要接收的数据库，db,表正则，表示自己这个canal要处理的数据业务，发送到对应的kafka topic中，实现不用的业务逻辑。 重置消息（获取历史消息）1234mysql -hshow binary logsshow binglog events in &#39;上面logs展示的一个binlog&#39;找到要重置的位置的id,如15463 12vi canal&#x2F;conf&#x2F;[这个是应用topic名，如example]里面展示了读取的哪一个binlog和对应的position，修改这两个值","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"mysql","slug":"大数据技术/mysql","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/mysql/"}],"tags":[]},{"title":"机器学习知识点","slug":"machine_learning/ML_QA","date":"2021-06-26T06:29:37.000Z","updated":"2021-06-27T02:48:22.031Z","comments":true,"path":"machine_learning/ML_QA/","link":"","permalink":"https://tlylft.github.io/machine_learning/ML_QA/","excerpt":"","text":"为什么做特征归一化特征归一化是将所有的特征都统一到一个大致相同的数值区间，通常为[0,1]通常两种方法：最大最小缩放，和均值方差优势适用于基于梯度更新的学习减小抖动，稳定同步下降，加快收敛（每个特征可以按同样的学习步调进行梯度下降） 什么是组合特征，如何处理高维组合特征？组合特征是将累呗特征两个或多个特征组合起来，构成高阶组合特征问题：特征集的个数为mn，组合起来的学习参数规模会很大，可以做embedding降维，先降维mk+nk,再组合kk one-hot特征表示的作用？主要用于编码类别特征哑变量-dummy variable避免数字特征编码类别带来的函数抖动避免引入人工误差假设，如大小关系，差异关系 欧氏距离与曼哈顿距离？欧式距离应用起来没有实际意义， 距离越大的维度对欧式距离贡献权重越大，不一定是对的曼哈顿距离主要应用于导航应用，每个维度的权重相同 余弦相似度和欧式距离？余弦距离表述的是空间的角度关系，表示的是相对差异，是比较稳定的度量指标，不受维度数量和特征值大小的影响，取值范围[-1,1]，值越大表示越相似。广泛应用于文本，图像和视频领域","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"AI + CRM 提高企业的 \"绩\" 和 \"效\"","slug":"knowledge_graph/CRM_AI","date":"2021-06-23T06:41:55.000Z","updated":"2021-06-23T06:48:46.193Z","comments":true,"path":"knowledge_graph/CRM_AI/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/CRM_AI/","excerpt":"","text":"https://mp.weixin.qq.com/s?__biz=MzA5OTQ1MDQ4Mw==&amp;mid=2456200810&amp;idx=1&amp;sn=f6e81f63d94c8d1399c0ad127b848740&amp;chksm=87102d76b067a460547490e64d0b121373df33a6aa83322d5f22c1b78ffe1128c5088b6d172d&amp;scene=21#wechat_redirect https://mp.weixin.qq.com/s?src=11&amp;timestamp=1624408357&amp;ver=3147&amp;signature=*MZO-WGo*xTJgvPZx-OFt0a3WxUf*n7I6hEhoOSlAQYNEjt*ifI4B9x8a4p-OeewOQtiRD0EwWwD99BuaYdbq*tJYSoMwdCuLKr8GZ6TTumKNvFZ*AwdvjpZPwi7DH8u&amp;new=1","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"}]},{"title":"kafka","slug":"big_data/kafka","date":"2021-06-17T05:25:27.000Z","updated":"2023-08-11T08:26:04.837Z","comments":true,"path":"big_data/kafka/","link":"","permalink":"https://tlylft.github.io/big_data/kafka/","excerpt":"","text":"1. 介绍kafka是一个分布式的流媒体平台，作为一个集群运行在一个或多个数据中心服务器上。 三个关键功能：发布和订阅record stream容错的持久方式存储能够记录 发生时的处理流信息 四个核心API:producer API:允许应用程序发布的记录流至一个或多个kafka topic中Consumer API：允许应用程序订阅一个或多个topic，并处理他们的记录的数据流Stream API：允许应用程序充当流处理器，从一个或多个主题消费输入流，并产生一个输出流至一个或多个输出的topic，有效变换输入流和输出流Connecter API: 允许构建和运行topic连接到现有的DB中重用生产者或消费者。例如：关系型DB可以捕捉对表的更改。 Topic：一个可发布和订阅的类别或主题，不同topic占用kafka不同存储空间一个topic不限制消费者的数量topic partition：对topic的分区，每个分区都是一个有序的，不可变的记录序列。可以持久保存所有已发布的数据（无论是否被使用），可以通过配置设置保留的时间。 2. 原理 2.1. 基本概念Zookeeper： kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。 kafka cluster： Broker： Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等…… Topic： 消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以拥有多个topic的分区。 Partition： Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹。每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件（早期版本中没有）三个文件， log文件就实际是存储message的地方，而index和timeindex文件为索引文件，用于检索消息。 Replication: 每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。 Message： 每一条发送的消息主体。消息主要包含消息体、消息大小、offset、压缩类型……等等！我们重点需要知道的是下面三个： 1、 offset：offset是一个占8byte的有序id号，它可以唯一确定每条消息在parition内的位置！ 2、 消息大小：消息大小占用4byte，用于描述消息的大小。 3、 消息体：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。Producer：Producer即生产者，消息的产生者，是消息的入口。Consumer： 消费者，即消息的消费方，是消息的出口。Consumer Group： 我们可以将多个消费者组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量。 所以一个group里的consumer数量多于要消费的topic的partitions数量时，多余的consumer是没有用的。 2.2. 存储策略 无论消息是否被消费，kafka都会保存所有的消息。那对于旧数据有什么删除策略呢？ 1、 基于时间，默认配置是168小时（7天）。 2、 基于大小，默认配置是1073741824。 需要注意的是，kafka读取特定消息的时间复杂度是O(1)，所以这里删除过期的文件并不会提高kafka的性能！ 2.3. 消费策略是建立在offset为有序的基础上，利用segment+有序offset+稀疏索引+二分查找+顺序查找等多种手段来高效的查找数据！至此，消费者就能拿到需要处理的数据进行处理了。那每个消费者又是怎么记录自己消费的位置呢？在早期的版本中，消费者将消费到的offset维护zookeeper中，consumer每间隔一段时间上报一次，这里容易导致重复消费，且性能不好！在新的版本中消费者消费到的offset已经直接维护在kafk集群的__consumer_offsets这个topic中。 2.4. Consumer Group中 Rebalance机制对于一个Consumer Group，可能随时都有Consumer加入或者退出这个Consumer Group，Consumer列表的变化势必会引起partition的重新分配。这个为Consumer分配partition的过程就被称为Consumer Rebalance。出现任何以下的场景都会触发Consumer Rebalance操作： 有新的消费者加入Consumer Group。 有消费者主动退出Consumer Group。 Consumer Group订阅的任何一个Topic出现分区数量的变化 默认情况下，Kafka提供了两种分配策略：Range和RoundRobin。 Rangerange策略的具体步骤如下： 1) 对一个topic中的partition进行排序2) 对消费者按字典进行排序3) 然后遍历排序后的partition的方式分配给消费者 举个例子，比如有两个消费者C0和C1，两个topic(t0,t1)，每个topic有三个分区p(0-2)， 那么采用Range策略，分配出的结果为： C0: [t0p0, t0p1, t1p0, t1p1]C1: [t0p2, t1p2] RoundRobin策略RoundRobin策略和Range策略类型，唯一的区别就是Range策略分配partition时，是按照topic逐次划分的。而RoundRobin策略则是将所有topic的所有分区一起排序，然后遍历partition分配给消费者。 因此，采用RoundRobin策略，分配出的结果为： C0: [t0p0, t0p2, t1p1]C1: [t0p1, t1p0, t1p2] 3. 安装3.1. 单点安装kafka安装包下载kafka_2.11-2.1.0.tgzjdk-1.8123456tar -zxf kafka_2.11-2.1.0.tgzcd kafka_xxx# 启动kafka内置的zookeeper port:2181bin&#x2F;zookeeper-server-start.sh config&#x2F;zookeeper.properties# 启动kafka port:9092bin&#x2F;kafka-server-start.sh config&#x2F;server.properties 启动前可根据需要调整kafka启动配置12345678910111213141516171819server.properties配置中需要关注以下几个参数：# The id of the broker. This must be set to a unique integer for each broker.# 表示broker的编号，如果集群中有多个broker，则每个broker的编号需要设置的不同broker.id&#x3D;0# listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;0.0.0.0:9092# broker对外提供的服务入口地址listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;192.168.110.142:9092# 外网ip访问advertised.listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;192.168.110.142:9092# 设置存放消息日志的地址# A comma separated list of directories under which to store log fileslog.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs# zookeeper.connect&#x3D;localhost:2181# kafka所需的zookeeper的集群地址zookeeper.connect&#x3D;192.168.110.142:2181 3.2. 集群安装假设有三个节点1234567891011121314cp config&#x2F;server.properties config&#x2F;server-1.propertiescp config&#x2F;server.properties config&#x2F;server-2.properties vi config&#x2F;server-1.properties # 修改broker.id &#x3D; 1listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;:9093log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs-1# 启动另外两个节点bin&#x2F;kafka-server-start.sh config&#x2F;server-1.propertiesbin&#x2F;kafka-server-start.sh config&#x2F;server-2.properties# 创建topicbin&#x2F;kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic repilcation-topic 4. 使用4.1. linux4.1.1. 创建topic123456bin&#x2F;kafika-topics.sh --create --zookeeper localhost:2181 --topic test --partitions 1 --replication-factor 1# 查看topicbin&#x2F;kafka-topics.sh --describe --zookeeper localhost:2181 --topic test# 查看所有topicbin&#x2F;kafika-topics.sh --zookeeper localhost:2181 --list 4.1.2. 生产者12# 启动生产者bin&#x2F;kafka-console-producer.sh --broker-list localhost:9092 --topic test 4.1.3. 消费者12# 从头开始消费bin&#x2F;kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 4.2. javamaven pom 文件consumer类12poll函数过期，不接受long，改接收durationConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(Duration.ofSeconds(1));producer","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"kafka","slug":"大数据技术/kafka","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"https://tlylft.github.io/tags/kafka/"}]},{"title":"neo4j Cypher语句","slug":"knowledge_graph/neo4j_cypher","date":"2021-06-15T08:56:51.000Z","updated":"2021-06-16T04:20:31.879Z","comments":true,"path":"knowledge_graph/neo4j_cypher/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/neo4j_cypher/","excerpt":"","text":"创建语句123456789# 创建新实体create (n:Person&#123;name:&quot;李四&quot;&#125;)# 创建新实体和关系create (n:Person&#123;name:&quot;李四&quot;&#125;)-[:loves&#123;level:1&#125;]-&gt;(m:Dog)create (n:Person)-[:loves]-&gt;(m:Dog)# 给两个已存在的实体创建关系, 有关系了还会多创建一个match (n:Person&#123;name:&quot;李四&quot;&#125;),(m:Person&#123;name:&quot;王五&quot;&#125;) create (n)-[k:known]-&gt;(m) return k# 有则返回 没有则创建match (n:Person&#123;name:&quot;李四&quot;&#125;),(m:Person&#123;name:&quot;王五&quot;&#125;) merge (n)-[k:known]-&gt;(m) return k 创建和删除索引123create index on :&lt;标签名称&gt;(属性名称)例： create index on: Person(name)drop index on:Person(name)创建和删除约束关系123create constraint on :&lt;标签名称&gt; assert (属性名称) is unique例： create constraint on :(p:Person) assert (p.name) is uniquedrop constraint on :(p:Person) assert (p.name) is unique 删除语句1234# delete 删除实体前需要先删关系MATCH (n:Person)-[r:has_phone]-&gt;(p:Phone) delete r# 同时删除实体和关系MATCH (n:Person)-[r:has_phone]-&gt;(p:Phone) delete r,n,p 查询语句match相当于sql中的select 123match ([alias:] node)-[releation]-&gt;(node)where (node | relation)return (node | relation) 查询一种节点123# 例：查询Person实体match (Person) return Person limit 10match (n:Person) return n limit 10查询多个节点1match (n:Person&#123;name:&quot;李四&quot;&#125;),(m:Person&#123;name:&quot;王五&quot;&#125;) return n,m 查询一种关系12MATCH p&#x3D;()-[r:has_phone]-&gt;() RETURN p LIMIT 25MATCH (n:Person)-[r:has_phone]-&gt;(p:Phone) RETURN n,p LIMIT 25where 条件123MATCH (n:Person)-[r:has_phone]-&gt;(p:Phone) where n.name&#x3D;&quot;张三&quot; RETURN n,p LIMIT 25MATCH (n:Person&#123;name:&quot;张三&quot;&#125;)-[r:has_phone]-&gt;(p:Phone) RETURN n,p LIMIT 25 查询多维关系1MATCH (n:Person)-[r:has_phone]-&gt;(p:Phone)-[:call]-&gt;(p1:Phone) where n.name&#x3D;&quot;张三&quot; RETURN n,p,p1 LIMIT 25查询计数1MATCH (n:Person)-[r:has_phone]-&gt;(p:Phone) where n.name&#x3D;&quot;张三&quot; RETURN count(p) 正则查询1MATCH (n:users) where n.name&#x3D;~&quot;Jack.*&quot; return n limit 10 包含查询1MATCH (n:users) where n.name contains &quot;J&quot; return n limit 10查询最短路径1234# 返回一个match (n:Person&#123;name:&quot;李四&quot;&#125;),(m:Person&#123;name:&quot;王五&quot;&#125;) p&#x3D;shortestpath((n)-[*..10]-(m)) return p# 返回所有最短路径match (n:Person&#123;name:&quot;李四&quot;&#125;),(m:Person&#123;name:&quot;王五&quot;&#125;) p&#x3D;allshortestpaths((n)-[*..10]-(m)) return p 更新语句123456# 一个实体可以对应多个实体的标签match (t:tiger) where id(t)&#x3D;1837 set t:Animal return t# 修改实体的一个属性match (t:tiger) where id(t)&#x3D;1837 set a.age&#x3D;10 renturn t# 修改关系的属性match (n:Person)-[l:love]-&gt;(:Person) set l.date&#x3D;&quot;1990.01.10&quot; return l","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"},{"name":"neo4j","slug":"neo4j","permalink":"https://tlylft.github.io/tags/neo4j/"}]},{"title":"neo4j APOC","slug":"knowledge_graph/neo4j_apoc","date":"2021-06-15T08:22:29.000Z","updated":"2021-06-15T08:57:34.229Z","comments":true,"path":"knowledge_graph/neo4j_apoc/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/neo4j_apoc/","excerpt":"","text":"介绍APOC: A package of component依赖包放到plugin文件目录下apoc-3.4.0.3-all.jarmysql-connector-java-5.1.21.jar核心功能可以优化索引，提高查询速度 组件jdbc","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"},{"name":"neo4j","slug":"neo4j","permalink":"https://tlylft.github.io/tags/neo4j/"}]},{"title":"医疗知识图谱","slug":"knowledge_graph/kg_medical","date":"2021-06-15T01:59:40.000Z","updated":"2021-06-21T10:14:09.003Z","comments":true,"path":"knowledge_graph/kg_medical/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/kg_medical/","excerpt":"","text":"https://github.com/liuhuanyong/QASystemOnMedicalKGhttps://github.com/zhihao-chen/QASystemOnMedicalGraph","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"}]},{"title":"python os package","slug":"python/python/python_os","date":"2021-06-11T02:09:40.000Z","updated":"2021-06-11T02:21:50.231Z","comments":true,"path":"python/python/python_os/","link":"","permalink":"https://tlylft.github.io/python/python/python_os/","excerpt":"","text":"路径问题12# 当前目录的绝对路径base_dir &#x3D; os.path.dirname(os.path.abspath(__file__)) 环境变量12345# 设置环境变量os.environ[&quot;HANLP_HOME&quot;] &#x3D; base_dir# 获取环境变量os.getenv(&#39;HANLP_HOME&#39;)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"simhash文本去重算法","slug":"NLP/similarity/simhash","date":"2021-06-08T14:52:40.000Z","updated":"2021-06-11T03:13:54.439Z","comments":true,"path":"NLP/similarity/simhash/","link":"","permalink":"https://tlylft.github.io/NLP/similarity/simhash/","excerpt":"","text":"https://www.cnblogs.com/shaosks/p/9121774.html https://zhuanlan.zhihu.com/p/92155250 背景常见的余弦夹角算法、欧式距离、Jaccard相似度、最长公共子串、编辑距离等。这些算法对于待比较的文本数据不多时还比较好用，如果我们的每天采集的数据以千万计算，性能就是一个非常大的瓶颈。传统的hash算法只负责将原始内容尽量均匀随机地映射为一个签名值，原理上相当于伪随机数产生算法。传统的hash算法产生的两个签名，如果相等，说明原始内容在一定概率下是相等的；如果不相等，除了说明原始内容不相等外，不再提供任何信息，因为即使原始内容只相差一个字节，所产生的签名也很可能差别极大。所以hash算法只适合相同性的检测而不适合相似性检测。理想当中的hash函数，需要对几乎相同的输入内容，产生相同或者相近的hash值，换言之，hash值的相似程度要能直接反映输入内容的相似程度，故md5等传统hash方法也无法满足我们的需求。 理解Simhash的背后是局部敏感哈希；基于simhash的文本去重技术背后，是基于局部敏感哈希的海量数据检索技术。 simhash也可以看做是一种文本你的分布式表示方法。难得的是，这种方法是无监督的。不过simhash挖掘文本信息的能力没有word2vec这种模型强，simhash编码会限制分类、聚类模型的效果上限。一般来说，在低精度、高速度的场景下，可以试一下simhash。 代码https://github.com/yanyiwu/simhash C++https://github.com/lipengyuer/DataScience/blob/master/src/nlp/LSH/simhash_v1.pyhttps://github.com/zyymax/text-similarity 我的代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119import osfrom datetime import datetimeimport jiebaimport numpy as npfrom nlp_server.logger.LoggerHandler import loggerclass SimHash(object): def __init__(self, content1, content2, hash_bits&#x3D;128, split_mode&#x3D;&#39;char&#39;): &quot;&quot;&quot; 初始化函数 :param content: 文本 :param hash_bits: hash位数 默认128 :param split_model: char-按字符特征生成 word-按分词特征生成 &quot;&quot;&quot; self.hash_bits &#x3D; hash_bits self.__init_stop_words() self.hash1 &#x3D; self._simhash(content1, split_mode) self.hash2 &#x3D; self._simhash(content2, split_mode) # def __str__(self): # return str(self.hash) def __init_stop_words(self): base_path &#x3D; os.path.abspath(os.path.dirname(__file__)) stop_word_path &#x3D; os.path.join(base_path, &#39;stop_words.txt&#39;) with open(stop_word_path, encoding&#x3D;&#39;utf-8&#39;) as f: stop_word &#x3D; f.readlines() self.stop_words &#x3D; [x.strip() for x in stop_word] def _simhash(self, content, split_model): &quot;&quot;&quot; 获取一句话的simhash表示 :param content: :param split_model: char-按字符特征生成 word-按分词特征生成 :return: &quot;&quot;&quot; if split_model &#x3D;&#x3D; &#39;word&#39;: tokens &#x3D; jieba.lcut(content) # 分词特征 else: tokens &#x3D; list(content) # 字符特征 # 为每个生成hash值特征 features &#x3D; [list(self.string_hash(x)) for x in tokens if x not in self.stop_words] features &#x3D; np.array(features, dtype&#x3D;&#39;int64&#39;) # 合并特征 features_ &#x3D; np.where(features &gt; 0, 1, -1) logger.debug(features_) vector &#x3D; features_.sum(axis&#x3D;0) logger.debug(&quot;simhash合并特征 &#123;&#125; : &#123;&#125; &quot;.format(content, vector)) # 降维 fingerprint &#x3D; np.where(vector &gt; 0, 1, 0) logger.debug(&quot;fingerprint:&#123;&#125;&quot;.format(fingerprint)) return fingerprint def string_hash(self, source): &quot;&quot;&quot; 单词转换为hash :param source: 单词 :return: hash值的0-1文本格式 &quot;&quot;&quot; if source &#x3D;&#x3D; &quot;&quot;: return 0 else: # 取asc2码 左移7位 x &#x3D; ord(source[0]) &lt;&lt; 7 m &#x3D; 1000003 # * (2**22) + 1000003 print(m, &quot;&#123;0:b&#125;&quot;.format(m)) mask &#x3D; (1 &lt;&lt; self.hash_bits) - 1 for c in source: x &#x3D; ((x * m) ^ ord(c)) &amp; mask # print(c, &quot;&#123;0:b&#125;&quot;.format(x)) x ^&#x3D; len(source) if x &#x3D;&#x3D; -1: x &#x3D; -2 # 文本化 str_x &#x3D; &quot;&#123;0:b&#125;&quot;.format(x) # print(source, str_x) # 补全维度 if len(str_x) &gt; self.hash_bits: str_x &#x3D; str_x[:self.hash_bits] else: str_x &#x3D; (self.hash_bits - len(str_x)) * &#39;0&#39; + str_x return str_x def hamming_distance(self): &quot;&quot;&quot; 海明距离 :return: &quot;&quot;&quot; # 异或结果 a &#x3D; np.bitwise_xor(self.hash1, self.hash2) return np.sum(a &#x3D;&#x3D; 1) def cosine_similarity(self, norm&#x3D;True): &quot;&quot;&quot; 计算两个向量之间的余弦相似度 :param norm: 是否归一化 :return: sim &quot;&quot;&quot; vector_a &#x3D; np.mat(self.hash1) vector_b &#x3D; np.mat(self.hash2) num &#x3D; float(vector_a * vector_b.T) denom &#x3D; np.linalg.norm(vector_a) * np.linalg.norm(vector_b) cos &#x3D; num &#x2F; denom sim &#x3D; 0.5 + 0.5 * cos return sim if norm else cosif __name__ &#x3D;&#x3D; &#39;__main__&#39;: start &#x3D; datetime.now() c1 &#x3D; &#39;中国， 中华人民共和国&#39; c2 &#x3D; &#39;中国， 我爱中华人民共和国&#39; hash &#x3D; SimHash(c1, c2, split_mode&#x3D;&#39;char&#39;) print(hash.hamming_distance(), &quot; &quot;, hash.cosine_similarity()) print(&quot;process dataloader cost time: &#123;&#125; s&quot;.format((datetime.now() - start).total_seconds()))","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"}]},{"title":"python pip安装","slug":"python/python/python_pip","date":"2021-06-07T09:32:26.000Z","updated":"2021-06-11T02:52:08.218Z","comments":true,"path":"python/python/python_pip/","link":"","permalink":"https://tlylft.github.io/python/python/python_pip/","excerpt":"","text":"pip 配置多个镜像源 创建pip配置文件linux: 修改 ~/.pip/pip.conf (没有就创建一个)windows:直接在user目录中创建一个pip目录，如：C:\\Users\\xx\\pip，新建文件pip.ini 配置文件内容old_version:1234567891011[global]index-url&#x3D;http:&#x2F;&#x2F;pypi.douban.com&#x2F;simpleextra-index-url&#x3D;http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F;extra-index-url&#x3D;https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple&#x2F;extra-index-url&#x3D;http:&#x2F;&#x2F;pypi.mirrors.ustc.edu.cn&#x2F;simple&#x2F;[install]trusted-host&#x3D;pypi.douban.comtrusted-host&#x3D;mirrors.aliyun.comtrusted-host&#x3D;pypi.tuna.tsinghua.edu.cntrusted-host&#x3D;pypi.mirrors.ustc.edu.cn new version pip-19.1.1+12345678[global]index-url&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F;extra-index-url&#x3D; https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple&#x2F; https:&#x2F;&#x2F;pypi.mirrors.ustc.edu.cn&#x2F;simple&#x2F; https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple&#x2F;[install]trusted-host&#x3D;mirrors.aliyun.com","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"平均绝对离差（MAD）","slug":"NLP/corrector/MAD","date":"2021-06-04T03:19:36.000Z","updated":"2021-06-11T03:09:19.102Z","comments":true,"path":"NLP/corrector/MAD/","link":"","permalink":"https://tlylft.github.io/NLP/corrector/MAD/","excerpt":"","text":"","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"corrector","slug":"NLP/corrector","permalink":"https://tlylft.github.io/categories/NLP/corrector/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"corrector","slug":"corrector","permalink":"https://tlylft.github.io/tags/corrector/"}]},{"title":"pycorrector 源码解读","slug":"NLP/corrector/pycorrector","date":"2021-06-04T00:34:23.000Z","updated":"2021-06-11T03:09:26.625Z","comments":true,"path":"NLP/corrector/pycorrector/","link":"","permalink":"https://tlylft.github.io/NLP/corrector/pycorrector/","excerpt":"","text":"1. introgit源码 2. 安装12345678# 直接调用pip install pycorrector # 预训练git clone https:&#x2F;&#x2F;github.com&#x2F;shibing624&#x2F;pycorrector&#x2F;cd pycorrectorpip install requirements.txtpip install requirements-mydev.txtpip install https:&#x2F;&#x2F;github.com&#x2F;kpu&#x2F;kenlm&#x2F;archive&#x2F;master.zip 3. 不同实现方式的源码解读3.1. 规则纠错 base_demo.py 3.1.1. 运行命令：1python examples&#x2F;base_demo.py 3.1.2. 检测器源码：pycorrector/detector.py使用kenlm算法。 步骤： 如果定义了language_model_path，则加载自定义模型，否则下载并加载预训练模型。 加载常用词频（word_freq）、人名、地名、停用词， 可自定义混淆集（容易混淆的词的map：custom_confusion） 检测：a) 词粒度检测：jieba.search分词,判断分词后是否为无效字符，是否在通用词频表中，否则可能为需要纠正的错误词。b) 字粒度检测：对文本进行n-gram分割，对每个二元组或三元组计算kenlm的概率得分，补全并做平均，通过平均绝对离差（MAD）确定错字的位置。 3.1.4. 纠正器源码pycorrector.corrector.py继承了detector类，加载3k+常用中文字符（cn_char_set） 纠正逻辑：切分成短句，对每句话纠正。每句话对每个可能的错字或词： 找出候选集a) 找同拼音的词可能：根据编辑距离取候选词（对候选词的每个位置做反向、常用字的替换，生成的词筛选出常用词），获取候选词同拼音的表述b) 找自定义混淆：在自定义混淆集，直接取纠正结果c) 对每个字找形近字的同拼音的字，替换后加入候选集将候选集的词根据词频表排序，作为这个错词的有序候选集。 通过语言模型纠正字词错误，找出概率最高的的候选词（如果是本身就存在于自定义混淆集的措词，直接用自定义的纠正词）将纠正的候选集的词匹配到原句中，使用kenlm.perplexity得到得分排序，设定一个ppl阈值（threshold=57），如果原句的得分和排序第一的修正相差不到这个阈值，则认为不需修正，否则修正为得分第一的修正项。3.1.5. 预训练模型：123456pre_trained_language_models &#x3D; &#123; # 语言模型 2.95GB &#39;zh_giga.no_cna_cmn.prune01244.klm&#39;: &#39;https:&#x2F;&#x2F;deepspeech.bj.bcebos.com&#x2F;zh_lm&#x2F;zh_giga.no_cna_cmn.prune01244.klm&#39;, # 人民日报训练语言模型 20MB &#39;people_chars_lm.klm&#39;: &#39;https:&#x2F;&#x2F;www.borntowin.cn&#x2F;mm&#x2F;emb_models&#x2F;people_chars_lm.klm&#39;&#125;","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"corrector","slug":"NLP/corrector","permalink":"https://tlylft.github.io/categories/NLP/corrector/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"corrector","slug":"corrector","permalink":"https://tlylft.github.io/tags/corrector/"}]},{"title":"scripy 处理矩阵","slug":"python/python/python_scripy","date":"2021-06-03T10:44:02.000Z","updated":"2021-06-03T10:49:56.941Z","comments":true,"path":"python/python/python_scripy/","link":"","permalink":"https://tlylft.github.io/python/python/python_scripy/","excerpt":"","text":"sparse.csr_matrixCSR方法采取按行压缩的办法, 将原始的矩阵用三个数组进行表示 和大家分享下我怎样理解的1234567from scipy import sparsedata &#x3D; np.array([1, 2, 3, 4, 5, 6]) #所有非零数值，需要填充的不为零的数据indices &#x3D; np.array([0, 2, 2, 0, 1, 2]) #所有值的列索引indptr &#x3D; np.array([0, 2, 3, 6]) #每行的非零数据 data[i：i+1] 理解成从data的第0-2个位置是第0行的数据，2-3个位置是第一行的数据...以此类推mtx &#x3D; sparse.csr_matrix((data,indices,indptr),shape&#x3D;(3,3))mtx.todense() # or mtx.toarray() 自己写的通过给定每行最大的n个值的列索引，创建对应的0,1稀疏矩阵(用于推荐系统cf的步骤计算)123456789101112import numpy as npfrom scipy import sparsek &#x3D; 3 # 第m 个物品找几个m &#x3D; 2 # 找几个相似物品total_num &#x3D; 5data &#x3D; np.array(k*m*[1]) #所有非零数值indices &#x3D; np.array([1, 2,4,0, 2,3]) #所有值的列索引indptr &#x3D;np.linspace(0,m*k,m+1) #每行的非零数据 data[i：i+1]mtx &#x3D; sparse.csr_matrix((data,indices,indptr),shape&#x3D;(m,total_num))mtx.todense()print(mtx.toarray())","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"CentOS7安装gcc-5.4.0","slug":"linux/centos_gcc","date":"2021-06-03T07:24:24.000Z","updated":"2021-06-11T03:00:07.027Z","comments":true,"path":"linux/centos_gcc/","link":"","permalink":"https://tlylft.github.io/linux/centos_gcc/","excerpt":"","text":"https://developer.aliyun.com/article/779859","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"深度学习框架在不支持avx的环境中部署","slug":"python/env/python_linux","date":"2021-05-28T00:41:35.000Z","updated":"2021-06-11T03:27:06.395Z","comments":true,"path":"python/env/python_linux/","link":"","permalink":"https://tlylft.github.io/python/env/python_linux/","excerpt":"","text":"错误异常在安装paddle或TensorFlow后报错，paddle提示AVX指令集错误，TensorFlow 可能是Illegal instruction (core dumped) 【paddle报错】WARNING: AVX is not support on your machine. Hence, no_avx core will be imported, It has much worse preformance than avx core. Error: AVX is not support on your machine, but you have installed paddlepaddle with avx core, WARNING: AVX is not support on your machine. Hence, no_avx core will be imported, It has much worse preformance than avx core. Error: AVX is not support on your machine, but you have installed paddlepaddle with avx core, you should reinstall paddlepaddle by 'python -m pip install -U paddlepaddle-gpu[==version] -f https://paddlepaddle.org.cn/whl/stable_noavx.html' Traceback (most recent call last): File \"run.py\", line 8, in from nlp_server import create_app, conf File \"/nlp_server/__init__.py\", line 10, in from nlp_server.route.nlp_route import nlp_route File \"/nlp_server/route/nlp_route.py\", line 12, in from nlp_server.models import * File \"/nlp_server/models/__init__.py\", line 8, in from nlp_server.models.address.detect import AddressDetect File \"/nlp_server/models/address/detect.py\", line 3, in import paddle File \"/usr/local/lib/python3.7/site-packages/paddle/__init__.py\", line 29, in from .fluid import monkey_patch_variable File \"/usr/local/lib/python3.7/site-packages/paddle/fluid/__init__.py\", line 35, in from . import framework File \"/usr/local/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 36, in from . import core File \"/usr/local/lib/python3.7/site-packages/paddle/fluid/core.py\", line 349, in raise e File \"/usr/local/lib/python3.7/site-packages/paddle/fluid/core.py\", line 308, in from .core_noavx import * ModuleNotFoundError: No module named 'paddle.fluid.core_noavx' fnwharbor.enncloud.cn/fnw/platform-nlp:20210506-095141 原因使用的服务器或者docker启动的宿主机的CPU不支持axv指令集，可通过cat /proc/cpuinfo查看 解决方法paddle 在不能执行的服务器上源码编译https://www.paddlepaddle.org.cn/documentation/docs/zh/1.0/beginners_guide/install/compile/compile_CentOS.html 附：安装cmake3.10.2 https://blog.csdn.net/kane8202/article/details/79495240cmake .. -DPY_VERSION=3.7 -DPYTHON_INCLUDE_DIR=/data/anaconda3/envs/paddle/include -DPYTHON_LIBRARY=/data/anaconda3/envs/paddle/lib -DWITH_FLUID_ONLY=ON -DWITH_GPU=OFF -DWITH_TESTING=OFF","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"tensorflow","slug":"tensorflow","permalink":"https://tlylft.github.io/tags/tensorflow/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"paddle","slug":"paddle","permalink":"https://tlylft.github.io/tags/paddle/"}]},{"title":"文本纠错核心问题","slug":"NLP/corrector/core_ability","date":"2021-05-26T02:26:58.000Z","updated":"2021-06-11T03:09:15.022Z","comments":true,"path":"NLP/corrector/core_ability/","link":"","permalink":"https://tlylft.github.io/NLP/corrector/core_ability/","excerpt":"","text":"中文文本纠错任务，常见错误类型包括：➢ 谐音字词，如 配副眼睛-配副眼镜➢ 混淆音字词，如 流浪织女-牛郎织女➢ 字词顺序颠倒，如 伍迪艾伦-艾伦伍迪➢ 字词补全，如 爱有天意-假如爱有天意➢ 形似字错误，如 高梁-高粱➢ 中文拼音全拼，如 xingfu-幸福➢ 中文拼音缩写，如 sz-深圳➢ 语法错误，如 想象难以-难以想象 医疗领域： 谐音错别字：耳室症如何治疗？——耳石症如何治疗？ 形近错别字：氨基已酸 ——氨基己酸 字词顺序错误：硫酸氯氢吡格雷 —— 硫酸氢氯吡格雷 字词补全：右旋糖苷铁口服液 ——右旋糖苷铁口服溶液 中文拼写错误：aspl —— 阿司匹林，阿斯 pi ling ——阿司匹林 语法错误 （Grammatical Error）：Nothing is [absolute——absolutely] right or wrong 常识知识错误：上海同济医院内分泌代谢科主治医师[刘辉——刘光辉]","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"corrector","slug":"NLP/corrector","permalink":"https://tlylft.github.io/categories/NLP/corrector/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"corrector","slug":"corrector","permalink":"https://tlylft.github.io/tags/corrector/"}]},{"title":"【读书笔记】基金分析","slug":"reading/fund","date":"2021-05-23T03:49:43.000Z","updated":"2023-08-10T12:05:09.064Z","comments":true,"path":"reading/fund/","link":"","permalink":"https://tlylft.github.io/reading/fund/","excerpt":"","text":"特征：看持仓判断基金类型，不要看名字越跌越买 但要看大盘消息面的正确分析基金经理业绩、基金平均表现，不要太在意净值高低，基金规模判断高点： 高位震荡判断加仓： 等第一次加仓亏损5%-10%时候再去加第二次。没有必要频繁在同一成本位置加仓，这样起不到拉低成本的作用。 规则：","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"mysql安装","slug":"big_data/mysql/mysql_install","date":"2021-05-20T05:28:04.000Z","updated":"2023-08-11T08:30:54.087Z","comments":true,"path":"big_data/mysql/mysql_install/","link":"","permalink":"https://tlylft.github.io/big_data/mysql/mysql_install/","excerpt":"","text":"1. 安装1.1. windows安装https://blog.csdn.net/ychgyyn/article/details/84404217 1.2. 下载安装包官网下载 1.3. 安装 解压下载好的压缩包放到你想要放的目录 配置环境变量path，添加安装目录下的bin目录 管理员运行cmd, 输入命令初始化数据库，并记录随机生成的密码(通常12位)1mysqld --initialize --console 1.4. linux安装 2. 配置 输入mysqld -install将mysql安装为Windows的服务 输入命令net start mysql或sc start mysql启动mysql服务 输入mysql -u root -p来登陆数据库，并输入前面记录的临时密码 登陆成功后输入命令```alter user ‘root’@’localhost’ identified by ‘想要设置的密码;将原来复杂的密码修改为自己的密码，并输入commit;提交 将mysql用户登录加密规则修改为mysql_native_password：ALTER USER ‘root’@’localhost’ IDENTIFIED WITH mysql_native_password BY ‘新密码’;tip:mysql8之前版本中加密规则为mysql_native_passwordmysql8以后的加密规则为caching_sha2_password,所以8以后的版本需要更改，这样navicate可以连上‘``` 开启远程可连接https://blog.csdn.net/weixin_42096620/article/details/110798766添加防火墙入站规则：端口 TCP 3306 3. 使用停止MySQL服务：net stop mysqld或sc stop mysqld删除MySQL服务：sc delete mysqld或mysqld -remove（需先停止服务） 4. 用户管理查看用户权限12use mysql;select host, user from user; 4.1. 创建用户https://www.cnblogs.com/zhongyehai/p/10695659.html 1CREATE USER &#39;username&#39;@&#39;host&#39; IDENTIFIED BY &#39;password&#39; 说明：username：你将创建的用户名host：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符%password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器 4.2. 用户授权1GRANT privileges ON databasename.tablename TO &#39;username&#39;@&#39;host&#39; 说明:privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALLdatabasename：数据库名tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用表示，如.例子:GRANT SELECT, INSERT ON test.user TO ‘pig’@’%’;GRANT ALL ON . TO ‘pig’@’%’;GRANT ALL ON maindataplus. TO ‘pig’@’%’; 用以上命令授权的用户不能给其它用户授权，如果想让该用户可以授权，用以下命令:1GRANT privileges ON databasename.tablename TO &#39;username&#39;@&#39;host&#39; WITH GRANT OPTION;撤销用户权限1REVOKE privilege ON databasename.tablename FROM &#39;username&#39;@&#39;host&#39;; 4.3. 更改密码123SET PASSWORD FOR &#39;username&#39;@&#39;host&#39; &#x3D; PASSWORD(&#39;newpassword&#39;);或SET PASSWORD &#x3D; PASSWORD(&quot;newpassword&quot;); 4.4. 删除用户1DROP USER &#39;username&#39;@&#39;host&#39;;","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"mysql","slug":"大数据技术/mysql","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://tlylft.github.io/tags/mysql/"}]},{"title":"文本纠错","slug":"NLP/corrector/spell_correction","date":"2021-05-17T03:03:40.000Z","updated":"2021-08-23T00:55:36.283Z","comments":true,"path":"NLP/corrector/spell_correction/","link":"","permalink":"https://tlylft.github.io/NLP/corrector/spell_correction/","excerpt":"","text":"中文文本纠错算法—错别字纠正的二三事医疗健康领域的短文本解析探索（三) ——文本纠错文本纠错与BERT的最新结合,Soft-Masked BERT 中文纠错数据集 NLPCC 2018 GEC官方数据集NLPCC2018-GEC训练集trainingdata[解压后114.5MB]，该数据格式是原始文本，未做切词处理。 汉语水平考试（HSK）和lang8原始平行语料HSK+Lang8[190MB]，该数据集已经切词，可用作数据扩增 以上语料，再加上CGED16、CGED17、CGED18的数据，经过以字切分，繁体转简体，打乱数据顺序的预处理后，生成用于纠错的熟语料(nlpcc2018+hsk)，网盘链接:https://pan.baidu.com/s/1BkDru60nQXaDVLRSr7ktfA 密码:m6fg [130万对句子，215MB] sighan https://github.com/iqiyi/FASPell 中有下载链接 常用算法编辑距离 训练框架中文文本纠错算法—错别字纠正的二三事：https://zhuanlan.zhihu.com/p/40806718https://mp.weixin.qq.com/s/qaK2OkJmXsNvc7BZw6G7Xg文本纠错与BERT的最新结合,Soft-Masked BERT：https://mp.weixin.qq.com/s/KspCRo5HiC9bUplegGM8aA pycorrector使用入门：https://blog.csdn.net/u014365862/article/details/106985974 PyCorrector文本纠错工具实践和代码详解： https://zhuanlan.zhihu.com/p/138981644 FASpell论文阅读：https://zhuanlan.zhihu.com/p/134709203https://zhuanlan.zhihu.com/p/89948512 说明没有看到论文的消融实验，实验反映只有BERT效果本来就是是相当差的。这个模型提高性能的重点不在于使用BERT，使用BERT只是为了避免检错数据不够时的过拟合问题，如果数据充足不用BERT应该也没有问题。这个模型主要区别于其他模型的地方在于抛弃了困惑集，更精准地建模汉字相似度并充分利用这一特征，以及在过滤时的高精确保召回的经验方法。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"corrector","slug":"NLP/corrector","permalink":"https://tlylft.github.io/categories/NLP/corrector/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"corrector","slug":"corrector","permalink":"https://tlylft.github.io/tags/corrector/"}]},{"title":"embedding","slug":"deep_learning/embedding","date":"2021-04-13T09:15:30.000Z","updated":"2021-06-11T02:59:23.868Z","comments":true,"path":"deep_learning/embedding/","link":"","permalink":"https://tlylft.github.io/deep_learning/embedding/","excerpt":"","text":"http://www.360doc.com/content/17/1021/00/16619343_696787348.shtml https://www.zhihu.com/question/344209738/answer/843929870https://www.cnblogs.com/lzida9223/p/10536177.htmlhttps://blog.csdn.net/tommorrow12/article/details/80896331 https://www.jianshu.com/p/63e7acc5e890https://blog.csdn.net/weixin_43914889/article/details/104699657 https://microstrong.blog.csdn.net/article/details/80852710 https://juejin.cn/post/6844903589299634183","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"深度学习中的dropout","slug":"deep_learning/dropout","date":"2021-04-13T09:00:44.000Z","updated":"2021-06-11T02:59:16.535Z","comments":true,"path":"deep_learning/dropout/","link":"","permalink":"https://tlylft.github.io/deep_learning/dropout/","excerpt":"","text":"https://www.cnblogs.com/tornadomeet/p/3258122.htmlhttps://www.cnblogs.com/dupuleng/articles/4341265.html 1. 解决的问题训练神经网络模型时，如果训练样本较少，为了防止模型过拟合，Dropout可以作为一种trikc供选择。Dropout是hintion最近2年提出的，源于其文章Improving neural networks by preventing co-adaptation of feature detectors.中文大意为：通过阻止特征检测器的共同作用来提高神经网络的性能。 2. 原理对隐含层的神经元以概率舍弃掉，形成部分权重共享，也可以理解成不同样本构成不同的模型取均值dropout的提出是为了防止在训练过程中的过拟合现象，那就有人想了，能不能对每一个输入样本训练一个模型，然后在test阶段将每个模型取均值，这样通过所有模型共同作用，可以将样本最有用的信息提取出来，而把一些噪声过滤掉。 那如何来实现这种想法呢？在每一轮训练过程中，我们对隐含层的每个神经元以一定的概率p舍弃掉，这样相当于每一个样本都训练出一个模型。假设有H个神经元，那么就有2H种可能性，对应2H模型，训练起来时间复杂度太高。我们通过权重共享（weights sharing)的方法来简化训练过程，每个样本所对应模型是部分权重共享的，只有被舍弃掉那部分权重不同。 使用dropout可以使用使一个隐含结点不能与其它隐含结点完全协同合作，因此其它的隐含结点可能被舍弃，这样就不能通过所有的隐含结点共同作用训练出复杂的模型（只针对某一个训练样本），我们不能确定其它隐含结点此时是否被激活，这样就有效的防止了过拟合现象。 3. 操作和理解Dropout是指在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了（有点抽象，具体实现看后面的实验部分）。 按照hinton的文章，他使用Dropout时训练阶段和测试阶段做了如下操作： 在样本的训练阶段，在没有采用pre-training的网络时（Dropout当然可以结合pre-training一起使用），hintion并不是像通常那样对权值采用L2范数惩罚，而是对每个隐含节点的权值L2范数设置一个上限bound，当训练过程中如果该节点不满足bound约束，则用该bound值对权值进行一个规范化操作（即同时除以该L2范数值），说是这样可以让权值更新初始的时候有个大的学习率供衰减，并且可以搜索更多的权值空间（没理解）。 在模型的测试阶段，使用”mean network(均值网络)”来得到隐含层的输出，其实就是在网络前向传播到输出层前时隐含层节点的输出值都要减半（如果dropout的比例为50%），其理由文章说了一些，可以去查看（没理解）。 关于Dropout，文章中没有给出任何数学解释，Hintion的直观解释和理由如下： 1. 由于每次用输入网络的样本进行权值更新时，隐含节点都是以一定概率随机出现，因此不能保证每2个隐含节点每次都同时出现，这样权值的更新不再依赖于有固定关系隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况。 2. 可以将dropout看作是模型平均的一种。对于每次输入到网络中的样本（可能是一个样本，也可能是一个batch的样本），其对应的网络结构都是不同的，但所有的这些不同的网络结构又同时share隐含节点的权值。这样不同的样本就对应不同的模型，是bagging的一种极端情况。个人感觉这个解释稍微靠谱些，和bagging，boosting理论有点像，但又不完全相同。 3. native bayes是dropout的一个特例。Native bayes有个错误的前提，即假设各个特征之间相互独立，这样在训练样本比较少的情况下，单独对每个特征进行学习，测试时将所有的特征都相乘，且在实际应用时效果还不错。而Droput每次不是训练一个特征，而是一部分隐含层特征。 4. 还有一个比较有意思的解释是，Dropout类似于性别在生物进化中的角色，物种为了使适应不断变化的环境，性别的出现有效的阻止了过拟合，即避免环境改变时物种可能面临的灭亡。 文章最后当然是show了一大把的实验来说明dropout可以阻止过拟合。这些实验都是些常见的benchmark，比如Mnist, Timit, Reuters, CIFAR-10, ImageNet. 4. 实验验证使用Dropout后，虽然训练样本的错误率较高，但是训练样本的错误率降低了，说明Dropout的泛化能力不错，可以防止过拟合。 5. 调用说明模型在训练时加入了dropout,那么在调用进行前向计算时，最好将dropout层去掉，否则前向过程依然会随机不考虑一些参数的信息，dropout参数大时，会导致每次返回的预测结果不同，不容易定位问题。","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"【读书笔记】刑法简介","slug":"reading/criminal_law/intro","date":"2021-04-08T05:03:22.000Z","updated":"2023-08-10T12:06:03.887Z","comments":true,"path":"reading/criminal_law/intro/","link":"","permalink":"https://tlylft.github.io/reading/criminal_law/intro/","excerpt":"","text":"法制：核心是对权力的限制。 1. 刑法构成1+11+1：一个刑法典：1997年10月1日正式实施十一个修正案：一个单行刑法：逃汇和套汇 2. 刑法目的规范维护说（基于行为正义）：为了维护一定的伦理秩序法益侵犯说（基于结果正义）：行为侵犯了法律要保护的利益，为了保护结果意义上的一种利益虽然这两种观点在出发点上很有冲突，但最终在我国的刑法中，采用了结合这两个理论支撑刑法的正当性，法益作为入罪的基础，伦理作为出罪的依据。 在两者间寻找一个平衡，得到相对完美的正义。 一个人没有完全处置自己身体或者说所有的权益，因为如果可以，最终会导致社会强者对弱智的剥削。所以从法益上来讲，自由不能以彻底放弃自由为代价。你对自己身体上制造的轻伤可以有决定权，但对伤害性的重伤，是不能要求他人来伤害你的。这样他人是构成了犯罪。 但是一种行为虽然侵犯了法律，但在伦理道德中是被鼓励的，那这种行为就不算犯罪。 3. 刑法机能保护机能：惩罚犯罪保护人权。保护受害人的人权。保障机能：保障人权，保障犯罪人的人权，限制司法机关的权利。 这决定了刑法在一定程度上并不能完全公正，甚至有些时候会使一些犯罪人受到保护，但保障机能是一定要存在的，不然会产生岳飞一样莫须有的罪名，如果说犯罪现象的产生是污染的水流，那么一次不公正的判决就是污染了水源。如果刑法权不受限制，那么一切正义都可能被架空。而刑法的产生最终是在追求平衡。 4. 刑法三大原则4.1. 罪刑法定原则 法无明文规定不为罪，法无明文规定不处罚 —限制国家刑法权利任何权利都有堕落的倾向。 —孟德斯鸠要把国家的权利切割成 立法权（制定法律），司法权（运用法律），行政权（行使法律），由不同的机构来掌握。保持动态的平衡。 罪刑法定的精神： 限权罪刑法定的内容： 4.1.1. 形式侧面（4个原则）： 制定法原则：是成文的罪刑法定，规定犯罪和刑法的法律必须是国家最高立法机关所规定的法律。行政法规和习惯法都不能作为法律的渊源。当地有男女通奸沉猪笼的习俗，但不能作为法律来执行。行政法规虽不能规定犯罪和刑法，但它能对犯罪构成填补（填补的是刑法中的空白罪状）。刑法规定猎杀珍稀野生动物犯法，但未规定什么动物是野生动物，这要参考行政法规作为填补。 事前的罪刑法定：禁止事后法。不能用明天的法惩罚今天的行为。但遵循从旧兼从轻原则， 如果明天的量刑改小了，那么就生效，如果明天的量刑改重了，那么就遵循今天的法律原则。 严格的罪刑法定：禁止类推。准确的说禁止不利于行为人的类推。因为类推是在创造规则。禁止类推但可以接受扩张，区别在于是在语言表述上的扩展还是规则上的创造。比如禁止组织妇女卖淫，那么组织男性卖淫就是类推。卖淫的定义是插入式行为，那么禁止组织幼女口交就算扩张表述。 确定的罪刑法定：禁止不定期刑，刑罚法规的适当。包括罪之法定和刑之法定，禁止绝对的不定期刑和绝对的不定刑。不定期刑：对司法权的限制，法官既要定罪，还要量刑。a)起源于西方定罪不量刑，由改造表现决定量刑。但这违背了三权分立的平衡。b）所以将量刑设定幅度，如3-10年，由监狱根据改造表现决定量刑。c)我国法官量刑给出的是绝对的量刑，但执行期间可以减刑。不定刑：对立法权的限制，法律不仅要规定犯罪行为还要规定刑法。 tips:刑法永远有例外。但如果说中了原则，就是正确的，但原则中加了绝对两个字，就是错误的。罪刑法定禁止事后犯罪。 正确罪行法定禁止类推。 正确罪刑法定绝对禁止事后犯罪。 错误 4.1.2. 实质侧面（3个原则）： 明确性原则：定法必须明确，不能模糊不清。一个法具备指引和裁判功能，对于民众和司法机构，都需要明确的规则。 合理性原则：刑法的处罚范围和处罚程度应当具有合理性。重罪重刑，轻罪轻刑。轻微的行为不论为刑法罪。 人道主义原则：禁止残酷不人道的刑罚。惩罚一个人仍然是尊重他。4.2. 罪刑相适应原则重罪重刑，轻罪轻刑，无罪不刑。相同情况相同对待，不同情况区别对待。 4.3. 适用平等原则刑法面前人人平等。对任何人犯罪，在适用法律上一律平等。不允许任何人有超越法律的特权。对于一切人的合法权益都要平等地加以保护，不允许有任何歧视。为何刑法要特别规定？ 因为在历史上，刑法是最容易不被平等执行的。 5. 刑法的解释任何的法律一经制订就已经滞后 6. 刑法的效力对刑法的空间效力规定的原则主要有属地原则、属人原则、保护原则和普遍管辖原则四种。我国刑法采取了以属地原则为主，兼采属人原则、保护原则和并有保留的采普遍管辖原则。 6.1. 空间效力6.1.1. 属地原则效力：维护国家主权，维持国内安定。 条件： 看地不看人，挂有国旗的船舶或航空器视为浮动领土 行为地或结果地，或者行为/结果的一部分发生在我国管辖范围内。 享有外交特权或豁免权的外国人，犯罪通过外交途径解决。6.1.2. 属人原则效力：本国公民在国外犯罪，仍受我国法律制裁。目的： 国家利益符合说-唤醒公民遵纪守法意识； 义务忠诚说-公民有忠于国家的义务，有遵守法律的义务; 代罚说：代替他国执行刑罚。保护我国公民在国外受到不公正处罚。条件： 国家公务人员和军人，在国外犯罪适用我国刑法。 非以上人员的中国公民在国外犯罪，只处罚三年以上的严重犯罪。最高刑为3年以下的犯罪行为，可以不追究。 6.1.3. 保护原则效力：目的：防止国外犯罪侵害我国相关利益。条件： 所犯之罪侵犯我国或我国公民的相关利益。 要求双重犯罪，即 按外国法和中国法都犯罪。 按我国刑法最低刑为3年以上的犯罪行为。 6.1.4. 普遍管辖外国人在外国犯罪，和我国利益没有关系条件： 中国所参加的国际条约规定的国际犯罪。国际法需转换为国内法管辖。劫持民用航空飞机 6.2. 时间效力未生效的判决 从旧兼从轻原则。 已经发生法律效力的判决，不再受从旧兼从轻原则的约束。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"apriori进行关联分析","slug":"machine_learning/apriori","date":"2021-04-06T02:13:24.000Z","updated":"2021-04-06T02:16:04.786Z","comments":true,"path":"machine_learning/apriori/","link":"","permalink":"https://tlylft.github.io/machine_learning/apriori/","excerpt":"","text":"https://github.com/apachecn/AiLearning/blob/master/docs/ml/11.md 关联分析关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式: 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"NLP 数据集","slug":"NLP/dataset","date":"2021-03-19T00:22:28.000Z","updated":"2021-06-11T03:19:27.316Z","comments":true,"path":"NLP/dataset/","link":"","permalink":"https://tlylft.github.io/NLP/dataset/","excerpt":"","text":"词库清华大学开放中文词库http://thuocl.thunlp.org/ 中华古诗词数据库最全中华古诗词数据集，唐宋两朝近一万四千古诗人, 接近5.5万首唐诗加26万宋诗. 两宋时期1564位词人，21050首词。https://github.com/chinese-poetry/chinese-poetry 汉字拆字字典https://github.com/kfcd/chaizi 中文简称数据集https://github.com/zhangyics/Chinese-abbreviation-dataset 中文人名语料库包含中文常见人名、中文古代人名、中文翻译人名、中文姓氏、中文称谓、中文成语等数据。https://github.com/wainshine/Chinese-Names-Corpus 中国宗教用户关键词列表https://www.dcjingsai.com/common/share/73.html 词向量上百种预训练中文词向量https://github.com/Embedding/Chinese-Word-Vectors 分类中文文本分类数据集THUCNewsTHUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档，划分出 14 个候选分类。http://thuctc.thunlp.org/#%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86THUCNews 实体1998年《人民日报》词性标注库https://pan.baidu.com/s/1gd6mslt 中文实体情感知识库刻画人们如何描述某个实体，包含新闻、旅游、餐饮，共计30万对。https://github.com/rainarch/SentiBridge 语义理解中文完形填空数据集https://github.com/ymcui/Chinese-RC-Dataset 对话中文对话情感分析数据集https://github.com/z17176/Chinese_conversation_sentiment 行业保险行业语料库https://github.com/Samurais/insuranceqa-corpus-zh Tushare财经数据接口TuShare是一个免费、开源的python财经数据接口包。http://tushare.org/ 爬取中国股市爬取信息数据集https://github.com/startprogress/China_stock_announcement 中文突发事件语料库https://github.com/shijiebei2009/CEC-Corpus 网站资源中科大自然语言处理与信息检索共享平台包括新闻，微博，Twitter，语义等资源数据集http://www.nlpir.org/wordpress/category/corpus%E8%AF%AD%E6%96%99%E5%BA%93/ 搜狗实验室搜狗实验室提供了一些高质量的中文文本数据集，但时间比较早，多为2012年以前的数据。https://www.sogou.com/labs/resource/list_pingce.php 中文语料小数据包含了中文命名实体识别、中文关系识别、中文阅读理解等一些小量数据。https://github.com/crownpku/Small-Chinese-Corpus ChineseNlpCorpushttps://github.com/InsaneLife/ChineseNLPCorpus","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"python 压缩包tarfile模块","slug":"python/python/python_tarfile","date":"2021-03-18T10:21:31.000Z","updated":"2021-06-11T02:17:13.628Z","comments":true,"path":"python/python/python_tarfile/","link":"","permalink":"https://tlylft.github.io/python/python/python_tarfile/","excerpt":"","text":"https://www.cnblogs.com/shona/p/11953678.html tarfile模块TarFile类对于就是tar压缩包实例. 其由member块组成, member块则包括header块和data块. 每个member以TarInfo对象形式描述. 所以TarFile就是TarInfo的序列. 其初始化函数的形参和TarFile类的属性对应, 其中比较重要是dereference属性,默认False(此时symbolic文件会以符号文件存进去),设置为True时会将其目标文件存到压缩包. getmember(name), getmembers(), getnames(): 分别返回指定文件名的TarInfo, 所有TarInfo和所有TarInfo文件名. 后两者顺序一致. 如果里面有很多个同名的member, 则取最后的. list(verbose=True) 列出tar里的文件信息, verbose相对于ls -l next() 就是for方法迭代器调用的, 返回下一个TarInfo对象. extractall(path=”.”, members=None), 解压所有文件, path是解压路径，默认当前目录，如果指明members(一个子集,TarInfo列表, 也可以是迭代器). extract(member, path=””), 解压指定member的文件,path是解压路径. extractfile(member): 提取相应对象为一个只读文件对象. member这里可以是文件名或者TarInfo. add(name, arcname=None, recursive=True, exclude=None, filter=None): 根据文件名创建TarInfo对象并添加文件到压缩包,可以指定arcname在压缩包里面使用的另外的名字, recursive是对文件夹处理时是否递归, exclude不建议用,filter(需要用key=value形式)是一个函数名,输入是TarInfo对象, 返回新的TarInfo对象或None(None的话就不被写入到压缩包, 可以用于过滤, 所以替代了exclude) addfile(tarinfo, fileobj=None): 将TarInfo对象或者文件对象添加到压缩包.一般配合gettarinfo使用 gettarinfo(name=None, arcname=None, fileobj=None): 通过文件名或文件对象来创造TarInfo对象. arcname可以重命名文件 使用简单intro: 压缩文件到tar.gz1234567891011import tarfile# 压缩tar &#x3D; tarfile.open(&#39;newfile.tar&#39;,&#39;w&#39;) # 创建一个压缩包tar.add(filepath, arcname&#x3D;&#39;xxx&#x2F;xxx.txt&#39;) # 将filepath文件添加到压缩包并重新命名路径，否则会将相对路径带入tar包中tar.close() # 关闭压缩包# 解压tar &#x3D; tarfile.open(&#39;newfile.tar&#39;,&#39;r&#39;) # 打开一个压缩包tar.extractall() # 解压包内所有文件（可设置解压地址）tar.close() # 关闭压缩包 创建压缩包1234567891011121314151617181920import osimport tarfiledef corpus_compose(source_path, target_path): &quot;&quot;&quot; tar压缩（会嵌套一层） :return: &quot;&quot;&quot; with tarfile.open(target_path, &#39;w&#39;) as f: f.add(source_path, arcname&#x3D;os.path.basename(source_path))def corpus_compose(source_path, target_path): &quot;&quot;&quot; tar压缩（每个文件压缩到第一层） :return: &quot;&quot;&quot; with tarfile.open(target_path, &#39;w&#39;) as f: for root, dir, files in os.walk(source_path): for file in files: fullpath &#x3D; os.path.join(root, file) f.add(fullpath) 解压缩123456789101112131415def extract_tarfile(tar_path, target_path): &quot;&quot;&quot; tar解压缩 :param tar_path: :param target_path: :return: &quot;&quot;&quot; try: tar &#x3D; tarfile.open(tar_path, &quot;r&quot;) file_names &#x3D; tar.getnames() for file_name in file_names: tar.extract(file_name, target_path) tar.close() except Exception as e: raise e不解压实现读取压缩包 # 我的文件是utf8格式，需要创建一个读取对象 utf8reader = codecs.getreader(&#39;utf-8&#39;) # 这个encoding只是读取tarfile的，不是里面文件的 with tarfile.open(&#39;sensitive_words.tar&#39;, mode=&#39;r&#39;,encoding=&#39;utf-8&#39;) as tar_f: for member in tar_f.getmembers(): # member直接读是个二进制流，需要utf8转换一下，返回的是一个file-like object 对象 file = utf8reader(tar_f.extractfile(member)) self.ac_tree.add_words_from_fileobj(file, type=int(member.name[:-4]))","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"代码漏洞扫描","slug":"NLP/code_detect","date":"2021-03-11T05:47:14.000Z","updated":"2021-06-11T03:15:49.219Z","comments":true,"path":"NLP/code_detect/","link":"","permalink":"https://tlylft.github.io/NLP/code_detect/","excerpt":"","text":"静态代码检测工具：安全类规约类https://www.v2ex.com/t/651723https://analyticsindiamag.com/6-machine-learning-tools-that-will-help-you-find-code-bugs/ ZoncolanZoncolan，静态分析工具，能在30分钟内扫描完整个代码库，及时发现bug的所在，检测内部的安全漏洞。 Zoncolan这么好的东西，能不能拿出来和大家一起分享呢？ Facebook安全工程经理Pieter Hooimeijer说，他们希望能推出开源的版本。不过，鉴于开源版本可不仅仅只用适配Facebook内部环境就好了，所以还需要增强灵活性，适配更多环境。 此前，Facebook已经针对Python推出了一个名为Pyre的代码检查器，虽然能力范围并不像Zoncolan一样强大，但这基本上就是Facebook准备开源的一个范例了。Hooimeijer说，这个基本上就是Python版的Zoncolan。 Pyre开源地址：https://github.com/facebook/pyre-check facebook的这款工具叫Infer(开源)可以检查Java , Object c 和c代码，美中不足的是不支持C++。1.通过词法分析2.语法分析3.控制流4.数据流分析等技术对程序代码进行扫描，来验证代码是否存在问题或满足技术指标。https://blog.csdn.net/sjtuyunlei/article/details/46507345https://fbinfer.com/docs/getting-startedhttps://github.com/facebook/infer/tree/master/examples sourceBrella https://www.sourcebrella.com/online-showcase/ sapfix https://discovery.ucl.ac.uk/id/eprint/10084761/1/SapFix-Automated-End-to-End-Repair-at-Scale-v2.pdf Source{d} (开源)https://www.viva64.com/en/b/0706/https://github.com/src-d/sourced-ce数据集 https://github.com/src-d/datasets/tree/master/PublicGitArchive/pga数据集论文 https://arxiv.org/abs/1803.10144 deepcodehttps://www.deepcode.ai/press","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"【读书笔记】文章-恭喜那些喜欢独处的人","slug":"reading/articles/恭喜那些喜欢独处的人","date":"2021-03-10T00:28:26.000Z","updated":"2021-03-10T00:41:00.361Z","comments":true,"path":"reading/articles/恭喜那些喜欢独处的人/","link":"","permalink":"https://tlylft.github.io/reading/articles/%E6%81%AD%E5%96%9C%E9%82%A3%E4%BA%9B%E5%96%9C%E6%AC%A2%E7%8B%AC%E5%A4%84%E7%9A%84%E4%BA%BA/","excerpt":"","text":"一个人独处，看似会失去很多，但也会收获更多。 【懂得自我沉静，不依赖别人】 把对别人的依赖降到最低，不会因为谁的离开而一蹶不振，也不会因为谁的出现而丢失自己。正因为如此，他们有自己的边界感，也尊重别人的边界感。内心静下来，更容易进入角色，每个细节都能表现到位。不能保证你一直在高光时刻、无忧无虑，却能让你即使遇到低谷，也能快速平复情绪，继续向前走。面对愿望沉下心来，不受任何事干扰，总有天会强大起来。懂得如何安静下来，不急不躁，心无杂念，这样一路向前，才能永远不跑偏。 【懂得接纳自己，努力爱自己】 可不可以不要修掉我的皱纹，那是我好不容易长出来的。这个世上，哪有人是完美无缺的？能接纳自己，无条件爱自己身上的每条皱纹，每个小缺陷，其实是种难得的本事。能与自己好好相处，全然接纳自己，爱自己的一切，这样的你，也值得被任何人欣赏。 【找个梦想，找个理由坚强】 《我的青春谁做主》中有句话：“一个人至少拥有一个梦想，有一个理由去坚强。心若没有栖息的地方，到哪里都是在流浪。”梦想与坚强，心灵栖息的地方，所幸，懂得独处的人都有了。享受孤独的路上，他们早拥有找寻幸福的能力，不依赖任何人，拥有实现理想的天赋，能静下心去自律。最重要的，不管自己身在何处，是否成功，他们都无条件接纳自己、爱自己，我羡慕这样的人。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"【读书笔记】文章-改变自己是神，改变别人是神经病","slug":"reading/articles/改变自己是神，改变别人是神经病","date":"2021-03-10T00:28:26.000Z","updated":"2021-03-10T00:36:35.038Z","comments":true,"path":"reading/articles/改变自己是神，改变别人是神经病/","link":"","permalink":"https://tlylft.github.io/reading/articles/%E6%94%B9%E5%8F%98%E8%87%AA%E5%B7%B1%E6%98%AF%E7%A5%9E%EF%BC%8C%E6%94%B9%E5%8F%98%E5%88%AB%E4%BA%BA%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%97%85/","excerpt":"","text":"【留下尊重差异的空间】 与其费尽心思改变别人， 还不好专心致志做好自己。 人心不同，不必强求， 改变一个人很难， 勉强一个人很累。 要学会给予尊重， 给各自留一些空间， 给感情留一点余地。 【从自己身上找原因】 总以自己为重，不顾别人感受， 当问题出现时， 便推脱责任，全都归咎于别人。 凡事从自身上找原因， 不要一昧的去指责别人。 自己主动改变，打破僵局， 就不会再有改变他人的欲望了。 【不去抱怨】 幸福的人不抱怨，抱怨的人不幸福。 与其开口抱怨，不如闭嘴做事， 用行动做出改变，适应新环境， 提升新技能，调整好心态。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"HMM 隐马尔可夫模型","slug":"NLP/algorithm/HMM","date":"2021-03-09T13:18:12.000Z","updated":"2021-03-10T05:41:13.621Z","comments":true,"path":"NLP/algorithm/HMM/","link":"","permalink":"https://tlylft.github.io/NLP/algorithm/HMM/","excerpt":"","text":"1. 隐马尔可夫模型任务：解决seq2seq序列映射的问题，将观测序列映射到状态序列。比如： 词性标注，命名实体识别详细推导pdf举例理解**知乎这篇理论和应用结合 1.1. 算法原理画了个图，大概描述了pdf 7.1中模型的基本结构定义描述了模型的前向过程， 定义入参 A,B,π什么是A?A是状态序列的状态转移矩阵，做一个简单的初始化值，每一个值表示在𝑡时刻处于状态$𝑞_𝑖$的条件下，在𝑡 + 1时刻转移到状态$𝑞_𝑗$的概率什么是B?B是状态序列转移到观测序列的观测概率矩阵，每一个值表示在𝑡时刻处于状态$𝑞_𝑖$的条件下，⽣成观测$𝑣_𝑘$的概率什么是π?为什么有ππ是初始化矩阵，表示在时刻𝑡 = 1处于每个状态𝑞𝑖的概率，是个元组。 为什么要有它？因为在上图中每一个序列的值都可以被计算到，但只有第一个状态序列中的第一个值却没有办法被计算，导致后面也没办法计算，所以我们以初始概率作为推动计算和图运行的开始。 我觉得比较清晰简单的理解方式：还没理清楚和后面一坨坨的关系 1.2. 算法推导在学习HMM的过程中，我们需要研究三个问题，它们分别是： 概率计算问题：给定模型参数和观测序列，计算该观测序列的概率。是后面两个问题的基础。 学习训练问题：给定观测序列，估计模型参数。 解码预测问题：给定模型参数和观测序列，求概率最大的状态序列。 1.2.1. 概率计算问题1.2.2. 学习训练参数1.2.2.1. 有监督推导（比较好理解）在有监督学习中，可以直接通过统计方法，求得模型的状态转移概率矩阵A、观测概率矩阵B、初始状态概率向量π。 1.2.2.2. 无监督推导（就是pdf一坨坨公式，后面有时间慢慢看）在无监督学习中，模型使用Baum-Welch算法来求得模型参数。Baum-Welch算法是HMM模型中最难的部分，由于本文是“入门”文章，这里就不展开推导了。 注一：其实Baum-Welch算法和EM算法是一样的，只是Baum-Welch算法提出得比较早，当时EM算法还没有被归纳出来。 1.2.3. 解码预测","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"algorithm","slug":"NLP/algorithm","permalink":"https://tlylft.github.io/categories/NLP/algorithm/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"algorithm","slug":"algorithm","permalink":"https://tlylft.github.io/tags/algorithm/"}]},{"title":"pytorch使用中遇到的问题","slug":"pytorch/torch_error","date":"2021-03-09T05:34:41.000Z","updated":"2021-03-10T13:26:20.763Z","comments":true,"path":"pytorch/torch_error/","link":"","permalink":"https://tlylft.github.io/pytorch/torch_error/","excerpt":"","text":"tensor格式问题 Expected tensor for argument #1 ‘indices’ to have scalar type Long；but got torch.IntTensor instead 分析：训练的批量样本数据输入值需要是long值或者int64的Tensor数据，而不是int值的Tensor数据。dataloader读取数据时，会自动根据格式转换为对应的tensor格式。 解决：在获取数据后手动转换下tensor的类型。 tensor_var.long()或者在传入dataloader的numpy类型那里，设置dtype=int64 模型调用结果不一致https://blog.csdn.net/confusingbird/article/details/108799908将前向过程的dropout层删掉","categories":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/categories/pytorch/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/tags/pytorch/"}]},{"title":"迁移学习","slug":"deep_learning/transfer_learning","date":"2021-03-07T02:13:48.000Z","updated":"2021-03-07T02:17:01.169Z","comments":true,"path":"deep_learning/transfer_learning/","link":"","permalink":"https://tlylft.github.io/deep_learning/transfer_learning/","excerpt":"","text":"有两种方式 将别人训练好的所有特征层的权重，作为自己训练的初始化继续进行训练。 将训练好的特征层冻住，只训练后面自己调整和加上的全连接层。 当自己的数据量比较小时，一般采用方式2，只训练最后一层当自己数据量适中，一般冻住一般的网络结构当自己的数据量比较大，或数据偏差大时，一般采用方式1，重新训练。","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"【敏感词检测】02- Aho-Corasick自动机","slug":"NLP/sensitive_word/sensitivewords ac","date":"2021-03-04T04:42:45.000Z","updated":"2021-06-11T03:12:45.056Z","comments":true,"path":"NLP/sensitive_word/sensitivewords ac/","link":"","permalink":"https://tlylft.github.io/NLP/sensitive_word/sensitivewords%20ac/","excerpt":"","text":"https://blog.csdn.net/zichen_ziqi/article/details/104525900/https://blog.csdn.net/danengbinggan33/article/details/83338789 1. 介绍AC自动机利用某些操作阻止了模式串匹配阶段的回溯,将时间复杂度优化到了O(n)，n为文本串长度 2. 构建2.1. 构建trie树trie树原理讲解：https://zhuanlan.zhihu.com/p/65115496单词结尾位置标注结尾符号标识，这里可以直接写上长度作为标识符，方便定位。 构建失配指针fail pointerac自动机,就是在tire树的基础上,增加一个fail指针,如果当前点匹配失败,则将指针转移到fail指针指向的地方,这样就不用回溯,而可以路匹配下去了.(当前模式串后缀和fail指针指向的模式串部分前缀相同,如abce和bcd,我们找到c发现下一个要找的不是e,就跳到bcd中的c处,看看此处的下一个字符(d)是不是应该找的那一个)Fail指针的实质含义是什么？如果一个点i的Fail指针指向j。那么root到j的字符串是root到i的字符串的一个后缀。 构建第一层的Fail一定指的是root。设点i的父节点的Fail指针指的是fa_fail，那么如果fa_fail有和i值相同的儿子j，那么i的Fail就指向j。否则指向fa_fail","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"sensitive","slug":"NLP/sensitive","permalink":"https://tlylft.github.io/categories/NLP/sensitive/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"sensitive","slug":"sensitive","permalink":"https://tlylft.github.io/tags/sensitive/"}]},{"title":"【敏感词检测】01- 任务介绍","slug":"NLP/sensitive_word/sensitivewords","date":"2021-03-04T04:42:45.000Z","updated":"2021-06-11T03:13:01.230Z","comments":true,"path":"NLP/sensitive_word/sensitivewords/","link":"","permalink":"https://tlylft.github.io/NLP/sensitive_word/sensitivewords/","excerpt":"","text":"业界发展数美接口：https://help.ishumei.com/docs/tj/text/response百度接口：https://ai.baidu.com/ai-doc/ANTIPORN/Nk3h6xbb2 关键问题 无意义的字符干扰 - 停用词 拼音干扰 - 拼音加入搜索树中 新词的分词问题 时效性 拆分字的情况 - 手动维护词典敏感词任务数美的任务分类：12345678910111213正常：0涉政：100色情：200辱骂：210广告：300灌水：400无意义：500违禁: 600其他：700黑账号：720黑IP：730高危账号：800自定义：900 百度：百度文本审核平台1234567890:低质灌水1:暴恐违禁2:文本色情3:政治敏感4:恶意推广5:低俗辱骂 6:恶意推广-联系方式7:恶意推广-软文推广8:广告法审核 整理：12345678910111213141516171819202122正常：0涉政：100 3:政治敏感色情：200 2:文本色情辱骂：210 5:低俗辱骂 广告：300 8:广告法审核灌水：400 0:低质灌水无意义：500违禁: 600 1:暴恐违禁其他：700黑账号：720黑IP：730高危账号：800自定义：9004:恶意推广6:恶意推广-联系方式7:恶意推广-软文推广 词库下载词库：https://github.com/fighting41love/funNLP https://blog.csdn.net/u014033218/article/details/88549226 敏感词词库：拆字词库：https://github.com/kfcd/chaizi 语料下载：最近7天200条被微博屏蔽的博文：https://weiboscope.jmsc.hku.hk/latest.phphttps://freeweibo.com/weibo/?latest 实现算法介绍 以下方法介绍及代码引用自 Serverless 实战：3 分钟实现文本敏感词过滤 代码demo https://github.com/toolgood/ToolGood.Words 方法1：replace()我们可以通过replace来实现，首先准备一个敏感词库，然后通过replace进行敏感词替换:这种方法虽然操作简单，但是存在一个很大的问题：在文本和敏感词汇非常庞大的情况下，会出现很严重的性能问题。1234567def worldFilter(keywords, text): for eve in keywords: text &#x3D; text.replace(eve, &quot;***&quot;) return textkeywords &#x3D; (&quot;关键词1&quot;, &quot;关键词2&quot;, &quot;关键词3&quot;)content &#x3D; &quot;这是一个关键词替换的例子，这里涉及到了关键词1还有关键词2，最后还会有关键词3。&quot;print(worldFilter(keywords, content))此时的输出结果是：0.12426114082336426，可以看到性能非常差。 方法2：regex正则匹配相较于replace，使用正则表达re.sub实现可能更加快速。123456789import timeimport redef worldFilter(keywords, text): return re.sub(&quot;|&quot;.join(keywords), &quot;***&quot;, text)keywords &#x3D;[ &quot;关键词&quot; + str(i) for i in range(0,10000)]content &#x3D; &quot;这是一个关键词替换的例子，这里涉及到了关键词1还有关键词2，最后还会有关键词3。&quot; * 1000startTime &#x3D; time.time()worldFilter(keywords, content)print(time.time()-startTime)输出时间结果是0.24773502349853516对比这两个例子，我们会发现当前两种方法的性能差距不是很大，但是随着文本数量的增加，正则表达的优势会逐渐凸显，性能提升明显方法3：DFA 过滤敏感词trie树DFA python代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import timeclass DFAFilter(object): def __init__(self): self.keyword_chains &#x3D; &#123;&#125; # 关键词链表 self.delimit &#x3D; &#39;\\x00&#39; # 限定 def parse(self, path): with open(path, encoding&#x3D;&#39;utf-8&#39;) as f: for keyword in f: chars &#x3D; str(keyword).strip().lower() # 关键词英文变为小写 if not chars: # 如果关键词为空直接返回 return level &#x3D; self.keyword_chains for i in range(len(chars)): if chars[i] in level: level &#x3D; level[chars[i]] else: if not isinstance(level, dict): break for j in range(i, len(chars)): level[chars[j]] &#x3D; &#123;&#125; last_level, last_char &#x3D; level, chars[j] level &#x3D; level[chars[j]] last_level[last_char] &#x3D; &#123;self.delimit: 0&#125; break if i &#x3D;&#x3D; len(chars) - 1: level[self.delimit] &#x3D; 0 def filter(self, message, repl&#x3D;&quot;*&quot;): message &#x3D; message.lower() ret &#x3D; [] start &#x3D; 0 while start &lt; len(message): level &#x3D; self.keyword_chains step_ins &#x3D; 0 for char in message[start:]: if char in level: step_ins +&#x3D; 1 if self.delimit not in level[char]: level &#x3D; level[char] else: ret.append(repl * step_ins) start +&#x3D; step_ins - 1 break else: ret.append(message[start]) break else: ret.append(message[start]) start +&#x3D; 1 return &#39;&#39;.join(ret)gfw &#x3D; DFAFilter()gfw.parse( &quot;.&#x2F;sensitive_words&quot;)content &#x3D; &quot;这是一个关键词替换的例子，这里涉及到了关键词1还有关键词2，最后还会有关键词3。&quot; * 1000startTime &#x3D; time.time()result &#x3D; gfw.filter(content)print(time.time()-startTime)执行结果：0.06450581550598145 方法4：Aho-Corasick自动机过滤敏感词算法Python——利用AC自动机进行关键词提取 里面有很多优秀外链，从原理到优化实现 效果提升繁体字、拼音转换：https://github.com/toolgood/ToolGood.Words/blob/master/python/ToolGood.Words.Translate.py AI算法百度paddle色情检测百度飞浆用了三个demo模型在paddlehub中， cnn lstm gru这是他的模型简介：色情检测模型可自动判别文本是否涉黄并给出相应的置信度，对文本中的色情描述、低俗交友、污秽文爱进行识别，核心采用LSTM网络结构并按字粒度进行切词。 github文本审核https://github.com/minitrill/TextAuidt github色情文章检测https://github.com/yudake/porn_fiction_classify 辱骂语料借鉴https://github.com/sfzhou5678/TextualAdversarialAttack-Tianchi","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"sensitive","slug":"NLP/sensitive","permalink":"https://tlylft.github.io/categories/NLP/sensitive/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"sensitive","slug":"sensitive","permalink":"https://tlylft.github.io/tags/sensitive/"}]},{"title":"centos7安装GPU服务","slug":"linux/linux_gpu","date":"2021-03-03T05:03:00.000Z","updated":"2022-02-11T02:31:19.825Z","comments":true,"path":"linux/linux_gpu/","link":"","permalink":"https://tlylft.github.io/linux/linux_gpu/","excerpt":"","text":"1. 查看显卡12345lspci | grep -i nvidia&gt;&gt;0001:00:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100 PCIe 16GB] (rev a1)sudo lshw -C video # 查看详细信息 然后到官网查看是否支持CUDA 架构排序（时间顺序）： Architecture Compute Compatibility GPU Series Tesla - 市面已经没有相关显卡 Fermi - GeForce 400, 500, 600, GT-630 Kepler 3.0 GTX 600*Tesla K10 Kepler 3.5 GTX 700*GTX Titan Z/BlackTesla K20/k40 Kepler 3.7 Tesla K80 Maxwell 5.0 GTX 900 (&lt;=960)Tesla M10 Maxwell 5.2 GTX 900 (&gt;=965)Tesla M4/M6/M40/M60 Pascal 6.0 Tesla P100 Pascal 6.1 GTX 10 SeriesNVidia Titan X/XP Tesla P4/P6/P40 Volta 7.0 NVidia Titan VTesla V100 Turing 7.5 GTX 16 SeriesRTX 20 SeriesNvidia Titan RTXTesla T4 Ampere 8.0 A30/A100 Ampere 8.6 RTX 30A2/A10/A16/A40 NVIDIA ampere显卡不支持cuda11以下的版本 2. 查看显卡驱动1nvidia-smi 禁用系统默认的nouveau显卡驱动（1）查看nouveau是否启动：lsmod | grep nouveau如果列表中有nouveau，则需要禁用，如果列表为空，则正常禁用部分参考安装基础包1yum install kernel-devel kernel-doc kernel-headers gcc* glibc* glibc-*安装内核包时需要先检查一下当前内核版本是否与所要安装的kernel-devel/kernel-doc/kernel-headers的版本一致，请务必保持两者版本一致，否则后续的编译过程会出问题。查看版本：12345678910111213141516# 查看当前内核版本 [root@localhost ~]# uname -a Linux localhost.localdomain 3.10.0-693.11.1.el7.x86_64 #1 SMP Mon Dec 4 23:52:40 UTC 2017 x86_64 x86_64 x86_64 GNU&#x2F;Linux# 查看kernel版本[root@localhost ~]# yum list | grep kernel- kernel-devel.x86_64 3.10.0-693.11.1.el7 @updates kernel-doc.noarch 3.10.0-693.11.1.el7 @updates kernel-headers.x86_64 3.10.0-693.11.1.el7 @updates kernel-tools.x86_64 3.10.0-693.11.1.el7 @updates安装显卡驱动：https://blog.csdn.net/weixin_42631192/article/details/107719150123456789101112131415161718192021222324252627282930313233# 安装显卡检测程序rpm -Uvh http:&#x2F;&#x2F;www.elrepo.org&#x2F;elrepo-release-7.0-2.el7.elrepo.noarch.rpm yum install nvidia-detect# 运行nvidia-detect[nlpadmin@NLP-Centos ~]$ nvidia-detect&gt;&gt; kmod-nvidia# 安装刚才检测到的驱动 [nlpadmin@NLP-Centos ~]$ yum install kmod-nvidia# 查看显卡[nlpadmin@NLP-Centos ~]$ nvidia-smiWed Mar 3 05:40:48 2021+-----------------------------------------------------------------------------+| NVIDIA-SMI 460.56 Driver Version: 460.56 CUDA Version: 11.2 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage&#x2F;Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|| 0 Tesla V100-PCIE... Off | 00000001:00:00.0 Off | 0 || N&#x2F;A 25C P0 35W &#x2F; 250W | 0MiB &#x2F; 16160MiB | 0% Default || | | N&#x2F;A |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|| No running processes found |+-----------------------------------------------------------------------------+&gt;&gt; 如果采用其他方法运行，安装后报错：1NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.或安装显卡时报错：123456789101112131415161718ERROR: Failed to run &#x2F;sbin&#x2F;dkms build -m nvidia -v 430.64 -k 3.10.0-1127.13.1.el7.x86_64: Error! echoYour kernel headers for kernel 3.10.0-1127.13.1.el7.x86_64 cannot befound at&#x2F;lib&#x2F;modules&#x2F;3.10.0-1127.13.1.el7.x86_64&#x2F;build or&#x2F;lib&#x2F;modules&#x2F;3.10.0-1127.13.1.el7.x86_64&#x2F;source.You can use the --kernelsourcedir option to tell DKMS where it’slocatedERROR: Failed to install the kernel module through DKMS. No kernel modulewas installed; please try installing again without DKMS, or check theDKMS logs for more information.ERROR: Installation has failed. Please see the file‘&#x2F;var&#x2F;log&#x2F;nvidia-installer.log’ for details. You may findsuggestions on fixing installation problems in the README availableon the Linux driver download page at www.nvidia.com.需要卸载,再按上面的方式运行123456# 查看安装的nvidia模块命令rpm -qa|grep -i nvid|sort# 删除找到的模块yum remove kmod-nvidia-390.87-1.el7_5.elrepo.x86_64 xorg-x11-drv-nvidia-384.81-1.el7.x86_64yum search kmod-nvidia nvidia-kmod-384.81-2.el7.x86_64注释：如果有错误提示“NVIDIA-SMI has failed because it couldn&#39;t communicate with the NVIDIA driver”需要运行nvidia-uninstall 3. 安装cuda12# 验证cuda安装成功nvcc -V 哭唧唧用anaconda的环境装吧。。。但是如果安装失败，可以尝试手动安装这些组件：CUDA、cuDNN、pyTorch 安装cuda 下载地址1234wget https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;10.2&#x2F;Prod&#x2F;local_installers&#x2F;cuda-repo-rhel6-10-2-local-10.2.89-440.33.01-1.0-1.x86_64.rpmsudo rpm -i cuda-repo-rhel6-10-2-local-10.2.89-440.33.01-1.0-1.x86_64.rpmsudo yum clean allsudo yum -y install cuda环境变量：123vi ~&#x2F;.bashrcexport PATH&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;cuda-9.2&#x2F;bin:$PATH&quot; export LD_LIBRARY_PATH&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;cuda-9.2&#x2F;lib64:$LD_LIBRARY_PATH&quot; 4. anaconda GPU环境会自动安装cuda环境… 4.1. pytorch这里找安装命令历史版本安装conda 安装使用pytorch源，安装可能会比较慢，有时win装不上，有时linux装不上，很迷1conda install pytorch torchvision torchaudio cudatoolkit&#x3D;10.2 -c pytorchpip 安装123# 可以在这里找安装命令里对应的whl下载下来，手动安装# https:&#x2F;&#x2F;download.pytorch.org&#x2F;whl&#x2F;torch_stable.htmlpip install torchxxxx.whl torchvisionxxx.whl trochaudio&#x3D;&#x3D;0.x.x验证：1234import torchtorch.cuda.is_available()# True 表示GPU安装成功torch.version.cuda","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"HaNLP NER解析","slug":"NLP/NER/HaNLP","date":"2021-03-01T11:39:25.000Z","updated":"2021-06-11T03:17:55.381Z","comments":true,"path":"NLP/NER/HaNLP/","link":"","permalink":"https://tlylft.github.io/NLP/NER/HaNLP/","excerpt":"","text":"https://github.com/hankcs/HanLPhttps://hanlp.hankcs.com/docs/tutorial.html 这个人的博客里讲了很多原理的东西https://blog.51cto.com/13636660/2351300","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"NER","slug":"NER","permalink":"https://tlylft.github.io/tags/NER/"}]},{"title":"python configparse模块","slug":"python/python/python_config","date":"2021-02-26T08:54:57.000Z","updated":"2021-02-26T09:01:27.410Z","comments":true,"path":"python/python/python_config/","link":"","permalink":"https://tlylft.github.io/python/python/python_config/","excerpt":"","text":"configparse模块https://www.cnblogs.com/zhou2019/p/10599953.html一、ConfigParser简介ConfigParser 是用来读取配置文件的包。配置文件的格式如下：中括号“[ ]”内包含的为section。section 下面为类似于key-value 的配置内容。123456789101112# devConfig.ini[db]db_host &#x3D; 127.0.0.1db_port &#x3D; 69db_user &#x3D; rootdb_pass &#x3D; roothost_port &#x3D; 69[concurrent]thread &#x3D; 10processor &#x3D; 20括号“[ ]”内包含的为section。紧接着section 为类似于key-value 的options 的配置内容。 二、ConfigParser 初始化对象使用ConfigParser 首选需要初始化实例，并读取配置文件：1234# configUtil.pyimport configparserconfig &#x3D; configparser.ConfigParser()config.read(&quot;devConfig.ini&quot;, encoding&#x3D;&quot;utf-8&quot;)三、ConfigParser 常用方法 1、获取所用的section节点 123# 获取所用的section节点config.sections()# 运行结果 [&#39;db&#39;, &#39;concurrent&#39;] 2、获取指定section 的options。即将配置文件某个section 内key 读取到列表中： 123r &#x3D; config.options(&quot;db&quot;)#运行结果 [&#39;db_host&#39;, &#39;db_port&#39;, &#39;db_user&#39;, &#39;db_pass&#39;, &#39;host_port&#39;] 3、获取指点section下指点option的值 1234567r &#x3D; config.get(&quot;db&quot;, &quot;db_host&quot;)r1 &#x3D; config.getint(&quot;db&quot;, &quot;k1&quot;) #将获取到值转换为int型r2 &#x3D; config.getboolean(&quot;db&quot;, &quot;k2&quot; ) #将获取到值转换为bool型r3 &#x3D; config.getfloat(&quot;db&quot;, &quot;k3&quot; ) #将获取到值转换为浮点型print(r)#运行结果# 127.0.0.1 4、获取指点section的所用配置信息 12345r &#x3D; config.items(&quot;db&quot;)print(r)print(dict(r)) # 转换为字典#运行结果#[(&#39;db_host&#39;, &#39;127.0.0.1&#39;), (&#39;db_port&#39;, &#39;69&#39;), (&#39;db_user&#39;, &#39;root&#39;), (&#39;db_pass&#39;, &#39;root&#39;), (&#39;host_port&#39;, &#39;69&#39;)] 5、修改某个option的值，如果不存在则会出创建 123# 修改某个option的值，如果不存在该option 则会创建config.set(&quot;db&quot;, &quot;db_port&quot;, &quot;69&quot;) #修改db_port的值为69config.write(open(&quot;new.ini&quot;, &quot;w&quot;)) 6、检查section或option是否存在，bool值12config.has_section(&quot;section&quot;) #是否存在该sectionconfig.has_option(&quot;section&quot;, &quot;option&quot;) #是否存在该option7、添加section 和 option 12345if not config.has_section(&quot;default&quot;): # 检查是否存在section config.add_section(&quot;default&quot;)if not config.has_option(&quot;default&quot;, &quot;db_host&quot;): # 检查是否存在该option config.set(&quot;default&quot;, &quot;db_host&quot;, &quot;1.1.1.1&quot;)config.write(open(&quot;ini&quot;, &quot;w&quot;)) 8、删除section 和 option12345import configparserconfig &#x3D; configparser.ConfigParser()config.read(&quot;ini&quot;, encoding&#x3D;&quot;utf-8&quot;)config.remove_section(&quot;default&quot;) #整个section下的所有内容都将删除config.write(open(&quot;ini&quot;, &quot;w&quot;))9、写入文件 以下的几行代码只是将文件内容读取到内存中，进过一系列操作之后必须写回文件，才能生效。 123456import configparserconfig &#x3D; configparser.ConfigParser()config.read(&quot;ini&quot;, encoding&#x3D;&quot;utf-8&quot;)写回文件的方式如下：（使用configparser的write方法）config.write(open(&quot;ini&quot;, &quot;w&quot;))","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"数据表示 vector,matrix, tensor","slug":"math/vector","date":"2021-02-09T07:02:33.000Z","updated":"2021-06-11T03:05:16.467Z","comments":true,"path":"math/vector/","link":"","permalink":"https://tlylft.github.io/math/vector/","excerpt":"","text":"表示标量scalar向量vector转置加法乘法 矩阵matrix乘法求逆 $XX^{-1}=I$运算耗时长，大规模矩阵应避免求逆运算 张量tensor范数L1 L2简单理解，就是模和模的平方 用在正则项里（惩罚力度） 作为目标函数（一般用误差的模的平方作为目标函数，也就是误差的L2范式） 求导http://www2.imm.dtu.dk/pubdb/edoc/imm3274.pdf","categories":[{"name":"math","slug":"math","permalink":"https://tlylft.github.io/categories/math/"}],"tags":[{"name":"math","slug":"math","permalink":"https://tlylft.github.io/tags/math/"}]},{"title":"kubernetes架构","slug":"tools/k8s","date":"2021-02-08T13:41:48.000Z","updated":"2021-11-17T05:34:35.868Z","comments":true,"path":"tools/k8s/","link":"","permalink":"https://tlylft.github.io/tools/k8s/","excerpt":"","text":"https://blog.51cto.com/lizhenliang/category15.html intoroduction基于容器的集群管理平台。对Docker及容器进行更高级更灵活的管理。 Kubernetes 这个单词来自于希腊语，含义是舵手或领航员。K8S是它的缩写，用“8”字替代了“ubernete”这8个字符。 structure一个K8S系统，通常称为一个K8S集群（Cluster）。 这个集群主要包括两个部分： 一个Master节点（主节点）：负责管理和控制 一群Node节点（计算节点）：工作负载节点，里面是具体的容器。 masterMaster节点包括API Server、Scheduler、Controller manager、etcd。API Server是整个系统的对外接口，供客户端和其它组件调用，相当于“营业厅”。Scheduler负责对集群内部的资源进行调度，相当于“调度室”。Controller manager负责管理控制器，相当于“大总管”。 node Node节点包括Docker、kubelet、kube-proxy、Fluentd、kube-dns（可选），还有就是Pod。 Pod是Kubernetes最基本的操作单元。一个Pod代表着集群中运行的一个进程，它内部封装了一个或多个紧密相关的容器。除了Pod之外，K8S还有一个Service的概念，一个Service可以看作一组提供相同服务的Pod的对外访问接口。这段不太好理解，跳过吧。 Docker，不用说了，创建容器的。 Kubelet，主要负责监视指派到它所在Node上的Pod，包括创建、修改、监控、删除等。 Kube-proxy，主要负责为Pod对象提供代理。 Fluentd，主要负责日志收集、存储与查询。","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"},{"name":"kubernetes","slug":"tools/kubernetes","permalink":"https://tlylft.github.io/categories/tools/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://tlylft.github.io/tags/kubernetes/"}]},{"title":"似然函数,最大似然估计","slug":"math/likelihood","date":"2021-02-08T04:33:46.000Z","updated":"2021-02-08T04:34:44.149Z","comments":true,"path":"math/likelihood/","link":"","permalink":"https://tlylft.github.io/math/likelihood/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/75731049https://www.zhihu.com/question/54082000https://blog.csdn.net/weixin_44940258/article/details/109731281","categories":[{"name":"math","slug":"math","permalink":"https://tlylft.github.io/categories/math/"}],"tags":[{"name":"math","slug":"math","permalink":"https://tlylft.github.io/tags/math/"}]},{"title":"matplotlib实时动态图","slug":"python/matplotlib/dynamic_plot","date":"2021-02-01T13:14:58.000Z","updated":"2021-02-05T02:32:51.832Z","comments":true,"path":"python/matplotlib/dynamic_plot/","link":"","permalink":"https://tlylft.github.io/python/matplotlib/dynamic_plot/","excerpt":"","text":"matplotlib实时动态图jupyter notebook12345678910111213141516171819202122232425262728import matplotlib.pyplot as pltfrom IPython import display # 引用前端展示模块%matplotlib inline #保证notebook内展示plt.ion() # 这是实时展示的开关plt.show()for t in range(400): prediction &#x3D; net(x) # input x and predict based on x loss &#x3D; loss_func(prediction, y) # must be (1. nn output, 2. target) optimizer.zero_grad() # clear gradients for next train loss.backward() # backpropagation, compute gradients optimizer.step() # apply gradients if t % 10 &#x3D;&#x3D; 0: # plot and show learning process plt.cla() plt.scatter(x.numpy(), y.numpy()) plt.plot(x.numpy(), prediction.data.numpy(), &#39;r-&#39;, lw&#x3D;5) plt.text(0.5, 0, &#39;Loss&#x3D;%.4f&#39; % loss.data.numpy(), fontdict&#x3D;&#123;&#39;size&#39;: 20, &#39;color&#39;: &#39;red&#39;&#125;) plt.pause(0.1) display.clear_output(wait&#x3D;True) # notebook中使用plt.ioff() #关闭实时展示plt.show()","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"matplotlib","slug":"python/matplotlib","permalink":"https://tlylft.github.io/categories/python/matplotlib/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"matplotlib subplot","slug":"python/matplotlib/subplot","date":"2021-02-01T13:04:45.000Z","updated":"2021-06-11T03:30:26.203Z","comments":true,"path":"python/matplotlib/subplot/","link":"","permalink":"https://tlylft.github.io/python/matplotlib/subplot/","excerpt":"","text":"subplot1. demo1123import torchimport torch.nn.functional as F # 激活函数在这里import matplotlib.pyplot as plt 1.1. Firstly generate some fake data123x = torch.linspace(-5, 5, 200) # x data (tensor), shape=(200, 1)x_np = x.numpy()print(x.data) tensor([-5.0000, -4.9497, -4.8995, -4.8492, -4.7990, -4.7487, -4.6985, -4.6482, -4.5980, -4.5477, -4.4975, -4.4472, -4.3970, -4.3467, -4.2965, -4.2462, -4.1960, -4.1457, -4.0955, -4.0452, -3.9950, -3.9447, -3.8945, -3.8442, -3.7940, -3.7437, -3.6935, -3.6432, -3.5930, -3.5427, -3.4925, -3.4422, -3.3920, -3.3417, -3.2915, -3.2412, -3.1910, -3.1407, -3.0905, -3.0402, -2.9899, -2.9397, -2.8894, -2.8392, -2.7889, -2.7387, -2.6884, -2.6382, -2.5879, -2.5377, -2.4874, -2.4372, -2.3869, -2.3367, -2.2864, -2.2362, -2.1859, -2.1357, -2.0854, -2.0352, -1.9849, -1.9347, -1.8844, -1.8342, -1.7839, -1.7337, -1.6834, -1.6332, -1.5829, -1.5327, -1.4824, -1.4322, -1.3819, -1.3317, -1.2814, -1.2312, -1.1809, -1.1307, -1.0804, -1.0302, -0.9799, -0.9296, -0.8794, -0.8291, -0.7789, -0.7286, -0.6784, -0.6281, -0.5779, -0.5276, -0.4774, -0.4271, -0.3769, -0.3266, -0.2764, -0.2261, -0.1759, -0.1256, -0.0754, -0.0251, 0.0251, 0.0754, 0.1256, 0.1759, 0.2261, 0.2764, 0.3266, 0.3769, 0.4271, 0.4774, 0.5276, 0.5779, 0.6281, 0.6784, 0.7286, 0.7789, 0.8291, 0.8794, 0.9296, 0.9799, 1.0302, 1.0804, 1.1307, 1.1809, 1.2312, 1.2814, 1.3317, 1.3819, 1.4322, 1.4824, 1.5327, 1.5829, 1.6332, 1.6834, 1.7337, 1.7839, 1.8342, 1.8844, 1.9347, 1.9849, 2.0352, 2.0854, 2.1357, 2.1859, 2.2362, 2.2864, 2.3367, 2.3869, 2.4372, 2.4874, 2.5377, 2.5879, 2.6382, 2.6884, 2.7387, 2.7889, 2.8392, 2.8894, 2.9397, 2.9899, 3.0402, 3.0905, 3.1407, 3.1910, 3.2412, 3.2915, 3.3417, 3.3920, 3.4422, 3.4925, 3.5427, 3.5930, 3.6432, 3.6935, 3.7437, 3.7940, 3.8442, 3.8945, 3.9447, 3.9950, 4.0452, 4.0955, 4.1457, 4.1960, 4.2462, 4.2965, 4.3467, 4.3970, 4.4472, 4.4975, 4.5477, 4.5980, 4.6482, 4.6985, 4.7487, 4.7990, 4.8492, 4.8995, 4.9497, 5.0000]) 1.2. Following are popular activation functions12345678y_relu = F.relu(x).numpy()y_sigmoid = torch.sigmoid(x).numpy()y_tanh = torch.tanh(x).numpy()y_softplus = F.softplus(x).numpy()y_softmax = F.softmax(x,dim=0)# softmax is a special kind of activation function, it is about probability# and will make the sum as 1. &lt;class &#39;torch.Tensor&#39;&gt; 1.3. Plot to visualize these activation function1%matplotlib inline 123456789101112131415161718192021222324252627plt.figure(1, figsize=(8, 6))plt.subplot(321)plt.plot(x_np, y_relu, c='red', label='relu')plt.ylim((-1, 5))plt.legend(loc='best')plt.subplot(322)plt.plot(x_np, y_sigmoid, c='red', label='sigmoid')plt.ylim((-0.2, 1.2))plt.legend(loc='best')plt.subplot(323)plt.plot(x_np, y_tanh, c='red', label='tanh')plt.ylim((-1.2, 1.2))plt.legend(loc='best')plt.subplot(324)plt.plot(x_np, y_softplus, c='red', label='softplus')plt.ylim((-0.2, 6))plt.legend(loc='best')plt.subplot(325)plt.plot(x_np, y_softmax, c='red', label='softmax')# plt.ylim((-0.05, 0.05))plt.legend(loc='best')plt.show() 2. demo21234567891011121314151617181920import matplotlib.pyplot as pltimport numpy as npx &#x3D; np.linspace(1, 2, 2)y1 &#x3D; np.sin(x)y2 &#x3D; np.cos(x)ax1 &#x3D; plt.subplot(2, 2, 1, frameon &#x3D; False) # 两行一列，位置是1的子图plt.plot(x, y1, &#39;b--&#39;)plt.ylabel(&#39;y1&#39;)ax2 &#x3D; plt.subplot(2, 2, 2, projection &#x3D; &#39;polar&#39;)plt.plot(x, y2, &#39;r--&#39;)plt.ylabel(&#39;y2&#39;)plt.xlabel(&#39;x&#39;)plt.subplot(2, 2, 3, sharex &#x3D; ax1, facecolor &#x3D; &#39;red&#39;)plt.plot(x, y2, &#39;r--&#39;)plt.ylabel(&#39;y2&#39;)plt.show()","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"matplotlib","slug":"python/matplotlib","permalink":"https://tlylft.github.io/categories/python/matplotlib/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"matplotlib","slug":"matplotlib","permalink":"https://tlylft.github.io/tags/matplotlib/"}]},{"title":"linux重定向","slug":"linux/linux_redistinct","date":"2021-02-01T05:12:25.000Z","updated":"2021-02-01T05:12:47.931Z","comments":true,"path":"linux/linux_redistinct/","link":"","permalink":"https://tlylft.github.io/linux/linux_redistinct/","excerpt":"","text":"Linux的3种重定向0:表示标准输入1:标准输出,在一般使用时，默认的是标准输出2:标准错误信息输出 只输出错误信息到日志文件nohup ./program &gt;/dev/null 2&gt;log &amp;什么信息也不要nohup ./program &gt;/dev/null 2&gt;&amp;1 &amp;知识补充，关于Linux的重定向 可以用来指定需要重定向的标准输入或输出。例如，将某个程序的错误信息输出到log文件 中：./program 2&gt;log。这样标准输出还是在屏幕上，但是错误信息会输出到log文件中。另外，也可 以实现0，1，2之间的重定向。2&gt;&amp;1：将错误信息重定向到标准输出。关于/dev/null文件Linux下还有一个特殊的文件/dev/null，它就像一个无底洞，所有重定向到它的信息都会消失得无影 无踪。这一点非常有用，当我们不需要回显程序的所有信息时，就可以将输出重定向到/dev/null。","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"linux centos7 磁盘扩容","slug":"linux/linux_disk","date":"2021-02-01T04:36:26.000Z","updated":"2021-02-01T04:44:11.118Z","comments":true,"path":"linux/linux_disk/","link":"","permalink":"https://tlylft.github.io/linux/linux_disk/","excerpt":"","text":"查看12345678910[root@NLP-Centos ~]# df -h文件系统 容量 已用 可用 已用% 挂载点devtmpfs 56G 0 56G 0% &#x2F;devtmpfs 56G 0 56G 0% &#x2F;dev&#x2F;shmtmpfs 56G 9.1M 56G 1% &#x2F;runtmpfs 56G 0 56G 0% &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;dev&#x2F;sda2 30G 3.8G 26G 13% &#x2F;&#x2F;dev&#x2F;sda1 497M 92M 406M 19% &#x2F;boot&#x2F;dev&#x2F;sdb1 725G 73M 688G 1% &#x2F;mnt&#x2F;resourcetmpfs 12G 8.0K 12G 1% &#x2F;run&#x2F;user&#x2F;1000 挂载盘扩容https://docs.azure.cn/zh-cn/articles/compute/aog-virtual-machines-qa-linux-root-file-system-extensionhttps://blog.csdn.net/qq825545356/article/details/93619434 打开分区表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495[root@NLP-Centos ~]# fdisk &#x2F;dev&#x2F;sdaThe device presents a logical sector size that is smaller thanthe physical sector size. Aligning to a physical sector (or optimalI&#x2F;O) size boundary is recommended, or performance may be impacted.欢迎使用 fdisk (util-linux 2.23.2)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。命令(输入 m 获取帮助)：m命令操作 a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition&#39;s system id u change display&#x2F;entry units v verify the partition table w write table to disk and exit x extra functionality (experts only)命令(输入 m 获取帮助)：p磁盘 &#x2F;dev&#x2F;sda：214.7 GB, 214748364800 字节，419430400 个扇区Units &#x3D; 扇区 of 1 * 512 &#x3D; 512 bytes扇区大小(逻辑&#x2F;物理)：512 字节 &#x2F; 4096 字节I&#x2F;O 大小(最小&#x2F;最佳)：4096 字节 &#x2F; 4096 字节磁盘标签类型：dos磁盘标识符：0x000c35bb 设备 Boot Start End Blocks Id System&#x2F;dev&#x2F;sda1 * 2048 1026047 512000 83 Linux&#x2F;dev&#x2F;sda2 1026048 62914559 30944256 83 Linux命令(输入 m 获取帮助)：d分区号 (1,2，默认 2)：2分区 2 已删除命令(输入 m 获取帮助)：p磁盘 &#x2F;dev&#x2F;sda：214.7 GB, 214748364800 字节，419430400 个扇区Units &#x3D; 扇区 of 1 * 512 &#x3D; 512 bytes扇区大小(逻辑&#x2F;物理)：512 字节 &#x2F; 4096 字节I&#x2F;O 大小(最小&#x2F;最佳)：4096 字节 &#x2F; 4096 字节磁盘标签类型：dos磁盘标识符：0x000c35bb 设备 Boot Start End Blocks Id System&#x2F;dev&#x2F;sda1 * 2048 1026047 512000 83 Linux命令(输入 m 获取帮助)：nPartition type: p primary (1 primary, 0 extended, 3 free) e extendedSelect (default p): p分区号 (2-4，默认 2)：2起始 扇区 (1026048-419430399，默认为 1026048)：将使用默认值 1026048Last 扇区, +扇区 or +size&#123;K,M,G&#125; (1026048-419430399，默认为 419430399)：将使用默认值 419430399分区 2 已设置为 Linux 类型，大小设为 199.5 GiB命令(输入 m 获取帮助)：p磁盘 &#x2F;dev&#x2F;sda：214.7 GB, 214748364800 字节，419430400 个扇区Units &#x3D; 扇区 of 1 * 512 &#x3D; 512 bytes扇区大小(逻辑&#x2F;物理)：512 字节 &#x2F; 4096 字节I&#x2F;O 大小(最小&#x2F;最佳)：4096 字节 &#x2F; 4096 字节磁盘标签类型：dos磁盘标识符：0x000c35bb 设备 Boot Start End Blocks Id System&#x2F;dev&#x2F;sda1 * 2048 1026047 512000 83 Linux&#x2F;dev&#x2F;sda2 1026048 419430399 209202176 83 Linux命令(输入 m 获取帮助)：wrThe partition table has been altered!Calling ioctl() to re-read partition table.WARNING: Re-reading the partition table failed with error 16: 设备或资源忙.The kernel still uses the old table. The new table will be used atthe next reboot or after you run partprobe(8) or kpartx(8)正在同步磁盘。 重启后还没有改变，需要修改根文件系统的大小。123456789101112131415161718192021[nlpadmin@NLP-Centos ~]$ sudo xfs_growfs &#x2F;dev&#x2F;sda2meta-data&#x3D;&#x2F;dev&#x2F;sda2 isize&#x3D;512 agcount&#x3D;4, agsize&#x3D;1934016 blks &#x3D; sectsz&#x3D;512 attr&#x3D;2, projid32bit&#x3D;1 &#x3D; crc&#x3D;1 finobt&#x3D;0 spinodes&#x3D;0data &#x3D; bsize&#x3D;4096 blocks&#x3D;7736064, imaxpct&#x3D;25 &#x3D; sunit&#x3D;0 swidth&#x3D;0 blksnaming &#x3D;version 2 bsize&#x3D;4096 ascii-ci&#x3D;0 ftype&#x3D;1log &#x3D;internal bsize&#x3D;4096 blocks&#x3D;3777, version&#x3D;2 &#x3D; sectsz&#x3D;512 sunit&#x3D;0 blks, lazy-count&#x3D;1realtime &#x3D;none extsz&#x3D;4096 blocks&#x3D;0, rtextents&#x3D;0data blocks changed from 7736064 to 52300544[nlpadmin@NLP-Centos ~]$ df -Th文件系统 类型 容量 已用 可用 已用% 挂载点devtmpfs devtmpfs 56G 0 56G 0% &#x2F;devtmpfs tmpfs 56G 0 56G 0% &#x2F;dev&#x2F;shmtmpfs tmpfs 56G 9.0M 56G 1% &#x2F;runtmpfs tmpfs 56G 0 56G 0% &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;dev&#x2F;sda2 xfs 200G 3.8G 196G 2% &#x2F;&#x2F;dev&#x2F;sda1 xfs 497M 92M 406M 19% &#x2F;boot&#x2F;dev&#x2F;sdb1 ext4 725G 73M 688G 1% &#x2F;mnt&#x2F;resourcetmpfs tmpfs 12G 0 12G 0% &#x2F;run&#x2F;user&#x2F;1000","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"centos7 xfce xrdp远程桌面","slug":"linux/centos7_desktop","date":"2021-01-27T03:02:49.000Z","updated":"2021-06-11T03:00:10.570Z","comments":true,"path":"linux/centos7_desktop/","link":"","permalink":"https://tlylft.github.io/linux/centos7_desktop/","excerpt":"","text":"设置开启远程桌面xfcehttps://www.cnblogs.com/bhoold/p/12266499.html 12345678910111213141516171819202122232425262728293031323334353637383940&#x2F;&#x2F; 安装桌面协议yum groupinstall &quot;X Window system&quot;&#x2F;&#x2F; 安装包含xfce的yum源yum install epel-release&#x2F;&#x2F; 安装xfce桌面yum groupinstall xfce&#x2F;&#x2F; 进入图形模式(如果是远程连接无效果)systemctl isolate graphical.target&#x2F;&#x2F; 安装基本字体(安装一个即可)yum install cjkuni-ukai-fonts &#x2F;&#x2F;楷体&#x2F;&#x2F; 安装输入法yum install fcitx*yum install im-chooser&#x2F;&#x2F; 安装浏览器yum install firefoxyum install https:&#x2F;&#x2F;dl.google.com&#x2F;linux&#x2F;direct&#x2F;google-chrome-stable_current_x86_64.rpm &#x2F;&#x2F;必须用yum安装rpm才不会出现以来问题&#x2F;&#x2F; 开启桌面远程连接服务vi ~&#x2F;.Xclients &#x2F;&#x2F; 编辑远程桌面配置文件(用户主目录有这个文件远程连接才不会黑屏闪退)#!&#x2F;bin&#x2F;bashXFCE&#x3D;&quot;$(which xfce4-session 2&gt;&#x2F;dev&#x2F;null)&quot;exec &quot;$XFCE&quot;chmod +x ~&#x2F;.Xclients &#x2F;&#x2F; 修改属性yum install -y xrdp tigervnc tigervnc-server &#x2F;&#x2F; 安装服务systemctl start xrdp &#x2F;&#x2F; 启动服务systemctl enable xrdp &#x2F;&#x2F; 开机启动systemctl status xrdp.service &#x2F;&#x2F; 查看服务状态netstat -antup|grep xrdp &#x2F;&#x2F; 查看服务端口firewall-cmd --permanent --zone&#x3D;public --add-port&#x3D;3389&#x2F;tcp &#x2F;&#x2F; 防火墙规则firewall-cmd --reload &#x2F;&#x2F; 重载规则chcon -t bin_t &#x2F;usr&#x2F;sbin&#x2F;xrdp &#x2F;&#x2F; SELinux放行chcon -t bin_t &#x2F;usr&#x2F;sbin&#x2F;xrdp-sesman &#x2F;&#x2F; SELinux放行 异常问题 连接时报错Failed to connect to socket /tmp/dbus-xxxxxxx: Connection refused 原因：Anaconda kills dbus session login manager on opensuse leap 42.3https://groups.google.com/a/continuum.io/forum/#!msg/anaconda/ZB8DoK0tY70/cUdp8hXdAAAJ看到其中提到Anaconda在./bashrc里面启动，毁掉dbus，导致用户无法重新登录 解决方案：开机启动是conda自动启动命令和dbus冲突,把anaconda的变量和启动删掉 vi ~/.bashrc12# added by Anaconda3 installerexport PATH&#x3D;&quot;&#x2F;user&#x2F; If you use anaconda, you may try this way: conda uninstall dbus restart vnc and login in again.1234I had the same issue. Removing Anaconda &#39;dbus&#39; solved it!!!哇咔咔，真的解决了。local&#x2F;anaconda3&#x2F;bin:$PATH&quot;#. &#x2F;user&#x2F;local&#x2F;anaconda3&#x2F;etc&#x2F;profile.d&#x2F;conda.sh#conda activate执行source ~/.bashrc之后重启服务器，vnc终于可以重新登录了 发现还是不行，查到一个问题https://github.com/TigerVNC/tigervnc/issues/592 12345If you use anaconda, you may try this way:conda uninstall dbusrestart vnc and login in again. I had the same issue. Removing Anaconda ‘dbus’ solved it!!!哇咔咔，真的解决了。","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"云主机搭建jupyter","slug":"linux/linux_jupyter","date":"2021-01-27T02:08:35.000Z","updated":"2021-02-02T05:19:16.038Z","comments":true,"path":"linux/linux_jupyter/","link":"","permalink":"https://tlylft.github.io/linux/linux_jupyter/","excerpt":"","text":"https://blog.csdn.net/qq_23845067/article/details/80474003 安装anaconda python运行，设置密码，获取秘钥 1234567#导入设定密码模块from notebook.auth import passwd# 生成密码passwd()#输入密码，并且验证输入密码#输入两次之后，会生成一个加密字符串，将其复制下来#退出python环境，ctrl+d 生成配置文件,修改配置 12jupyter notebook --generate-configvi &#x2F;root&#x2F;.jupyter&#x2F;jupyter_notebook_config.py 12345678910# 设定ip访问，允许任意ip访问c.NotebookApp.ip &#x3D; ‘*’# 不打开浏览器c.NotebookApp.open_browser &#x3D; False# 用于访问的端口，设定一个不用的端口即可，这里设置为7000c.NotebookApp.port &#x3D; 8888# 设置登录密码， 将刚刚复制的秘钥内容替换此处的xxxc.NotebookApp.password &#x3D; u&#39;sha1:bcd259ccf...&lt;your hashed password here&gt;&#39;# 配置项目文件夹，存储jupyter note和其他文件c.NotebookApp.notebook_dir &#x3D; u’jupyter’ 启动服务nohup jupyter notebook —allow-root 2&gt;/data/logs/jupyter.nohup &amp; 开机自动启动 123root: vi &#x2F;etc&#x2F;rc.d&#x2F;rc.local添加安装python环境的用户启动服务命令：su - nlpadmin -c &quot;ah &#x2F;data&#x2F;software&#x2F;cmd&#x2F;jupyter_startup.sh&quot;","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"分词工具对比","slug":"NLP/segment/seg_tools","date":"2021-01-26T05:54:18.000Z","updated":"2021-06-11T03:13:07.248Z","comments":true,"path":"NLP/segment/seg_tools/","link":"","permalink":"https://tlylft.github.io/NLP/segment/seg_tools/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/66495302 snownlphttps://github.com/isnowfy/snownlphttps://zhuanlan.zhihu.com/p/101493588 hanlpgithub地址安装12pip install hanlp_restful #轻量级调接口pip install hanlp&#x3D;&#x3D;2.1.0a48 使用1234567import hanlpHanLP &#x3D; hanlp.load(hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH) # 世界最大中文语料库text &#x3D; [&#39;2021年HanLPv2.1为生产环境带来次世代最先进的多语种NLP技术。&#39;, &#39;阿婆主来到北京立方庭参观自然语义科技公司。&#39;]# 默认GPUHanLP(text)# CPUHanLP(text, devices&#x3D;[])","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"segment","slug":"NLP/segment","permalink":"https://tlylft.github.io/categories/NLP/segment/"}],"tags":[{"name":"nlp","slug":"nlp","permalink":"https://tlylft.github.io/tags/nlp/"},{"name":"segment","slug":"segment","permalink":"https://tlylft.github.io/tags/segment/"}]},{"title":"python唯一请求码生成","slug":"python/python/unique_id","date":"2021-01-26T01:39:55.000Z","updated":"2021-01-26T01:43:29.182Z","comments":true,"path":"python/python/unique_id/","link":"","permalink":"https://tlylft.github.io/python/python/unique_id/","excerpt":"","text":"python唯一请求码生成https://www.cnblogs.com/standby/p/7021943.html hashlib+time12345678910111213import time, hashlibdef create_id(): m &#x3D; hashlib.md5(str(time.perf_counter()).encode(&#39;utf-8&#39;)) return m.hexdigest()if __name__ &#x3D;&#x3D; &#39;__main__&#39;: print(type(create_id())) print(create_id()) print(create_id()) print(create_id())","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[]},{"title":"【读书笔记】那些怪诞又实用的日常心理学","slug":"reading/The_weird_and_practical_psychology","date":"2021-01-22T06:27:48.000Z","updated":"2023-08-10T12:04:23.041Z","comments":true,"path":"reading/The_weird_and_practical_psychology/","link":"","permalink":"https://tlylft.github.io/reading/The_weird_and_practical_psychology/","excerpt":"","text":"实验1：看不见的大猩猩https://search.bilibili.com/all?keyword=%E7%9C%8B%E4%B8%8D%E8%A7%81%E7%9A%84%E5%A4%A7%E7%8C%A9%E7%8C%A9%E5%AE%9E%E9%AA%8C描述：几个大学生穿着白色或黑色的衣服在传球，一开始你会被告知“一会会问你穿黑色衣服的人互相传了几次球”然后你就会仔细的看着穿黑衣服的人传球，等到结束后会问你传球次数以及有没有看到什么奇怪的东西，传球次数只要认真看了基本都能答对，但是有相当一部分人表示自己没看到奇怪的东西，而一部分人表示自己看到了一只大猩猩走了过去。说明：简单的来说，就是所谓我们的视觉盲区。你所看到的，只是你想看到的世界。你所经历的事情和环境，也许也错过了很多信息。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"pycharm配置","slug":"tools/pycharm","date":"2021-01-21T03:09:13.000Z","updated":"2022-05-12T00:34:34.033Z","comments":true,"path":"tools/pycharm/","link":"","permalink":"https://tlylft.github.io/tools/pycharm/","excerpt":"","text":"文件头设置docker连接Flask + Gunicorn + Docker部署新手教程 远程连接虚拟环境debug卡死setting -&gt; Build.execution,Deployment -&gt; Python Debugger设置勾选 Attach to subprocess automatically while debugging gebent compatible两个选项","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"},{"name":"pycharm","slug":"pycharm","permalink":"https://tlylft.github.io/tags/pycharm/"}]},{"title":"flask 部署(gunicorn, docker, nginx)","slug":"python/Flask/flask_docker_deploy","date":"2021-01-21T02:36:07.000Z","updated":"2021-06-11T03:28:16.820Z","comments":true,"path":"python/Flask/flask_docker_deploy/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_docker_deploy/","excerpt":"","text":"flask123项目拷贝后，直接运行python main.pynohup python main.py &gt;nohup_path.txt &amp; flask + dockerDockerfile view1234567FROM python:3.7WORKDIR &#x2F;project&#x2F;nlp_platformCOPY . .RUN mkdir &#x2F;logs; pip install -r requirements.txt -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simpleCMD [&quot;python&quot;, &quot;run.py&quot;]注意： flask中设置host为0.0.0.0才能被外部调用，127.0.0.1只能在docker内被主机调用，不能产生网络端口映射12if __name__ &#x3D;&#x3D; &#39;__main__&#39;: app.run(host&#x3D;&#39;0.0.0.0&#39;,port&#x3D;8000) docker 镜像构建12345docker build -t 10.37.144.182:8002&#x2F;nlp&#x2F;nlp_platform:v0.1 .docker push 10.37.144.182:8002&#x2F;nlp&#x2F;nlp_platform:v0.1docker run --name platform -dit -p 8004:8000 nlp_platform:v0.1 flask + gunicorn + docker参考：用Docker部署Flask应用什么是gunicorn?Gunicorn介绍简单说：做了多进程管理在管理 worker 上，使用了 pre-fork 模型，即一个 master 进程管理多个 worker 进程，所有请求和响应均由 Worker 处理。Master 进程是一个简单的 loop, 监听 worker 不同进程信号并且作出响应。比如接受到 TTIN 提升 worker 数量，TTOU 降低运行 Worker 数量。如果 worker 挂了，发出 CHLD, 则重启失败的 worker, 同步的 Worker 一次处理一个请求。gunicorn的应用gunicorn 配置参数详解在windows环境中不能运行！！！！！！ 配置gunicorn文件[gunicorn_conf.py]简单的：123workers &#x3D; 5 # 定义同时开启的处理请求的进程数量，根据网站流量适当调整，建议workers 数量是 (2*CPU) + 1worker_class &#x3D; &quot;gevent&quot; # 采用gevent库，支持异步处理请求，提高吞吐量bind &#x3D; &quot;0.0.0.0:8888&quot; # 监听IP放宽，以便于Docker之间、Docker和宿主机之间的通信 复杂的12345678910111213141516171819202122232425262728293031323334import multiprocessing# !监听地址和端口bind &#x3D; &#39;0.0.0.0:8888&#39;# !worker进程的数量。建议值2-4 x $(NUM_CORES)， 缺省为1。workers &#x3D; multiprocessing.cpu_count() * 2 + 1# 每个进程的开启线程# threads &#x3D; multiprocessing.cpu_count() * 2# !服务器中在pending状态的最大连接数，即client处于waiting的数目。超过这个数目， client连接会得到一个error。建议值64-2048backlog &#x3D; 2048# !worker进程的工作方式。 有 sync, eventlet, gevent, tornado, gthread, 缺省值sync。worker_class &#x3D; &quot;gevent&quot;# 客户端最大同时连接数。只适用于eventlet， gevent工作方式。# worker_connections &#x3D; 1000# daemon &#x3D; False# debug &#x3D; True#进程名和日志proc_name &#x3D; &#39;gunicorn.pid&#39;pidfile &#x3D; &quot;log&#x2F;gunicorn.pid&quot;accesslog &#x3D; &quot;log&#x2F;gunicorn_access.log&quot;# access_log_format &#x3D; &#39;%(h)s %(t)s %(U)s %(q)s&#39;## 这个地方是控制台输出的报错路径，控制台找不到报错信息看这里！！！看这里！！errorlog &#x3D; &quot;log&#x2F;gunicorn_error.log&quot;timeout &#x3D; 600 ## 指gunicorn判定启动进程timeout的时间！！ 在web服务启动初始化时间比较长时，一定要设置，在设定时间内服务未启动成功，gunicorn判定为超时，会创建新进程debug&#x3D;Falsecapture_output &#x3D; True 使用gunicorn运行, name为flask主程序的文件名，app为文件中的flask app变量名1gunicorn name:app -c .&#x2F;gunicorn.conf.py docker部署12345678## DockerfileFROM python:3.7WORKDIR &#x2F;project&#x2F;nlp_platformCOPY . .RUN mkdir &#x2F;logs; pip install -r requirements.txt -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simpleCMD [&quot;gunicorn&quot;, &quot;run:app&quot;, &quot;-c&quot;, &quot;.&#x2F;gunicorn_conf.py&quot;] docker 镜像构建和使用12345docker build -t 10.37.144.182:8002&#x2F;nlp&#x2F;nlp_platform:v0.2 .docker push 10.37.144.182:8002&#x2F;nlp&#x2F;nlp_platform:v0.2docker run --name platform -dit -p 8004:8888 nlp_platform:v0.2 flask +gunicorn+ nginx+docker基于docker部署的 flask +gunicorn+ nginxhttps://github.com/danriti/nginx-gunicorn-flask Nginx_conf1234567server &#123; listen 80; server_name &lt;your dns&gt;;location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;0.0.0.0:5000; &#125;&#125; https://zhuanlan.zhihu.com/p/78432719?hmsr=toutiao.io","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"AI开发平台","slug":"NLP/ai_platform","date":"2021-01-15T07:51:14.000Z","updated":"2021-06-11T03:15:36.467Z","comments":true,"path":"NLP/ai_platform/","link":"","permalink":"https://tlylft.github.io/NLP/ai_platform/","excerpt":"","text":"百度开发平台https://console.bce.baidu.com/ai/?_=1550569312984&amp;locale=zh-cn#/ai/face/overview/index SDK文档 API鉴权认证","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"linux ftp 搭建使用","slug":"tools/ftp","date":"2021-01-11T01:07:10.000Z","updated":"2021-06-11T04:20:58.611Z","comments":true,"path":"tools/ftp/","link":"","permalink":"https://tlylft.github.io/tools/ftp/","excerpt":"","text":"https://www.hangge.com/blog/cache/detail_2449.html主动模式和被动模式：https://blog.csdn.net/newborn2012/article/details/15812821/https://www.imooc.com/article/15136 拉取镜像docker pull fauria/vsftpd 启动服务 /var/ftp:/home/vsftpd：映射 docker 容器 ftp 文件根目录（冒号前面是宿主机的目录，建议宿主机使用 /var 这样公共权限文件夹，如果使用类似 /home 这样的目录可能会造成客户端无法连接上服务器问题）-p：映射 docker 端口（冒号前面是宿主机的端口）-e FTP_USER=test -e FTP_PASS=test ：设置默认的用户名密码（都为 test）PASV_ADDRESS：宿主机 ip，当需要使用被动模式时必须设置。PASV_MIN_PORT~ PASV_MAX_PORT：给客服端提供下载服务随机端口号范围，默认 21100-21110，与前面的 docker 端口映射设置成一样。 123456docker run -d -v &#x2F;data&#x2F;kubeflow&#x2F;data&#x2F;kubeflow-nlp-pvc-pvc-b1c49f7e-760c-4b9b-a891-8a5494eec53a:&#x2F;home&#x2F;vsftpd \\-p 8000:20 -p 8001:21 -p 21100-21110:21100-21110 \\-e FTP_USER&#x3D;test -e FTP_PASS&#x3D;test \\-e PASV_ADDRESS&#x3D;10.37.144.183 \\-e PASV_MIN_PORT&#x3D;21100 -e PASV_MAX_PORT&#x3D;21110 \\--name vsftpd --restart&#x3D;always fauria&#x2F;vsftpd ftp://test:test@10.37.144.183:8001/model.joblib","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"},{"name":"ftp","slug":"tools/ftp","permalink":"https://tlylft.github.io/categories/tools/ftp/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"}]},{"title":"文本分类","slug":"NLP/classification/text_clas","date":"2021-01-06T02:35:07.000Z","updated":"2021-11-17T05:41:42.942Z","comments":true,"path":"NLP/classification/text_clas/","link":"","permalink":"https://tlylft.github.io/NLP/classification/text_clas/","excerpt":"","text":"中文文本分类，TextCNN，TextRNN，FastText，TextRCNN，BiLSTM_Attention, DPCNN, Transformer, 基于pytorch，开箱即用。https://github.com/649453932/Chinese-Text-Classification-Pytorch UNKNOWN类别问题： 训练时加一个不匹配的类别标签 二分类可以把 label做成-1， 0， 1三种 置信度足够高于0.7 0.8 才算匹配 前一步加匹配/不匹配分类器，或者正则筛选","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"python序列化存储 pickle, joblib, json","slug":"python/python/python_storage","date":"2021-01-05T02:33:10.000Z","updated":"2021-02-20T06:20:54.222Z","comments":true,"path":"python/python/python_storage/","link":"","permalink":"https://tlylft.github.io/python/python/python_storage/","excerpt":"","text":"pickle模块和joblib模块浅析 pickle模块详解从零开始python反序列化攻击：pickle原理解析 &amp; 不用reduce的RCE姿势 区别json 和 pickle 更多应用在字符串和字典格式的转换中。joblib 只能应用于磁盘存储。joblib更适合大数据量的模型，比pickle更加高效，但是joblib只能将对象存储在磁盘文件中，不能保存为字符串。 示例pickle123456789101112131415#对象保存为一个字符串&gt;&gt;&gt; import pickle&gt;&gt;&gt; a1 &#x3D; (&quot;pickle&quot;,123,[4,5,6],&#123;&#39;A&#39;:1,&#39;B&#39;:2&#125;)&gt;&gt;&gt; p1 &#x3D; pickle.dumps(a1)&gt;&gt;&gt; a2 &#x3D; pickle.loads(p1)# 高效 的二进制来存储&gt;&gt;&gt; import pickle&gt;&gt;&gt; a1 &#x3D; (&quot;pickle&quot;,123,[4,5,6],&#123;&#39;A&#39;:1,&#39;B&#39;:2&#125;)&gt;&gt;&gt; p1 &#x3D; pickle.dumps(a1,True)&gt;&gt;&gt; a2 &#x3D; pickle.loads(p1)# 多个对象保存在磁盘文件中：with open(train_out_path, &#39;wb&#39;) as train_file: dump((x_train, y_train), train_file) joblib123from joblib import dump, loaddump((x_train, y_train), train_out_path)x_train, y_train &#x3D; load(train_data_path)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"文本标注工具doccano","slug":"NLP/label/doccano","date":"2020-12-31T02:59:36.000Z","updated":"2021-01-04T05:40:15.068Z","comments":true,"path":"NLP/label/doccano/","link":"","permalink":"https://tlylft.github.io/NLP/label/doccano/","excerpt":"","text":"文本标注工具doccano安装12345docker run -d --rm --name doccano \\ -e &quot;ADMIN_USERNAME&#x3D;admin&quot; \\ -e &quot;ADMIN_EMAIL&#x3D;admin@example.com&quot; \\ -e &quot;ADMIN_PASSWORD&#x3D;password&quot; \\ -p 8003:8000 chakkiworks&#x2F;doccano http://10.37.144.182:8003/ doccano 用户名：admin 密码：password","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"label","slug":"NLP/label","permalink":"https://tlylft.github.io/categories/NLP/label/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"label","slug":"label","permalink":"https://tlylft.github.io/tags/label/"},{"name":"doccano","slug":"doccano","permalink":"https://tlylft.github.io/tags/doccano/"}]},{"title":"kubernetes 安装","slug":"tools/kubernetes","date":"2020-12-30T01:31:22.000Z","updated":"2021-01-11T09:58:08.987Z","comments":true,"path":"tools/kubernetes/","link":"","permalink":"https://tlylft.github.io/tools/kubernetes/","excerpt":"","text":"install 安装docker依赖Docker CE， 我安装的18.06.1-ce 安装kubectl 123&gt; kubectl versionClient Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;20&quot;, GitVersion:&quot;v1.20.0&quot;, GitCommit:&quot;af46c47ce925f4c4ad5cc8d1fca46c7b77d13b38&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-12-08T17:59:43Z&quot;, GoVersion:&quot;go1.15.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux&#x2F;amd64&quot;&#125;Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;17&quot;, GitVersion:&quot;v1.17.14&quot;, GitCommit:&quot;f238f5142728be4033c37aa0ad69bf806090beae&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2020-11-11T13:03:54Z&quot;, GoVersion:&quot;go1.13.15&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux&#x2F;amd64&quot;&#125; 文档中文文档 命令12345kubectl get knative -n kubeflowkubectl get inferenceservice -n kubeflowkubectl get ksvc -n kubeflowkubectl get revision -n kubeflow kubectl get pod -l model&#x3D;sklearn-from-uri -n kubeflow","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"},{"name":"k8s","slug":"tools/k8s","permalink":"https://tlylft.github.io/categories/tools/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://tlylft.github.io/tags/k8s/"}]},{"title":"docker打包python程序","slug":"tools/docker_python","date":"2020-12-23T11:08:57.000Z","updated":"2020-12-23T11:28:04.713Z","comments":true,"path":"tools/docker_python/","link":"","permalink":"https://tlylft.github.io/tools/docker_python/","excerpt":"","text":"程序打包https://blog.csdn.net/weixin_41907511/article/details/85337505 目录挂载https://blog.csdn.net/magerguo/article/details/72514813","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"},{"name":"docker","slug":"docker","permalink":"https://tlylft.github.io/tags/docker/"}]},{"title":"python序列化 处理json格式和文件","slug":"python/python/python_json","date":"2020-12-23T10:28:26.000Z","updated":"2020-12-23T11:06:10.780Z","comments":true,"path":"python/python/python_json/","link":"","permalink":"https://tlylft.github.io/python/python/python_json/","excerpt":"","text":"https://www.cnblogs.com/linwow/p/10693781.html 1. 几种方式的介绍 我们把对象(变量)从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。 为什么要序列化？ 持久保存状态在断电或重启程序之前将程序当前内存中所有的数据都保存下来（保存到文件中），以便于下次程序执行能够从文件中载入之前的数据，然后继续执行，这就是序列化。 跨平台数据交互序列化之后，不仅可以把序列化后的内容写入磁盘，还可以通过网络传输到别的机器上，如果收发的双方约定好实用一种序列化的格式，那么便打破了平台/语言差异化带来的限制，实现了跨平台数据交互。 在python中，有专门处理json格式的模块—— json , joblib 和 pickle模块 json 和 pickle 区别json模块和pickle模块都有 dumps、dump、loads、load四种方法，而且用法一样。不一样的是json模块序列化出来的是通用格式，其它编程语言都认识，就是普通的字符串，而picle模块序列化出来的只有python可以认识，其他编程语言不认识的，表现为乱码 2. 使用2.1. json 包的使用https://www.cnblogs.com/chen55555/articles/10246730.html 2.1.1. 基本操作12import json dict &#x3D; &#123;&#39;a&#39;:&#39;1111&#39;,&#39;b&#39;:&#39;2222&#39;,&#39;c&#39;:&#39;3333&#39;,&#39;d&#39;:&#39;4444&#39;&#125; json.dumps() 将字典类型转化成字符串类型12# ensure_ascii&#x3D;False 显示中文str &#x3D; json.dumps(dict, ensure_ascii&#x3D;False)json.loads()将字符串类型转化成字典类型1json_dict &#x3D; json.loads(str)json.dump()用于将dict类型的数据转成str，并写入到json文件中。12345json.dump(dict_name, open(filename, &quot;w&quot;))# 或with open(filename, &quot;w&quot;) as f: f.write(dict_name) f.close()json.load()用于从json文件中读取数据。得到字典类型1jsObj &#x3D; json.load(open(filename)) 读写的文件中存在多个json12345with open(file,encoding&#x3D;&#39;utf-8&#39;) as f: for line in f.readlines(): # 按行加载 line_json &#x3D; json.loads(line) text &#x3D; line_json[&#39;text&#39;] jsonlines 包的使用说是可以读写多行，待验证https://blog.csdn.net/weixin_43420032/article/details/88547515https://blog.csdn.net/weixin_38604274/article/details/105158918","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"python ArgumentParser","slug":"python/python/python_args","date":"2020-12-23T01:50:38.000Z","updated":"2021-01-05T07:34:26.420Z","comments":true,"path":"python/python/python_args/","link":"","permalink":"https://tlylft.github.io/python/python/python_args/","excerpt":"","text":"Python 关于argparse子命令subparsers()方法 1234567891011121314import argparseif __name__ &#x3D;&#x3D; &#39;__main__&#39;: parser &#x3D; argparse.ArgumentParser(description&#x3D;&#39;data vectorizer using sklearn&#39;) parser.add_argument(&#39;-b&#39;, &#39;--base_path&#39;, help&#x3D;&#39;job base directory&#39;, default&#x3D;&#39;&#x2F;data&#x2F;task_1&#x2F;job_001&#x2F;&#39;) parser.add_argument(&#39;-test_size&#39;, &#39;--test_size&#39;,type&#x3D;float, help&#x3D;&#39;test corpus rate&#39;, default&#x3D;0.3) args &#x3D; parser.parse_args() logger.info(&#39;input args: &#123;&#125;&#39;.format(args)) logger.info(&#39;parsing arguments...&#39;) base_path &#x3D; args.base_path 每个参数解释如下:name or flags - 选项字符串的名字或者列表，例如 foo 或者 -f, —foo。action - 命令行遇到参数时的动作，默认值是 store。store_const，表示赋值为const；append，将遇到的值存储成列表，也就是如果参数重复则会保存多个值;append_const，将参数规范中定义的一个值保存到一个列表；count，存储遇到的次数；此外，也可以继承 argparse.Action 自定义参数解析；nargs - 应该读取的命令行参数个数，可以是具体的数字，或者是?号，当不指定值时对于 Positional argument 使用 default，对于 Optional argument 使用 const；或者是 * 号，表示 0 或多个参数；或者是 + 号表示 1 或多个参数。const - action 和 nargs 所需要的常量值。default - 不指定参数时的默认值。type - 命令行参数应该被转换成的类型。choices - 参数可允许的值的一个容器。required - 可选参数是否可以省略 (仅针对可选参数)。help - 参数的帮助信息，当指定为 argparse.SUPPRESS 时表示不显示该参数的帮助信息.metavar - 在 usage 说明中的参数名称，对于必选参数默认就是参数名称，对于可选参数默认是全大写的参数名称.dest - 解析后的参数名称，默认情况下，对于可选参数选取最长的名称，中划线转换为下划线.","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"rasa policy","slug":"chatbot/rasa_policy","date":"2020-12-21T05:29:23.000Z","updated":"2023-08-11T08:42:14.438Z","comments":true,"path":"chatbot/rasa_policy/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_policy/","excerpt":"","text":"RASA policy对话系统rasa - Policies rasa源代码阅读-探索memoization policy Fallback Policy (rasa1.x)","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"docker仓库搭建","slug":"tools/docker_warehouse","date":"2020-12-16T04:37:55.000Z","updated":"2021-06-11T04:22:11.245Z","comments":true,"path":"tools/docker_warehouse/","link":"","permalink":"https://tlylft.github.io/tools/docker_warehouse/","excerpt":"","text":"1. Registry镜像方式 https://www.cnblogs.com/gcgc/p/10489385.htmlhttps://blog.csdn.net/qq_40378034/article/details/90752212https://www.cnblogs.com/edisonchou/p/docker_registry_repository_setup_introduction.html 首先，下载Registry镜像并启动1docker pull registry 运行容器1docker run -d -v &#x2F;data&#x2F;registry&#x2F;images:&#x2F;var&#x2F;lib&#x2F;registry -p 8002:5000 --restart&#x3D;always --name xdp-registry registry Registry服务默认会将上传的镜像保存在容器的/var/lib/registry，我们将主机的data/registry/images目录挂载到该目录，即可实现将镜像保存到主机的data/registry/images目录了。将服务的5000端口映射到主机的8002端口 验证（1）浏览器访问http://ip:8002/v2，出现下面情况说明registry运行正常。（2）http://10.37.144.183:8002/v2/_catalog 这个可以看有什么镜像12$curl http:&#x2F;&#x2F;10.37.144.183:8002&#x2F;v2&#x2F;_catalog &#123;&quot;repositories&quot;:[&quot;nginx&quot;]&#125; (3) 查看taghttp://10.37.144.183:8002/v2/image_name/tags/list 上传镜像123docker imagesdocker tag nginx:latest 10.37.144.183:8002&#x2F;nginx:latestdocker push 10.37.144.183:8002&#x2F;nginx:latest 如果报错12The push refers to repository [10.37.144.183:8002&#x2F;nginx]Get https:&#x2F;&#x2F;10.37.144.183:8002&#x2F;v2&#x2F;: http: server gave HTTP response to HTTPS client 这是因为我们启动的registry服务不是安全可信赖的。这时需要修改客户端docker的配置文件/etc/docker/daemon.json,重启客户端docker123456789&#123; &quot;registry-mirrors&quot;: [ &quot;https:&#x2F;&#x2F;pee6w651.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;10.37.144.183:8002&quot;]&#125;## linux重启systemctl restart docker## windows重启docker-machine restart default push成功1234567The push refers to repository [10.37.144.183:8002&#x2F;nginx]4eaf0ea085df: Pushed2c7498eef94a: Pushed 7d2b207c2679:Pushed5c4e5adc71a8: Pushed 87c8a1d8f54f: Pushedlatest: digest: sha256:13e4551010728646aa7e1b1ac5313e04cf75d051fa441396832fcd6d600b5e71 size: 1362 下载镜像123docker pull localhost:5000&#x2F;镜像名:版本号例如docker pull localhost:5000&#x2F;nginx:latest 2. Harbor企业级仓库https://www.cnblogs.com/wdliu/p/10250385.html 2.1. 安装准备 下载harbor1.7.5 下载地址 安装docker-compose12yum install epel-release -yyum install docker-compose 2.2. 安装 解压1tar -xvf harbor-offline-installer-v1.2.2.tgz 修改配置harbor.cfg12hostname &#x3D; 10.1.210.33 # 仓库地址，主机IP或者域名harbor_admin_password &#x3D; Harbor12345 # 默认管理员密码 修改挂载目录 默认都在/data下1#vi docker-compose.yml 自签TLS证书 执行安装 12cd harbor.&#x2F;install.sh 查看安装组件1docker-compose ps 2.3. 修改对外端口 在harbor目录下1、修改docker-compose.yml文件映射为8002端口12345678910111213141516#vi docker-compose.ymlproxy: image: nginx:1.11.5 container_name: nginx restart: always volumes: - .&#x2F;common&#x2F;config&#x2F;nginx:&#x2F;etc&#x2F;nginx ports: - 8002:80 - 1143:443 depends_on: - mysql - registry - ui - log 修改common/templates/registry/config.yml文件加入8002端口：注意变量 $public_url:8002 有的版本是$ui_url:800212345678#vim common&#x2F;templates&#x2F;registry&#x2F;config.ymlauth: token: issuer: registry-token-issuer realm: $public_url:8002&#x2F;service&#x2F;token rootcertbundle: &#x2F;etc&#x2F;registry&#x2F;root.crt service: token-service 停止harbor，重新启动并生成配置文件：12#docker-compose stop# .&#x2F;install.sh 服务端添加信任主机 /etc/docker/daemon.json123456789&#123; &quot;registry-mirrors&quot;: [ &quot;https:&#x2F;&#x2F;pee6w651.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;10.37.144.183:8002&quot;]&#125;## linux重启systemctl restart docker## windows重启docker-machine restart default 2.4. 登陆验证12docker login -u admin -p **** 10.37.144.182:8002docker pull 10.37.144.182&#x2F;kubeflow&#x2F;nginx:latest 2.5. 上传镜像访问web 10.37.144.182:8002,在系统中新建项目kubeflow后，在服务端docker运行以下命令1234docker login -u admin -p Harbor12345 10.37.144.182:8002docker tag nginx:latest 10.37.144.182:8002&#x2F;kubeflow&#x2F;nginx:latestdocker push 10.37.144.182:8002&#x2F;kubeflow&#x2F;nginx:latestdocker logout 10.37.144.182:8002如果上传镜像到远程仓库，可能会有上传不上去的情况，这是因为网络传输无法传递大几G的docker层，可以考虑增加一些层数分层上传。 2.6. 下载镜像docker pull 10.37.144.182:8002/kubeflow/nginx:latest 3. 通过K8s编辑yaml文件下载Harbor仓库的镜像https://blog.csdn.net/weixin_48191138/article/details/110200692","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"},{"name":"docker","slug":"docker","permalink":"https://tlylft.github.io/tags/docker/"}]},{"title":"miniconda安装","slug":"python/env/miniconda","date":"2020-12-16T00:37:02.000Z","updated":"2021-06-11T03:27:12.105Z","comments":true,"path":"python/env/miniconda/","link":"","permalink":"https://tlylft.github.io/python/env/miniconda/","excerpt":"","text":"https://www.cnblogs.com/gaoqinglong/p/9748962.html Anaconda是一个发行包，里面集成打包了很多的软件包，使用conda包管理器来安装软件，比较方便，但是Anaconda软件包太大。Miniconda中只有Conda包管理器 安装下载安装包https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/或12# 在linux在使用以下命令下载minicondawget -c https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;miniconda&#x2F;Miniconda3-latest-Linux-x86_64.sh 安装miniconda1234# 安装刚刚下载的Miniconda，bash就是运行.sh文件的意思$bash Miniconda3-latest-Linux-x86_64.sh # 查看安装成功$conda --version 如果没有，增加环境变量12345678910vi &#x2F;root&#x2F;.bashrc或 当前用户环境变量vi ~&#x2F;.bashrc或 系统环境变量vi &#x2F;etc&#x2F;profile# 增加变量并保存export PATH&#x3D;&quot;&#x2F;data&#x2F;miniconda3&#x2F;bin:$PATH&quot;# 激活变量source &#x2F;root&#x2F;.bashrc 添加镜像源12345# 添加镜像conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;freeconda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forgeconda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;biocondaconda config --set show_channel_urls yes","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"anaconda","slug":"anaconda","permalink":"https://tlylft.github.io/tags/anaconda/"}]},{"title":"【autoML】kubeflow pipLine","slug":"machine_learning/kubeflow_pipline","date":"2020-12-10T03:13:03.000Z","updated":"2021-03-04T15:42:25.484Z","comments":true,"path":"machine_learning/kubeflow_pipline/","link":"","permalink":"https://tlylft.github.io/machine_learning/kubeflow_pipline/","excerpt":"","text":"1. 准备环境 kubeflow Kubernetes 动态PV使用 储备知识：nfs, pv, pvc 2. 分配动态pv共享空间常用命令：123456789# 创建pv pvc 或其他kube组件kubectl create -f xx.yaml [-n $namespace]# 查看pv pvckubectl get pv [-n $namespace]kubectl get pvc [-n $namespace]kubectl describe pvc $pvc_name [-n $namespace]# 删除kebectl delete pv $pvc_name [-n $namespace]kebectl delete pvc $pvc_name [-n $namespace]1. 创建一个持久化pv （如果k8s已经配置为动态分配pvc，则不需要这一步）123456789101112131415kubectl create -f pv.yaml -n $namespace# cat pv.yamlapiVersion: v1kind: PersistentVolumemetadata: name: nlp-piplinespec: capacity: storage: 20Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Recycle nfs: path: &#x2F;data&#x2F;kubeflow&#x2F;data&#x2F;nlp server: 10.37.144.1832. 创建一个pvc12345678910111213kubectl create -f pvc.yaml -n $namespace# cat pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: nlp-pvcspec: accessModes: - ReadWriteMany storageClassName: nfs-storageclass resources: requests: storage: 20Gi3. 查看我这里是设置的动态分配pvc1234567$ kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpvc-a71e2a30-097c-421c-87d2-685a5a4560e9 10Gi RWO Delete Bound anonymous&#x2F;workspace-test-gw kubeflow-nfs-storage 49m$ kubectl get pvc -n kubeflowNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEnlp-pvc Bound pvc-41492222-36c7-4321-87bc-90faf81c7ae8 20Gi RWX kubeflow-nfs-storage 40m 3. make pipline 设计拆分组件：首先对算法流程进行拆分，拆分粒度自己掌握 完成各组件的代码：流程组件的继承方式有两种：a)封装成docker服务, 使用镜像拉取方式串接流程 b)使用kubeflow的kfp dsl函数继承，提交pipline会自动打包镜像 上传kubeflow运行： a) 上传kubeflow pipline ui界面 b) 使用notebook c) 服务器命令运行 3.1. 镜像+配置文件+pipline ui官网例程 3.1.1. 创建可复用的组件program.py 123456789101112131415161718192021222324#!&#x2F;usr&#x2F;bin&#x2F;env python3import argparsefrom pathlib import Path# Function doing the actual work (Outputs first N lines from a text file)def do_work(input1_file, output1_file, param1): for x, line in enumerate(input1_file): if x &gt;&#x3D; param1: break _ &#x3D; output1_file.write(line)# Defining and parsing the command-line argumentsparser &#x3D; argparse.ArgumentParser(description&#x3D;&#39;My program description&#39;)parser.add_argument(&#39;--input1-path&#39;, type&#x3D;str, help&#x3D;&#39;Path of the local file containing the Input 1 data.&#39;) # Paths should be passed in, not hardcodedparser.add_argument(&#39;--param1&#39;, type&#x3D;int, default&#x3D;100, help&#x3D;&#39;Parameter 1.&#39;)parser.add_argument(&#39;--output1-path&#39;, type&#x3D;str, help&#x3D;&#39;Path of the local file where the Output 1 data should be written.&#39;) # Paths should be passed in, not hardcodedargs &#x3D; parser.parse_args()# Creating the directory where the output file will be created (the directory may or may not exist).Path(args.output1_path).parent.mkdir(parents&#x3D;True, exist_ok&#x3D;True)with open(args.input1_path, &#39;r&#39;) as input1_file: with open(args.output1_path, &#39;w&#39;) as output1_file: do_work(input1_file, output1_file, args.param1) 3.1.2. 创建组件docker镜像12345678910111213141516# dockerFileFROM python:3.7# pip installRUN pip install -r &#x2F;scripts&#x2F;requirements.txt -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple&#x2F;# upload codeCOPY .&#x2F;scripts &#x2F;scripts#COPY scripts&#x2F;seg_jieba.py &#x2F;scripts&#x2F;seg_jieba.py#COPY stopword.txt &#x2F;scripts&#x2F;stopword.txtWORKDIR &#x2F;scriptsVOLUME &#x2F;data# will be overwritten by kf pipeline#ENTRYPOINT [&quot;python&quot;, &quot;&#x2F;scripts&#x2F;seg_jieba.py&quot;]#CMD [&quot;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf&quot;] 12docker build -t gcr.io&#x2F;my-org&#x2F;my-image:latest .docker push &quot;$full_image_name&quot; 3.1.3. 创建piplinekfp方式https://www.kubeflow.org/docs/pipelines/sdk/python-function-components/ 写符合kfp规定的py文件demo1: cheating-contanerless无训练步骤的基础容器 123456789101112131415161718192021222324252627282930313233import kfpfrom kfp import dsl@dsl.pipeline(name&#x3D;&#39;my-pipeline&#39;)def pipeline(): op0 &#x3D; dsl.ContainerOp( name&#x3D;&quot;gen-numbers&quot;, image&#x3D;&#39;python:alpine3.6&#39;, command&#x3D;[&quot;sh&quot;, &quot;-c&quot;], arguments&#x3D;[ &#39;python -c &quot;import random; import json; import sys; json.dump([i for i in range(20, 26)], open(\\&#39;&#x2F;tmp&#x2F;out.json\\&#39;, \\&#39;w\\&#39;))&quot;&#39;], file_outputs&#x3D;&#123;&#39;out&#39;: &#39;&#x2F;tmp&#x2F;out.json&#39;&#125;, ) with dsl.ParallelFor(op0.output) as item: op1 &#x3D; dsl.ContainerOp( name&#x3D;&quot;my-item-print&quot;, image&#x3D;&quot;library&#x2F;bash:4.4.23&quot;, command&#x3D;[&quot;sh&quot;, &quot;-c&quot;], arguments&#x3D;[&quot;echo do output op1 item: %s&quot; % item], ) op_out &#x3D; dsl.ContainerOp( name&#x3D;&quot;total&quot;, image&#x3D;&quot;python:alpine3.6&quot;, command&#x3D;[&quot;sh&quot;, &quot;-c&quot;], arguments&#x3D;[&#39;echo output gen-numbers: %s &amp;&amp; python -c &quot;print(sum(%s))&quot;&#39; % (op0.output, op0.output)], )if __name__ &#x3D;&#x3D; &#39;__main__&#39;: kfp.compiler.Compiler().compile(pipeline, __file__ + &#39;.yaml&#39;) demo2: 使用镜像封装好的可复用组件，使用PVCdsl 使用pvc 123456# Create a new empty PVC, size is 150G:vol_new &#x3D; dsl.PipelineVolume(size&#x3D;&quot;150G&quot;)# Use an existing PVC, presumably already containing data:vol_existing &#x3D; dsl.PipelineVolume(pvc&#x3D;&quot;my-existing-data&quot;)# Clone an existing snapshot:vol_from_snap &#x3D; dsl.PipelineVolume(data_source&#x3D;&quot;snapshot1&quot;) 参数解释：pvc: An existing PVC already filled with data, to use as a Persistent Volume for this pipeline.size: The size of a new PVC to be created dynamically, as part of the pipeline.C.storage_class: The storage class to use for the dynamically created PVC.data_source: The name of an existing VolumeSnapshot K8s object from which to clone data for a new dynamically created PVC, or a reference to a dsl.PipelineVolumeSnapshot instance. 12345678910111213141516171819202122232425262728import kfpfrom kfp import dsl# 使用pvc# 1. 创建一个指定大小的pvc# vol_new &#x3D; dsl.PipelineVolume(size&#x3D;&quot;150G&quot;)# 2. 使用已经存在的PVC, presumably already containing data:# vol_existing &#x3D; dsl.PipelineVolume(pvc&#x3D;&quot;my-existing-data&quot;)# 3. 克隆一个PVC Clone an existing snapshot:# vol_from_snap &#x3D; dsl.PipelineVolume(data_source&#x3D;&quot;snapshot1&quot;)vol &#x3D; dsl.PipelineVolume(pvc&#x3D;&quot;nlp-pvc&quot;, name&#x3D;&quot;pvc-b283bc98-5806-427b-bc25-4cf76869b5ff&quot;)@dsl.pipeline(name&#x3D;&#39;segment-pipeline&#39;)def pipeline(): op0 &#x3D; dsl.ContainerOp( name&#x3D;&quot;jieba segment&quot;, image&#x3D;&#39;10.37.144.182:8002&#x2F;kubeflow&#x2F;seg_jieba:v0.1&#39;, command&#x3D;[&quot;python&quot;, &quot;&#x2F;scripts&#x2F;seg_jieba.py&quot;], arguments&#x3D;[&#39;-b&#39;, &#39;&#x2F;data&#39;], # 将数据卷挂载到镜像中的&#x2F;data目录 pvolumes&#x3D;&#123;&quot;&#x2F;data&quot;: vol&#125; # file_outputs&#x3D;&#123;&#39;out&#39;: &#39;&#x2F;data&#x2F;job_data&#x2F;job_001&#x2F;out.json&#39;&#125;, )if __name__ &#x3D;&#x3D; &#39;__main__&#39;: kfp.compiler.Compiler().compile(pipeline, __file__ + &#39;.yaml&#39;) 编译成yaml或tar上传12pip install kpfdsl-compile --py cheating-containerless.py --output cheating2.tar.gz 或者直接执行main函数，会生成对应的yaml文件。 3.2. NOTEBOOKmnist 从开发到部署官网例子https://github.com/kubeflow/examples/tree/master/mnist#vanilla 快速开发一套基于Kubeflow Pipelines的机器学习工作流https://help.aliyun.com/document_detail/156212.htmlKubeflow Pipeline - 构建一个机器学习 Workflowhttps://zhuanlan.zhihu.com/p/77607425 4. submit pipline4.1. pipline ui4.2. kfp提交https://help.aliyun.com/document_detail/156212.html12345678910111213KFP_SERVICE&#x3D;&quot;ml-pipeline.kubeflow.svc.cluster.local:8888&quot; import kfp.compiler as compiler compiler.Compiler().compile(sample_pipeline, __file__ + &#39;.tar.gz&#39;) client &#x3D; kfp.Client(host&#x3D;KFP_SERVICE) try: experiment_id &#x3D; client.get_experiment(experiment_name&#x3D;EXPERIMENT_NAME).id except: experiment_id &#x3D; client.create_experiment(EXPERIMENT_NAME).id run &#x3D; client.run_pipeline(experiment_id, RUN_ID, __file__ + &#39;.tar.gz&#39;, params&#x3D;&#123;&#39;learning_rate&#39;:learning_rate, &#39;dropout&#39;:dropout, &#39;model_version&#39;:model_version, &#39;commit&#39;:commit&#125;) https://github.com/kubeflow/pipelines/tree/5445ce82c7cd79bd517565750f72cf6a893c8cee/components/gcp/ml_engine","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"},{"name":"autoML","slug":"machine-learning/autoML","permalink":"https://tlylft.github.io/categories/machine-learning/autoML/"}],"tags":[{"name":"autoML","slug":"autoML","permalink":"https://tlylft.github.io/tags/autoML/"},{"name":"kubeflow","slug":"kubeflow","permalink":"https://tlylft.github.io/tags/kubeflow/"}]},{"title":"文本标注工具brat","slug":"NLP/label/brat","date":"2020-12-03T10:03:05.000Z","updated":"2022-01-16T11:58:16.746Z","comments":true,"path":"NLP/label/brat/","link":"","permalink":"https://tlylft.github.io/NLP/label/brat/","excerpt":"","text":"https://wetest.qq.com/lab/view/31.html 1. 标注工具brat1.1. 简介官网Git代码 pros: 业内常用的BRAT 标注实体的同时可以进行关系的标注 可以多人访问，也适合多人协同标注 支持多任务同时标注 支持二级标注 cons: 没有用户管理界面 对小白用户界面可读性差 features: 面向unix-like系统 标注实体的同时可以进行关系的标注 server服务端 可以多人访问，也适合多人协同标注 文件存储 1.2. 安装unix-like环境 1.2.1. docker安装http://10.37.144.182:8001/ brat 用户名：brat 密码：brat1docker run --name&#x3D;brat -d -p 8001:80 -v &#x2F;data&#x2F;brat&#x2F;data:&#x2F;bratdata -v &#x2F;data&#x2F;brat&#x2F;cfg:&#x2F;bratcfg -e BRAT_USERNAME&#x3D;brat -e BRAT_PASSWORD&#x3D;brat -e BRAT_EMAIL&#x3D;liufangtong@enn.cn cassj&#x2F;brat 1.2.2. apache安装Ubuntu18.04：保姆级brat标注工具部署功能比较全的一篇博文centos7:centos7安装SELinux导致启动页面报错问题问题123Error: ActiongetCollectionInformation failed on error Internal Server ErrorError: Actionwhoami failed on error Internal Server ErrorError: ActionloadConf failed on error Internal Server Error原因出现以上问题的原因是由于SELinux的权限的限制。安全增强型 Linux（Security-Enhanced Linux）简称 SELinux，它是一个 Linux 内核模块，也是 Linux 的一个安全子系统。brat将可执行脚本(CGI脚本)、静态文件以及注释的数据都保存在同一个目录中，即brat目录中。SELinux的html目录默认配置为防止从非CGI目录执行CGI脚本。所以，只更改Apache配置是不够的，还需要设置brat目录中相应配置文件的权限。参看以下方法解决即可解决方案123456789# 进入brat文件夹cd &#x2F;var&#x2F;www&#x2F;html&#x2F;brat# 对文件进行授权## 对brat目录下的所有文件进行读操作授权chcon -t httpd_sys_content_t .## 对brat目录下的CGI脚本进行运行操作授权chcon -t httpd_sys_script_exec_t *.cgi## 对brat目录下work和data目录进行读写操作授权sudo chcon -R -t httpd_sys_script_rw_t work data 1.3. 中文支持特别说明：brat本身是不支持中文的，如果在配置文件里定义中文会报错，解决办法是修改./server/src/projectconfig.py文件的第163行，加上中文支持即可：12345n &#x3D; re.sub(u&#39;[^a-zA-Z\\u4e00-\\u9fa5&lt;&gt;,0-9_-]&#39;, &#39;_&#39;, n)sudo a2enmod fastcgisudo a2enmod rewritesudo &#x2F;etc&#x2F;init.d&#x2F;apache2 reloaddocker修改配置流程：12345docker exec -it brat bashcd &#x2F;var&#x2F;www&#x2F;brat&#x2F;brat-v1.3_Crunchy_Frogcd server&#x2F;src&#x2F;vi projectconfig.py# 修改163行 1.4. 增加用户(非必须项)：打开config.py文件，找到对应的行，即可增加用户1234USER_PASSWORD &#x3D; &#123; &#39;admin&#39;: &#39;admin&#39;, &#39;test&#39;: &#39;test&#39;, #(add USERNAME:PASSWORD pairs below this line.) &#125; 1.5. 标注配置主要的设置文件就是 annotation.conf: 标注类别 visual.conf: 标注显示 tools.conf: 标注工具 kb_shortcuts.conf 快捷键 在新建的项目数据文件夹内创建放入这四个文件，若未创建视觉、工具和快捷键配置文件，则使用默认配置。（注意服务器目录权限） 参考：https://www.jianshu.com/p/5043a2128a5f 每个文件需要包含四类模块：entities、relations、events、attributes。各个模块都可以定义为空，其中 entities用来定义标注的实体名称，其格式为每行一个实体类型，比如：人名、地名、英雄名、技能名等 relations用来定义实体间的关系，格式为每行定义一种关系，第一列为关系类型，随后是用逗号分隔的ArgN:实体名，用来表示关系的各个相关者。比如例子中，同盟关系是存在于英雄之间 events用来定义事件，每行定义一类事件，第一列为事件名，随后是用逗号分隔的Participant:实体名，用来表示事件的各个参与者。比如例子中，1v1事件需要多个英雄参加 attributes用来定义属性，每行一个属性，第一列为属性名，随后是用逗号分隔的Arg:&lt;模块类型&gt;, Value:属性值，注意属性值可以有多个 1.5.1. annotation.conf声明 实体、事件、关系、属性的类型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 实体标注[entities] PersonLocationOrganization# 实体多级标注Living-thing Person Animal Plant !Nonliving-thing Building Vehicle### 这里标注时父entity也是可以选中的，在父entity前面加上”!”可以令父entity不可选，如!Living-thing# 事件[events]# 事件名称 参数名称：参数类型Gene_expression Theme:ProteinBinding Theme+:ProteinPositive_regulation Theme:&lt;EVENT&gt;|Protein, Cause?:&lt;EVENT&gt;|ProteinNegative_regulation Theme:&lt;EVENT&gt;|Protein, Cause?:&lt;EVENT&gt;|Protein# 关系[relations]# 关系名称 关系的属性，syntax ARG:TYPE (where ARG are, by convention, Arg1 and Arg2)Part-of Arg1:Protein, Arg2:ComplexMember-of Arg1:Protein, Arg2:Complex# “|”分隔符列出所有可能的类型 Located Arg1:Person, Arg2:Building|City|CountryLocated Arg1:Building, Arg2:City|CountryLocated Arg1:City, Arg2:Country# 等价关系Equiv Arg1:Protein, Arg2:Protein, &lt;REL-TYPE&gt;:symmetric-transitiveEquiv Arg1:Simple_chemical, Arg2:Simple_chemical, &lt;REL-TYPE&gt;:symmetric-transitiveEquiv Arg1:Organism, Arg2:Organism, &lt;REL-TYPE&gt;:symmetric-transitive# 定义实体重叠的范围，# 语法 &lt;OVERLAP&gt; Arg1:TYPE1, Arg2:TYPE2, &lt;OVL-TYPE&gt;:TYPE-SPEC# TYPE-SPEC 可选值包括 contain, equal 和 cross。# contain: TYPE1实体范围可包含（完全）TYPE2 实体范围# equal: TYPE1和TYPE2实体的跨度可以相等# cross: TYPE1和TYPE2实体的可以相交&lt;OVERLAP&gt; Arg1:Country, Arg2:Organization, &lt;OVL-TYPE&gt;:contain&lt;OVERLAP&gt; Arg1:Person, Arg2:Person, &lt;OVL-TYPE&gt;:equal&lt;OVERLAP&gt; Arg1:&lt;ENTITY&gt;, Arg2:&lt;ENTITY&gt;, &lt;OVL-TYPE&gt;:&lt;ANY&gt;# 属性定义[attributes]# 名称 参数Negation Arg:&lt;EVENT&gt;Confidence Arg:&lt;EVENT&gt;, Value:Possible|Likely|Certain 1.5.2. visual.conf一些可视化的设置如标签颜色，显示名称在./brat-v1.3_Crunchy_Frog/visual.conf分为两个部分labels和drawing，labels是设置标记的全程和显示文字，drawing是设置颜色等信息。1234567891011121314151617181920212223242526272829303132333435[labels]# 定义用户界面中标签类别的显示，如果未再此设置则按annotation.conf中的名称显示。# 作用：再用户界面中用任意字符显示标签；界面空间有限时可使用缩写# 标记类型 | 全称 | 显示文字PER | PERSON | 人物[drawing]# 语法 ENTITY&#x2F;RELATION KEY1:VALUE1，KEY2:VALUE2……# KEY:VALUE对选项说明# fgColor：任何HTML颜色规范（例如“black”），设置标注标签文字颜色。# bgColor：任何HTML颜色规范（例如“white”），设置标注标签背景颜色。# borderColor：任何HTML颜色规范（例如“black”），设置标注标签边框颜色。支持指定“ darken”设置阴影。# color：任何HTML颜色规范（例如“black”），设置弧线的颜色。# dashArray：设置为虚线。# 设置默认值SPAN_DEFAULT fgColor:black, bgColor:lightgreen, borderColor:darkenARC_DEFAULT color:black, arrowHead:triangle-5ATTRIBUTE_DEFAULT glyph:*Protein bgColor:#7fa2ffSimple_chemical bgColor:#8fcfffComplex bgColor:#8f97ffOrganism bgColor:#ffccaaPositive_regulation bgColor:#e0ff00Regulation bgColor:#ffff00Negative_regulation bgColor:#ffe000Cause color:#007700Equiv dashArray:3-3, arrowHead:noneNegation box:crossed, glyph:&lt;NONE&gt;, dashArray:&lt;NONE&gt;Confidence dashArray:3-6|3-3|-, glyph:&lt;NONE&gt; 1.5.3. tools.conf分为以下几个配置模块：[options][search][normalization][annotators][disambiguators] 1.5.4. kb_shortcuts.conf可以对标签设置快捷键，在./brat-v1.3_Crunchy_Frog/kb_shortcuts.conf选中标记后，键盘上按快捷键，可以快速切换选项12345678910# 快捷键1 标签1# 快捷键2 标签2P ProteinS Simple_chemicalX ComplexO OrganismC CauseT Theme","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"label","slug":"NLP/label","permalink":"https://tlylft.github.io/categories/NLP/label/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"label","slug":"label","permalink":"https://tlylft.github.io/tags/label/"}]},{"title":"Rasa框架解读（2）-rasa2.0 配置","slug":"chatbot/rasa_02_config","date":"2020-12-01T05:41:45.000Z","updated":"2023-08-11T08:42:51.666Z","comments":true,"path":"chatbot/rasa_02_config/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_02_config/","excerpt":"","text":"版本迁移1.x-&gt;2.xhttps://rasa.com/docs/rasa/migration-guide#manually-migrating-from-the-fallback-policy 1. 安装与部署1.1. 安装 安装环境 初始化项目1rasa init 1.2. 运行https://rasa.com/docs/rasa/command-line-interface训练模型1rasa train 运行123456rasa run \\ -m models \\ --enable-api \\ --log-file out.log \\ --auth-token thisismysecretrasa run action 2. 语料填充rasa 2.0中，不用文件区分数据源，而是使用标记区分。可设置的四个标记为：1234versionnlustoriesrules举例：123456789101112131415161718192021222324252627version: &quot;2.0&quot;nlu:- intent: greet examples: | - Hey - Hi - hey there [Sara](name)- intent: faq&#x2F;language examples: | - What language do you speak? - Do you only handle english?stories:- story: greet and faq steps: - intent: greet - action: utter_greet - intent: faq - action: utter_faqrules:- rule: Greet user steps: - intent: greet - action: utter_greet 2.1. version 配置1version: &quot;2.0&quot; 需要在所有YAML数据文件中指定version。否则，Rasa会认为使用的是已安装的Rasa Open Source版本支持的最新数据版本。Rasa开源版本大于计算机上已安装版本的培训数据文件将被跳过。当前，Rasa 2.x的最新培训数据格式规范是2.0。 2.2. NLU 语料配置意图12345nlu:- intent: check_balance examples: | - What&#39;s my [credit](account) balance? - What&#39;s the balance on my [credit card account]&#123;&quot;entity&quot;:&quot;account&quot;,&quot;value&quot;:&quot;credit&quot;&#125;同义词同义词的配置对实体识别的效果没有优化的影响，而是方便做实体归一化。12345nlu:- synonym: credit examples: | - credit card account - credit account正则表达设定的规则会作为一个特征，来优化分类器识别意图。1234nlu:- regex: help examples: | - \\bhelp\\b 3. 服务配置3.1. 模型存储TODO: 如何将模型存到服务器端？保持服务端和运行端数据一致 本地存储获取1234# 指定模型rasa run --model models&#x2F;20190506-100418.tar.gz# 指定目录，获取最新的模型启动运行rasa run --model models&#x2F; 服务端获取You can configure the HTTP server to fetch models from another URL by adding it to your endpoints.yml:The server will query the url for a zipped model every wait_time_between_pulls seconds.123models: url: http:&#x2F;&#x2F;my-server.com&#x2F;models&#x2F;default wait_time_between_pulls: 10 # In seconds, optional, default: 100","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"【知识图谱】-03事件抽取(Event Extraction)","slug":"knowledge_graph/kg_ee","date":"2020-11-27T06:58:56.000Z","updated":"2022-01-29T08:21:38.866Z","comments":true,"path":"knowledge_graph/kg_ee/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/kg_ee/","excerpt":"","text":"啥是事件抽取(Event Extraction)知识抽取-事件抽取开放域事件抽取及相关论文整理 百度竞赛：数据集比赛说明基准代码参考算法 ERNIE:论文 git代码YiDai-03 DuIE_pytorch SemEval-2020SemEval-2020自由文本关系抽取冠军方案解读 1. 概述1.1. 背景知识图谱的构建都是以实体为核心，缺乏事件知识事件抽取(Event Extraction, EE)是NLP领域信息抽取任务中的重要研究方向，在商业、军事等领域的情报工作中应用非常广泛。 1.2. 概念1.2.1. 什么是事件？事件是发生在磨具个特定的时间点或时间段，某个特定的地域范围内，由一个或者多个角色参与的一个或者多个动作组成的事情或者状态的改变 不同的动作或者状态改变表达了不同的事件类型，如：我吃饭和我喝水同一类事件类型不同元素或不同粒度的元素代表了不同的事件实例，如我吃饭和你吃饭 1.2.2. 什么是事件抽取？含有事件信息的非结构化文本 -&gt; 用户感兴趣的事件信息，并以结构化的形式呈现出来完整的事件（5W1H）：who(施事者)what(做什么) -谓语动词体现whom(受事者)when(什么时间)where(地点)how(怎么做) - 详细描述事件 事件抽取vs关系抽取关系抽取：两个实体之间的关系，一般是单一的关系事件抽取：触发词和实体之间的关系，可能是多个关系，如和person的关系，和org的关系和pos的关系等 1.3. 任务定义Closed-domainClosed-domain事件抽取使用预定义的事件模式从文本中发现和提取所需的特定类型的事件。事件模式包含多个事件类型及其相应的事件结构。D.Ahn首先提出将ACE事件抽取任务分成四个子任务：触发词检测、事件/触发词类型识别、事件论元检测和参数角色识别。我们使用ACE术语来介绍如下事件结构: -「事件提及」：描述事件的短语或句子，包括触发词和几个参数。-「事件触发词」：最清楚地表达事件发生的主要词，一般指动词或名词。-「事件论元」：一个实体，时间表达式，作为参与者的值和在事件中具有特定角色的属性。-「论元角色」：论元与它所参与的事件之间的关系 事件发现（event detection）:从文本中发现事件触发词（event trigger） 事件/触发词类型识别 (event/trigger type identification)：根据事件触发词，确定事件类型 事件元素抽取（argument extraction）:从文本中识别事件元素（event argument） 角色识别 (role identification)：根据事件元素，确定事件参与者的角色 Open domain在没有预定义的事件模式的情况下，开放域事件抽取的目的是从文本中检测事件，在大多数情况下，还可以通过提取的事件关键词聚类相似的事件。事件关键词指的是那些主要描述事件的词/短语，有时关键词还进一步分为触发器和参数。 「故事分割」：从新闻中检测故事的边界。「第一个故事检测」：检测新闻流中讨论新话题的故事。「话题检测」：根据讨论的主题将故事分组。「话题追踪」：检测讨论先前已知话题的故事。「故事链检测」：决定两个故事是否讨论同一个主题。 前两个任务主要关注事件检测;其余三个任务用于事件集群。虽然这五项任务之间的关系很明显，但每一项任务都需要一个不同的评价过程，并鼓励采用不同的方法来解决特定问题。 1.4. 应用场景丰富现有的知识图谱，支撑业务信息获取引擎网络舆情监控、突发事件告警、情报收集领域例：喜马拉雅山有多高？ - 实体图谱汶川地震死亡人数有多少？ -事件图谱 垂直领域： 12345678**关键技术：**![](kg_ee&#x2F;2022-01-08-11-09-35.png)共指关系：不同数据源表示的是同一个事件时序关系：理清事件发生的先后顺序，帮助从大量的时序关系中挖掘出常见的事理关系![](kg_ee&#x2F;2022-01-08-14-28-46.png)因果关系：![](kg_ee&#x2F;2022-01-08-14-28-20.png) 2. 评测和数据集国际公开的评测组织：DARPATDT: 主要做主题检测和追踪，不会具体抽出事件的类型和元素ACE：可以具体抽出事件的类型和元素ECB:做因果经常用的数据集 [6]ACE2005 English Corpus: https://catalog.ldc.upenn.edu/LDC2006T06 [7] Rich ERE: https://www.aclweb.org/old_anthology/W/W15/W15-0812.pdf TAC2015 KBP2017 ACE2005 Chinese Corpus DuEE-Fin金融领域篇章级别事件抽取数据集,包含13个已定义好的事件类型约束和1.15万中文篇章（存在部分非目标篇章作为负样例） 示例：ACE -英文事件识别数据集根据不同领域定义了不同抽取模板和训练语料包括 8个大类（life,business,personal），33 event types599 documents6000 labeled sentences ACE2005英文数据集，事件监测性能2013年：67.52020年：74.9元素抽取性能：2013年：52.72020年：70.1核心问题：依赖大量人工标注的训练数据，仅利用文本从句子中抽取固定类别的事件知识。 3. 实现方法根据实现方式,元事件抽取可以分为两类:基于模式匹配的方式和基于机器学习的方式。基于机器学习的元事件抽取将元事件检测和论元识别转换成分类问题,可以分为管道式方法(pipeline)和联合学习方法(Joint Event Extraction)。 3.1. Pipline流水线方法将事件抽取任务分解为一系列基于分类的子任务 包括事件识别、元素抽取、属性分类 和可报告性判别; 每一个子任务由一个机器学习分类器负责实施。 常用特征： 百度DuEE模型DuEE: A Large-Scale Dataset for Chinese Event Extraction in Real-World Scenarios代码下载 3.1.1. DMCNN *论文解读：https://blog.csdn.net/qq_29496135/article/details/109085606论文解读：https://www.jianshu.com/p/84fd666b1900论文链接：http://www.nlpr.ia.ac.cn/cip/yubochen/yubochenPageFile/acl2015chen.pdf 2015年提出的基于CNN的模型。是第一个将深度学习模型应用在事件抽取任务中，并取得显著效果的模型。这是一种pipeline方式的事件抽取方案，即对触发词的检测和识别、对论元的检测和识别两个任务是分开进行的，后者依赖于前者的预测结果。两个子任务都被转换成了多分类问题，模型都采用DMCNN，只是稍有不同。 第一阶段：使用DMCNN对句子中的每个单词进行分类来识别触发词输入：词级别语义特征：当前词的上下文词句子级别语义特征：CWF：词嵌入PF：当前词的位置EF：无模型：DMCNN 动态部分分为两段表示，以当前触发词作为切分输出：每个事件类型的softmax 第二阶段：使用DMCNN对句子中的每个单词进行分类来识别论元角色输入：词级别语义特征：所有词的词向量拼接句子级别语义特征：CWF：词嵌入PF：当前词与触发器词的相对距离EF：触发器的事件类型编码模型：DMCNN 动态部分分为三段表示，以当前触发词和候选论元作为切分输出：每个角色类型的softmax 优势：结合了词汇及和句子级特征。引入单词表示模型，规范语义，基于CNN捕捉句子级线索，动态多池卷积神经网络保留更多关键信息。弊端：该方法存在错误传播的问题、无法利用事件触发器和参数角色的相互依赖关系，且未考虑到离散特征通过动态多池CNN解决了上述joint system的缺点，在该系统中，单词被连续表示，feature用DMCNN从数据中被自动学习，因此减轻了unseen words或unseen features的问题，从data中抽取到了更有效的feature（Chen et al. 2015） 3.1.2. DuEE模型论文地址：https://sci-hub.se/10.1007/978-3-030-60457-8论文解读：https://blog.csdn.net/weixin_42691585/article/details/115497275触发词抽取模型论元抽取模型枚举分类模型对于一些序列标注抽取不能解决的论元提取，可以采用枚举分类的方式，构建分类任务，如：提取上市状态这个论元类型，可设置事件抽取schema为枚举型。[筹备上市、暂停上市、正式上市、终止上市]评测方法采用预测论元F1值作为评价指标，对于每个篇章，采用不放回的方式给每个目标事件寻找最相似的预测事件（事件级别匹配），搜寻方式是优先寻找与目标事件的事件类型相同且角色和论元正确数量最多的预测事件 f1_score = (2 P R) / (P + R)，其中 预测论元正确=事件类型和角色相同且论元正确P=预测论元正确数量 / 所有预测论元的数量R=预测论元正确数量 / 所有人工标注论元的数量 模型优化https://github.com/onewaymyway/duee_2020https://blog.csdn.net/weixin_42691585/article/details/115557227更改预训练模型，加bi-gru 3.2. Joint Event Extraction事件抽取的流水线方法在每个子任务阶段都有可能存在误差 ， 这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积 ， 使得事件抽取的性能急剧衰减。 为了解决这一问题 ， 一些研究工作提出 事件的联合抽取方法。 在联合抽取方法中， 事件的所有相关信息会通过一个模型同时抽取出来。 同时预测event triggers和arguments 结构化预测问题 pros:减少上游组件（触发器标识）到下游分类器（参数标识）的错误传播。通过全局feature来利用event triggers和argument roles间的相互依赖性。 例子： ​ In Baghdad, a cameraman died when an American tank fired on the … 这里died是Die的event trigger，fired是Attack的event trigger。cameraman是died的victim argument，也是fired的target argument。 在pipelined方法中，cameraman是died的argument很好识别，因为他们的距离比较近，但cameraman和fired的距离比较远，所以可能无法识别出cameraman是fired的argument。 但是joint方法可以编码全局特征，可能会学习到“died的victim argument通常是attack的target argument”这样的信息，从而来解决这一问题 弊端：joint system在unseen words或unseen features上缺乏泛化能力，无法提取EE的底层结构（由于其离散表示来自于手工特征集） PSL 3.2.1. 利用局部&amp;全局特征做结构化预测（Li et al. 2013）3.2.2. JRNN（Nguyen et al. 2016）Joint Event Extraction via Recurrent Neural Networks 2016论文解读：https://blog.csdn.net/lufei99/article/details/103497761论文解读：https://zhuanlan.zhihu.com/p/63215208论文地址：https://aclanthology.org/N16-1034/ 使用RNN将事件识别和论元角色分类相结合，构建包含文本序列特征和局部窗口特征的局部特征，然后将文本输入到RNN模型中，得到深度学习的上下文表示，主要针对事件触发词之间、事件论元之间、事件触发词和事件论元之间的全局特性，以同时提高多任务的性能。提出了一种双向 RNN用于联合事件抽取。在编码阶段，它使用 RNN 来汇总上下文信息；在预测阶段，则根据学习到的特征表示同时预测触发词和论元。以前的方法严重依赖于特定语言的知识和现有的 NLP 工具。 3.2.3. dbRNN事件抽取联合模型论文解读：https://blog.csdn.net/lufei99/article/details/107039846论文题目：Jointly Extracting Event Triggers and Arguments by Dependency-Bridge RNN and Tensor-Based Argument Interaction 3.2.4. JMEE 【EMNLP 2018 | JMEE】*论文题目：Jointly Multiple Events Extraction via Attention-based Graph Information Aggregation 论文来源：EMNLP 2018 论文链接：https://arxiv.org/abs/1809.09078 代码链接：https://github.com/lx865712528/EMNLP2018-JMEE论文解读：https://blog.csdn.net/byn12345/article/details/105411433/ 关键词：多事件抽取，GCN，attention，句法依存结构 3.2.5. EMNLP 2019 | HMEAE论文题目：HMEAE: Hierarchical Modular Event Argument Extraction 论文来源：EMNLP 2019 清华、微信AI 论文链接：https://www.aclweb.org/anthology/D19-1584/ 代码链接：https://github.com/thunlp/HMEAE 关键词：事件元素抽取（EAE），概念层次，attention，BERT，CNN 论文解读：https://blog.csdn.net/byn12345/article/details/105640110 ENNLP 2019 Doc2EDAG论文题目： Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial Event Extraction论文地址：https://arxiv.org/pdf/1904.07535.pdf论文代码：https://github.com/dolphin-zs/Doc2EDAG 数字化财务文档， 内容抽取本文聚焦金融领域： 事件元素分散（元素可能在不同句子中）； 多事件（一个文档包含多个事件）现有事件抽取只能提供句子范围内的事件元素，本文聚焦篇章级。 数据集： ChFinAnn 包中国股市上市公司第一手官方信息，有五大类数据，数百种类型，如年报和盈利预测标注：远程监督将事件知识库映射到文本文档来获取标注数据关键时间角色必须存在； 匹配的论元数目应该大于一个阈值； 不标注触发词 3.2.6. IJCAI 2019论文题目：Extracting Entities and Events as a Single Task Using a Transition-Based Neural Model 论文来源：IJCAI 2019 武汉大学, 东华大学, 西湖大学 论文链接：https://www.ijcai.org/Proceedings/2019/753 代码链接：https://github.com/zjcerwin/TransitionEvent 关键词：事件抽取，实体抽取，联合学习，transition-based model论文解读：https://blog.csdn.net/byn12345/article/details/105741623 3.2.7. ACL2021 | 探讨跨句事件联合抽取问题*论文题目：MLBiNet: A Cross-Sentence Collective Event Detection Network 本文作者：娄东方、廖智霖、邓淑敏、张宁豫、陈华钧（浙江大学） 接收会议：ACL 2021 论文链接：https://arxiv.org/pdf/2105.09458.pdf 开源代码：https://github.com/zjunlp/DocED 论文解读：https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/118917619 3.3. 小样本https://blog.csdn.net/byn12345/article/details/113868995 论文题目：Few-shot Learning for Multi-label Intent Detection 论文来源：AAAI 2021 论文链接：https://arxiv.org/abs/2010.05256 代码链接：https://github.com/AtmaHou/FewShotMultiLabel 4. 事件图谱构建的挑战数据：标注规模小、数据稀疏、无标注数据，包括ace中有些事件类型的样本数也非常少。领域数据难构造，标注成本大类别：事件动态发生，新事件不断出现文本： 仅利用句子无法准确、完整的抽取事件（篇章信息的挑战）知识：仅利用文本信息无法准确推断事件关系（人有背景知识） 模型层面：pipeline方式存在错误信息的传递，如何减小错误信息传递论元之间的关联关系的有效利用无标注数据的评价指标设计 5. 基于知识的数据自动生成生成数据 Generating labeled data运用结构化的知识库自动生成语料distant(weak) supervision in RE问题挑战： 现有知识库缺少触发词信息 事件元素并不是都必须出现知识库中只有60%的事件包含所有的事件元素 一个事件的多个元素可以出现在多个句子中只有0.02%的事件实例能在一句话中找到所有的事件元素 方法：利用世界知识和语言学知识，自动生成大规模事件语料使用tf-idf找到一些关键的实体，在百度百科中寻找这些实体的句子，把句子中的动词通过tf-idf排序、过滤，找出关键的动词，作为trigger words， 完善在frame net中， 将这些信息在百度百科的句子进行回标，标注数据的评价 6. 事件抽取算法6.1. 基于阅读理解范式的事件抽取传统方法建模为序列标注和分类任务在样本量较大的常见事件类型上效果较好对于样本比较少的罕见事件类型上表现较差 模型框架：实验结果： 6.2. 融合frameNet的事件识别方法利用FrameNet中的框架及其标注例句扩充事件抽取训练集FrameNet 语言学家定义及标注的语义框架资源 层级的组织结构 FrameNet规模 1000+ 框架 10000+ 词法单元 150000+ 标注例句 总结： 事件知识不可或缺 企业信息监控 风险信用控制 智能投顾通用领域的事件抽取很难 大规模、高质量的训练数据 鲁棒性的特征表示限定域的事件抽取有可能有不错的性能 文本类型受限 语言表示规律性较强，知识密集","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"}]},{"title":"一些技巧","slug":"deep_learning/skills","date":"2020-11-25T12:43:24.000Z","updated":"2022-06-08T07:38:01.634Z","comments":true,"path":"deep_learning/skills/","link":"","permalink":"https://tlylft.github.io/deep_learning/skills/","excerpt":"","text":"https://blog.csdn.net/han_xiaoyang/article/details/50521064https://blog.csdn.net/gbz3300255/article/details/106380301 intro 最菜的算法工程师靠调学习率 次菜的算法工程师靠试新模型 合格的算法工程师会懂得做数据 不错的算法工程师还会用新paper优化实际问题 优秀的算法工程师能数据、模型、策略joint design&amp;iterate 顶级的算法工程师能颠覆行业方法论 调优首先贴出夕小瑶公众号写到的算法工程师升级打怪路线：https://mp.weixin.qq.com/s/1DQ6Ihx8MhAtZndYEMYvhg嗯，我不能只关注离线测试集指标涨不涨，我还要判断测试集靠不靠谱，包括采样/数据分布的线上一致性、时效性、标注正确率、评测方差/置信度等。嗯，我不能对着同一个测试集做大量没道理的炼丹，比如暴力调参、疯狂改随机种子、暴力乱加策略、暴力魔改、暴力增删改查等。我知道大量的无意义超参调整，只会变相的让模型用超参过拟合这个测试集。最终结果往往是，向上汇报猛如虎，线上用户用脚投票。wok，准确率从90%一下子涨到99%了！肯定不是我nb，绝对是出bug或者标签泄漏了！嗯，新老方法都有其存在的意义和发挥作用的阶段，都是不可缺的。 那么模型调优应该怎么做呢？ 基准模型从简单的模型开始，主键增加复杂模型来看效果 early stopping 很重要 避免过拟合 数据收集有很多方法： 聚类，数据增强,懂得制造业务有效的数据集标注标准采样策略关于标注标准，这其实是个比较吃业务经验的事情。懂得提供贴合业务场景的数据，在流量大的真实业务场景中，都会面临大量的边界样本和人都要分辨半天，甚至需要足够学历、阅历才能分辨出情感极性的样本，这种数据也是需要学习的。而且，在不同场景下，标注数据的意义和价值都会产生变化，比如，句子“oppo最新款手机多少钱”与句子“vivo最新款手机多少钱”的文本相关性，在搜索场景，就是妥妥的负例，因为用户的出发点是获取真实知识，你如果给用户返回vivo的价格，那用户会有一种被欺骗感。但是，在搜索广告场景，却完全可以作为正例，因为本身vivo和oppo的大众认知相对比较近，用户在搜索广告场景的出发点可能是买一部不错的安卓机，并且用户觉得oppo可能是不错的选择，那这时候你给出vivo的信息，用户往往不会反感，甚至可能因为发现vivo更合适而下单。 训练数据和测试数据的分布要均衡，不然测试数据中没有训练过是没有意义的。 可视化很重要，如果是本地开发机，善用 cv.imshow 直观、便捷地可视化处理的结果；一个基础的 train/inference 流程跑通后，分别构建 1 张、10 张的数据用于 debug，确保任意改动后，可以 overfit；调试代码阶段避免随机性、避免数据增强，一定用 tensorboard 之类的工具观察 loss 下降是否合理； loss不下降train loss与test loss结果分析 train loss 不断下降，test loss不断下降，说明网络仍在学习;train loss 不断下降，test loss趋于不变，说明网络过拟合;train loss 趋于不变，test loss不断下降，说明数据集100%有问题;train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"node4j安装与使用","slug":"knowledge_graph/neo4j","date":"2020-11-24T04:22:47.000Z","updated":"2021-06-15T09:09:40.018Z","comments":true,"path":"knowledge_graph/neo4j/","link":"","permalink":"https://tlylft.github.io/knowledge_graph/neo4j/","excerpt":"","text":"1. 介绍node4j官网链接社区版和企业版对比 https://www.zhihu.com/question/421353529noe4j 4.0特性比较Neo4j、JanusGraph、HugeGraph 2. 安装2.1. docker 安装 展开详情 1docker pull neo4j 第一步，在你根目录的任意一个子目录（我这里是/home)下建立四个基本的文件夹 data——数据存放的文件夹 logs——运行的日志文件夹 conf——数据库配置文件夹（在配置文件neo4j.conf中配置包括开放远程连接、设置默认激活的数据库） import——为了大批量导入csv来构建数据库，需要导入的节点文件nodes.csv和关系文件rel.csv需要放到这个文件夹下） 1234567891011docker run -d --name container_name \\ &#x2F;&#x2F;-d表示容器后台运行 --name指定容器名字 -p 7474:7474 -p 7687:7687 \\ &#x2F;&#x2F;映射容器的端口号到宿主机的端口号 -v &#x2F;home&#x2F;neo4j&#x2F;data:&#x2F;data \\ &#x2F;&#x2F;把容器内的数据目录挂载到宿主机的对应目录下 -v &#x2F;home&#x2F;neo4j&#x2F;logs:&#x2F;logs \\ &#x2F;&#x2F;挂载日志目录 -v &#x2F;home&#x2F;neo4j&#x2F;conf:&#x2F;var&#x2F;lib&#x2F;neo4j&#x2F;conf &#x2F;&#x2F;挂载配置目录 -v &#x2F;home&#x2F;neo4j&#x2F;import:&#x2F;var&#x2F;lib&#x2F;neo4j&#x2F;import \\ &#x2F;&#x2F;挂载数据导入目录 --env NEO4J_AUTH&#x3D;neo4j&#x2F;password \\ &#x2F;&#x2F;设定数据库的名字的访问密码 neo4j &#x2F;&#x2F;指定使用的镜像# 快捷docker run -d --name neo4j -p 8474:7474 -p 8687:7687 -v &#x2F;data&#x2F;neo4j&#x2F;data:&#x2F;data -v &#x2F;data&#x2F;neo4j&#x2F;logs:&#x2F;logs -v &#x2F;data&#x2F;neo4j&#x2F;conf:&#x2F;var&#x2F;lib&#x2F;neo4j&#x2F;conf -v &#x2F;data&#x2F;neo4j&#x2F;import:&#x2F;var&#x2F;lib&#x2F;neo4j&#x2F;import --env NEO4J_AUTH&#x3D;neo4j&#x2F;password neo4j ### 2.2. 3.5以下版本安装 展开详情 https://blog.csdn.net/JD_Wang0/article/details/104408190 1. 安装jdk8, recommended for Neo4j 3.0.x Version 7 is recommended for releases prior to 2.3.0. 2. Find the zip file you just downloaded and right-click, extract all. Place the extracted files in a permanent home on your server, for example D:\\neo4j\\. The top level directory is referred to as NEO4J_HOME. To run Neo4j as a console application, use: \\bin\\neo4j console To install Neo4j as a service use: \\bin\\neo4j install-service. For additional commands and to learn about the Windows PowerShell module included in the Zip file, see the Windows installation documentation. Visit http://localhost:7474 in your web browser. Connect using the username 'neo4j' with default password 'neo4j'. You'll then be prompted to change the password. 启动方式： >neo4j.bat console >访问：http://localhost:7474 neo4j neo4j 服务启动：./bin/neo4j start 3. 使用3.1. 数据导入3.1.1. 命令行 csv3.1.2. python py2neo3.1.3. m3.2. 目录结构123data 目录： 导入的数据存储在该目录下logs 目录： 日志bin 目录： 导入，cpyher等 查询语法cypher语句","categories":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"}],"tags":[{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"},{"name":"neo4j","slug":"neo4j","permalink":"https://tlylft.github.io/tags/neo4j/"}]},{"title":"RASA链接实现","slug":"chatbot/rasa_link","date":"2020-11-20T07:53:01.000Z","updated":"2023-08-11T08:42:10.585Z","comments":true,"path":"chatbot/rasa_link/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_link/","excerpt":"","text":"静态链接实现在domain.yml中配置问题回复时，使用[website](link)作为链接12utter_answer_bw_q1: - text: 您好，请提交SLM修改组织层级可解决该问题。[website](http:&#x2F;&#x2F;10.38.64.55:8081&#x2F;document.html) 动态链接实现增加action方法 在action.py中定义操作 在domain.yml中的actions:下引用操作。","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"关系抽取","slug":"NLP/relation_extract","date":"2020-11-20T05:39:15.000Z","updated":"2021-06-11T03:16:28.765Z","comments":true,"path":"NLP/relation_extract/","link":"","permalink":"https://tlylft.github.io/NLP/relation_extract/","excerpt":"","text":"1. 关系抽取 https://blog.csdn.net/qq_40931181/article/details/106078068https://zhuanlan.zhihu.com/p/77868938 1.1. 基于规则的方法优点：比较准确，不需要 训练数据 缺点：low recall rate，人力成本需要大量设计规则，规则本身难设计 1.2. 基于监督学习的方法 定义关系类型 定义实体类型 训练数据准备 ​ 实体标注好类型 ​ 实体之间的关系","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"rasa槽位配置","slug":"chatbot/rasa_slots","date":"2020-10-13T03:05:35.000Z","updated":"2023-08-11T08:42:17.909Z","comments":true,"path":"chatbot/rasa_slots/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_slots/","excerpt":"","text":"https://blog.csdn.net/ljp1919/article/details/104018940","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"NLP论文","slug":"tools/paper","date":"2020-09-21T01:42:14.000Z","updated":"2020-09-21T01:58:38.211Z","comments":true,"path":"tools/paper/","link":"","permalink":"https://tlylft.github.io/tools/paper/","excerpt":"","text":"https://scholar.google.com/https://www.paperswithcode.com/ 查看综述：dialogue system review/survey 核心学者车万翔（http://ir.hit.edu.cn/~car/chinese.htm）刘知远（http://nlp.csai.tsinghua.edu.cn/~lzy/）严睿 （http://www.ruiyan.me/）黄民烈（http://coai.cs.tsinghua.edu.cn/hml/）邱锡鹏（https://xpqiu.github.io/）Christopher Manning（https://nlp.stanford.edu/manning/） 顶会CCL（http://cips-cl.org/static/CCL2020/index.html）NLPCC（http://tcci.ccf.org.cn/conference/2020/）ACL（https://acl2020.org/）EMNLP（https://2020.emnlp.org/） 论文组成摘要（Abstract）介绍（Introduction）模型（Model）实验（Experimental）总结（Conclusion）参考文献（References）","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"},{"name":"paper","slug":"tools/paper","permalink":"https://tlylft.github.io/categories/tools/paper/"}],"tags":[]},{"title":"Docker容器","slug":"tools/docker","date":"2020-09-20T02:50:43.000Z","updated":"2023-01-13T04:35:33.766Z","comments":true,"path":"tools/docker/","link":"","permalink":"https://tlylft.github.io/tools/docker/","excerpt":"","text":"1. 介绍https://www.runoob.com/docker/docker-tutorial.html 2. 安装2.1. windowsdockerwin7安装和镜像加速 其实是win10以下的系统没有docker支持，然后docker tool使用virturalbox创建了一个linux的虚拟机,在虚拟机中安装了docker，在windows的tool中使用docker-machine进行管理每个虚拟机，调用了这些machine，所以在windows中是可以直接使用docker命令的，但是涉及网络端口，其实docker启动的是虚拟机的端口。 启动问题多次安装会遇到一个问题，就是安装成功，但是启动的时候，访问不到docker的服务，一直refuse。这是因为在第一次安装的时候，docker tool给了一台虚拟机a, 第二次可能给了另一台虚拟机b，他们的ip如果被分配不同了，因为安装的bug, 第二次安装完启动docker服务的时候，docker tool一直访问虚拟机a的ip,就找不到docker 服务。解决方法：将系统变量中的$DOCKER_HOST修改为虚拟机b的ip123456&gt; echo $DOCKER_HOSTtcp:&#x2F;&#x2F;192.168.99.101:2376&gt;docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSdefault * virtualbox Running tcp:&#x2F;&#x2F;192.168.99.100:2376 v19.03.12&gt; 修改系统变量，重启 ，就好了 2.2. centos7 https://www.runoob.com/docker/centos-docker-install.html 配置yum国内镜像源123456789101112a.备份yum默认仓库文件$ cd &#x2F;etc&#x2F;yum.repos.d ---进入仓库目录$ mv CentOS-Base.repo CentOS-Base.repo.backup ---备份默认源文件b.下载国内仓库源文件（ps：各个版本的Linux的源文件有差异$ wget -O .&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.163.com&#x2F;.help&#x2F;CentOS7-Base-163.repo ---下载网易仓库源文件并重命名# 下载后执行以下两条命令$ yum clean all ---清空缓存$ yum makecache ---生成缓存 使用官网脚本自动安装123456789101112131415# 安装container-selinuxsudo yum install container-selinux# 配置docker镜像仓库-阿里云yum install epel-release yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repocurl -fsSL https:&#x2F;&#x2F;get.docker.com | bash -s docker --mirror Aliyun或指定版本安装# 查看有什么版本yum list docker-ce --showduplicates | sort -r# 安装dockeryum install -y docker-ce docker-ce-cli containerd.ioyum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io 启动docker1234$ sudo systemctl start docker## 设置docker开机自启动systemctl enable dockersystemctl restart docker 镜像存储目录迁移 https://www.cnblogs.com/hellxz/p/docker-change-data-root.html 1234567891011$docker version#查看docker镜像的默认存储路径$docker info |grep &quot;Docker Root Dir&quot;# 修改&#x2F;etc&#x2F;docker&#x2F;daemon.json 增加一行graph&#123; &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;hub-mirror.c.163.com&quot;, &quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;], &quot;graph&quot;: &quot;&#x2F;data&#x2F;docker&quot;&#125;# 保存 重启$sudo systemctl restart docker docker-compose 查看内核 uname -r 下载： https://github.com/docker/compose/releasesdocker-compose-linux-x86_64mv docker-compose-linux-x86_64 /usr/local/bin/mv docker-compose-linux-x86_64 docker-composechmod 777 docker-compose-linux-x86_64./docker-compose -vdocker-compose —version GPU nvidia-docker Setup the repository and the GPG key1distribution&#x3D;$(. &#x2F;etc&#x2F;os-release;echo $ID$VERSION_ID) &amp;&amp; curl -s -L https:&#x2F;&#x2F;nvidia.github.io&#x2F;libnvidia-container&#x2F;$distribution&#x2F;libnvidia-container.repo | sudo tee &#x2F;etc&#x2F;yum.repos.d&#x2F;nvidia-container-toolkit.repo 安装nvidia-docker21234sudo yum install -y nvidia-docker2sudo systemctl restart docker验证sudo docker run --rm --gpus all nvidia&#x2F;cuda:11.0.3-base-ubuntu20.04 nvidia-smi 3. 使用docker常用命令12345678910111213141516171819docker container ls -a #查看container信息docker exec -it containerID bash #进入containerdocker run -p 4000:80 imageName #将机器的 4000 端口映射到容器的 80 端口docker run -d -p 4000:80 imageName # 内容相同，但在分离模式下docker logs -f containerID # 查看容器日志docker stats [--no-stream] containerID # 查看容器进程资源docker ps # 查看所有正在运行的容器的列表docker stop containerID # 平稳地停止指定的容器docker ps -a # 查看所有容器的列表，甚至包含未运行的容器docker kill containerID # 强制关闭指定的容器docker rm containerID # 从此机器中删除指定的容器docker rm $(docker ps -a -q) # 从此机器中删除所有容器docker images -a # 显示此机器上的所有镜像docker rmi imagename # 从此机器中删除指定的镜像docker rmi $(docker images -q) # 从此机器中删除所有镜像docker login # 使用您的 Docker 凭证登录此 CLI 会话docker tag &lt;image&gt; username&#x2F;repository:tag # 标记 &lt;image&gt; 以上传到镜像库docker push username&#x2F;repository:tag # 将已标记的镜像上传到镜像库docker run username&#x2F;repository:tag # 运行镜像库中的镜像 3.1. docker 容器 3.1.1. 基本用法拉取镜像1docker pull ubuntu启动容器123456docker run [param] [image] [command]docker run -it ubuntu &#x2F;bin&#x2F;bash-i: 交互式操作。-t: 终端。退出终端，直接输入 exit-d: 后台运行--name&#x3D;&quot;&quot;： 指定名字后，可以代替container id使用查看容器1234## 查看正在运行的docker ps## 查看所有的docker ps -a查看日志1docker log -f &lt;容器 ID&gt;停止容器1234docker start &lt;容器 ID&gt;docker stop &lt;容器 ID&gt;# 停止的容器可以通过 docker restart 重启docker restart &lt;容器 ID&gt;进入容器在使用 -d 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入：1234# 这个命令在退出后容器也停止了docker attach &lt;容器 ID&gt;# 这个命令退出后容器继续运行docker exec &lt;容器 ID&gt; 3.1.2. 容器查看进入操作系统12345678# 进入一个正在运行的容器系统docker exec -it &lt;container id&gt; &#x2F;bin&#x2F;bash# 使用root账号登陆docker exec -it --user root &lt;container id&gt; &#x2F;bin&#x2F;bash# 开始运行一个容器，直接进入系统docker run -it &lt;container id&gt; &#x2F;bin&#x2F;bash# 开始运行一个容器，使用root直接进入系统docker run -it --user root &lt;container id&gt; &#x2F;bin&#x2F;bashdocker怎么修改容器的时间 3.1.3. 容器管理导出容器1docker export 1e560fca3906 &gt; ubuntu.tar导入容器123cat docker&#x2F;ubuntu.tar | docker import - test&#x2F;ubuntu:v1## url方式docker import http:&#x2F;&#x2F;example.com&#x2F;exampleimage.tgz example&#x2F;imagerepo删除容器1234docker rm -f 1e560fca3906或docker stop xxxdocker rm xxx查看容器占用资源123docker stats|grep xxx # 会一直跳进程docker stats xxx # 会一直跳进程docker stats --no-stream xxx 3.1.4. web服务123456#启动一个web容器docker pull training&#x2F;webapp# 使用-p方式进行容器端口和本机端口的映射docker run -d -P training&#x2F;webapp python app.py# 指定端口映射（将服务的5000端口映射到本机的5001端口）docker run -d -p 5001:5000 training&#x2F;webapp python app.py win7系统要使用docker tool创建的虚拟机主体验证1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSdefault * virtualbox Running tcp:&#x2F;&#x2F;192.168.99.100:2376 v19.03.12查看端口是否映射成功http://192.168.99.100:5001/ 3.1.5. 目录挂载1. volume 和 -v 的解释VOLUMEDockerfile中 VOLUME 方式挂载到宿主机上的是匿名卷，在宿主机上是自动匿名挂载到 /var/lib/docker/volumes/ 目录下的，代码如下：12345FROM frolvlad&#x2F;alpine-java:jre8-slimMAINTAINER oas.cloudCOPY nickdir .VOLUME &#x2F;usr&#x2F;local&#x2F;oas&#x2F;file&#x2F;WORKDIR &#x2F;usr&#x2F;local&#x2F;oas&#x2F;上述 VOLUME /usr/local/oas/file/ 定义的是容器内目录所在路径，在容器创建过程中会在容器中创建该目录，而宿主机上的挂载目录名是随机生成的，例如：/var/lib/docker/volumes/593fda6d7b8296bfca22894b326727c734133eebb11c9bc2c25a73b892157a37，这里宿主机上的/var/lib/docker/volumes/593fda6d7b8296bfca22894b326727c734133eebb11c9bc2c25a73b892157a37目录对应的就是容器中的 /usr/local/oas/file/ 目录docker -vdocker -v 可以指定挂载到宿主机的具体目录，相对于Dockerfile的 VOLUME 挂载方式更具有可控性，代码如下：123456$ docker run —name tengine-web -d -p 9527:80 -p 9000:9000 \\-v &#x2F;usr&#x2F;local&#x2F;tengine&#x2F;logs:&#x2F;var&#x2F;log&#x2F;nginx \\-v &#x2F;usr&#x2F;local&#x2F;tengine&#x2F;conf.d:&#x2F;etc&#x2F;nginx&#x2F;conf.d \\-v &#x2F;usr&#x2F;local&#x2F;tengine&#x2F;conf&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf \\-v &#x2F;usr&#x2F;local&#x2F;tengine&#x2F;html:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\-v &#x2F;usr&#x2F;local&#x2F;oas&#x2F;file:&#x2F;usr&#x2F;local&#x2F;oas&#x2F;file nginx上述命令就可以将宿主机的 /usr/local/tengine/logs 等目录挂载到容器的 /var/log/nginx 等对应目录，冒号前为宿主机目录（绝对路径），冒号后为镜像内挂载的路径（绝对路径）。 tips:镜像内挂载的路径如果不为空，好像挂载不到宿主机。 2. volume 和 -v的结合使用的理解 当Dockerfile中声明了匿名卷,但是run的时候没有使用-v绑定匿名卷的话,那么docker就会在/var/lib/docker/volumes这个目录下创建一个随机目录来绑定匿名卷。当Dockerfile中声明了匿名卷,run的时候使用-v，就将-v指定的目录绑定到容器的匿名卷。所以真正使用的时候我们在Dockerfile构建镜像的时候，最好去声明一个匿名卷，就算用户run的时候忘了指定，也可以将目录数据持久化存储。如：123456FROM centos:latestRUN groupadd -r redis &amp;&amp; useradd -r -g redis redisRUN yum -y update &amp;&amp; yum -y install epel-release &amp;&amp; yum -y install redis &amp;&amp; yum -y install net-toolsRUN mkdir -p &#x2F;config &amp;&amp; chown -R redis:redis &#x2F;configVOLUME &#x2F;share&#x2F;data #声明容器中&#x2F;share&#x2F;data为匿名卷EXPOSE 6379那么使用该Dockerfile构建镜像的为12345# docker build -t image-redis &#x2F;&#x2F;构建镜像image-redis......#docker run -d -it -name redis1 -v &#x2F;data:&#x2F;share&#x2F;data image-redis &#x2F;&#x2F;运行一个容器并且将当前机器的&#x2F;data目录绑定到容器的匿名卷中.....#docker run -d -it -name redis2 image-redis &#x2F;&#x2F;运行一个容器但是不绑定目录到容器的匿名卷，这时候再&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes（不同版本目录不一样）中就会创建一个目录绑定匿名卷 3. 数据卷共享如果要授权一个容器访问另一个容器的Volume，我们可以使用-volumes-from参数来执行docker run 3.2. 镜像管理查看镜像12docker imagesdocker image ls 获取镜像(相同标签不同代码的时候，可以强制更新)1docker pull &lt;image&gt;查找镜像1docker search &lt;image&gt;删除镜像1234docker rmi &lt;image&gt;docker image rm &lt;image&gt;# 强制删除docker image rm -f &lt;image&gt;创建镜像1、从已经创建的容器中更新镜像，并且提交这个镜像2、使用 Dockerfile 指令来创建一个新的镜像1docker build -t imagename:&#123;version&#125; .重命名镜像1234docker tag IMAGEID(镜像id) REPOSITORY:TAG（仓库：标签）#例子docker tag ca1b6b825289 registry.cn-hangzhou.aliyuncs.com&#x2F;xxxxxxx:v1.0docker run -d -v /data/registry/images:/var/lib/registry -p 8002:5000 —restart=always —name xdp-registry registry 3.3. dockerfile修改镜像时间，宿主机与容器时间相差8小时1RUN &#x2F;bin&#x2F;cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime &amp;&amp; echo &#39;Asia&#x2F;Shanghai&#39; &gt;&#x2F;etc&#x2F;timezone 4. 维护Docker 空间清理和目录迁移 123456查看Docker的磁盘使用情况:类似于Linux上的df命令docker system df清理磁盘，删除关闭的容器、无用的数据卷和网络，以及dangling镜像(即无tag的镜像)docker system prune清理得更加彻底，可以将没有容器使用Docker镜像都删掉。注意，这两个命令会把你暂时关闭的容器，以及暂时没有用到的Docker镜像都删掉了…所以使用之前一定要想清楚.。我没用过，因为会清理 没有开启的 Docker 镜像。docker system prune -a","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"},{"name":"Docker","slug":"Docker","permalink":"https://tlylft.github.io/tags/Docker/"}]},{"title":"Flask框架底层的WSGI server","slug":"python/Flask/flask_wsgi","date":"2020-09-20T02:48:43.000Z","updated":"2021-06-11T03:29:08.697Z","comments":true,"path":"python/Flask/flask_wsgi/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_wsgi/","excerpt":"","text":"https://www.liaoxuefeng.com/wiki/1016959663602400/1017805733037760 https://juejin.im/post/6844903863229612040","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"动态词向量算法（ELMo,GPT,BERT）","slug":"NLP/word2vec/word2vec_dynamic","date":"2020-08-28T09:05:06.000Z","updated":"2020-08-28T09:09:12.890Z","comments":true,"path":"NLP/word2vec/word2vec_dynamic/","link":"","permalink":"https://tlylft.github.io/NLP/word2vec/word2vec_dynamic/","excerpt":"","text":"ELMo,GPT,BERT对比https://blog.csdn.net/sinat_25394043/article/details/103422018（1）特征提取器：elmo采用LSTM进行提取，GPT和bert则采用Transformer进行提取。很多任务表明Transformer特征提取能力强于LSTM，elmo采用1层静态向量+2层LSTM，多层提取能力有限，而GPT和bert中的Transformer可采用多层，并行计算能力强。 （2）单/双向语言模型： GPT采用单向语言模型，elmo和bert采用双向语言模型。但是elmo实际上是两个单向语言模型（方向相反）的拼接，这种融合特征的能力比bert一体化融合特征方式弱。GPT和bert都采用Transformer，Transformer是encoder-decoder结构，GPT的单向语言模型采用decoder部分，decoder的部分见到的都是不完整的句子；bert的双向语言模型则采用encoder部分，采用了完整句子。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"word2vec","slug":"NLP/word2vec","permalink":"https://tlylft.github.io/categories/NLP/word2vec/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"word2vec","slug":"word2vec","permalink":"https://tlylft.github.io/tags/word2vec/"}]},{"title":"交叉验证","slug":"machine_learning/cross_validation","date":"2020-08-24T15:21:39.000Z","updated":"2020-08-28T08:05:46.922Z","comments":true,"path":"machine_learning/cross_validation/","link":"","permalink":"https://tlylft.github.io/machine_learning/cross_validation/","excerpt":"","text":"交叉验证交叉验证是机器学习建模中非常非常重要的一步，也是大多数人所说的“调参”的过程。 常用的交叉验证技术叫做K折交叉验证(K-fold Cross Validation)。 我们先把训练数据再分成n批次的训练集和验证集，之后使用训练集来训练模型，然后再验证集上评估模型的准确率，(取平均值保证score的稳定性)。举个例子，比如一个模型有个参数叫$\\alpha$，我们一开始不清楚要选择0.1还是1，所以这时候我们进行了交叉验证：把所有训练集分成K块，依次对每一个$\\alpha$值 进行k次训练评估它的准确率均值。 在交叉验证中经常使用K折交叉验证，就是在已有的数据上重复做多次的验证。为什么需要这么做？为了给每个超参数的值评测出来的结果更加稳定。在K折交叉验证中，什么时候需要取较大的K值？一般情况下数据量较少的时候我们取的K值会更大，因为数据量较少的时候如果每次留出比较多的验证数据，对于训练模型本身来说是比较吃亏的，所以这时候我们尽可能使用更多的数据来训练模型。由于每次选择的验证数据量较少，这时候K折中的K值也会随之而增大，但到最后可以发现，无论K值如何选择，用来验证的样本个数都是等于总样本个数。 实现KNN的交叉验证代码（手写）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import numpy as npfrom sklearn import datasetsfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import KFold # 交叉iris &#x3D; datasets.load_iris()X &#x3D; iris.datay &#x3D; iris.targetprint(X.shape, y.shape)# 定义需要搜索设定的K值ks &#x3D; [1,3,5,7,9,11,13,15]# Kfold 设置分为5堆进行交叉验证kf &#x3D; KFold(n_splits &#x3D; 5, random_state&#x3D;2001, shuffle&#x3D;True)best_k &#x3D; ks[0]best_score &#x3D; 0# 循环超参数k值for k in ks: curr_score &#x3D; 0 # 循环k-folder的k次划分 for train_index,valid_index in kf.split(X): #print(train_index) cls &#x3D; KNeighborsClassifier(n_neighbors&#x3D;k) cls.fit(X[train_index], y[train_index]) curr_score +&#x3D; cls.score(X[valid_index], y[valid_index]) # 每个超参数值 取平均 获得稳定的score avg_score &#x3D; curr_score&#x2F;5 # 评价哪一个超参数值效果最好 if avg_score &gt; best_score: best_k &#x3D; k best_score &#x3D; avg_score print(&quot;current best score is %.2f&quot;%best_score,&quot;best_k:%d&quot;%best_k)print(&quot;after cross validation, the final best k is: %d&quot;%best_k)&gt;&gt;output:current best score is 0.96 best_k:1current best score is 0.96 best_k:1current best score is 0.97 best_k:5current best score is 0.98 best_k:7current best score is 0.98 best_k:7current best score is 0.98 best_k:7current best score is 0.98 best_k:7current best score is 0.98 best_k:7after cross validation, the final best k is: 7 实现KNN的交叉验证代码 GridSearchCV123456789101112131415161718from sklearn import datasetsfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import GridSearchCV # 通过网格方式搜索参数iris &#x3D; datasets.load_iris()X &#x3D; iris.datay &#x3D; iris.target# 定义需要搜索设定的K值ks &#x3D; [1,3,5,7,9,11,13,15]parameters &#x3D; &#123;&#39;n_neighbors&#39;:ks&#125; # n_neighbors是Knn需要传入的参数knn &#x3D; KNeighborsClassifier()# 是封装好的网格搜索的模型，实现了对每个参数进行模型评估, 训练集clf &#x3D; GridSearchCV(knn, parameters, cv&#x3D;5)clf.fit(X,y)print(&quot;current best score is %.2f&quot;%clf.best_score_,&quot;best_k:&quot;,clf.best_params_)","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[]},{"title":"【Leecode】动态规划","slug":"leecode/DP","date":"2020-08-23T12:30:24.000Z","updated":"2023-08-11T07:52:48.952Z","comments":true,"path":"leecode/DP/","link":"","permalink":"https://tlylft.github.io/leecode/DP/","excerpt":"","text":"当把一个大问题拆解成一堆小问题时，而这些小问题会出现被重复计算的情况下，动态规划的目的就是解决这些小问题重复调用的情况,避免重复的计算。 动态规划在NLP中的应用：维特比算法、拼写纠错（编辑距离） Fibonacci sequence1,1,2,3,5,8,13,21…,第n个数等于多少？如果用递归方式去解决，那它的时间复杂度为$O(n^2)$，空间复杂度为$O(n)$而使用动态规划，每次只存储两个记忆的数值，就避免了这类问题。12345678910def fib_dp(n): a,b &#x3D; 1,1 c &#x3D; 0 if n &#x3D;&#x3D; 0: return a if n &#x3D;&#x3D; 1: return b for i in range(2,n): c &#x3D; a + b a &#x3D; b b &#x3D; c return c Maximum Value Continuous Subsequence给定一组数组，寻找子数组使得它们之和最大输入: nums = [-2,1,-3,4,-1,2,1,-5,4]输出: 6解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。123456789def maxSubArray(self, nums: List[int]) -&gt; int: max_sum &#x3D; -99999 last_max &#x3D; 0 for num in nums: last_max &#x3D; (last_max + num) if (last_max + num) &gt; num else num max_sum &#x3D; last_max if last_max &gt; max_sum else max_sum return max_sum 找零、爬楼梯问题提供1，3，5面值的硬币，再给个目标值（23），怎样使给零钱的数量最少？ 背包问题假设背包能装9kg的东西，现在有五个物品分别是2，2，4，6，3kg，在不超过背包容量的范围内，能装的最大值是多少呢？ 最短路径$min_dist(i, j) = w[i][j] + min(min_dist(i, j-1), min_dist(i-1, j))$ Edit Distance设A和B是两个字符串，要用最少的字符操作将字符串A转换为字符串B，这里所说的字符操作包括（1）删除一个字符；（2）插入一个字符；（3）修改一个字符。将A转换为B所用的最少字符操作数称为A到B的编辑距离，记为d[A][B]，d[][]中的A，B指的是A和B的长度，设计一个算法对任给的A，B，计算出d[A][B]https://blog.csdn.net/dms2017/article/details/90261238 定义一个 n+1 * m+1 的矩阵，每个点代表从word1[i]到word2[j]的最短编辑距离 参考最短路径的思想，每个点参照的是左边，上边，左上三个算出来的距离。对于每个点matrix[i,j]从左边 matrix[i, j-1]的状态 变换到matrix[i,j]的状态，相当于一个insert操作，编辑距离+1从上边 matrix[i-1, j]的状态 变换到matrix[i,j]的状态，相当于一个delete操作，编辑距离+1从左上边 matrix[i-1, j-1]的状态 变换到matrix[i,j]的状态，相当于一个replace操作，如果两个字符相同，不需要replace，则编辑距离+0, 如果两个字符不同，需要replace，则编辑距离+1123456789101112131415161718192021222324252627word1 &#x3D; &quot;horse&quot;word2 &#x3D; &quot;ros&quot;n &#x3D; len(word1)m &#x3D; len(word2)#定义一个 n+1 * m+1 的矩阵，每个点代表从word1[i]到word2[j]的最短编辑距离res &#x3D; [[0]*(m+1) for _ in range(n+1)]# n行m列# 初始化 默认参照行和列for i in range(1, n+1): res[i][0] &#x3D; res[i-1][0] + 1for i in range(1, m+1): res[0][i] &#x3D; res[0][i-1] + 1#核心智力for i in range(1, n+1): for j in range(1, m+1): if word1[i-1] &#x3D;&#x3D; word2[j-1]: res[i][j] &#x3D; res[i-1][i-1] else: res[i][j] &#x3D; min(res[i-1][j]+1, res[i][j-1]+1, res[i-1][j-1]+1) print(res)print(res[-1][-1]) DTW Dynamic Time Warping 动态时间规整DTW是一种衡量两个时间序列之间的相似度的方法，主要应用在语音识别领域来识别两段语音是否表示同一个单词。warping 可以理解成是在寻找点和点的对应关系DTW 是在寻找两短语音之间最好的对应关系。找到所有的对应path里差异最小的对应情况。 第一段语音的开始连接第二段语音的开始，第一段语音的结尾连接第二段语音的结尾节点 non-overlapping 不允许节点关系有交叉，确保在矩阵表中计算方向是一致的（如下图：计算方向为向上和向右，满足动态规划的计算）。 允许有跳跃节点，也就是这个节点在另一段语音中没有对应关系。 不同的rule给不同的权重 https://www.cnblogs.com/ningjing213/p/10502519.html12345678910111213141516171819202122232425262728293031323334def dtw_distance(ts_a, ts_b, d&#x3D;lambda x,y: abs(x-y), mww&#x3D;10000): &quot;&quot;&quot;Computes dtw distance between two time series Args: ts_a: time series a ts_b: time series b d: distance function mww: max warping window, int, optional (default &#x3D; infinity) Returns: dtw distance &quot;&quot;&quot; # Create cost matrix via broadcasting with large int ts_a, ts_b &#x3D; np.array(ts_a), np.array(ts_b) M, N &#x3D; len(ts_a), len(ts_b) cost &#x3D; np.ones((M, N)) # Initialize the first row and column cost[0, 0] &#x3D; d(ts_a[0], ts_b[0]) for i in range(1, M): cost[i, 0] &#x3D; cost[i-1, 0] + d(ts_a[i], ts_b[0]) for j in range(1, N): cost[0, j] &#x3D; cost[0, j-1] + d(ts_a[0], ts_b[j]) # Populate rest of cost matrix within window for i in range(1, M): for j in range(max(1, i - mww), min(N, i + mww)): choices &#x3D; cost[i-1, j-1], cost[i, j-1], cost[i-1, j] cost[i, j] &#x3D; min(choices) + d(ts_a[i], ts_b[j]) # Return DTW distance given window return cost[-1, -1] 代码比对，一般不采取这种方法，而是构造一个逻辑树，比对两颗树的相似度 viterbi","categories":[{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/categories/Leecode/"}],"tags":[{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/tags/Leecode/"}]},{"title":"语言模型","slug":"NLP/language_model","date":"2020-08-22T01:44:22.000Z","updated":"2020-09-01T01:38:19.793Z","comments":true,"path":"NLP/language_model/","link":"","permalink":"https://tlylft.github.io/NLP/language_model/","excerpt":"","text":"语言模型 Language Modelwhat is Language Model 用来判断一句话从语法上是否通顺，可以应用于联想输入法，搜索引擎的联想， 从以下三个方面去定义语言模型： 语法，语义，通顺性 1. n-gram modelhttps://zhuanlan.zhihu.com/p/32829048 1.1. 什么是n-gramN-Gram是一种基于统计语言模型的算法。它的基本思想是将文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。 每一个字节片段称为gram，对所有gram的出现频度进行统计，并且按照事先设定好的阈值进行过滤，形成关键gram列表，也就是这个文本的向量特征空间，列表中的每一种gram就是一个特征向量维度。 该模型基于这样一种假设，第N个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram。 1.2. 原理过程我们有一个由 m 个词组成的序列（或者说一个句子），我们希望算这个词序列的概率。P(全民AI是趋势) = P(全民,AI,是,趋势)这个表示不好算，所以采用chain rule为什么n-gram model生成概率要考虑的前置条件太多，概率也不好算，关联性不强，所以只考虑前几个token。markov assumption预测的概率只和前n个最近的token相关。即当前这个词仅仅跟前面几个有限的词相关，因此也就不必追溯到最开始的那个词，这样便可以大幅缩减上述算式的长度。 概率计算： 共现有顺序要求，要考虑概率为0的情况做smooth。如何训练：训练模型用极大似然MLE 如何评价： 困惑度perplexity： average log likelihoodlikelihood 是语言模型的表示，选取概率最大的表示。log 是为了将乘法变成加法，使变得平滑 x越大， perplexity越小，模型越好为什么使用2，可以看一下entropy的概念，启发式的做法。 LME的理解：最大化序列的概率。在n-gram里，是基于统计，count，这个概率值count出来是不变的。所以极大似然取argmax最大就行了。在神经网络，是在训练这个概率，目标函数是使概率值最大，概率值是会一直变化的，极大似然就是训练使概率最大。 smoothing+1是为了避免概率为0的现象， +V V是语料库的总词数。 是做归一化，保证整体加起来还是等于1。举个例子： 文本纠错 grammarly 编辑距离没有考虑语境，需要加入上下文的内容。 错误的单词怎么识别？两个词连接的概率很低，或者单词本身就不是正确的单词。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"torch 简介","slug":"pytorch/torch_intro","date":"2020-08-18T07:41:07.000Z","updated":"2021-08-25T06:01:46.384Z","comments":true,"path":"pytorch/torch_intro/","link":"","permalink":"https://tlylft.github.io/pytorch/torch_intro/","excerpt":"","text":"指路链接：官方文档：https://pytorch.org/docs/stable/index.html中文文档：https://pytorch-cn.readthedocs.io/zh/latest/学习不迷路：https://github.com/xiaotudui/PyTorch-Tutorialhttps://www.bilibili.com/video/av74281036/莫凡demo:https://github.com/MorvanZhou/PyTorch-Tutorialhttps://www.bilibili.com/video/BV1Vx411j7kT?p=5https://mofanpy.com/tutorials/machine-learning/torch/why/ 1. 介绍1.1. whyPyTorch 是 PyTorch 在 Python 上的衍生. 因为 PyTorch 是一个使用 PyTorch 语言的神经网络库, Torch 很好用, 但是 Lua 又不是特别流行, 所有开发团队将 Lua 的 Torch 移植到了更流行的语言 Python 上. 是的 PyTorch 一出生就引来了剧烈的反响. 1.2. 特点灵活类似numpy，语言更加python新版本优化了运行速度cuda,算法后，torch就和tensorflow差不多了 1.3. 区别pytorch vs numpy我们使用Numpy也是可以手动去编写神经网络进行反向传播深度学习的，就是有两个问题， 1.Numpy手动去编写神经网络很繁琐，代码量较大，不利于大规模开发；2.Numpy无法直接使用GPU加速计算 看到网上有很多人说PyTorch很好用，比TensorFlow优雅便捷。个人认为其中一个很主要的原因PyTorch很类似与Numpy，对数据操作处理很简单。并且PyTorch是支持使用GPU加速的，所以有人比喻PyTorch是GPU版本的Numpy。pytorch vs tensorflowtensorflow是构建的静态图，而pytorch是实时构建动态图。如何理解呢？据 PyTorch 自己介绍, 他们家的最大优点就是建立的神经网络是动态的, 对比静态的 Tensorflow, 他能更有效地处理一些问题, 比如说 RNN 变化时间长度的输出. 而我认为, 各家有各家的优势和劣势, 所以我们要以中立的态度. 两者都是大公司, Tensorflow 自己说自己在分布式训练上下了很大的功夫, 那我就默认 Tensorflow 在这一点上要超出 PyTorch, 但是 Tensorflow 的静态计算图使得他在 RNN 上有一点点被动 (虽然它用其他途径解决了), 不过用 PyTorch 的时候, 你会对这种动态的 RNN 有更好的理解. 而且 Tensorflow 的高度工业化, 它的底层代码… 你是看不懂的. PyTorch 好那么一点点, 如果你深入 API, 你至少能比看 Tensorflow 多看懂一点点 PyTorch 的底层在干嘛. 2. 安装pytorch 安装参考链接：https://github.com/xiaotudui/PyTorch-Tutorial/blob/master/Tutorial/P1.%20PyTorch%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%AE%89%E8%A3%85.md或 GPU安装：https://www.jianshu.com/p/02c96485c100linux gpu安装http://localhost:4000/linux/linux_gpu/ 下载命令官网地址：https://pytorch.org/get-started/previous-versions/ 1234567# CUDA 11.1pip install torch&#x3D;&#x3D;1.8.0+cu111 torchvision&#x3D;&#x3D;0.9.0+cu111 torchaudio&#x3D;&#x3D;0.8.0 -f https:&#x2F;&#x2F;download.pytorch.org&#x2F;whl&#x2F;torch_stable.html# CUDA 10.2pip install torch&#x3D;&#x3D;1.8.0 torchvision&#x3D;&#x3D;0.9.0 torchaudio&#x3D;&#x3D;0.8.0# CPU onlypip install torch&#x3D;&#x3D;1.8.0+cpu torchvision&#x3D;&#x3D;0.9.0+cpu torchaudio&#x3D;&#x3D;0.8.0 -f https:&#x2F;&#x2F;download.pytorch.org&#x2F;whl&#x2F;torch_stable.html 123conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;pytorchconda config --set show_channel_urls yesconda install pytorch&#x3D;1.8.1 torchvision cudatoolkit&#x3D;10.2 验证：123456import torchtorch.cuda.is_available()# True 表示GPU安装成功torch.cuda.get_device_name() # GeForce RTX 2070 Supertorch.version.cudatorch.backends.cudnn.version() transformers安装12conda install transformerspip install transformers","categories":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/categories/pytorch/"}],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/tags/pytorch/"}]},{"title":"Navicat Premium数据库密码转义","slug":"tools/navicat_pw","date":"2020-08-18T07:24:48.000Z","updated":"2020-08-18T07:32:21.936Z","comments":true,"path":"tools/navicat_pw/","link":"","permalink":"https://tlylft.github.io/tools/navicat_pw/","excerpt":"","text":"Navicat Premium数据库密码转义https://blog.csdn.net/javaliuzhiyue/article/details/90297579 导出连接文件文件-&gt; 导出链接选择相关的数据库连接，导出 获取加密后的密码 一段大神写的密码恢复的PHP代码GitHub上一个大神写了一个PHP，可以直接破解这个密码，一切成功的开始。https://github.com/tianhe1986/FatSmallTools 本地没有安装PHP，so直接找个在线运行的工具https://tool.lu/coderunner/ 粘贴代码，修改参数，一切顺利 执行代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143&lt;?phpnamespace FatSmallTools;class NavicatPassword&#123; protected $version &#x3D; 0; protected $aesKey &#x3D; &#39;libcckeylibcckey&#39;; protected $aesIv &#x3D; &#39;libcciv libcciv &#39;; protected $blowString &#x3D; &#39;3DC5CA39&#39;; protected $blowKey &#x3D; null; protected $blowIv &#x3D; null; public function __construct($version &#x3D; 12) &#123; $this-&gt;version &#x3D; $version; $this-&gt;blowKey &#x3D; sha1(&#39;3DC5CA39&#39;, true); $this-&gt;blowIv &#x3D; hex2bin(&#39;d9c7c3c8870d64bd&#39;); &#125; public function encrypt($string) &#123; $result &#x3D; FALSE; switch ($this-&gt;version) &#123; case 11: $result &#x3D; $this-&gt;encryptEleven($string); break; case 12: $result &#x3D; $this-&gt;encryptTwelve($string); break; default: break; &#125; return $result; &#125; protected function encryptEleven($string) &#123; $round &#x3D; intval(floor(strlen($string) &#x2F; 8)); $leftLength &#x3D; strlen($string) % 8; $result &#x3D; &#39;&#39;; $currentVector &#x3D; $this-&gt;blowIv; for ($i &#x3D; 0; $i &lt; $round; $i++) &#123; $temp &#x3D; $this-&gt;encryptBlock($this-&gt;xorBytes(substr($string, 8 * $i, 8), $currentVector)); $currentVector &#x3D; $this-&gt;xorBytes($currentVector, $temp); $result .&#x3D; $temp; &#125; if ($leftLength) &#123; $currentVector &#x3D; $this-&gt;encryptBlock($currentVector); $result .&#x3D; $this-&gt;xorBytes(substr($string, 8 * $i, $leftLength), $currentVector); &#125; return strtoupper(bin2hex($result)); &#125; protected function encryptBlock($block) &#123; return openssl_encrypt($block, &#39;BF-ECB&#39;, $this-&gt;blowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); &#125; protected function decryptBlock($block) &#123; return openssl_decrypt($block, &#39;BF-ECB&#39;, $this-&gt;blowKey, OPENSSL_RAW_DATA|OPENSSL_NO_PADDING); &#125; protected function xorBytes($str1, $str2) &#123; $result &#x3D; &#39;&#39;; for ($i &#x3D; 0; $i &lt; strlen($str1); $i++) &#123; $result .&#x3D; chr(ord($str1[$i]) ^ ord($str2[$i])); &#125; return $result; &#125; protected function encryptTwelve($string) &#123; $result &#x3D; openssl_encrypt($string, &#39;AES-128-CBC&#39;, $this-&gt;aesKey, OPENSSL_RAW_DATA, $this-&gt;aesIv); return strtoupper(bin2hex($result)); &#125; public function decrypt($string) &#123; $result &#x3D; FALSE; switch ($this-&gt;version) &#123; case 11: $result &#x3D; $this-&gt;decryptEleven($string); break; case 12: $result &#x3D; $this-&gt;decryptTwelve($string); break; default: break; &#125; return $result; &#125; protected function decryptEleven($upperString) &#123; $string &#x3D; hex2bin(strtolower($upperString)); $round &#x3D; intval(floor(strlen($string) &#x2F; 8)); $leftLength &#x3D; strlen($string) % 8; $result &#x3D; &#39;&#39;; $currentVector &#x3D; $this-&gt;blowIv; for ($i &#x3D; 0; $i &lt; $round; $i++) &#123; $encryptedBlock &#x3D; substr($string, 8 * $i, 8); $temp &#x3D; $this-&gt;xorBytes($this-&gt;decryptBlock($encryptedBlock), $currentVector); $currentVector &#x3D; $this-&gt;xorBytes($currentVector, $encryptedBlock); $result .&#x3D; $temp; &#125; if ($leftLength) &#123; $currentVector &#x3D; $this-&gt;encryptBlock($currentVector); $result .&#x3D; $this-&gt;xorBytes(substr($string, 8 * $i, $leftLength), $currentVector); &#125; return $result; &#125; protected function decryptTwelve($upperString) &#123; $string &#x3D; hex2bin(strtolower($upperString)); return openssl_decrypt($string, &#39;AES-128-CBC&#39;, $this-&gt;aesKey, OPENSSL_RAW_DATA, $this-&gt;aesIv); &#125;&#125;use FatSmallTools\\NavicatPassword;&#x2F;&#x2F;需要指定版本，11或12$navicatPassword &#x3D; new NavicatPassword(12);&#x2F;&#x2F;$navicatPassword &#x3D; new NavicatPassword(11);&#x2F;&#x2F;解密$decode &#x3D; $navicatPassword-&gt;decrypt(&#39;B0BE0C4D50BABBBA8C2B747003649520&#39;);&#x2F;&#x2F;$decode &#x3D; $navicatPassword-&gt;decrypt(&#39;73EFB530B74DCCE359F34539742ECD9E8D1FE826F5C263CE&#39;);echo $decode.&quot;\\n&quot;;","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"},{"name":"navicat","slug":"navicat","permalink":"https://tlylft.github.io/tags/navicat/"}]},{"title":"多模态学习","slug":"machine_learning/multimodal","date":"2020-08-18T06:54:07.000Z","updated":"2020-08-18T07:38:17.668Z","comments":true,"path":"machine_learning/multimodal/","link":"","permalink":"https://tlylft.github.io/machine_learning/multimodal/","excerpt":"","text":"什么是多模态学习？每一种信息的来源或者形式，都可以称为一种模态。例如，人有触觉，听觉，视觉，嗅觉；信息的媒介，有语音、视频、文字等；多种多样的传感器，如雷达、红外、加速度计等。以上的每一种都可以称为一种模态。 同时，模态也可以有非常广泛的定义，比如我们可以把两种不同的语言当做是两种模态，甚至在两种不同情况下采集到的数据集，亦可认为是两种模态。 因此，多模态机器学习，英文全称 MultiModal Machine Learning (MMML)，旨在通过机器学习的方法实现处理和理解多源模态信息的能力。目前比较热门的研究方向是图像、视频、音频、语义之间的多模态学习。 多模态学习从1970年代起步，经历了几个发展阶段，在2010后全面步入Deep Learning阶段。 探究方向多模态学习可以划分为以下五个研究方向： 多模态表示学习 Multimodal Representation 模态转化 Translation cv的模态转换成nlp的模态 对齐 Alignment 多模态融合 Multimodal Fusion 协同学习 Co-learning 难点不同模态的噪声的处理数据缺失的处理","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"Rasa框架解读（1）- rasa1.x调研","slug":"chatbot/rasa_01","date":"2020-08-10T01:20:20.000Z","updated":"2023-08-11T08:43:35.006Z","comments":true,"path":"chatbot/rasa_01/","link":"","permalink":"https://tlylft.github.io/chatbot/rasa_01/","excerpt":"","text":"1. RASARasa是一个用于自动文本和基于语音的对话的开源机器学习框架。老版本中两个模块是被独立安装的，新版本中合并到一起了，需要自定义可以独自安装模块实现拓展。https://github.com/RasaHQ/rasa分为Rasa core和 Rasa nlu两个模块： 基于rasa nlu 实现自然语言理解用于理解用户消息，包括意图识别和实体识别，它会把用户的输入转换为结构化的数据。 基于rasa core实现对话管理是一个对话管理平台，用于举行对话和决定下一步做什么。 首先，将用户输入的Message传递到Interpreter(NLU模块)，该模块负责识别Message中的”意图(intent)“和提取所有”实体”(entity)数据；其次，Rasa Core会将Interpreter提取到的意图和识别传给Tracker对象，该对象的主要作用是跟踪会话状态(conversation state)；第三，利用policy记录Tracker对象的当前状态，并选择执行相应的action，其中，这个action是被记录在Track对象中的；最后，将执行action返回的结果输出即完成一次人机交互。领域识别，要判断是开放域的问题还是专业领域的问题。 demo:https://github.com/zqhZY/_rasa_chatbot 源码解读：https://zhuanlan.zhihu.com/p/231020989?utm_source=wechat_sessionhttps://zhuanlan.zhihu.com/p/231163197https://zhuanlan.zhihu.com/p/231199874https://zhuanlan.zhihu.com/p/76623359 https://mubu.com/doc/19aK8HlxFw# 1.1. simple-demo1.1.1. 安装rasa环境为rasa创建一个python环境，我用的python 3.7.4版本123456conda create -n rasa python&#x3D;3.7.4## 只安装rasapip install rasa ## 安装过程中依赖的包有很多，因为公司的网络经常出现中断的情况，中断的包可以一个个自己装## 安装rasa-x 和 rasapip install rasa-x --extra-index-url https:&#x2F;&#x2F;pypi.rasa.com&#x2F;simple安装后检查下numpy的版本号，太高运行会报错，我试了1.19.1可以。 1.1.2. 初始化/创建 一个rasa项目1rasa init 会创建一个项目目录 1.1.3. NLU训练1.1.3.1. 定义NLU训练数据定义NLU训练数据，可以是一个文件，也可以是一个目录。文件可以是markdown格式，也可以是json格式。https://rasa.com/docs/rasa/nlu/training-data-format/#training-data-formatdata/nlu.md markdown 有两种标注形式：12[&lt;entity text&gt;](&lt;entity name&gt;)[&lt;entity-text&gt;]&#123;&quot;entity&quot;: &quot;&lt;entity name&gt;&quot;&#125;第二种支持拓展同义词，角色和分组。分组是解决槽位多值的问题，e.g. 北京和上海的天气角色是解决一个实体多义的问题，e.g. 北京到上海的机票1[&lt;entity-text&gt;]&#123;&quot;entity&quot;: &quot;&lt;entity name&gt;&quot;, &quot;role&quot;: &quot;&lt;role name&gt;&quot;, &quot;group&quot;: &quot;&lt;group name&gt;&quot;, &quot;value&quot;: &quot;&lt;entity synonym&gt;&quot;&#125;nlu.md可以标注的东西包含：意图对应的训练预料同义词的语料正则表达式的配置查找表例子:123456789101112131415161718## intent:check_balance- what is my balance &lt;!-- no entity --&gt;- how much do I have on my [savings](source_account) &lt;!-- entity &quot;source_account&quot; has value &quot;savings&quot; --&gt;- how much do I have on my [savings account]&#123;&quot;entity&quot;: &quot;source_account&quot;, &quot;value&quot;: &quot;savings&quot;&#125; &lt;!-- synonyms, method 1--&gt;- Could I pay in [yen](currency)? &lt;!-- entity matched by lookup table --&gt;## intent:greet- hey- hello## synonym:savings &lt;!-- synonyms, method 2 --&gt;- pink pig## regex:zipcode- [0-9]&#123;5&#125;## lookup:additional_currencies &lt;!-- specify lookup tables in an external file --&gt;path&#x2F;to&#x2F;currencies.txt 1.1.3.2. 定义意图和动作：domain.ymlRasa基于intents、entities和当前对话的内部状态，从actions中选择下一步采取的行动。比如机器人选择utter_greet的话，就会从templates中找出相应的句子作为回复。也可以定义自己的action，作为python类来调用。 intents：NLU模型识别的意图； entities：NLU模型识别的实体； actions：机器人说和做的内容，比如问候对方、调用某个API、查询数据库等； slots：用来跟踪上下文和多轮对话的关键信息，具体参考slot types； templates：说话模板。1234567891011121314151617181920intents:#定义意图 - greet - goodbye - chat entities: - action templates:#表示对于相应的意图采取什么样的回复 utter_greet: - &quot;hello!&quot; utter_goodbye: - &quot;byebye :(&quot; utter_chat: - &quot;It seems like funny!&quot; actions:#定义bot可以采取的动作 - utter_greet - utter_goodbye - utter_chat pipline 的配置和选择https://blog.csdn.net/ljp1919/article/details/103960020/源码里的方法，中文可选用crf 1.1.4. rasa corehttps://blog.csdn.net/ling620/article/details/99845885Rasa Core包含两个内容： stories和domain。 domain.yml：包括对话系统所适用的领域，包含意图集合，实体集合和相应集合story.md：训练数据集合，原始对话在domain中的映射。 1.1.4.1. story是人为定义了一条一条故事线，可以通过启用交互服务，自动拓展故事线。也可以直接在这里定义。12345678910111213141516## Generated Story No7* greet - utter_greet* request_management&#123;&quot;package&quot;: &quot;\\u5957\\u9910&quot;&#125; - slot&#123;&quot;package&quot;: &quot;\\u5957\\u9910&quot;&#125; - utter_ask_package* inform&#123;&quot;package&quot;: &quot;\\u5957\\u9910\\u4e00&quot;&#125; - slot&#123;&quot;package&quot;: &quot;\\u5957\\u9910\\u4e00&quot;&#125; - utter_confirm* confirm - utter_ack_management - utter_ask_morehelp* deny - utter_goodbye* thanks - utter_thanks 1.1.4.2. policyhttps://www.jianshu.com/p/52c13eb39ab5https://www.jianshu.com/p/21808ac8d409rasa内置的是keras Lstm 对每个时刻的对话状态进行学习，最终的目标是训练出policy模型。KerasPolicy的模型很简单 LSTM+Dense+softmax。导致的问题是我们需要不断地完善自己的story，把各种情况下的story进行补充，花费了大量的人工。 所以后续会对policy策略进行复写和优化。更改模型或是增加一些调整策略。 1.2. 中文支持的rasa-nlu1.2.1. 官网支持的方式训练语料小于1000条可以采用mitie预训练中文词向量模型，默认可以加载wiki训练的词向量，大于1000条可以使用tensorflow_embedding，词向量转换后使用cos余弦相似度实现意图区分，但会有未登录词的问题。 nlp_mitiegithub贡献的中文rasa_nlu的配置文件常见的有两种，一种是 Rasa_NLU_Chi贡献的基于mitie预训练中文词向量模型，yml配置文件如下：12345678910language: &quot;zh&quot;pipeline:- name: &quot;nlp_mitie&quot; model: &quot;data&#x2F;total_word_feature_extractor_zh.dat&quot;- name: &quot;tokenizer_jieba&quot;- name: &quot;ner_mitie&quot;- name: &quot;ner_synonyms&quot;- name: &quot;intent_entity_featurizer_regex&quot;- name: &quot;intent_classifier_mitie&quot;安装mitiepip install git+https://github.com/mit-nlp/MITIE.git或下载https://github.com/mit-nlp/MITIE.git安装cmake：pip install cmake -i http://pypi.douban.com/simple/ —trusted-host pypi.douban.com到手的是mitie已经从github上下载好的包。可以解压后。cmd到文件夹路径下，然后运行python setup.py build , 然后再运行python setup.py install 来安装。最后, 直接pip install 文件夹的路径来安装 安装spacyhttps://blog.csdn.net/wangyizhen_nju/article/details/93623123pip install rasa[spacy]英文：python -m spacy download en_core_web_mdspacy link en_core_web_md en中文：python -m spacy download zh_core_web_sm(好像不行，用下面这个直接下载)https://github.com/howl-anderson/Chinese_models_for_SpaCy/releasespip install zh_core_web_sm-2.x.x.tar.gzpython -m spacy link zh_core_web_sm zh config.ymlhttps://rasa.com/docs/rasa/nlu/choosing-a-pipeline/1234567891011121314language: &quot;zh&quot;pipeline: &quot;pretrained_embeddings_spacy&quot;## is equal to language: &quot;zh&quot;pipeline:- name: &quot;SpacyNLP&quot;- name: &quot;SpacyTokenizer&quot;- name: &quot;SpacyFeaturizer&quot;- name: &quot;RegexFeaturizer&quot;- name: &quot;CRFEntityExtractor&quot;- name: &quot;EntitySynonymMapper&quot;- name: &quot;SklearnIntentClassifier&quot;语料ui界面https://github.com/paschmann/rasa-uihttps://rasahq.github.io/rasa-nlu-trainer/ 1.2.2. 中文rasa项目（Rasa_NLU_Chi 复写中文支持的Rasa NLU ）参考： https://blog.csdn.net/ling620/article/details/99845885 Rasa NLU曾经是一个独立的库，但它现在是Rasa框架的一部分。 Rasa_NLU是一个开源的、可本地部署并配套有语料标注工具RASA NLU Trainer。其本身可支持任何语言，中文因其特殊性需要加入特定的tokenizer作为整个流程的一部分。 Rasa_NLU_Chi 作为 Rasa_NLU 的一个 fork 版本，加入了jieba 作为中文的 tokenizer，实现了中文支持。可以理解为相当于rasa init后的项目中文支持下载地址：https://github.com/crownpku/Rasa_NLU_Chi 该部分简单介绍基于 Rasa_NLU_Chi 构建一个本地部署的特定领域的中文 NLU 系统的过程。 注意sklearn和numpy的版本号，否则运行过程中报 shape()不匹配的错误！12345# 训练模型python -m rasa_nlu.train -c sample_configs&#x2F;config_jieba_mitie_sklearn.yml --data data&#x2F;examples&#x2F;rasa&#x2F;demo-rasa_zh.json --path models# 运行nlu服务python -m rasa_nlu.server -c sample_configs&#x2F;config_jieba_mitie_sklearn.yml --path models训练过程demo里的Pipline自动化选取了crf的参数，也可以在自定义组件的时候将训练参数作为pipline的参数传递进来。 启动服务，用postman看一下rasa-nlu的输出： 1.2.3. 中文rasa项目（rasa-nlu-gao自定义组件）rasa对话系统踩坑记https://www.jianshu.com/p/5d9aa2a444a3项目代码：https://github.com/GaoQ1/rasa_chatbot_cnmagic function :https://github.com/GaoQ1/rasa_nlu_gq可以安装直接用，也可以拷贝下来在这个基础上参考它实现的方式再完善自己系统的继续拓展方法。 1.3. Pros and ConsPros Story 对话流程结构清晰 相对完整的对话工具 集成好的情况下，用户配置较灵活 Cons 基于机器学习，需要自定义的组件太多 源码中文支持不好，rasa-nlu模块需要替换为自定义的中文模块 NLU内嵌的算法较固定，如果选用其他模型，需要自定义延展 状态policy需要根据自己的系统需求进行自定义 受框架限制，延展相对不灵活 外部语料的嵌入 1.4. 迁移需要考虑的问题 语料需要重新标注，以前有些从逻辑上解决的问题转换成了语料问题 需要词向量训练 一个槽位多值的问题实现的效果 拼音转换（文本纠错）是否可以嵌入RASA 训练语料和分词器是否必须保持一致 自定义扩展的实现 槽位推荐的模块","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"}]},{"title":"【读书笔记】新员工指导人技巧","slug":"reading/director_skill","date":"2020-08-10T00:53:15.000Z","updated":"2023-08-10T12:02:11.617Z","comments":true,"path":"reading/director_skill/","link":"","permalink":"https://tlylft.github.io/reading/director_skill/","excerpt":"","text":"1. 第一周辅导计划2. 开始上手 - EDIP辅导技能educate -&gt; Demo -&gt; Imitate -&gt; practice讲解 -&gt; 示范 -&gt; 模仿 -&gt; 练习讲解清晰，可融入示范。 模仿讲解，不当纠偏， 反复练习，直到达标。教三练四： 3. 独挑大梁 - 协同辅导在计划执行中跟进，观察，及时反馈。 3.1. 步骤1：前期沟通 3.2. 步骤2：观察记录 确定观察主题(辅导计划工作或临时工作) 精确观察观察行为：观察说了什么，怎么说的，怎么做的，动作，字眼，语气，眼神，回应的速度等；越精确越好。观察结果：看达到的效果和目标的差距。精确的差距。 简单笔记 拉进与他的关系，可以作为证据作为反馈。不带思维局限性，不带有色眼镜，保持客观公正。3.3. 步骤3： 反馈反馈不是为了让对方高兴或是不高兴。经典三问：通过三个问题，让他自己反思，自我总结。 你有哪些方面做的比较好？ 如果再做一次，你会有哪些做的不一样？ 你学到了什么，今后再会怎么做？ 直接反馈： 回顾情景（情景细节越多，描述越清晰） 描述行为（行为描述，要具象） 传达影响（不是对企业，客户的影响，而是指导人自己的直观感受，如我觉得被看不起，我觉得做的太慢了，我感觉有些惊讶，我们平时并不是这么做的，对方无法反对你的个人体验）话术： 当你在做什么事情，做/说出什么行为时，我感到什么影响。 处理异议：反馈中产生了分歧意见，不要激化矛盾，要打开思路，开放接纳，优雅让步，让他主动思考。 使用激发思考/推测/比较 让我们从另一个角度去看，是什么原因导致对方的问题？ 如果你是客户接收到这样的信息，你会怎么想？ 你是否可以把竞争对手对待客户的方式，和我的建议做个对比。 转移注意力 行动计划：引言：为行动计划确定方向 那我们都同意，你对这件事还能做得更好是吧?/下次注意。讨论行动计划 询问被辅导者的观点 表达自己方案 对计划达成共识 总结：寻求被辅导者反馈：表达自己需要补充和澄清的内容。和询问对方对自己的建议 4. 面对迷茫和困惑 - 同理解决心理问题，解决迷茫和困惑。 增加压力和不自信 像是劝告，不能缓释压力 高高在上的指点，增加两人心理距离 暗含了责备，增加了愧疚感 推卸责任的说法，可以缓释，但对未来工作态度产生不好的影响 只反应了客观情绪，推荐这种说法。 4.1. 同理心同理是跟着对方的感觉走，只表达对方的事实和情感。例：抱怨情景：我遇到问题没有人解答识别： 【事实】向王姐请教没有获得指导 【情感】自卑、无助、焦急反馈：遇到问题得不到解答，总觉得没学到东西，你应该很着急，让我们看看怎么可以处理这种情况。 4.2. 倾听一般反馈完，并不是立刻需要给解决方案，而是被指导人会继续有倾诉的欲望。这时需要良好的倾听。怎么听？获得对方的信任，激发对方的倾诉欲望，提倡五位一体的倾听方式，用耳听，用眼看，用嘴问，用脑思考，用心感受。 保持开放和放松的姿态 端正坐姿面对对方，身体倾向对方 眼神接触或身体语言 提问或重复以确认听到的内容 保持客观冷静，不做评判 集中精力听出逻辑 听什么？核心信息是什么？贯穿始终的主题是什么？他的观点是什么？对他重要的是什么？避免消极提问，转换为积极提问。消极提问一般是以抱怨，责备的语气出现，积极提问是以解决问题的基础出现。 4.3. ABC理论情绪不是由事件所引起的，而是由经历了这一事件的人对事件的解释和评价引起的。 心理疏导过程： 问询阶段：先找出激发事件（A）;询问被辅导者对此事件的干手机反应，找出C;询问为何会有这样的情绪，逐步找出非理性信念B. 领悟阶段：帮助被辅导者识别非理性信念；分析指出不合理所在（D） 疏通阶段：以理性新年取代非理性信念（E）建立新的合理信念","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"BERT（3）文本分类","slug":"NLP/transformer/bert_classification","date":"2020-08-07T05:50:08.000Z","updated":"2021-11-12T03:00:33.077Z","comments":true,"path":"NLP/transformer/bert_classification/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/bert_classification/","excerpt":"","text":"bert部分可以直接用，也可以微调后再用 l","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"ELMO","slug":"NLP/word2vec/ELMO","date":"2020-08-07T01:29:06.000Z","updated":"2020-08-07T01:36:21.076Z","comments":true,"path":"NLP/word2vec/ELMO/","link":"","permalink":"https://tlylft.github.io/NLP/word2vec/ELMO/","excerpt":"","text":"不同的任务生成向量是不一样的，因为依赖的是上下文。 有多少层，每层干什么的？ 依赖关系是根据任务的不同去选择的。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"word2vec","slug":"NLP/word2vec","permalink":"https://tlylft.github.io/categories/NLP/word2vec/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"word2vec","slug":"word2vec","permalink":"https://tlylft.github.io/tags/word2vec/"}]},{"title":"BP 神经网络","slug":"deep_learning/BP","date":"2020-08-05T00:50:26.000Z","updated":"2021-03-01T02:17:40.461Z","comments":true,"path":"deep_learning/BP/","link":"","permalink":"https://tlylft.github.io/deep_learning/BP/","excerpt":"","text":"这篇文章详细做了两层神经网络的反向传播推导。一文弄懂神经网络中的反向传播法——BackPropagation BP从左到右是计算的关系，从右向左是求导（梯度）的关系。 激活函数，梯度消失的问题：浅层网络一般使用sigmoid和tanh没什么问题，深度网络在x值越来越大的时候，变化趋于0了。介绍一下从右向左的步骤，也就是BP反向传播。首先， 先对流程有个了解： 所有的x值我们是已知给定的，也就是实例，f(x)是我们的预测值，也可是说期待的值。 w是我们一开始随机给定的一种变换梯度，假设我们随机给定了w，从左到右的过程就是实现了一次模拟的预测，当我们发现这个预测值和我们期待的并不太吻合时，需要从右向左做一次反向传播，返回给左边我们期待的调整信息。怎么得到这个信息呢，就是用反向的求导，根据每步计算公式的导数，反推回每一步参数对f(x)的影响梯度是多少。大概就是用上一步反推出的输出值（红色的）乘以这一个公式的导数公式，求导的x值用正向计算时在这一步的x值，得到再向前反推的新的输出值。一直计算到网络最初的w,就能得到w值需要调整的梯度。sigmoid求导的特殊性 导数$\\cfrac {\\delta(x)} {dx} = (1- \\delta(x)) \\delta(x)$，所以可以直接将sigmoid gate那部分看成一个整体直接计算，直接推算出在sigmoid之前的那一步的输出值。算出了w的梯度。就可以y应用$w_0 = w_0 + \\alpha \\nabla w_0 $得到调整的新的$w_0$的值了。其他w的值也同理。 $\\alpha$是学习率，可设置成0.1后在调整。 我们通常讲的梯度下降，外面还会再套一层误差函数或损失函数。$E(x) = \\Sigma (y^{(i)} - f^{(i)})$， 去求对于误差函数的梯度，以此来降低误差。 所以神经网络重要的是构建出一个可被优化求导的损失函数。如果不是可求导的，那就构建一个。","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"梯度消失和梯度爆炸","slug":"deep_learning/gradient","date":"2020-08-05T00:49:33.000Z","updated":"2020-08-05T00:50:06.693Z","comments":true,"path":"deep_learning/gradient/","link":"","permalink":"https://tlylft.github.io/deep_learning/gradient/","excerpt":"","text":"https://segmentfault.com/a/1190000023465065 https://blog.csdn.net/dulingtingzi/article/details/80254038","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"LSTM","slug":"deep_learning/LSTM","date":"2020-08-04T10:09:21.000Z","updated":"2023-06-26T08:20:57.398Z","comments":true,"path":"deep_learning/LSTM/","link":"","permalink":"https://tlylft.github.io/deep_learning/LSTM/","excerpt":"","text":"LSTM参考博文: https://wmathor.com/index.php/archives/1397/ https://colah.github.io/posts/2015-08-Understanding-LSTMs/ （原文） 译 理解 LSTM 网络 （译文）pytorch lstmpytorch bilstm 1. LSTM (Long short term memory)概述a special case of RNN , solve long term dependency problems. introdeced in 1997.本身是一种RNN, 会将上一时刻的状态传递给下一时刻，但是穿插了很多的类似于门电路的概念。 解决问题：I grow up in French, …. I speak (Frence/Chinese/English).这个问题基本的RNN不能解决，因为时间序列太长存在梯度消失的问题。LSTM的提出就是解决这种长时记忆的问题。 2. RNN网络结构问题RNN人类并不是每时每刻都从一片空白的大脑开始他们的思考。在你阅读这篇文章时候，你都是基于自己已经拥有的对先前所见词的理解来推断当前词的真实含义。我们不会将所有的东西都全部丢弃，然后用空白的大脑进行思考。我们的思想拥有持久性。 传统的神经网络并不能做到这点，看起来也像是一种巨大的弊端。例如，假设你希望对电影中的每个时间点的时间类型进行分类。传统的神经网络应该很难来处理这个问题——使用电影中先前的事件推断后续的事件。 RNN 解决了这个问题。RNN 是包含循环的网络，允许信息的持久化。链式的特征揭示了 RNN 本质上是与序列和列表相关的。他们是对于这类数据的最自然的神经网络架构。并且 RNN 也已经被人们应用.在过去几年中，应用 RNN 在语音识别，语言建模，翻译，图片描述等问题上已经取得一定成功，并且这个列表还在增长。 长期依赖的问题RNN 的关键点之一就是他们可以用来连接先前的信息到当前的任务上，例如使用过去的视频段来推测对当前段的理解。如果 RNN 可以做到这个，他们就变得非常有用。但是真的可以么？答案是，还有很多依赖因素。 有时候，我们仅仅需要知道先前的信息来执行当前的任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词。如果我们试着预测 “the clouds are in the sky” 最后的词，我们并不需要任何其他的上下文 —— 因此下一个词很显然就应该是 sky。在这样的场景中，相关的信息和预测的词位置之间的间隔是非常小的，RNN 可以学会使用先前的信息。 但是同样会有一些更加复杂的场景。假设我们试着去预测“I grew up in France… I speak fluent French”最后的词。当前的信息建议下一个词可能是一种语言的名字，但是如果我们需要弄清楚是什么语言，我们是需要先前提到的离当前位置很远的 France 的上下文的。这说明相关信息和当前预测位置之间的间隔就肯定变得相当的大。 不幸的是，在这个间隔不断增大时，RNN 会丧失学习到连接如此远的信息的能力。 （比如，词语间隔为4，可以学习到这个知识，但当词语间隔很长的段落时，就学习不到了，在理论上应该是能够解决这个长期依赖的问题） LSTM网络结构LSTM的输入输出展开图1展开图2：这张图非常便于理解参数num_layers。实际上就是个depth堆叠，每个蓝色块都是LSTM单元。 结构门设计LSTM 通过刻意的设计来避免长期依赖问题。记住长期的信息在实践中是 LSTM 的默认行为，而非需要付出很大代价才能获得的能力！所有 RNN 都具有一种重复神经网络模块的链式的形式。在标准的 RNN 中，这个重复的模块只有一个非常简单的结构，例如一个 tanh 层。LSTM 同样是这样的结构，但是重复的模块拥有一个不同的结构。不同于 单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互。 2.2. 核心思路这一时刻的输出 = 上一时刻的输出 一个sigmoid的值（0-1之间可认为是权重） + 这一时刻的输入 一个权重 两个权重可以表示是相对的权重，比如一个0.6一个0.8，也可以是归一化（$i_t = 1 - f_t$）以后 一个0.6一个0.4。上一时刻所处的门可以叫做重置门或遗忘门，这一时刻的输入所在的门可以叫做更新门或输入门。 详解各个门第一步 forget门，决定了上一时刻和这一时刻输出的关系第二步 input gate 输入门，控制是否允许变量通过我们的输入门，$i_t$为对于输入的权重训练，会通过sigmoid函数将值控制在0-1之间，表示$C_i$的影响占比， 第三步 更新状态$f_t$是上一输出对状态影响的权重 $i_t$是这一输入对状态影响的权重，这两个变量一般通过sigmoid函数后产生，值在0-1之间。第四步 输出门 output gate， 控制是否允许输出。并不能保证解决梯度的问题，只是比RNN更保留更长时序的特征。 2.1. 变化模型 2.3. LSTM 应用 2.4. Bi-LSTM2. GRU（Gate recurrent Unit）门控循环单元，2014LSTM 是三个门，GRU简化成两个门，参数更少，在大多数情况下，效果是可以保证的，结构更简洁一些。 3. seq2seq","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"特征工程","slug":"machine_learning/feature_preprocess","date":"2020-08-02T10:34:11.000Z","updated":"2020-09-25T02:14:54.403Z","comments":true,"path":"machine_learning/feature_preprocess/","link":"","permalink":"https://tlylft.github.io/machine_learning/feature_preprocess/","excerpt":"","text":"1. 特征工程模型的输入一定是数量化的信息，需要把现实生活中的物品表示成向量、矩阵、张量的形式。 如何对数据进行预处理,通常来说，首先转换为以0为中心化的表示（数值-均值），然后做一次消除差异，做一下标准差。 使用工具包：sklearn.preprocessing 1.1. 处理方式1.1.1. 常见的数值特征处理方式 二值化 分桶（固定间隔分桶，分位数分桶，使用模型找到分桶） 缩放 （ 标准化缩放） 缺失值处理（ 补平均值，补中位数） 特征交叉（ 对两个数值特征进行加减乘除） 操作 非线性编码（多项式，高斯核） 统计量（正负值个数，均值，方差，最大值，最小值，偏度，峰度）1.1.2. 分类特征处理方式 自然数编码（给每一个类别分配一个编号） 独热编码 分层编码（例如对邮政编码，身份证等进数据划分编码）1.2. 特征缩放对大数值列进行标准化，让所有特征类的浮动区间都变成差不多的。为什么要进行特征缩放？在我们使用欧氏距离这样通过距离表述样本关系的情况中，如KNN,K-means等，如果数据点中其中某一个维度的值较大，表现的距离差在这个维度上也会很大，就会使得其他维度的特征影响不明显（起不到作用），所以需要特征缩放进行标准化操作，也就是把特征映射到类似的量纲空间，目的是不让某些特征的影响变得太大。特征缩放的两种方式有两种常见的特征标准化的方法。它们分别是线性归一化和标准差归一化。其中，线性归一化指的是把特征值的范围映射到[0,1]区间，标准差标准化的方法使得把特征值映射到均值为0，标准差为1的正态分布。 使用哪种方法是需要尝试的。 线性归一化（Min-max Normalization）通过数据点落在最大值和最小值所在区间的比例表示每个点的值，所有的特征值都会落在[0,1]的区间里。12from sklearn.preprocessing import StandardScalerdata[&#39;normAmount&#39;] &#x3D; StandardScaler().fit_transform(data[&#39;Amount&#39;].reshape(-1,1)) 标准差标注化（Z-socre Normalization）把特征值映射到均值为0，标准差为1的正态分布(0,1)。转换后的特征有负有正，而且它们的均值为0 缺失值处理删除法最简单的处理方法叫做“删除法”：一旦遇到了缺失值，我们就删掉相应的记录。第一种删除法 是把相应的属性全部删掉，也就是删掉整个列。这种方法适用于该特征的缺失值很多，存在大量的缺失值。简单的例子是，比如我们发起了一个问卷调查，其中有必填项也有选填项，但有可能只有不到30%的人填写了选填项，这个时候就产生大量的缺失值。而且，如果我们觉得这个选填项没有非常大的价值，其实可以丢弃掉，不放在模型里。缺点：如果一个特征中只有几个样本缺失了这条特征，全部删掉整个列是不太明智的。因为等同于完全废弃掉了此特征，所以实际使用的时候还是要多加深思。第二种删除法是把该行数据删除掉。这种方法也简单且直接，也是平时工程里常用的方法，实现起来也非常简单。 缺点：对于维度很多的数据，假如大量的维度都存在缺失值，这个方法很容易丢弃掉大量的样本。设想一下数据里含有100多个特征，而且其中60多个特征都允许出现缺失值(可以理解为选填项)， 那这个时候对于一个记录来讲，它有大概率包含至少一个缺失值。所以，如果这时候使用此方案，最终会发现大量的记录都被我们丢弃掉了，这使得样本数据量急剧变小，从而影响后续建模的效果。 填补法尝试着用一个新的值来填补缺失值。对于数值型(real-valued)变量，我们经常使用平均法则，就是用平均值来填补缺失值。除了平均值，有些人可能也会想到使用中位数来调补，两者均可。 缺点：填补的值对于当前的样本来说很不合理，这时候反而会影响模型的效果。举个例子，目前在某公司担任技术专家的张三，他没有提供自己的薪资，如果这时候我们使用所有IT从业人员的平均薪资来填补缺失值，那对于张三来说是不太合理的。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"【读书笔记】云雀叫了一整天 -- 木心","slug":"reading/skylark_cried_all_day","date":"2020-08-01T09:13:37.000Z","updated":"2023-08-10T12:04:54.615Z","comments":true,"path":"reading/skylark_cried_all_day/","link":"","permalink":"https://tlylft.github.io/reading/skylark_cried_all_day/","excerpt":"","text":"云雀叫了一整天我是一个在黑暗中大雪纷飞的人哪！ 爱情 罗密欧与朱丽叶爱才是生命，然后生命才能爱我想莎士比亚的原意如此—《火车中的情诗》 心情 我倒并不悲伤只是想放声大哭一场—《哭》","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"【读书笔记】论语","slug":"reading/The_Analects","date":"2020-08-01T06:00:06.000Z","updated":"2023-08-10T12:04:45.486Z","comments":true,"path":"reading/The_Analects/","link":"","permalink":"https://tlylft.github.io/reading/The_Analects/","excerpt":"","text":"子曰：“饭疏食饮水，曲肱而枕之，乐亦在其中矣。不义而富且贵，于我如浮云。”《论语 述而篇 第十六章》 译文：孔子说：“吃粗粮，喝清水，弯起胳膊当枕头，这其中也有着乐趣。而通过干不正当的事得来的富贵，对于我来说就像浮云一般。” 解读：孔子极力提倡“安贫乐道”，有理想有抱负的人，不会因极度追求吃穿住而，无论什么样的条件，都可以乐在其中。但不符合道的精神而得来的荣华富贵，是不值得提倡的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"BiLSTM_CRF","slug":"NLP/NER/BiLSTM-CRF","date":"2020-07-10T06:05:35.000Z","updated":"2021-06-11T03:10:43.675Z","comments":true,"path":"NLP/NER/BiLSTM-CRF/","link":"","permalink":"https://tlylft.github.io/NLP/NER/BiLSTM-CRF/","excerpt":"","text":"backgroundCRFLSTM 为什么要用bi-lstm CRF首先，LSTM解决了长短时记忆的问题，能够捕获到语义中前后词对于标签的影响，CRF是为了解决避免B-PER后继续出现B-PER的问题，通过有前后标签的转移概率控制输出结果，更加符合期望输出。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"NER","slug":"NER","permalink":"https://tlylft.github.io/tags/NER/"}]},{"title":"GPU 环境安装","slug":"python/env/gpu_install","date":"2020-07-04T10:43:27.000Z","updated":"2021-10-20T02:23:10.054Z","comments":true,"path":"python/env/gpu_install/","link":"","permalink":"https://tlylft.github.io/python/env/gpu_install/","excerpt":"","text":"windows 安装cudahttp://blog.sina.com.cn/s/blog_14935c5880102wu86.html https://blog.csdn.net/j879159541/article/details/93199150 安装cudnn官网下载：https://developer.nvidia.com/rdp/cudnn-archive下载对应cuda版本和系统的cudnn解压文件夹，将解压后的文件夹下的文件拷贝到cuda安装目录下，与之相对应的文件夹下。 安装tensorflow-gputensorflow-gpu版本和cuda版本对应关系https://tensorflow.google.cn/install/source_windows 1234567conda create -n tf-gpu python&#x3D;3.7.4python -m pip install -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple tensorflow-gpu&#x3D;&#x3D;1.14.0# numpy 需要降到匹配版本 pip install -U -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple numpy&#x3D;&#x3D;1.16.0pip install bert-tensorflow# checkfrom bert import modeling 安装 pytorch-gpuhttps://blog.csdn.net/Person_one/article/details/107133285 创建环境12conda create --name pytorch python&#x3D;3.7.4conda activate pytorch 找合适版本去官网https://pytorch.org/get-started/locally/. 找到和本机cuda版本匹配的Torch安装命令我的 cuda=10.0 匹配 torch=1.2.0，官网安装命令为：1234# 官网安装conda install pytorch&#x3D;&#x3D;1.2.0 torchvision&#x3D;&#x3D;0.4.0 cudatoolkit&#x3D;10.0 -c pytorch# 或者通过cuda版本自己寻找对应版本（没有验证）conda install pytorch torchvision cudatoolkit&#x3D;10.0 -c pytorch conda安装123456# 添加清华源torch镜像conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;pytorch&#x2F;# 把 -c pytorch 去掉conda install pytorch&#x3D;&#x3D;1.2.0 torchvision&#x3D;&#x3D;0.4.0 cudatoolkit&#x3D;10.0# 或conda install pytorch torchvision cudatoolkit&#x3D;10.0 pip 安装https://download.pytorch.org/whl/torch_stable.html 验证123import torchprint(torch.__version__) # 查看pytorch版本print(&#39;gpu:&#39;,torch.cuda.is_available()) # gpu加速是否可用","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}]},{"title":"中文分词简介","slug":"NLP/segment/seg_intro","date":"2020-06-10T01:16:39.000Z","updated":"2021-06-11T03:12:22.312Z","comments":true,"path":"NLP/segment/seg_intro/","link":"","permalink":"https://tlylft.github.io/NLP/segment/seg_intro/","excerpt":"","text":"1. 为什么会有分词问题在英文的NLP分析中，单词已经在一句话中被空格隔开，每个单词代表了不同的含义，而中文的每个词具有同样的意义，但是没有分割符号，所以对于中文文本问题，需要进行切词处理，在词间加入边界标记符。 难点：歧义问题未登录词问题分词粒度的把握 2. 分词技术2.1. 基于规则分词主要通过维护词典，在切分时，对每个字符串与词表中的词进行逐一匹配。简单高效，但词典维护量大，网络新词层出不穷。 2.1.1. 正向最大匹配算法 Maximum match method研究生命的起源 给定一个窗口大小：5 【研究生命的】一句话正向取窗口长度的文本，与词典匹配，成功则加入分词，不成功则减掉最后一个字继续匹配。【研究生命的 F】【研究生命 F】【研究生 T】【命的起源 F】【命的起 F】【命的 F】【命 T】【的起源 F】【的起 F】【的 T】【起源 T】 2.1.2. 逆向最大匹配算法研究生命的起源 给定一个窗口大小：5 【生命的起源】一句话反向取窗口长度的文本，与词典匹配，成功则加入分词，不成功则减掉第一个字继续匹配。【生命的起源 F】【命的起源 F】【的起源 F】【起源 T】【研究生命的 F】【究生命的 F】【生命的 F】【命的 F】【的 T】【研究生命 F】【究生命 F】【生命 T】【研究 T】 2.1.3. 双向最大匹配算法前两种办法的结果，取划分词数最少的划分方式，如果词数相同，取单字较少的结果。 2.2. 基于统计分词建立统计模型对单词划分，进行概率计算，获得概率最大的分词方式 2.2.1. HMM算法介绍 2.2.2. CRF算法介绍 2.3. 分词工具工具对比","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"segment","slug":"NLP/segment","permalink":"https://tlylft.github.io/categories/NLP/segment/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"segment","slug":"segment","permalink":"https://tlylft.github.io/tags/segment/"}]},{"title":"fasttext","slug":"NLP/word2vec/fasttext","date":"2020-05-26T08:35:25.000Z","updated":"2021-06-11T03:14:37.756Z","comments":true,"path":"NLP/word2vec/fasttext/","link":"","permalink":"https://tlylft.github.io/NLP/word2vec/fasttext/","excerpt":"","text":"Fasttext（高效的文本分类和表示工具）是fastText是FAIR(Facebook AIResearch) 在2016年推出的一款文本分类与向量化工具。官网：(http://fasttext.cc)fastText开源、免费、轻量级，适用于文本分类和文本向量化表示场景，运行于标准硬件环境。裁剪压缩过的模型甚至可以轻松跑在移动设备上.Fasttext最惊艳的地方在于，和最前沿深度神经网络模型相比，它在分类精度等指标毫不逊色的情况下，把训练和推断速度降低了几个数量级！按Facebook的报告，在普通多核CPU上， 10亿词的文本训练时间小于10分钟， 50万句子分到31.2万类别用时小于1分钟。 Fasttext能够做到效果好，速度快，主要因为：一是利用了词内的n-gram信息(subword n-gram information)，二是用到了层次化Softmax回归(Hierarchical Softmax)的训练trick。 python apihttps://fasttext.cc/docs/en/python-module.html","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"word2vec","slug":"NLP/word2vec","permalink":"https://tlylft.github.io/categories/NLP/word2vec/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"word2vec","slug":"word2vec","permalink":"https://tlylft.github.io/tags/word2vec/"}]},{"title":"word2vec 介绍","slug":"NLP/word2vec/intro","date":"2020-05-25T07:16:41.000Z","updated":"2021-06-11T03:14:46.402Z","comments":true,"path":"NLP/word2vec/intro/","link":"","permalink":"https://tlylft.github.io/NLP/word2vec/intro/","excerpt":"","text":"backgroud作者：Tomas MIkolov下面是Tomas MIkolov的三篇有关word embedding的文章。1、 Efficient Estimation of Word Representation in Vector Space, 20132、 Distributed Representations of Sentences and Documents, 20143、 Enriching Word Vectors with Subword Information, 2016 whatWord2vec是词的一种表示，他将词以固定维数的向量表示出来。  是无监督学习，因为输出并没有label。 但是从输入的和输出的形式上来看，输入的是一对对单词，看起来像是有监督，其实并不是。 因为词向量的本质可以看出是一个只有一层的神经网络，因此必须有输入，输出。而训练过程或者说目的不是得到预测结果单词，或者对单词进行分类。最为关键的是获得hidden layer中权重。 也就是说借助了sequence2sequence模型训练过程，得到hidden layer的权重。 why 可以表示词相似度，有语义性传统的基于词袋模型 one-hot representation在判定同义词，相似句子的时候很无力。例如在一个只有两个词的词典中。快递被编码为v1 = [0,1]，快件被编码为v2 =[1,0]，计算两个的相似度。为v1*v2 = 0而word2vec充分利用上下文信息，对上下文进行训练。每个词不在是 只有一个位置为1，其余位置为0的稀疏向量。而是一个稠密的固定维度向量。 减少存储直观上可减少额外存储和计算开销。 how1) 用上下文预测中心词 cbow（continue bag of word）2) 利用中心词预测上下文 skip-gram basic knowledgesigmoid 和 softmax函数二叉树和huffman树 预训练词向量https://github.com/Embedding/Chinese-Word-Vectors 词向量表示的方法和特点 one_hot tf-idf的bag of word 主题模型 LSA（SVD）,pLSA, LDA通过降维的方式，语料大，计算大 基于词向量的固定表征word2vec fast-text glove gensimword2vec fast-text 基于局部的滑窗语料学习到上下文信息 基于词向量的动态表征：elmo gpt bert可以解决一次多意的问题bert 基于句子的负采样，更适合做句子的表征。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"word2vec","slug":"NLP/word2vec","permalink":"https://tlylft.github.io/categories/NLP/word2vec/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"word2vec","slug":"word2vec","permalink":"https://tlylft.github.io/tags/word2vec/"}]},{"title":"python 连接mysql","slug":"python/python/python_mysql","date":"2020-05-19T07:33:56.000Z","updated":"2021-06-11T04:18:40.923Z","comments":true,"path":"python/python/python_mysql/","link":"","permalink":"https://tlylft.github.io/python/python/python_mysql/","excerpt":"","text":"简单操作insertupdate更改或删除操作，如捕获异常，需要回滚，否则会出问题。 insert or update123456789101112131415# 写入# -*- coding: UTF-8 -*-import MySQLdbdb &#x3D; MySQLdb.connect(&quot;localhost&quot;,&quot;root&quot;,&quot;root&quot;,&quot;blog&quot; )cursor &#x3D; db.cursor()update: 2021-02-26 13:06:48try: cursor.executemany(sql,[[16,&#39;aaa2&#39;,&#39;bbb2&#39;]])except Exception,e: print e# 关闭数据库连接cursor.close()db.commit()db.close() 封装方法https://www.cnblogs.com/BlueSkyyj/p/10039972.htmlself.db = pymysql.connect(self.host,self.username,self.password,self.database[,self.port,charset=’utf8’])123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143# FileName : DBHandle.py# Author : Adil# DateTime : 2018&#x2F;11&#x2F;29 2:03 PM# SoftWare : PyCharmimport pymysql# username : adil# password : helloyyjclass DataBaseHandle(object): &#39;&#39;&#39; 定义一个 MySQL 操作类&#39;&#39;&#39; def __init__(self,host,username,password,database,port): &#39;&#39;&#39;初始化数据库信息并创建数据库连接&#39;&#39;&#39; # 下面的赋值其实可以省略，connect 时 直接使用形参即可 self.host &#x3D; host self.username &#x3D; username self.password &#x3D; password self.database &#x3D; database self.port &#x3D; port self.db &#x3D; pymysql.connect(self.host,self.username,self.password,self.database,self.port,charset&#x3D;&#39;utf8&#39;) # 这里 注释连接的方法，是为了 实例化对象时，就创建连接。不许要单独处理连接了。 # # def connDataBase(self): # &#39;&#39;&#39; 数据库连接 &#39;&#39;&#39; # # self.db &#x3D; pymysql.connect(self.host,self.username,self.password,self.port,self.database) # # # self.cursor &#x3D; self.db.cursor() # # return self.db def insertDB(self,sql): &#39;&#39;&#39; 插入数据库操作 &#39;&#39;&#39; self.cursor &#x3D; self.db.cursor() try: # 执行sql self.cursor.execute(sql) # tt &#x3D; self.cursor.execute(sql) # 返回 插入数据 条数 可以根据 返回值 判定处理结果 # print(tt) self.db.commit() except: # 发生错误时回滚 self.db.rollback() finally: self.cursor.close() def deleteDB(self,sql): &#39;&#39;&#39; 操作数据库数据删除 &#39;&#39;&#39; self.cursor &#x3D; self.db.cursor() try: # 执行sql self.cursor.execute(sql) # tt &#x3D; self.cursor.execute(sql) # 返回 删除数据 条数 可以根据 返回值 判定处理结果 # print(tt) self.db.commit() except: # 发生错误时回滚 self.db.rollback() finally: self.cursor.close() def updateDb(self,sql): &#39;&#39;&#39; 更新数据库操作 &#39;&#39;&#39; self.cursor &#x3D; self.db.cursor() try: # 执行sql self.cursor.execute(sql) # tt &#x3D; self.cursor.execute(sql) # 返回 更新数据 条数 可以根据 返回值 判定处理结果 # print(tt) self.db.commit() except: # 发生错误时回滚 self.db.rollback() finally: self.cursor.close() def selectDb(self,sql): &#39;&#39;&#39; 数据库查询 &#39;&#39;&#39; self.cursor &#x3D; self.db.cursor() try: self.cursor.execute(sql) # 返回 查询数据 条数 可以根据 返回值 判定处理结果 data &#x3D; self.cursor.fetchall() # 返回所有记录列表 print(data) # 结果遍历 for row in data: sid &#x3D; row[0] name &#x3D; row[1] # 遍历打印结果 print(&#39;sid &#x3D; %s, name &#x3D; %s&#39;%(sid,name)) except: print(&#39;Error: unable to fecth data&#39;) finally: self.cursor.close() def closeDb(self): &#39;&#39;&#39; 数据库连接关闭 &#39;&#39;&#39; self.db.close()if __name__ &#x3D;&#x3D; &#39;__main__&#39;: DbHandle &#x3D; DataBaseHandle(&#39;127.0.0.1&#39;,&#39;adil&#39;,&#39;helloyyj&#39;,&#39;AdilTest&#39;,3306) DbHandle.insertDB(&#39;insert into test(name) values (&quot;%s&quot;)&#39;%(&#39;FuHongXue&#39;)) DbHandle.insertDB(&#39;insert into test(name) values (&quot;%s&quot;)&#39;%(&#39;FuHongXue&#39;)) DbHandle.selectDb(&#39;select * from test&#39;) DbHandle.updateDb(&#39;update test set name &#x3D; &quot;%s&quot; where sid &#x3D; &quot;%d&quot;&#39; %(&#39;YeKai&#39;,22)) DbHandle.selectDb(&#39;select * from test&#39;) DbHandle.insertDB(&#39;insert into test(name) values (&quot;%s&quot;)&#39;%(&#39;LiXunHuan&#39;)) DbHandle.deleteDB(&#39;delete from test where sid &gt; &quot;%d&quot;&#39; %(25)) DbHandle.selectDb(&#39;select * from test&#39;) DbHandle.closeDb() 异常报错需要回滚才能重连sqlalchemy.exc.InvalidRequestError: Can’t reconnect until invalid transaction is rolled back","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"mysql","slug":"big_data/mysql/mysql","date":"2020-05-15T05:11:32.000Z","updated":"2023-08-11T08:27:21.110Z","comments":true,"path":"big_data/mysql/mysql/","link":"","permalink":"https://tlylft.github.io/big_data/mysql/mysql/","excerpt":"","text":"1. 表操作1.1. 创建表1.2. 更改表增加列1alter table table_name add column create_time varchar(50) COMMENT &#39;工单创建时间&#39; [after work_order_id];更改主键1234# 现将要设置的主键不能为空alter table ai_customer_complaint_classification_h modify work_order_id varchar(50) not null, modify primary_category varchar(50) not null, modify sub_category varchar(50) not null# 更改主键需要先drop掉之前的索引，再添加alter table ai_customer_complaint_classification_h DROP PRIMARY KEY ,add primary key(work_order_id,primary_category,sub_category) 1.3. 增删改查1.3.1. insert1.3.1.1. 查询select分页查询12345--方式1:select * from ta12 limit 10;-- 读取十行select * from ta12 limit 10,10 --从第十行读取 往后再读十行--方式2:select * from ta12 limit 10 offset 20 ; --从第二十行开始读取10行分页查询大规模数据的性能调优https://zhuanlan.zhihu.com/p/206597199 1.3.1.2. insert into插入数据操作，主键存在会报错。1INSERT INTO &#96;enn_news&#96;.&#96;keywords_hot&#96; ( &#96;keywords&#96;, &#96;version&#96;, &#96;state&#96;, &#96;weight&#96;) VALUES ( &#39;保民生&#39;, &#39;39&#39;, &#39;1&#39;, &#39;11&#39;); 1.3.2. 删除数据1DELETE FROM 表名称 WHERE 列名称 &#x3D; 值 1.3.3. 修改数据1.3.3.1. update1UPDATE &#96;keywords_hot&#96; SET &#96;weight&#96;&#x3D;&#39;13&#39; WHERE (&#96;id&#96;&#x3D;&#39;1403&#39;) 1.3.3.2. replace intoreplace into 主要作用类似insert插入操作。主要的区别是replace会根据主键或者唯一索引检查数据是否存在，如果存在就先删除在更新。所以想要修改的源数据是被执行删除操作的，create_time字段不会留痕。1REPLACE INTO t_test (&#96;name&#96;)VALUES(&#39;a&#39;) 1.3.4. insert or updatehttps://blog.csdn.net/zfs_zs/article/details/86229538 ON DUPLICATE KEY UPDATE ON DUPLICATE KEY UPDATE只是MySQL的特有语法，并不是SQL标准语法！ 1234567891011INSERT INTO pms_statistic (id,tenantId,tenantName,isDeleted,createTime,updateTime)VALUES (6257,50,&#39;保存或修改0&#39;,1,&#39;2020-01-00&#39;) , (6258,51,&#39;保存或修改1&#39;,1,&#39;2020-01-01&#39;) , (6259,52,&#39;保存或修改2&#39;,1,&#39;2020-01-02&#39;) , (62510,53,&#39;保存或修改3&#39;,1,&#39;2020-01-03&#39;) ON DUPLICATE KEY UPDATE tenantId &#x3D; VALUES(tenantId),tenantName &#x3D; VALUES(tenantName),isDeleted &#x3D; VALUES(isDeleted),createTime &#x3D; VALUES(createTime) 该语句是基于主键（PRIMARY KEY）或唯一索引（UNIQUE INDEX）使用的。如果已存在该唯一标示或主键就更新（显示受影响行的值：2） 如果不存在该唯一标示或主键则作为新行插入（显示受影响行的值：1） 如上：如果id（6257，6258，6259，62510）存在，根据id更新ON DUPLICATE KEY UPDATE后的字段数据（tenantId = VALUES(tenantId),tenantName = VALUES(tenantName),isDeleted = VALUES(isDeleted),createTime = VALUES(createTime)） 1.4. 函数now() 当前时间 2. 事务操作delete 或 update操作失败时，需要回滚db.rollback() 3. 表管理查询表大小1select table_schema, table_name, concat(round((data_length&#x2F;1024&#x2F;1024),2),&#39;MB&#39;) as data from information_schema.tables where table_schema&#x3D;&quot;your_db_name&quot; ;","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"mysql","slug":"大数据技术/mysql","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://tlylft.github.io/tags/mysql/"}]},{"title":"collection Counter","slug":"python/python/python_counter","date":"2020-05-15T02:42:49.000Z","updated":"2021-06-11T04:17:57.289Z","comments":true,"path":"python/python/python_counter/","link":"","permalink":"https://tlylft.github.io/python/python/python_counter/","excerpt":"","text":"https://www.cnblogs.com/keke-xiaoxiami/p/8553076.html","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"文本分类","slug":"NLP/algorithm/text_classification","date":"2020-05-12T00:53:25.000Z","updated":"2021-06-11T03:07:57.535Z","comments":true,"path":"NLP/algorithm/text_classification/","link":"","permalink":"https://tlylft.github.io/NLP/algorithm/text_classification/","excerpt":"","text":"应用新闻分类情感分析语种识别 多分类问题下的调优 类别样本均衡，每个类别的样本数据量大小最好相差不多。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"algorithm","slug":"NLP/algorithm","permalink":"https://tlylft.github.io/categories/NLP/algorithm/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"algorithm","slug":"algorithm","permalink":"https://tlylft.github.io/tags/algorithm/"}]},{"title":"【读书笔记】爱因斯坦的梦","slug":"reading/Einsteins_dream","date":"2020-05-06T03:43:38.000Z","updated":"2023-08-10T12:05:23.285Z","comments":true,"path":"reading/Einsteins_dream/","link":"","permalink":"https://tlylft.github.io/reading/Einsteins_dream/","excerpt":"","text":"有关于时间的思考 013 这并不是说其他性质不可能存在，而是说其他的性质可能存在于其他的世界中。 事物不是永恒的，也不是在一条时间线上多变的，在不同的世界维度，可能就有着不同的含义和表现形式。it can be everything. 1905.04.14 假定时间是曲向自己的一个圆，而世界重复他自己，完全准确的，且是永不止息的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"BERT（2） 基础架构","slug":"NLP/transformer/bert02_structure","date":"2020-04-28T00:38:56.000Z","updated":"2021-11-17T14:29:11.580Z","comments":true,"path":"NLP/transformer/bert02_structure/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/bert02_structure/","excerpt":"","text":"基础架构transformer的原论文中是6个encoder堆叠构成了编码端，6个decoder堆叠构成了解码端。而bert的基础结构是抛弃了解码部分，由TRM(transformer)的encoder部分堆叠而成。 他的训练结果是transformer decoder的输入。 bert-base: 12层的TRM encoderber-large: 24层的TRM encoder TRM encoder transformer的输入：input emb： 可以使用训练的词向量或者随机初始化的向量position encoding: 三角函数表示位置信息 bert的输入:input = token emb + segment emb + position embinput是分词后的结果token emb: 理解为词的emb，对每个词做随机的初始化, 信息代表了每个词segment emb: 理解为句子的emb，cls到第一个句子结束标为Ea(0),第二个句子标位Eb(1),信息代表了两个句子pos emb: 理解为位置的emb，与trm不同的是，随机初始化让模型自己学习出来？？ 为什么，目前只是实验效果好。。。都是(768维)，相加后得到最终的input embedding bert 预训练任务我们的输入是分词后的sentence,采用one hot 编码作为bert的输入，在最前面设置一个[cls]的字符，如果是两个句子的输入，中间用[sep]分隔，对bert部分进行微调训练，得到每个位置对应的词向量后， 上面加一层linear classifier ，这一部分是完全训练的模型，得到了对应的类别。 MLM + NSP 前置知识AR(autogressive)自回归模型，只能考虑单侧的信息，典型的是GPTAE(autoencoding)自编码模型，从损坏的输入数据中重建原始数据。可以使用上下文 信息， bert就是使用的AE 下面的例子：从目标函数上理解，AR是利用句子前面的信息顺序单向预测后面的词， AE是打乱了文本信息，利用上下文预测词，让文本重建。 mask模型的缺点：mask的内容会认为是相互独立的，缺少关联性我爱吃饭 mask之后： 【我爱 mask mask】优化目标： P(我爱吃饭|我爱maskmask)=P(mask=吃|我爱)P(mask=饭|我爱) MLM任务masked language model. 掩码语言模型对训练样本抽出15%做Mask(一句话盖住15%的词)，然后预测它。 mask具体策略：选取15%的词随机mask， 其中10% 替换成其他10% 不动80% 替换成mask NSP任务next sentence prediction[sep]和[cls]两个符号，是为了训练NSP任务，sep符号是为了区分前后两句话；cls是表示两个句子之间是否有关联关系的二分类任务，训练时， 将CLS的输出向量接一个二分类器，做一个二分类任务。训练数据样本： 从训练语料库去除两个连续的段落作为正样本 从不同的文档中随机创建一堆段落作为负样本 问题：主题预测和连贯性预测合并为一个单项任务。这样使得主题预测任务非常简单，就很难产生效果。 Albert中针对这一点有调整，它的正负样本均来自同一个文档。 主题预测： 两个句子是不是同一个文档连贯预测： 两个句子是不是挨着。 cls输出向量的含义：并不能代表整个句子的语义信息，用cls的输出信息直接做文本相似度任务时，效果并不好。 bert pretrain模型直接拿来用作sentence embedding 效果甚至不如 word embedding, cls embedding的效果最差（也就是pooled output）. 把所有普通token embedding做pooling勉强能用（这个方式也是开源项目bert-as-service的默认做法），但也没有word embedding效果好。 苏神的 bert whitening可以参考下，是bert做文本相似的另外的思路 bert微调 一般步骤： 在大量通用语料训练通用的LM(pretrain) - 获取谷歌中文bert 在领域语料上继续训练LM（Domain transfer） - 比如财务、能源或微博语料 在任务相关的小数据上继续训练 （Task transfer） - 情感文本上 在任务相关数据上做具体任务（fine-tune） tricks:1.先2再3再4，逐步训练效果最好 ，可提升1-3个点2.在步骤2领域内训练时，可使用动态mask，即每次epoch都重新mask数据，而不是一直使用同一套3.在步骤2领域内训练时，可使用n-gram mask, 比如ERNIE和SpanBert都做了类似于实体词的mask, 不好做实体词可以做n-gram4.参数 batch size： 16,32,64影响不大 learning rate(Adam): 5e-5 3e-5 2e-5 尽可能小一些避免灾难性遗忘 number of epochs: 3,4 weighted decay 修改后的adam，使用warmup,搭配线性衰减5.其他：数据增强，自蒸馏，外部知识融入","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"BERT（1） 常见任务和BERTTology","slug":"NLP/transformer/bert01_intro","date":"2020-04-28T00:36:56.000Z","updated":"2021-11-17T14:28:50.373Z","comments":true,"path":"NLP/transformer/bert01_intro/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/bert01_intro/","excerpt":"","text":"1. Bertbidirection encoder representation from transformertransformer中encoder部分的表示learned from a large amount of text without annotationgoogle 提供的开源的项目解决方案https://github.com/google-research/bert 常用的BERTTology模型预训练有三种 句式关系式： 预测句子之间的关系是否属于NSP或者是否相关 AR式：类似GPT2的从左到右自回归模型 AE式：类似bert将一部分破坏然后还原回来 1.1. basic knowledge需要熟悉 word2vec ,RNN 等重点在transformer 1.2. environment requiredtensorflow = 1.13.0numpy = 1.16.3 1.3. Application1.3.1. Classification1.3.2. 槽位填充1.3.3. 推理1.3.4. 阅读理解基于抽取的问答，通过给出一段话，每个问题和对应的答案。模型的输入是文章和问题两个向量，模型的输出是两个整型：答案的起始位置。 红色和蓝色代表学习到的特征向量，代表s和e，和bert的结果逐个做点乘，得到起始位置的概率。 1.4. BERTTology1.4.1. GPT-适合文章生成去掉bert的encoder部分，只保留decoder部分。是永无监督方式训练的自回归语言模型。 它将每个新产生的单词添加在输入序列的后面，将这个序列当做下一步需要的新输入。GPT2根据输入的具体句子或词，预测出下一个可能出现的序列。不同规模的版本：小、中、大、特大（15亿参数）： 解码器层数分别为12,24,36,48GPT31750亿参数 1.4.2. DialoGPT-支持人机对话模型1.4.3. Transformer-XL 支持长文本输入50个字词提升到900个字词。self-attention引入两个调整：1. 循环机制 2. 相对位置编码 使得预测下一个字词任务比transformer快1800多倍循环机制相对位置编码 1.4.4. XLNet-支持更长文本的模型Transformer-XL上加入了bert的思想，能够获得双向上下文信息，并克服了bert模型的缺点： 没有使用MLM，克服bert微调不匹配的问题 xlnet本身是自回归模型，不存在bert独立性假设的缺陷1.4.5. MPNert-弥补XLNet不足的模型1.4.6. RoBERTa-稳健性更好bert升级版1.4.7. BERT_WWM Wo-BERT -基于词掩码Whole word masking, 先分词，再mask,比基于字的训练效果好（尤其在文本分类、生成任务重）1.4.8. SpanBERT- 基于小段文字掩码提升计算速度，做法： span masking: mask单词的所有字词，而不是某个字。从几何分布中采样得到需要mask的长度，对该长度的端进行mask,直到mask掉15% span boundary object: 表示段中的字词 single-sequence training: 直接输入一整段连续的序列句子，使模型获得更长的上下文信息。1.4.9. T5-适合文本翻译1.4.10. XML\\XML-Roberta -适用多种语言翻译1.4.11. UniLM2.0 -阅读写作1.4.12. StructureBERT、 BART- 语法纠错1.4.13. PEGASUS-摘要生成1.5. study link https://github.com/tangyudi/Ai-Learn/tree/master/NLP%E9%80%9A%E7%94%A8%E6%A1%86%E6%9E%B6BERT","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"}]},{"title":"python代码格式化工具autopep8","slug":"tools/autopep8","date":"2020-04-21T01:01:33.000Z","updated":"2021-06-11T04:20:40.551Z","comments":true,"path":"tools/autopep8/","link":"","permalink":"https://tlylft.github.io/tools/autopep8/","excerpt":"","text":"https://blog.csdn.net/hahahahli/article/details/86079652 安装包1pip install autopep8 官方文档 https://pypi.org/project/autopep8/ 配置autopep8打开 Preferences -&gt; Tools -&gt; External Tools点开左上角+号Name：autopep8（可以自定义）Programs：/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autopep8.py（注意！路径必须为autopep8安装路径）Arguments：—in-place —aggressive —aggressive $FilePath$Working directory：$ProjectFileDir$Outoput fillters：$FILE_PATH$\\:$LINE$\\:$COLUMN$\\:.* 使用方法右键 -&gt; External Tools -&gt; AutoPEP8 排错1.运行时提示no such file or directory 原因：autopep8 路径写错或没写扩展名 解决办法：路径补充完整，必需精确到扩展名（windows下为autopep8.exe）如：Programs：/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autopep8.py 2.运行时提示permission denied 原因：autopep8.py这个文件没有执行权限 解决办法：chmod 755 autopep8.py","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"}]},{"title":"Jmeter压测工具","slug":"tools/jmeter","date":"2020-04-13T06:13:12.000Z","updated":"2021-06-11T04:21:18.176Z","comments":true,"path":"tools/jmeter/","link":"","permalink":"https://tlylft.github.io/tools/jmeter/","excerpt":"","text":"https://www.cnblogs.com/monjeo/p/9330464.html 1. 下载进入官网：http://jmeter.apache.org/下载apache-jmeter-5.2.1.zip 版本，对应jdk1.8。然后就进行解压。 1）解压之后压缩包叫apache-jmeter-4.0.zip，如是src.zip后缀的都不对，打开之后会报错不可用，因为里面缺少我们下一步将要配置的环境变量.jar文件。 2）对应的jdk版本不可太低，一般jmeter3.0的对应jdk1.7，jmeter4.0对应jdk1.8以上，否者启用jmeter也会报错。 3）一定要确保环境变量配置正确（包括jdk的与jmeter的环境变量配置）。 好了，接下来进行环境变量配置吧，因为是新手所以参照了大佬们的教程，我就根据自己的实际遇到的情况，总结一下来做备忘。 2. 安装2.1. 环境变量1234JMETER_HOME :D:\\setup\\apache-jmeter-5.2.1classpath: %JMETER_HOME%\\lib\\ext\\ApacheJMeter_core.jar;%JMETER_HOME%\\lib\\jorphan.jar;%JMETER_HOME%\\lib&#x2F;logkit-2.0.jar; 3. 新建测试进入安装目录下的bin目录，双击或管理员执行jmeter.bat 4. 生成报告jmeter -n -t E:\\aa.jmx -l E:\\result1.jtl -e -o E:\\result_report1-n 代表不使用界面启动，直接执行了-t 后面是要加载的jmx文件-o 后面是生成的报告目录","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"}]},{"title":"linux 系统信息","slug":"linux/basic_info","date":"2020-04-13T04:58:06.000Z","updated":"2023-08-08T08:47:01.539Z","comments":true,"path":"linux/basic_info/","link":"","permalink":"https://tlylft.github.io/linux/basic_info/","excerpt":"","text":"1. 查看系统版本12345cat &#x2F;proc&#x2F;versionuname -a&gt;&gt;Linux elcndc5fncs04t 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU&#x2F;Linuxcat &#x2F;etc&#x2F;redhat-release&gt;&gt;CentOS Linux release 7.4.1708 (Core) 2. 查看内存12345&gt;&gt; cat &#x2F;proc&#x2F;meminfo | grep MemTotal&gt;&gt; free -h total used free shared buff&#x2F;cache availableMem: 31G 12G 6.7G 307M 12G 17GSwap: 8.0G 6.6M 8.0G 查看内存占用最多的进程1ps auxw|head -1;ps auxw|sort -rn -k4|head -10 3. 查看磁盘12345678910111213&gt;&gt; df -hFilesystem Size Used Avail Use% Mounted on&#x2F;dev&#x2F;mapper&#x2F;rootvg-lv_root 20G 14G 6.1G 70% &#x2F;devtmpfs 16G 0 16G 0% &#x2F;devtmpfs 16G 104K 16G 1% &#x2F;dev&#x2F;shmtmpfs 16G 866M 15G 6% &#x2F;runtmpfs 16G 0 16G 0% &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;dev&#x2F;mapper&#x2F;rootvg-lv_home 20G 724M 20G 4% &#x2F;home&#x2F;dev&#x2F;mapper&#x2F;datavg-lv_data 294G 146G 133G 53% &#x2F;data&#x2F;dev&#x2F;sda1 497M 157M 341M 32% &#x2F;boottmpfs 3.2G 16K 3.2G 1% &#x2F;run&#x2F;user&#x2F;42tmpfs 3.2G 0 3.2G 0% &#x2F;run&#x2F;user&#x2F;1001tmpfs 3.2G 0 3.2G 0% &#x2F;run&#x2F;user&#x2F;1006 如果想把已经挂载在mnt目录上的硬盘挂载到data目录上123456df -Th # 显示磁盘类型和分区情况mkdir &#x2F;data umount &#x2F;mnt（卸载硬盘已挂载的mnt目录）mount &#x2F;dev&#x2F;sdb1 &#x2F;data #挂载新的目录vi &#x2F;etc&#x2F;fstab （编辑fstab文件修改或添加，使重启后可以自动挂载）&#x2F;dev&#x2F;sdb1 &#x2F;data ext4 auto 0 0 # 将 mnt 改为 data, ext4为分区磁盘类型 查看CPU1234567891011## 查看CPU个数cat &#x2F;proc&#x2F;cpuinfo | grep &quot;physical id&quot; | uniq | wc -l## 查看CPU核数cat &#x2F;proc&#x2F;cpuinfo | grep &quot;cpu cores&quot; | uniq## 总数cat &#x2F;proc&#x2F;cpuinfo | grep &quot;processor&quot;## CPU 支持的指令集cat &#x2F;proc&#x2F;cpuinfo | grep flag CPU占用最多的10个进程1ps auxw|head -1;ps auxw|sort -rn -k3|head -10 查看GPU1lspci | grep -i nvidia 查看位数1getconf LONG_BIT 修改home目录第一种办法：暴力修改：123456789vi &#x2F;etc&#x2F;passwd 登录名：加密口令：数字用户ID:数字组ID:注释字段：起始目录：shell程序 liufangtong:x:1006:1006::&#x2F;data&#x2F;home&#x2F;liufangtong:&#x2F;bin&#x2F;bash# timeout in locking authority file &#x2F;data&#x2F;home&#x2F;liuft&#x2F;.Xauthoritysudo chown liuft:liuft -R &#x2F;data&#x2F;home&#x2F;liuftcp &#x2F;原宿主目录&#x2F;.bashrc &#x2F;目标目录 linux 命令终端提示符显示-bash-4.2#解决方法发现用户登录的CRT的终端提示符显示的是-bash-4.2# 而不是root@主机名 + 路径的显示方式。原因是用户在用户目录下面的几个配置文件丢失，丢失文件如下：1、.bash_profile2、.bashrcroot在/root下， [user]在/home/[user]下以上这些文件是每个用户都必备的文件。使用以下命令从主默认文件重新拷贝一份配置信息到/root目录下12cp &#x2F;etc&#x2F;skel&#x2F;.bashrc &#x2F;root&#x2F;cp &#x2F;etc&#x2F;skel&#x2F;.bash_profile &#x2F;root&#x2F;","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"【读书笔记】文艺复兴","slug":"reading/the_renaissance","date":"2020-04-11T09:01:14.000Z","updated":"2023-08-10T12:04:37.664Z","comments":true,"path":"reading/the_renaissance/","link":"","permalink":"https://tlylft.github.io/reading/the_renaissance/","excerpt":"","text":"","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"句法分析","slug":"NLP/syntax","date":"2020-04-11T06:05:48.000Z","updated":"2021-06-11T03:16:38.392Z","comments":true,"path":"NLP/syntax/","link":"","permalink":"https://tlylft.github.io/NLP/syntax/","excerpt":"","text":"https://blog.csdn.net/qq_37171771/article/details/79342819 PCFG content free grammars probabilistice.g.S -&gt; NP VPNP -&gt; DT(The) NN(dog) 12345678NP： noun phraseVP: verb phrasePP: prepositionse phraseDT: determinerVi: intransitive verbVt: transitive verbNN: nounIN: preposition CFG is 4 tuple G=(N,sigma, R,S)N : non-terminalsNN DT IN S NP VP PP Vi Vtsigma: terminalsdog the with sleep saw man woman inR: relationS -&gt; NP VPVP -&gt; ViVP -&gt; Vt NPVP -&gt; VP PPNP -&gt; DT NNNP -&gt; NP PPPP -&gt; IN NPS: start","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"医药领域实体识别","slug":"NLP/NER/medical_NER","date":"2020-04-03T07:03:52.000Z","updated":"2023-02-20T01:03:41.294Z","comments":true,"path":"NLP/NER/medical_NER/","link":"","permalink":"https://tlylft.github.io/NLP/NER/medical_NER/","excerpt":"","text":"网上看的一个讲特定行业的NER的思路，可以参考。 项目背景","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"NER","slug":"NER","permalink":"https://tlylft.github.io/tags/NER/"}]},{"title":"【transformer】 01-Transformer","slug":"NLP/transformer/transformer","date":"2020-04-02T00:36:56.000Z","updated":"2023-08-14T01:59:55.986Z","comments":true,"path":"NLP/transformer/transformer/","link":"","permalink":"https://tlylft.github.io/NLP/transformer/transformer/","excerpt":"","text":"Transformer[TOC] 自从Google在2017年此文《Attention is All You Need》提出来Transformer后，便开启了大规模预训练的新时代，也在历史的长河中一举催生出了BERT这样的大一统模型。 1. basic knowledge1.1. Seq2Seq 网络输入一个序列 输出一个序列，且长度可变。网络结构的提出主要用于机器翻译。输入输出很直观。 序列经过编码形成编码向量，然后解码成输出序列，中间有一个向量C传递信息，且C的长度是固定的。 1.2. RNN vs TransformerRNN网络也算是一种encoder-decoder模型，一般设置为两三层解决问题，不能并行计算， 因为每个下一步都依赖于上一步。 而transformer通过self-attention机制解决RNN不能并行问题，输出结果是同时被计算出来的，目前基本取代RNN 1.3. word2vec vs Transformer 1.4. seq2seq vs Transformerseq2seq:当输入句子比较长时，所有语义完全转换为一个中间语义向量C来表示，单词原始的信息已经消失，可想而知会丢失很多细节信息。所以Encoder-Decoder是有缺陷的，其缺陷在于：当输入信息太长时，会丢失掉一些信息。transformer:为解决上述问题，设计了self-attention机制。 2. 整体结构模型主要分为编码器和解码器。multi-Head中包含一个特殊的结构：self-attentionencoder和decoder结构略有不同：decoder的多头多了一层masked掩码 注：1.注意上图中的N*, encoder和decoder部分都是由n（一般6-7个）个结构相同但参数不同的编码器组成，是循环训练n个encoder，这里并不是并行训练。2.albert会有部分的模型层参数是共享的。 2.1. 引入Attention机制模型相较于seq2seq,Attention 模型的特点是 Eecoder 不再将整个输入序列编码为固定长度的「中间向量Ｃ」，而是编码成一个向量的序列(包含多个向量)。引入了Attention的Encoder-Decoder 模型如下图。优势： 从输出的角度每个输出的词Y会受到每个输入词的整体影响，不是只主要受某一个词的影响，毕竟整个输入语句是整体而连贯的，但同时每个输入词对每个输出的影响又是不一样的，即每个输出Y受每个输入词的影响权重不一样，而这个权重便是由Attention计算，也就是所谓的注意力分配系数，计算每一项输入对输出权重的影响大小 从编码的角度讲在根据给到的信息进行编码时（或称特征提取），不同信息的重要程度是不一样的（可用权重表示），即有些信息是无关紧要的，比如一些语气助词之类的，所以这个时候在编码时，就可以有的放矢，根据不同的重要程度针对性汲取相关信息 2.2. attention 注意力机制简单来说解决的问题： 问题不同，需要关注的维度区域也不同.含义公式： $ Attention(Query, Source) = \\sum_{i=1}^{L_x}Similarity(Query, Key_i) * Value_i $ attention表示的是查询向量和已知项的关系表示。矩阵公式： $ Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k} })V $QK做点乘得到某个值，一个向量在另一个向量上的投影长度，是个标量，可以反映两个向量的相似度，点乘结果越大，可以表示越相似。 2.2.1. 举例说明图片表示示例 q: 查询矩阵 （输入的矩阵表示—婴儿部分的矩阵向量）k_i: 待查询矩阵 （将图片划分多个查询区域，每个区域的不同矩阵表示）q*k: 婴儿矩阵和区域矩阵的相似度，该相似度作为后续该区域计算婴儿关系的权重，相似度越高，表示这部分和婴儿的关系越密切，权重越高。v_i: 自身含义的编码序列 （每个图片区域i的值向量表示）最终， $attention(婴儿， 图片) \\\\\\= sim(婴儿, 区域1) v1 + sim(婴儿, 区域2) v2 + sim(婴儿, 区域3) v3 + sim(婴儿, 区域4) v4 \\\\\\= weight1 v1 + weight2 v2 + weight3 v3 + weight4 v4$ 文本表示示例 F(Q,K) ： F函数为计算相似性的函数，有多种实现方式，如：点乘，cos mltsoftmax： 归一化，使得 a1+a2 +a3+a4 = 1，即表示为权重和V矩阵相乘得到attention value 2.2.2. 模型中的self-attention机制模型为自注意力机制，多了一个自（self),我的理解是因为一条文本内自己的单词的注意力表示？ 论文中的一些设定：1.设定词向量维度为512维2.查询向量、键向量、值向量这三个向量设置的是64维，比词嵌入向量更低，因为词嵌入和编码器的输入/输出向量的维度是512，但也不是必须比编码器输入输出的维数小，这样做主要是为了让后续多头注意力的计算更稳定3.多头注意力机制对每个512维的输入向量都设置了8个头，不同的头关注每个输入向量不同的部分，而每个头的维度则是：512/8 = 64，且再多说一句，也可以设置为2个头，不一定非得设置为8个头 $X = (x1, x2… x3)$ 分别为每个单词512位的词向量表示，作为transformer模型的输入。shape=(n, 512)$Q = (q1, q2…q3) = X W^Q = (x1Wq, x2Wq)$ 如何获取QKV?这三个向量的生成方法是把输入的向量分别乘以三个不同的权重矩阵$W^{Q}$、$W^{K}$、$W^{V}$，得到Q、K、V，而这些权重矩阵是在模型训练阶段中训练出来的「对于权重矩阵W^{Q}/W^{K}/W^{V}如何训练出来的，还是标准老套路：先随机初始化，然后在损失函数中表示出来，最后通过反向传播不断优化学习得出，最终目标是最小化模型的预测误差 ============================================== 完善到了这里！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！ 如何计算得到attention的值 为什么要除以d_k?softmax(x)，x比较大时函数太平缓，梯度很小，不容易做gradient decent。 也可以理解为做一次归一化，做一次降维 优势： 从效率角度解决了RNN不能并行计算的问题 2.2.3. multi-head self-attention每个头分别关注了输入向量的某一部分，如256位的输入向量分为8个头，每个头关注了32个向量维度。训练多个q,k,v, 每个头关注了不同的关注点，可以考虑到更多的细节局部信息的影响。但是好像没有考虑位置信息。将多个头计算出的Z进行拼接， 得到多头机制的输出 2.3. encoder 2.3.1. 输入部分 embedding 位置嵌入为什么需要位置编码？TODO: 2.3.2. positional encoding将位置信息加入输入层。 在self-attension中，是没有位置信息的 原始paper这样说： 每个位置都有自己唯一的位置向量编码（不是从数据中学来的） 换句话说： 每个embedding向量添加一个one hot的位置信息向量RNN训练的是一套参数，transformer训练的是不同的参数 RNN 的梯度消失和普通网络的梯度消失有什么不同？说是RNN由于连乘效应产生梯度消失，并不十分准确，RNN的梯度是个总的梯度和，并不是会趋于0，它的梯度被近距离梯度主导，被远距离梯度忽略不计。 RNN和transformer的区别RNN是串行化训练的序列，transformer的注意力机制是并行处理的，比RNN快，但是会缺少顺序信息，所以加入位置编码 2i理解成偶数位置， 2i+1理解成奇数位置，在偶数位置使用sin函数，奇数位置使用cos函数， 得到和embedding一样维度的位置编码。将512维度的位置编码和512维度embedding相加，就是这个字整个transformer的输入编码。 为什么要分奇数偶数不同的编码？ 2.3.4. 残差和LayerNormhttps://www.bilibili.com/video/BV1Di4y1c7Zm?p=4 2.3.5. batch normal vs layer normalhttps://www.bilibili.com/video/BV1Di4y1c7Zm?p=5&amp;spm_id_from=pageDriver batch normal效果在NLP中很少比layer normal效果好。 batch normal batch Nomal是针对一个batch中的所有样本的某/每一个特征做batch normal, 比如每个同学的身高特征，体重特征，年龄特征。优点：可以解决内部的协变量偏移缓解了梯度饱和问题，加快收敛缺点：batch size比较小，效果比较差（batch数据不能很好代表全部数据）RNN中效果比较差 ，RNN输入是动态的，不能有效的获取batch中的均值和方差（同理，可能因为样本长度很长的地方，没有batch的数据能够代表整体数据） layer normal BN的那种表示对于文本情景不太适合，LN对一个样本的所有单词做缩放。 2.4. Decoderhttps://www.bilibili.com/video/BV1Di4y1c7Zm?p=7&amp;spm_id_from=pageDriver 2.4.1. masked multi-head为什么需要mask?因为预测的时候，我们是不知道字符下一个特征的，所以把当前单词后面的特征mask掉 2.4.2. 交互层 multi-headencoder 是Q生成KV矩阵， Q来自于输入decoder 是KV生成的Q矩阵，KV 来自于encoder最后一层的输出，Q来自decoder的上一个输出","categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"},{"name":"transformer","slug":"LLM/transformer","permalink":"https://tlylft.github.io/categories/LLM/transformer/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"}]},{"title":"tensorflow introduction","slug":"tensorflow/tensor_intro","date":"2020-04-01T12:08:40.000Z","updated":"2021-06-11T04:20:31.651Z","comments":true,"path":"tensorflow/tensor_intro/","link":"","permalink":"https://tlylft.github.io/tensorflow/tensor_intro/","excerpt":"","text":"1. introgoogle的AI学习系统，底层是C++,上层是python。 windows系统目前兼容python3.5/3.6，mac和linux都可以 Tensorflow 2.0取消了会话，定义完op直接可输出结果，不需要会话启动清理了1.0的废弃的API和减少重复简API可以使用Keras和eager execution轻松构建模型 2. installgpu安装参见：https://tlylft.github.io/python/Anaconda/gpu_install/ 2.1. tesorflow1 安装anaconda 123pip install tensorflowpip install tensorflow-gpupip install tensorflow --upgrade 2.2. tesorflow2123pip install tensorflow&#x3D;&#x3D;2.0.0pip install tensorflow-gpu&#x3D;&#x3D;2.0.0pip uninstall tensorflow 3. basic concept使用图graphs来表示计算任务，图中的节点为operation，一个op获得0个或多个tensor，执行计算，产生0或多个tensor。在session会话中执行图，图必须在session里被启动。使用tensor表示数据，可看做是一个n维的数组或列表。通过变量variable维护状态使用feed和fetch可以为任意的操作赋值和取值 4. session","categories":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://tlylft.github.io/categories/tensorflow/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://tlylft.github.io/tags/tensorflow/"}]},{"title":"keras 线性回归","slug":"python/keras/keras_LR","date":"2020-03-31T06:11:55.000Z","updated":"2021-06-11T03:29:15.332Z","comments":true,"path":"python/keras/keras_LR/","link":"","permalink":"https://tlylft.github.io/python/keras/keras_LR/","excerpt":"","text":"环境安装介绍可以将tensorflow等看做是后台计算，keras是前端封装，所以安装时也要先安装tensorflow,注意这两个东西的版本是有对应关系的。 通过构建线性回归模型讲解keras的基本实现过程一元线性回归123456789101112131415import kerasfrom keras import layers#简单模型，先构建一个顺序模型model &#x3D; leras.Sequential()# 加入模型结构层,（输入和输出的维度 y&#x3D; ax+b 输入一个x, 输出一个y）model.add(layers.Dense(1, input_dim &#x3D; 1))# 查看构建的整体结构model.summary()# 编译模型，确定优化函数和损失函数model.compile(optimizer &#x3D; &#39;adam&#39;, loss &#x3D; &#39;mse&#39;)# 训练模型model.fit(x,y,epochs &#x3D; 3000)# 使用模型model.predict(x) 多元线性回归$f(x) = w_1x_1+w_2x_2 +b$读取数据12345import pandas as pddata &#x3D; pd.read_csv(path)data.head()x &#x3D; data[data.columns[1:-1]]y &#x3D; data.iloc[:,-1]123456789101112131415import kerasfrom keras import layers#简单模型，先构建一个顺序模型model &#x3D; leras.Sequential()# 加入模型结构层,（输入和输出的维度 y&#x3D; ax+b 输入一个x, 输出一个y）model.add(layers.Dense(1, input_dim &#x3D; 3))# 查看构建的整体结构model.summary()# 编译模型，确定优化函数和损失函数model.compile(optimizer &#x3D; &#39;adam&#39;, loss &#x3D; &#39;mse&#39;)# 训练模型model.fit(x,y,epochs &#x3D; 3000)# 使用模型model.predict(x) 分类问题分类问题的损失函数，我们一般采用交叉熵表示，因为不是一个数值，用均值方差显然不合理，分类结果的表示一般采用概率分布，所以用实际值和预测值分布之间的交叉熵可以更好的表示出差异。sigmoid 函数，将输出转换为趋向于0或1的解， softmax函数，将输出转换为每种类别的分布。 二分类问题keras一般使用binary_crossentropy计算二元交叉熵解决二分类问题的损失函数。多分类一般使用 categorical_crossentropy 和 sparse_categorical_crossentropy","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"keras","slug":"python/keras","permalink":"https://tlylft.github.io/categories/python/keras/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"keras","slug":"keras","permalink":"https://tlylft.github.io/tags/keras/"}]},{"title":"Anaconda 安装","slug":"python/env/install","date":"2020-03-31T05:25:19.000Z","updated":"2021-06-11T03:27:16.278Z","comments":true,"path":"python/env/install/","link":"","permalink":"https://tlylft.github.io/python/env/install/","excerpt":"","text":"1. 安装Anaconda1.1. 下载与平台一致的安装包anaconda和python版本对应关系：python 3.6.3 Anaconda3-5.0.1python 3.6.4 Anaconda3-5.1.0python 3.7.1 Anaconda3-2018-12 历史版本下载: https://repo.anaconda.com/archive/ https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ 1.2. 安装1.2.1. windows下的安装直接双击安装 1.2.2. linux下的安装bash Anaconda3-4.3.1-Lixux-x86.sh中间会配置安装目录增加环境变量12345678# 增加环境变量vi &#x2F;root&#x2F;.bashrc# added by Anaconda3 4.4.0 installerexport PATH&#x3D;&quot;&#x2F;root&#x2F;anaconda3&#x2F;bin:$PATH&quot;保存后!!!source &#x2F;root&#x2F;.bashrc 1.3. notebook 的配置设置默认目录 在开始菜单里找到并打开Anaconda Prompt，输入如下命令，然后执行。1jupyter notebook --generate-config 打开上一步显示的文件路径，修改默认目录的配置1234# 修改前#c.NotebookApp.notebook_dir &#x3D; &#39;&#39;# 修改后c.NotebookApp.notebook_dir &#x3D; &#39;E:\\\\Notebook&#39; 修改notebook 的快捷启动方式在win开始菜单中找到jupyter notebook快捷图标，鼠标右键&gt;&gt;属性&gt;&gt;快捷方式&gt;&gt;目标删除最后的 “%USERPROFILE%/“ 。2. conda 包管理工具python和C语言的库都可以安装conda -versionconda listconda install conda update conda remove *rm -rf ~/anaconda 频道管理国内源conda config —add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config —add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config —add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2conda config —add channels https://pypi.douban.com/simplehttps://pypi.doubanio.com/simpleconda config —set show_channel_urls yes 删除源conda config —remove channels https://pypi.doubanio.com/simple/附加源conda-forge因此conda-forge是可以安装软件包的附加渠道。如果在https://anaconda.org注册并上传自己的Conda软件包，可以添加自己的频道。conda install -c conda-forge flask-sqlalchemy更改频道每次安装包时指定一个频道，该套件必须存在于该频道：conda install -c some-channel packagename增加频道（优先）如果经常使用相同的频道，那么可能需要将其添加到配置中conda config —add channels some-channel增加频道（末尾）conda config —append channels some-channel删除频道conda config —remove channels some-channel查看频道conda config —show-sources 3. 创建虚拟环境conda create -n envname python=3.6 4. 激活环境activate envname(windows)source activate envname (linux)添加到notebook中pip install ipykernelpython -m ipykernel install —user —name envname查看notebook内核jupyter kernelspec list删除内核jupyter kernelspec remove envname 5. 迁移环境pip批量导出包含环境中所有组件的requirements.txt文件 pip freeze &gt; requirements.txt pip批量安装requirements.txt文件中包含的组件依赖 pip install -r requirements.txt conda批量导出包含环境中所有组件的requirements.txt文件 conda list -e &gt; requirements.txt conda批量安装requirements.txt文件中包含的组件依赖 conda install —yes —file requirements.txt 6. 安装包6.1. 正常安装6.2. 内网环境安装（代理）Anaconda找到.condarc文件，windows: C:\\Users\\\\{username}.condarc修改内容为：12345678910111213channels: - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F; - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;conda-forge&#x2F; - https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;cloud&#x2F;msys2&#x2F; - defaultsshow_channel_urls: Trueallow_other_channels: True proxy_servers: http: http:&#x2F;&#x2F;proxy.tencent.com:8080 https: http:&#x2F;&#x2F;proxy.tencent.com:8080 ssl_verify: Falsepippip —proxy=http://username:password@proxyURL:portNumber install tensorflow 6.3. linux内网环境安装 （生成whl）https://blog.csdn.net/gf19960103/article/details/96483511","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://tlylft.github.io/tags/Anaconda/"}]},{"title":"机器翻译","slug":"NLP/translation","date":"2020-03-30T12:21:19.000Z","updated":"2021-06-11T03:16:46.480Z","comments":true,"path":"NLP/translation/","link":"","permalink":"https://tlylft.github.io/NLP/translation/","excerpt":"","text":"1. traditional method中文 -&gt; 英文今天 天气 很 好the weather is great today.词到词的翻译+ sequential algorithm 排列顺序 2. neural machine translation2.1. pre-knowledge2.1.1. 端到端的方法multi-model learning input: 中文 通过 RNN/LSTM 模型 生成一个中间特征 output: 英文 也是通过RNN/LSTM 模型（同encoder-decoder 框架） 2.1.2. multimodel learningRN/LSTM 表示时序的数据，如文本和语言CNN 可做图片有多种组合可以解决不同的问题：CNN to RNN/LSTM: 看图说话RNN/LSTM to CNN: 文字生成图片RNN/LSTM to RNN/LSTM： 机器翻译，语音识别，生成音乐 2.1.3. RNN/LSTMhttp://localhost:4000/deep_learning/RNN/ 2.2. seq2seq model一种端到端的模型，也是采用encoder-decoder 思想， 学习 meaning vector的表示，可以连接机器翻译中的两种语言表示。decoder每次输出一个结果时，会产生一个loss， 我们是通过降低loss的方式来训练模型的。 训练数据是以翻译对的方式提供：\\,\\，\\…通常会将输入和输出，都标准化为同样长度的数据，这样转换为一个矩阵，再做batch会很方便，一般选取最长句子的长度作为输入/输出的向量长度，其他句子用特殊符号补位。 训练时，如何评定一个predict值和truth值的loss或差异呢。一般会采用n-gram的方法。e.g. 可以看uni-gram，truth中的每个单词是否存在在predict中，当然，uni-gram 效果没有考虑语序问题。 所以也可以采用bi-gram 或 tri-gram,或者几种n-gram的结合方式去评估。 预测时，如何判断当前输出是最优解呢？第一个单词输出时，希望并只考虑当前输出是最优的解，每一步都是这样想要得到最优解的话， 可以看做是一种贪心greedy算法，但这种方法只能得到局部的最优解，他只考虑了在当前输出的情况下（当前位置左右）的最好的可能，不一定是适配于整个输出的。比如我们在第一步得到第一个单词最优解是weather，但不能说先输出today就是不对的。解决方法：exhaustic search, 穷举法，保留所有的可能，都计算完再看，很耗资源。 beam search, 保留每次最优的top n. 每次都保留最优的topn, 加权值取长度的平均值可以避免一种可能过早的出现结束符结束。 问题：long term dependency 梯度消失 ，关联差linear 不能并行化，效率慢 attention attention for image captioning attention for machine translation self attention","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"python异常码","slug":"python/Flask/flask_exception","date":"2020-03-18T11:15:00.000Z","updated":"2021-06-11T03:28:10.950Z","comments":true,"path":"python/Flask/flask_exception/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_exception/","excerpt":"","text":"封装自定义的异常体可以通过继承的方式，定义自己需要的成员变量12345678910111213141516171819202122# define error codeARGS_ERROR &#x3D; 101DATABASE_ERROR &#x3D; 102OTHER_ERROR &#x3D;200# define error desc for codeerror_dict &#x3D; &#123;ARGS_ERROR: &#39;arguments error&#39;, DATABASE_ERROR:&#39;database connection error&#39;, OTHER_ERROR: &#39;system error&#39;&#125;class ErrorException(Exception): status_code &#x3D; 400 def __init__(self, message, status_code&#x3D;None, payload&#x3D;None): Exception.__init__(self) self.err_msg &#x3D; message self.err_code &#x3D; status_code if status_code is not None else OTHER_ERROR self.err_desc &#x3D; error_dict.get(self.err_code) def to_dict(self): rv &#x3D; dict(status &#x3D;self.err_code, status_desc &#x3D; self.err_desc, msg&#x3D;self.err_msg) return rv 抛出异常1234567891011try: # do somethingexcept Exception as e: # 这个只会打印错误信息本身 logger.error(&quot;query error.&quot;, e) # 这个可以打印溯源错误的层叠关系，和raise一样。但只是打印并不抛出，程序异常码仍为0-正常 traceback.print_exc() # format_exc返回字符串类型，print_exc直接打印 logger.error(traceback.format_exc()) # raise会错误的层叠关系，抛出异常，程序异常码为exit 1 raise ErrorException(&quot;query error.&quot;,DATABASE_ERROR) 获取异常123456try: # 调用抛出异常的代码except ErrorException as e: err_code &#x3D; e.err_code err_desc &#x3D; e.err_desc return ErrorResponse(e.err_code,e.err_desc,e.err_msg)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"Flask 项目配置","slug":"python/Flask/flask_project","date":"2020-03-18T10:56:28.000Z","updated":"2021-06-11T03:28:35.002Z","comments":true,"path":"python/Flask/flask_project/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_project/","excerpt":"","text":"flask 启动配置直接run.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# file: run.pyimport portalockerfrom flask import Flask, render_templatefrom NER.WordCloudNER import init_dictfrom route.NLPRoute import *from scheduler.ScheduleController import init_schedulerfrom utils.DBUtil import dbfrom config.config import conf# 创建 flask app# 有页面的时候，设置 template 和 static 目录app &#x3D; Flask(__name__,template_folder&#x3D;&quot;templates&quot;,static_folder&#x3D;&#39;static&#39;)# 接口web服务，直接创建即可# app &#x3D; Flask(__name__)# 加载蓝图管理app.register_blueprint(nlp_route, url_prefix&#x3D;&quot;&#x2F;nlp&quot;)# 引入配置文件中的相关配置app.config.from_object(conf)# 加载数据库db.app &#x3D; appdb.init_app(app)# 可以解决oracle数据库中文字符乱码问题os.environ[&quot;NLS_LANG&quot;] &#x3D; &quot;GERMAN_GERMANY.UTF8&quot;# 页面渲染@app.route(&#39;&#x2F;&#39;)def render_index(): return render_template(&#39;index.html&#39;)@app.route(&#39;&#x2F;touch&#39;)def render_audio(): return render_template(&#39;touch.html&#39;)@app.route(&#39;&#x2F;report&#39;, methods&#x3D; [&#39;get&#39;])def render_report(): url &#x3D; request.args.get(&quot;report_url&quot;) url &#x3D; &#39;http:&#x2F;&#x2F;freport.bdmp.cluster.enn.cn:8080&#x2F;report&#x2F;&#39; + url return render_template(&#39;showIframe.html&#39;, visit_url &#x3D; url)# 启动项目if __name__ &#x3D;&#x3D; &#39;__main__&#39;: # 多进程启动会有启动重复的情况，可以把不想启动多个进程的部分，用文件锁控制 # schedule need start just 1 time file &#x3D; open(&quot;data&#x2F;schedule&#x2F;scheduler.lock&quot;, &quot;wb&quot;) try: portalocker.lock(file, portalocker.LOCK_EX| portalocker.LOCK_NB) init_scheduler() except: pass # 本地启动https的服务没有问题，服务器上需要配置ssl_context SERVER &#x3D; conf.SERVER SERVER_PORT &#x3D; conf.SERVER_PORT if APP_ENV &#x3D;&#x3D; &#39;dev&#39;: app.run(host&#x3D;SERVER, port&#x3D;SERVER_PORT) else: app.run(host&#x3D;SERVER, port&#x3D;SERVER_PORT, ssl_context&#x3D;(&#39;.&#x2F;cert.pem&#39;, &#39;.&#x2F;key.pem&#39;)) init文件https://github.com/goalong/flask-demo/blob/master/app/\\_\\_init\\_\\_.pyhttps://gitee.com/fengyu3631/flask-demo/blob/master/app/__init__.py目录结构：flask app的应用目录单独放在子文件夹下，把上面的主文件改为init,在主文件中调用app即可。 __init__.py1234567891011121314151617from flask import Flask, current_appfrom nlp_server.config.config import conffrom nlp_server.route.nlp_route import nlp_routedef create_app(): app &#x3D; Flask(&#39;nlp_platform&#39;) # 蓝图管理 app.register_blueprint(nlp_route, url_prefix&#x3D;&quot;&#x2F;nlp&quot;) # 引入配置文件中的相关配置 app.config.from_object(conf) # 初始化创建的对象 conf.init_app(app&#x3D;app) return apprun.py123456from nlp_server import create_appapp &#x3D; create_app()if __name__ &#x3D;&#x3D; &#39;__main__&#39;: app.run(host&#x3D;&#39;0.0.0.0&#39;,port&#x3D;8000) https://segmentfault.com/a/1190000018087099?utm_source=tag-newest","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"概率图模型","slug":"NLP/algorithm/graph_theorem","date":"2020-03-16T08:35:25.000Z","updated":"2021-06-11T03:07:16.397Z","comments":true,"path":"NLP/algorithm/graph_theorem/","link":"","permalink":"https://tlylft.github.io/NLP/algorithm/graph_theorem/","excerpt":"","text":"图定义图是由结点及连接结点的编组成的集合。结点记作𝑣，结点集合记作𝑉 ；边记作𝑒，边的集合记作𝐸；图记作𝐺 = (𝑉, 𝐸)。 概率图模型是由图表示的概率分布。设由联合分布$P(Y)$ ，$Y$是⼀组随机变量。由⽆向图$𝐺 = (𝑉, 𝐸)$表示概率分布$P(Y)$ ，即在图$G$中，结点 $v\\in V$表示⼀个随机变量 $Y_v$， ；边$e\\in E$表示随机变量之间的概率依赖关系。 1. 有向图模型和无向图模型1.1. 模型举例有向图模型：Naive BayesHMM无向图模型：Logistic RegressionLinear-chain CRF 1.2. 联合概率的表示在有向图里，联合概率通过指向关系来表述成每个条件概率，每一个点的条件概率只依赖于局部。在无向图里，联合概率为图中每个最小团（clique）的关系（feature function）的乘积。同时为了保证概率和相加为1，最后结果需要除以一个normalization Term/partition function。 partition function是一个全局的需要计算的变量，是无向图中的难点，离散型的时候可以通过维特比算法解决，连续型的时候需要考虑的东西比较多。 2. 生成式模型和判别式模型概率模型计算的是变量的概率分布，利用已知变量推断未知变量的分布的过程称为“推断”。生成式模型先学习联合概率分布P(x,y), 再依此来构造目标函数，求解条件概率密度P(Y|X)判别式模型直接通过训练样本计算条件概率P(Y|X)，再来构造目标函数。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"algorithm","slug":"NLP/algorithm","permalink":"https://tlylft.github.io/categories/NLP/algorithm/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"algorithm","slug":"algorithm","permalink":"https://tlylft.github.io/tags/algorithm/"}]},{"title":"RNN 循环神经网络","slug":"deep_learning/RNN","date":"2020-03-16T00:59:56.000Z","updated":"2021-06-11T02:59:31.213Z","comments":true,"path":"deep_learning/RNN/","link":"","permalink":"https://tlylft.github.io/deep_learning/RNN/","excerpt":"","text":"1. RNN introduction1.1. why RNN许多数据是随着时间的变化而变化的，股票、天气、语音、文本等，这种数据叫做时序的数据，Time series data.为了处理这样的序列数据，有了RNN，处理时序的数据模型。它的好处：可以处理不同时长的数据。应用：语音识别，文本分类，分词标注，翻译 1.2. RNN vs HMM继承了HMM的思路， 类比HMM中的转移状态，这一时刻的状态是和上一时刻的状态有关，我们想要解决这一时刻和上两个时刻或上好几个时刻的状态有关的情况，满足：$S_{t+1} = f(s_o,s_1,…,s_t)$区别： 隐层表示是不同的HMM是用one hot 表示的，是一种稀疏表示方式，状态转移过程中需要转移函数，这个转移矩阵的表示会非常大，RNN采用分布式表示，是稠密的表示方式，转移的权重表示可以压缩成小的矩阵表示。 1.3. RNN vs BP2. Recurrent Neural Network具有记忆功能，序列顺序的改变会影响输出结果 2.1. 模型结构 2.1.1. 线性关系的简单理解这张图没什么太大意义，就是说明下y2的输出除了和输入的两个6有关系，还和上一时刻隐藏层算出来的16也有关系。 2.1.2. Vanilla（原始的）RNN:循环神经网络不仅考虑了当前输入和输出的关系，还有时序上的关系，设定：U为输入的权重矩阵，W为状态转移的（即上一状态和这一状态下的）权重矩阵，V为输出时的权重矩阵。当在t时刻，输入为$x^{(t)}$隐层输入和上一时刻隐层的输出对输出结果的影响：$S_t = tanh(Ux_t + WS_{t-1} + bias)$输出为 隐层状态的一次转换加上激活函数：$O_t = softmax(VS_t+ bias)$深度： CNN是在隐层的深度，RNN是在时序上的深度，也可以延伸隐层的深度 2.2. 两种形式：Elman network 和 Jordan networkElman network 包含了隐层自己之间的关联Jordan network 包含了更多隐层和上一时刻的输出层之间的关联其实他们两者的差别非常小 2.3. 不足和缺点：梯度问题例1：有一朵云飘在（）例2：我从小生长的美国，所以我可以说一口流利的（） 第一个例子是可以通过RNN实现填补的，而第二个就很难，因为RNN原始类似是一个BP网络，在向前传递时，会存在梯度爆炸或者梯度消失的问题，到长序列的问题，影响力是下降的。 缺点： 会存在梯度爆炸或者梯度消失的问题vanishing/exploding gradient如果训练的时候范数很小，序列越长，最后训练出的梯度会越来越小，逐渐消失，反之，会发生梯度爆炸。所以RNN很难训练。解决梯度爆炸，可以通过缩小计算出的梯度值，如果梯度太大，乘以一个系数的方式解决： Bidirectional RNNs","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"python中的文件锁","slug":"python/python/python_filelock","date":"2020-03-15T14:58:58.000Z","updated":"2021-06-11T04:18:20.087Z","comments":true,"path":"python/python/python_filelock/","link":"","permalink":"https://tlylft.github.io/python/python/python_filelock/","excerpt":"","text":"1. 安装包12pip install portalocker# fcntl 在windows中无法安装，发现portalocker可以。 2. 使用说明https://pypi.org/project/portalocker/ 3. 应用lock限制进程/线程的启动重复问题12345678910if __name__ &#x3D;&#x3D; &#39;__main__&#39;: app.debug &#x3D; True file &#x3D; open(&quot;scheduler.lock&quot;, &quot;wb&quot;) try: portalocker.lock(file, portalocker.LOCK_EX| portalocker.LOCK_NB) # do what you need to do init_scheduler() except: print(&#39;except&#39;) file.close()会自动解锁文件，无需执行解锁操作：portalocker.unlock(file)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"Flask中的定时任务","slug":"python/Flask/flask_schedule","date":"2020-03-15T11:02:18.000Z","updated":"2021-06-11T03:28:51.212Z","comments":true,"path":"python/Flask/flask_schedule/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_schedule/","excerpt":"","text":"1. 安装包https://apscheduler.readthedocs.io/en/stable/userguide.html1pip install apscheduler需要根据web框架选用合适的scheduler：BlockingScheduler 只支持在项目中只有定时作业的情况下。BackgroundScheduler 会在后台运行，如果不满足一下情况，可以选择这个。AsyncIOScheduler: use if your application uses the asyncio moduleGeventScheduler: use if your application uses geventTornadoScheduler: use if you’re building a Tornado applicationTwistedScheduler: use if you’re building a Twisted applicationQtScheduler: use if you’re building a Qt application可以选择不同的存储方式，默认是内存存储 2. 编写需要定时的函数123def org_name_init(schedule_type): print(&#39;【&#123;&#125;】start schedule task..&#39;.format(schedule_type)) print(&#39;执行定时任务&#39;) 3. 嵌入定时器3.1. ScheduleManager1234567891011121314151617181920212223242526272829303132333435363738# -*- coding: utf-8 -*-&#39;&#39;&#39;@Date : 2020&#x2F;3&#x2F;15 9:59@Author : liufangtong@desc :&#39;&#39;&#39;from apscheduler.schedulers.background import BackgroundScheduler# from apscheduler.schedulers.blocking import BlockingSchedulerfrom apscheduler.events import EVENT_JOB_EXECUTED, EVENT_JOB_ERRORfrom logger.ScheduleLoggerHandler import schedule_loggerfrom scheduler.KpiNameInit import *from scheduler.OrgNameInit import *from utils.EmailHandler import EmailHandler# 事件的监听，异常可以打日志，发邮件或打电话def my_listener(event): if event.exception: print(&#39;任务出错了！！！！！！&#39;) subject &#x3D; &#39;定时任务数据获取异常&#39; else: print(&#39;任务照常运行...&#39;) subject &#x3D; &#39;定时任务数据获取正常&#39; email &#x3D; EmailHandler() to_list &#x3D; [&#39;ccc@xx.cn&#39;] msg &#x3D; str(event.__dict__) email.send_email(to_list, subject, msg)# 如果是程序内置的job,不需要时常更改，可以直接初始化增加def init_scheduler(): scheduler &#x3D; BackgroundScheduler() scheduler.add_job(func&#x3D;kpi_name_init, args&#x3D;(&#39;定时任务&#39;,), name&#x3D;&#39;kpi词典定时任务&#39;, trigger&#x3D;&#39;cron&#39;, hour &#x3D; &#39;&#39;, minute&#x3D;&#39;*&#x2F;1&#39;) scheduler.add_job(func&#x3D;org_name_init, args&#x3D;(&#39;定时任务&#39;,),name&#x3D;&#39;org词典定时任务&#39;, trigger&#x3D;&#39;cron&#39;, minute&#x3D;&#39;*&#x2F;1&#39;) # scheduler.add_job(func&#x3D;aps_test, args&#x3D;(&#39;一次性任务&#39;,), next_run_time&#x3D;datetime.datetime.now() + datetime.timedelta(seconds&#x3D;12)) # scheduler.add_job(func&#x3D;aps_test, args&#x3D;(&#39;循环任务&#39;,), trigger&#x3D;&#39;interval&#39;, seconds&#x3D;3) scheduler._logger &#x3D; schedule_logger scheduler.add_listener(my_listener, EVENT_JOB_EXECUTED | EVENT_JOB_ERROR) scheduler.start() 定时模式 triggerhttps://blog.csdn.net/weiwangchao_/article/details/81285778add_job的第二个参数是trigger，它管理着作业的调度方式。它可以为date, interval或者cron。对于不同的trigger，对应的参数也相同。cron定时调度（某一定时时刻执行）12345678910111213(int|str) 表示参数既可以是int类型，也可以是str类型(datetime | str) 表示参数既可以是datetime类型，也可以是str类型year (int|str) – 4-digit year -（表示四位数的年份，如2008年）month (int|str) – month (1-12) -（表示取值范围为1-12月）day (int|str) – day of the (1-31) -（表示取值范围为1-31日）week (int|str) – ISO week (1-53) -（格里历2006年12月31日可以写成2006年-W52-7（扩展形式）或2006W527（紧凑形式））day_of_week (int|str) – number or name of weekday (0-6 or mon,tue,wed,thu,fri,sat,sun) - （表示一周中的第几天，既可以用0-6表示也可以用其英语缩写表示）hour (int|str) – hour (0-23) - （表示取值范围为0-23时）minute (int|str) – minute (0-59) - （表示取值范围为0-59分）second (int|str) – second (0-59) - （表示取值范围为0-59秒）start_date (datetime|str) – earliest possible date&#x2F;time to trigger on (inclusive) - （表示开始时间）end_date (datetime|str) – latest possible date&#x2F;time to trigger on (inclusive) - （表示结束时间）timezone (datetime.tzinfo|str) – time zone to use for the date&#x2F;time calculations (defaults to scheduler timezone) -（表示时区取值1234567891011#表示2017年3月22日17时19分07秒执行该程序sched.add_job(my_job, &#39;cron&#39;, year&#x3D;2017,month &#x3D; 03,day &#x3D; 22,hour &#x3D; 17,minute &#x3D; 19,second &#x3D; 07)#表示任务在6,7,8,11,12月份的第三个星期五的00:00,01:00,02:00,03:00 执行该程序sched.add_job(my_job, &#39;cron&#39;, month&#x3D;&#39;6-8,11-12&#39;, day&#x3D;&#39;3rd fri&#39;, hour&#x3D;&#39;0-3&#39;)#表示从星期一到星期五5:30（AM）直到2014-05-30 00:00:00sched.add_job(my_job(), &#39;cron&#39;, day_of_week&#x3D;&#39;mon-fri&#39;, hour&#x3D;5, minute&#x3D;30,end_date&#x3D;&#39;2014-05-30&#39;)#表示每5秒执行该程序一次，相当于interval 间隔调度中seconds &#x3D; 5sched.add_job(my_job, &#39;cron&#39;,second &#x3D; &#39;*&#x2F;5&#39;)interval 间隔调度（每隔多久执行）weeks (int) – number of weeks to waitdays (int) – number of days to waithours (int) – number of hours to waitminutes (int) – number of minutes to waitseconds (int) – number of seconds to waitstart_date (datetime|str) – starting point for the interval calculationend_date (datetime|str) – latest possible date/time to trigger ontimezone (datetime.tzinfo|str) – time zone to use for the date/time calculations 12#表示每隔3天17时19分07秒执行一次任务sched.add_job(my_job, &#39;interval&#39;,days &#x3D; 03,hours &#x3D; 17,minutes &#x3D; 19,seconds &#x3D; 07) date 定时调度（作业只会执行一次）12run_date (datetime|str) – the date&#x2F;time to run the job at -（任务开始的时间）timezone (datetime.tzinfo|str) – time zone for run_date if it doesn’t have one already12345# The job will be executed on November 6th, 2009sched.add_job(my_job, &#39;date&#39;, run_date&#x3D;date(2009, 11, 6), args&#x3D;[&#39;text&#39;])# The job will be executed on November 6th, 2009 at 16:30:05sched.add_job(my_job, &#39;date&#39;, run_date&#x3D;datetime(2009, 11, 6, 16, 30, 5), args&#x3D;[&#39;text&#39;]) 3.2. 放置到flask启动中1234567if __name__ &#x3D;&#x3D; &#39;__main__&#39;: app.debug &#x3D; True init_scheduler() # app.run(host&#x3D;&#39;127.0.0.1&#39;, port&#x3D;8080) SERVER &#x3D; configs[APP_ENV].SERVER SERVER_PORT &#x3D; configs[APP_ENV].SERVER_PORT app.run(host&#x3D;SERVER, port&#x3D;SERVER_PORT) 解决多进程中APScheduler重复运行的问题问题产生分析：https://blog.csdn.net/weixin_30815469/article/details/95011739 在一个python web应用中需要定时执行一些任务，所以用了APScheduler这个库。又因为是用flask这个web框架，所以用了flask-apscheduler这个插件（本质上与直接用APScheduler一样，这里不作区分）。 在开发中直接测试运行是没有问题的，但是用gunicorn部署以后发生了重复运行的问题： 每个任务在时间到的时刻会同时执行好几遍。 注意了一下重复的数量，恰恰是gunicorn里配置的worker进程数量，显然是每个worker进程都启动了一份scheduler造成。 通过文件锁解决：123456789101112if __name__ &#x3D;&#x3D; &#39;__main__&#39;: app.debug &#x3D; True file &#x3D; open(&quot;scheduler.lock&quot;, &quot;wb&quot;) try: portalocker.lock(file, portalocker.LOCK_EX| portalocker.LOCK_NB) init_scheduler() except: print(&#39;already have one scheduler starting&#39;) # app.run(host&#x3D;&#39;127.0.0.1&#39;, port&#x3D;8080) SERVER &#x3D; configs[APP_ENV].SERVER SERVER_PORT &#x3D; configs[APP_ENV].SERVER_PORT app.run(host&#x3D;SERVER, port&#x3D;SERVER_PORT) 自定义增删任务（接口）https://blog.csdn.net/weiwangchao_/article/details/81285778","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"pyhton 发送邮件","slug":"python/python/python_email","date":"2020-03-15T10:47:54.000Z","updated":"2021-06-11T04:18:08.723Z","comments":true,"path":"python/python/python_email/","link":"","permalink":"https://tlylft.github.io/python/python/python_email/","excerpt":"","text":"1. exchange 发送邮件 https://blog.csdn.net/LeoForBest/article/details/79429955 1.1. 安装包1pip install exchangelib 1.2. 代码12345678910111213141516171819202122232425262728293031323334353637383940414243# -*- coding: utf-8 -*-&#39;&#39;&#39;@Date : 2020&#x2F;3&#x2F;15 13:55@Author : icey@desc : 邮件报警&#39;&#39;&#39;from exchangelib import DELEGATE, Account, Credentials, Configuration, NTLM, Message, Mailbox, HTMLBodyfrom exchangelib.protocol import BaseProtocol, NoVerifyHTTPAdapterimport urllib3# 消除urllib3的warning 输出urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)#此句用来消除ssl证书错误，exchange使用自签证书需加上BaseProtocol.HTTP_ADAPTER_CLS &#x3D; NoVerifyHTTPAdapterclass EmailHandler(object): def __init__(self, user, password): # 输入你的域账号如example\\leo self.cred &#x3D; Credentials(username&#x3D;user, password&#x3D;password) # exchange的服务器 self.config &#x3D; Configuration(server&#x3D;&#39;xx.xx.xx&#39;, credentials&#x3D;self.cred, auth_type&#x3D;NTLM) self.account &#x3D; Account( primary_smtp_address&#x3D;&#39;xxx@xx.cn&#39;, # credentials&#x3D;cred, config&#x3D;self.config, autodiscover&#x3D;False, access_type&#x3D;DELEGATE ) def send_email(self,To,subject,content): try: m &#x3D; Message( account&#x3D; self.account, subject&#x3D;subject, body&#x3D;HTMLBody(content), to_recipients&#x3D; To ) m.send_and_save() return True except Exception as e: # logger.error(&quot;【%s】邮件发送失败,请检查信息&quot;%subject) return False 1.3. 调用1234email &#x3D; EmailHandler(&#39;xxx@xx.xx&#39;, &#39;yourpassword&#39;)to_list &#x3D; [&#39;xx@xx.cn,&#39;xxx@xx.com&#39;]msg &#x3D; str(event.__dict__)email.send_email(to_list, subject, msg) SMTP邮件发送 https://www.cnblogs.com/damon-/p/9010523.html 123456789101112131415161718192021222324252627282930313233343536373839404142import smtplibfrom email.mime.text import MIMETextfrom email.utils import formataddrclass EmailHandler(object): def __init__(self,user,password,type &#x3D; 0): &quot;&quot;&quot; :param user:str 发送人邮箱地址（用户名） :param password:str 发送人在QQ或163申请的授权码 :param type:int 0 为QQ邮箱 1 为163邮箱 &quot;&quot;&quot; self.__QQ &#x3D; &#123;&#39;smtp&#39;:&#39;smtp.qq.com&#39;,&#39;port&#39;:465&#125; self.__163 &#x3D; &#123;&#39;smtp&#39;:&#39;smtp.163.com&#39;,&#39;port&#39;:25&#125; self.user &#x3D; user self.password &#x3D; password if type &#x3D;&#x3D; 0: self.server&#x3D;smtplib.SMTP_SSL (self.__QQ[&#39;smtp&#39;],self.__QQ[&#39;port&#39;]) self.server.login (self.user,self.password) elif type &#x3D;&#x3D; 1: self.server&#x3D;smtplib.SMTP_SSL (self.__163[&#39;smtp&#39;],self.__163[&#39;port&#39;]) self.server.login (self.user,self.password) def send_mail(self,To,subject,content): &quot;&quot;&quot; :param To:str 接收人邮箱地址 :param subject:str 邮件标题 :param content:str 邮件内容 :return:bool True 成功 False 失败 &quot;&quot;&quot; try: msg &#x3D; MIMEText(content,&#39;plain&#39;,&#39;utf-8&#39;) msg[&#39;From&#39;] &#x3D; formataddr([&#39;spider邮件报警系统&#39;,self.user]) msg[&#39;To&#39;] &#x3D; formataddr([&#39;&#39;,To]) msg[&#39;Subject&#39;] &#x3D; subject self.server.sendmail(self.user,To,msg.as_string()) print(&quot;【%s】邮件发送成功&quot;%subject) return True except Exception as f: print(&quot;【%s】邮件发送失败,请检查信息&quot;%subject) return False","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"word2vec 静态词向量算法（CBOW，skip-gram, glove）","slug":"NLP/word2vec/word2vec_model","date":"2020-03-13T14:49:24.000Z","updated":"2021-06-11T03:15:13.787Z","comments":true,"path":"NLP/word2vec/word2vec_model/","link":"","permalink":"https://tlylft.github.io/NLP/word2vec/word2vec_model/","excerpt":"","text":"Word2vec基于浅层神经网络获得词向量的工具。一个输入层，一个隐藏层。两种模型方式训练词向量，经验论中，skip gram效果更好。CBOW 根据中心词周围的词来预测中心词Skip gram根据中心词来预测周围的词 CBOW本质上还是无监督，因为不用打标签，但在评价的时候还是参考了设定的标签。拿到语料之后，对于每个句子，我们选取一些词作为中心词，进行遮挡，因为是根据中心词周围的词来预测中心词,把每个词用one hot编码表示，训练出向量矩阵关系，使得最后的预测结果为中心词。 步骤如图，i drink coffee everyday. 设置coffee为中心词， 每个词用One hot表示。 定义一个浅层神经网络模型。（1）输入层是每个词（除了中心词）的One hot vector $V_N$，可以理解为表示这个词的位置有没有；乘以一个权重矩阵$WI_{VN}$,V是语料大小（语料中共含有V个单词），N是表示的向量维度大小100-300， 也就是每一行表示了一个词在输入层的词向量，语料一共有多少词就有多少行。 每个词和这个W相乘，拿到的结果就是 将每个词对应的W中的位置提取出来了。（2）隐层：将上一步提取出来的n个词的向量，取平均值得到隐层的输入，得到了一个N维的向量表示，可以理解成将这个句子用每个词做平均表示。乘以一个权重矩阵$W’_{NV}$,这个矩阵也可以理解成隐藏层为每个词做的向量表示，句向量乘以每个词，得到了 一个$1*V$的向量，这个向量的每个值代表了每个词的输出情况（概率），（3）做一次softmax,值最大的index就表示了中心词最可能是哪个词。（在训练过程中，目标函数是将中心词预测位置的数值和中心词one hot的差值最小化。）Skip gram离得越近的单词，相似度越高 通过中间的单词去预测周边的单词可能是什么。因为离得越近的单词，相似度越高，就可以得出这些词之间相关度是很高的，所以在模型训练的时候，给定中间的词，和定义周边的范围（滑窗大小），通过权重调整训练，去逼近我们期望的词的概率是最大的这种情况（我们的目标函数）。 那就有以下问题：设置滑窗大小？ 如何去表示最大的这个概率？ 如何去训练$\\theta$权重，去逼近目标函数？ softmax? 为什么点乘？ hierarchical output layer层级树，因为softmax计算量太大，所以用这种方式减少计算量。 representation Glove官网：https://nlp.stanford.edu/projects/glove/官网实现代码（C）：https://github.com/stanfordnlp/GloVepython 实现代码：https://github.com/maciejkula/glove-python 原理安装https://www.jianshu.com/p/7afed1281a0a作者写的官方教程：https://github.com/maciejkula/glove-python/wiki/Installation-on-Windows踩的坑：python3.7装不上！！！！python3.7装不上！！！！python3.7装不上！！！！直接装也装不上！！！！直接装也装不上！！！！直接装也装不上！！！！啊啊啊啊装疯了 安装gcc (1) Download mingw-w64.https://sourceforge.net/projects/mingwbuilds/files/host-windows/releases/4.8.1/64-bit/threads-posix/seh/(2) Unzip mingw-w64 to a directory with no spaces e.g. C:\\mingw64\\(3) Add the bin\\ directory to your PATH(4) Verify that running $where gcc.exe in a command prompt prints your MinGW64 installation first. Re-arrange your PATH if not 环境隔离，python3.6 下载源码，编译(1) Install an up-to-date version of libpython (conda install “libpython&gt;=2.1”)(2) Clone this repository and move into its root directory (glove-python)(3) Runpython setup.py build_ext —compiler=mingw32 to verify it builds and double check it uses your installation of MinGW64. You can ignore the warnings but make sure it creates a directory called build\\lib.blah with some .pyd files inside(4) 执行pip install . to add the compiled libraries to your current environment 训练https://cloud.tencent.com/developer/article/14349111234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from glove import Glovefrom glove import Corpus# 准备数据集sentense &#x3D; [[&#39;你&#39;,&#39;是&#39;,&#39;谁&#39;],[&#39;我&#39;,&#39;是&#39;,&#39;中国人&#39;]]corpus_model &#x3D; Corpus()corpus_model.fit(sentense, window&#x3D;10)#corpus_model.save(&#39;corpus.model&#39;)print(&#39;Dict size: %s&#39; % len(corpus_model.dictionary))print(&#39;Collocations: %s&#39; % corpus_model.matrix.nnz)&gt;&gt; Dict size: 5&gt;&gt; Collocations: 6# 训练100指的是维度glove &#x3D; Glove(no_components&#x3D;100, learning_rate&#x3D;0.05)glove.fit(corpus_model.matrix, epochs&#x3D;10, no_threads&#x3D;1, verbose&#x3D;True)glove.add_dictionary(corpus_model.dictionary)&gt;&gt;&gt; Performing 10 training epochs with 1 threads&gt;&gt;&gt; Epoch 0&gt;&gt;&gt; Epoch 1&gt;&gt;&gt; Epoch 2&gt;&gt;&gt; Epoch 3&gt;&gt;&gt; Epoch 4&gt;&gt;&gt; Epoch 5&gt;&gt;&gt; Epoch 6&gt;&gt;&gt; Epoch 7&gt;&gt;&gt; Epoch 8&gt;&gt;&gt; Epoch 9# 模型保存和加载glove.save(&#39;glove.model&#39;)glove &#x3D; Glove.load(&#39;glove.model&#39;)# 求相似度glove.most_similar(&#39;我&#39;, number&#x3D;10)&gt;&gt;&gt; [(&#39;中国人&#39;, 0.15130809810072138),&gt;&gt;&gt; (&#39;你&#39;, 0.0739901044877504),&gt;&gt;&gt; (&#39;谁&#39;, -0.05137569131012555),&gt;&gt;&gt; (&#39;是&#39;, -0.08668606334919005)]# 词向量矩阵# 全部词向量矩阵glove.word_vectors# 指定词条词向量glove.word_vectors[glove.dictionary[&#39;你&#39;]]","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"word2vec","slug":"NLP/word2vec","permalink":"https://tlylft.github.io/categories/NLP/word2vec/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"word2vec","slug":"word2vec","permalink":"https://tlylft.github.io/tags/word2vec/"}]},{"title":"文本相似度","slug":"NLP/similarity/similarity_method","date":"2020-03-13T11:47:23.000Z","updated":"2021-06-11T03:14:01.067Z","comments":true,"path":"NLP/similarity/similarity_method/","link":"","permalink":"https://tlylft.github.io/NLP/similarity/similarity_method/","excerpt":"","text":"1. 应用及意义这是一个听起来很简单的概念，简单的理解是通过词表示计算两句话之间的相近程度。在思考它的应用前，会了解到有许多计算文本相似度的方法，那么为什么会有这么多的方法呢？ 大概是因为，文本相似度的计算是要需要满足各种不同的场景， 用什么样的方法取决于在特定场景、语料下，哪种方式更适合。 从one hot到tf-idf 到词袋模型，无所谓算法的难易，而在于在特定语料计算中，哪种方式的效果更能准确的表达出文本间的相似关系。 2. 方法介绍欧式距离相似度只考虑了大小，而余弦相似既考虑了方向又考虑了大小。方向体现在：每个词代表了一个维度的方向，欧式距离只考虑了每个词上的距离去做运算，而余弦相似却通过相乘内积的方式，将不存在的向量方向（词）维度的距离归零。优势体现在： s1和s2明明不相关的两句话，欧式却认为相似度是最近的，而余弦可以把这种不相关识别出来。 2.1. Euclidean distance$d = |s_1 - s_2| = \\sqrt (x_1-y1)$我们 今天 去 爬山:(1,0,1,1,1,0,0,0)你们 昨天 跑步: (0,0,0,0,0,1,1,1)你们 又 去 爬山 又 去 跑步: (0,2,2,1,0,1,0,1) cosine similarity","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"}]},{"title":"神经网络基础","slug":"deep_learning/neuron_network","date":"2020-03-12T12:38:48.000Z","updated":"2021-08-23T08:40:23.563Z","comments":true,"path":"deep_learning/neuron_network/","link":"","permalink":"https://tlylft.github.io/deep_learning/neuron_network/","excerpt":"","text":"通过设定输入，和一个可求导的输出，算法通过梯度下降自动逼近和调整特征权重的一种模型。 不需要手动训练和调整差分等规则。 1. 多层神经网络1.1. 神经元 The Neuron前期介绍的都是基于统计学的模型，n-gram model, 用CNN神经网络解决非线性的关系单层神经元的网络就相当于LR.x1..xn 为inputw 为需要训练的权重对x和w进行线性组合 wx+b传入激活函数，输出结果。 激活函数一般为sig 1.2. 全连接网络 Full Connected Networks 全连接神经网络的本质：将低维数据向高维数据映射，通过增加数据所在的维度空间，让数据变得线性可分。理论上全连接神经网络可以对任何数据进行分类。 但缺点是，需要更多的参数参与训练。 一旦参数过多，则训练过程较难收敛。 隐藏层节点个数和层数：个数主要决定了模型的拟合能力， 如果过拟合，考虑减少节点个数和层数。 作用： 全连接神经网络往往放到模型的最后部分，具有调节维度的作用，可以轻松的将原有维度变换到任意维度。一般前后层维度的比值在0.2-5，更容易训练模型。 每一个颜色为一个layer（j为第一层的input个数，i为第二次的参数个数）w为上一层到下一层的权重全连接网络，对于每一层的w，都构成一个填满的i*j大小的矩阵 1.3. Bias构造一个偏置b 1.4. 特征工程https://tlylft.github.io/machine_learning/feature_preprocess/ 1.5. 初始化权重随机初始化，常见的是高斯初始化 1.6. 层级间输入与输出的关系1.6.1. linear combiner对于第二层的每个节点i, $z^l_i$ 表示每个第二层的神经元的输入函数$z_i^l = w_{i1}^l a_1^{l-1} + w_{i2}^l a_2^{l-1} + b_i^l$ 每个节点都表示一遍： 1.6.2. active functionhttps://tlylft.github.io/machine_learning/function/乘积值会越来越大，使用激活函数可以压缩数值的范围.sigmoid压缩到0-1的话，从另一个角度讲，可以表示为概率了。常用于二分类多分类的问题，可以用softmax,它是sigmoid的延伸 pros: 神经网络是一层层线性，非线性的组合的叠加，空间度和自由度都很大，可以训练出我们想象不到的规则和表达方式，在此之前，一般的ML是带有人为偏见的，我们会认为（假设）他们的关系可能是线性的，他的分布可能是泊松分布，这种假设就成了主观的先验，训练的效果会受到影响。我们可以应用神经网络的结构对输入与输出层的关系进行模拟逼近。cons:Tricky：如何表示 $f(x) = wx + b$中的 b输入层x 设置增加x0 = 1w 权重 增加对应的 w0, 这样 $b = w_0 = w_0x_0$ 1.7. loss function 损失函数 1.8. 多层网络的表示 NN and LRA neural network = running several logistic regressions at the same time.第一层： $f(x) = \\delta (W^1X+b_1)$ 第二层： $f(x) = \\delta (W^2(\\delta (W^1X+b_1))+b_2)$第三层：如何确定变化：$\\partial f \\over \\partial w^2 $涉及到组合函数的偏导，复合函数的导数是每一部分导数的乘积的形式，如下图，组成了一个chain rule.最后回归到 $W^1,W^2,W^3..$ 这三个参数的确定和优化，x的变化会影响$f(x)$怎样的变化，找到他们直接梯度的关系，沿着梯度比较小的地方偏移和下降。 1.9. 正则化惩罚项https://tlylft.github.io/machine_learning/regularization_penalty/ 1.10. dropout过拟合问题，除了用l1,l2惩罚项，还可以用dropout.正则化的原理是减小每个神经元的权重，但保留每个神经元， dropout的原理是随机选择一部分神经元（0.4-0.6之间的drop率） 1.11. 应用如果设置输入和输出相等，那么可以作为一种加密解密的应用场景，或者是压缩的应用场景。","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"NLP中的词表示","slug":"NLP/word2vec/word_represent","date":"2020-03-12T03:24:10.000Z","updated":"2021-06-11T03:14:59.240Z","comments":true,"path":"NLP/word2vec/word_represent/","link":"","permalink":"https://tlylft.github.io/NLP/word2vec/word_represent/","excerpt":"","text":"1. 词表示：将语言转换成数学问题，传递给计算机，进行处理和计算。自然语言可以看成一个词序列，是个非连续的数据。 1.1. One hot one-hot优缺点分析 优点： 非常Naive的表示方式，简单直接有效。 一是解决了分类器不好处理离散数据的问题； 二是在一定程度上也起到了扩充特征的作用（上面样本特征数从3扩展到了9）； 缺点：但词典大的时候存储量大，向量sparse，而且不能表示词语间的语义相似性。 首先，它是一个词袋模型，不考虑词与词之间的顺序； 其次，它假设词与词相互独立（在大多数情况下，词与词是相互影响的）； 最后，它得到的特征是离散稀疏的； 1.1.1. boolean representation单词表示dict = {我们，去，爬山，今天，你们，昨天，跑步}我们:(1,0,0,0,0,0,0)爬山:(0,0,1,0,0,0,0)跑步:(0,0,0,0,0,0,1)昨天:(0,0,0,0,0,1,0)句子表示dict = {我们，又，去，爬山，今天，你们，昨天，跑步}boolean representation我们 今天 去 爬山:(1,0,1,1,1,0,0,0)你们 昨天 跑步: (0,0,0,0,0,1,1,1)你们 又 去 爬山 又 去 跑步: (0,1,1,1,0,1,0,1) 1.1.2. Count-based Representation加入了词频的权重。我们 今天 去 爬山:(1,0,1,1,1,0,0,0)你们 昨天 跑步: (0,0,0,0,0,1,1,1)你们 又 去 爬山 又 去 跑步: (0,2,2,1,0,1,0,1) 1.1.3. TF-IDF 权重处理Term Frequecy- Inverse Document Frequency考虑了单词的重要性，tf类似于count-based 表示词频，idf考虑了单词的重要性，一个词出现的多不代表它重要，出现的少不代表它不重要。 $tf = \\cfrac {n_{ij}}{\\sum_k n_{kj}} $一个词在当前文档中出现的次数 除以 这篇文档的所有词的总次数&lt;一个词在这篇文章中出现越多，说明越重要，权重越大&gt;$idf_i = log \\cfrac{D}{n_i}$所有的文档个数 除以 出现过的文档个数 ，log的意义是防止这个数值过大。 &lt;一个词在每篇文章中都出现，说明它是个通用词，对分类和相似度等的查找并不重要，权重越小&gt; 主题模型 LSA（SVD）,pLSA, LDA1.2. Distribution Representation1.2.1. intro词向量不是只与自己本身相关，也会加入对其他词影响的权重。代表了一个单词的意思meaning。一个好的词向量表示，相似的词能够在二维空间坐标系里聚集在一起。与one-hot的对比one-hot 词向量的长度为词典的长度，而分布式的表示的长度是自己定义的，是一个稠密的向量，避免了稀疏性的问题。one-hot 词向量只有一个数有值表示自己的出现，而分布式每个位置都是非零的数值，表示在词向量维度空间中的位置。可以通过这种位置关系将语义相似表现出来。capacity比one hot 具备更好的表达能力global generation one hot 是一种 local generation, 分布式的表示具有更好的泛化能力，泛化能力体现在通用性强，在测试数据中不会过拟合，（比如k-means聚类算法，如果有一类只聚到了一个样本，那么这类样本的预测就会出现过拟合现象，所以k-means被定义为一种local generation的算法）深度学习生成方式分布式词向量的生成是通过深度学习模型训练得来的，有很多可以生成词向量的模型，常用的是skip-Gram模型，还有Gloue, CBOW,RNN/LSTM, MF(matrix factorization), Gaussian Embedding.需要设定的参数是：dim = 100/200/300/50 (需要生成的词向量长度)其他的参数不同的模型自己的参数。业界需要很大量级的语料库， 1 billion 或 10 B: 包含1B/10B个单词, 否则效果不会很准确。耗费的资源非常大，一般会采用大厂已经训练好的词向量直接使用。 专业领域的话通用性比较差，需要自己训练。效果 1.2.2. basic theorem以下原理会包含在模型训练中： 在一个文章里，离得越近的词相似度相对越大 词向量转换为句向量 word embedding to sentence embedding average Rule 平均值法则 对每列取平均值，生成一个新的类似于词向量的句向量 LSTM/RNN 时序 1.2.3. algorithmCBOW的用法是，通过周围的单词去预测中间的单词，而Skip-Gram和它相反，是通过中间的单词去预测周边的单词可能是什么。CBOW的应用场景并不多。CBOW常见并不常用，应用场景不多Skip-Gram常用的模型https://tlylft.github.io/NLP/algorithm/skip_gram_model/ Glone基本常用 2. 相似度 https://tlylft.github.io/NLP/similarity/similarity_method/ 3. Semantic Similarity 语义相似度需要学习到：sim(我们去爬山,我们去运动)&gt; sim(我们去爬山, 我们去吃饭)如何获取语义上的表示方式，使得我们可以更加丰富的表示出语义的相似情况呢？ 我们可以基于上下文可以定义词语的意思。12345# 定义滑窗长度size &#x3D; 6：... and the cuteeeeee kitten purred and then...... the cute furry cat purred and miaowed ..... that the small kitten miaowed and she ...... the loud furry dog ran and bit ..给定一个单词，可将经常和这个词在滑窗size内一起出现的词组成一个词向量：vocabulary: {bit, cute,furry,loud,miaowed,purred,ran,small}kitten context words: cute, purred, small, miaowedcat context words: cute, ffurry, miaoweddog context words: load, furry, ran, bit转换成词向量：kitten = [0,1,0,0,1,1,0,1]cat = [0,1,1,0,1,0,0,0]dog = [1,0,1,1,0,0,1,0]相似度计算：sim(kitten,cat) = cos(kitten,cat) = 0.58sim(kitten,dog) = cos(kitten,dog) = 0sim(cat, dog) = cos(cat,dog) = 0.39 3.1. embeding matrix3.2. word2VecCBOW continuous bag of words m是个one hot 输入，V代表的是权重向量，y hat 是一个归一化的结果的词向量分布 训练的是U和V skip-gram","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"word2vec","slug":"NLP/word2vec","permalink":"https://tlylft.github.io/categories/NLP/word2vec/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"word2vec","slug":"word2vec","permalink":"https://tlylft.github.io/tags/word2vec/"}]},{"title":"TextCNN:CNN 在文本中的应用","slug":"NLP/algorithm/TextCNN","date":"2020-03-12T02:41:22.000Z","updated":"2021-06-11T04:23:20.084Z","comments":true,"path":"NLP/algorithm/TextCNN/","link":"","permalink":"https://tlylft.github.io/NLP/algorithm/TextCNN/","excerpt":"","text":"1. CNN参阅：https://tlylft.github.io/deep_learning/CNN/ 2. TextCNNI like drink cokeI like drink popsinput：I like drinkoutput : coke应用概率的统计方法，是学习 $P(w_4|w_1w_2w_3)$，但是这样我们只能够学习到coke和drink, pops和drink的关系，不能学习到coke和pops的关系，但希望学习到coke和pops存在一个向量夹角（相似程度），这个夹角的度数要比coke和table近很多。和概率的方法的区别： 概率统计是直接统计词出现的概率关系，而神经网络是通过训练来逼近这种关系。 输入层的表示：一般以词向量/word2vec形式表示卷积核的大小：一般会以表示一个词的词向量大小为最小单位（一行代表了一个最小特征-一个词的表示），行数代表了上下文的特征。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"algorithm","slug":"NLP/algorithm","permalink":"https://tlylft.github.io/categories/NLP/algorithm/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"algorithm","slug":"algorithm","permalink":"https://tlylft.github.io/tags/algorithm/"}]},{"title":"拼音汉字转换","slug":"chatbot/pinyin2Chinese","date":"2020-03-09T02:38:35.000Z","updated":"2023-08-11T08:41:16.724Z","comments":true,"path":"chatbot/pinyin2Chinese/","link":"","permalink":"https://tlylft.github.io/chatbot/pinyin2Chinese/","excerpt":"","text":"1. 汉字转换成拼音 参阅： https://www.jb51.net/article/167461.htm 1.1. pypinyin (比xpinyin更好一些)安装 pip install pypinyin demo123456789101112131415161718192021import pypinyin # 不带声调的(style&#x3D;pypinyin.NORMAL)word &#x3D; &#39;nihao&#39;pretty_list &#x3D; pypinyin.pinyin(word, style&#x3D;pypinyin.NORMAL)&gt;&gt; output: [[&#39;ni&#39;],[&#39;hao&#39;]] # 带声调的(默认)def yinjie(word): s &#x3D; &#39;&#39; # heteronym&#x3D;True开启多音字 for i in pypinyin.pinyin(word, heteronym&#x3D;True): s &#x3D; s + &#39;&#39;.join(i) + &quot; &quot; return s if __name__ &#x3D;&#x3D; &quot;__main__&quot;: print(pinyin(&quot;忠厚传家久&quot;)) print(yinjie(&quot;诗书继世长&quot;)) 2. 拼音转换成汉字开源包Pinyin2Hanzi的介绍使用demo: https://www.oschina.net/p/pinyin2hanzi源码作者的blog:https://www.letiantian.me/2016-02-08-pinyin-hanzi/源码地址：https://github.com/letiantian/Pinyin2Hanzi自训练词库的流程基于Pinyin2Hanzi的自训练:https://www.kutu66.com//GitHub/article_136352手动实现维特比算法： intro: https://blog.csdn.net/Zh823275484/article/details/87973851code:https://github.com/liuhuanyong/Pinyin2Chinese 2.1. 开源包Pinyin2Hanzi使用作者的blog介绍到，它主要实现了基于HMM方法的拼音转文字方式，和基于词库+动态规划的方式。我大概尝试了一下这两种方法，认为针对我测试的情况，基于词库的效果更好一些。先来看一下如何借助该工具进行转换： 判断是否为拼音，简化拼音1234567from Pinyin2Hanzi import is_pinyinprint(is_pinyin(&#39;lang&#39;))&gt;&gt; Truefrom Pinyin2Hanzi import simplify_pinyinprint(simplify_pinyin(&#39;lue&#39;))# 输出：&#39;lve&#39; 第一种：基于HMM的方式1234567891011121314from Pinyin2Hanzi import DefaultHmmParamsfrom Pinyin2Hanzi import viterbipinyin &#x3D; [&#39;ni&#39;, &#39;zhi&#39;, &#39;bu&#39;, &#39;zhi&#39;, &#39;dao&#39;]# 构建一个可调用hmm模型的实体hmmparams &#x3D; DefaultHmmParams()# 利用维特比找到最优解， path_num为返回的候选集个数，默认返回6个，log &#x3D; True&#x2F;False 决定是否进行对数打分，默认为falseresult &#x3D; viterbi(hmm_params&#x3D;hmmparams, observations&#x3D;pinyin, path_num &#x3D; 2)# 输出结果for item in result: print(item.score, item.path)&gt;&gt; output:&gt;&gt; 1.3155294593897203e-08 [&#39;你&#39;, &#39;知&#39;, &#39;不&#39;, &#39;知&#39;, &#39;道&#39;]&gt;&gt; 3.6677865125992192e-09 [&#39;你&#39;, &#39;只&#39;, &#39;不&#39;, &#39;知&#39;, &#39;道&#39;] 注意：不规范的拼音在解析时会发生KeyError，zhii不规范 第二种： 基于词库方式123456789101112from Pinyin2Hanzi import DefaultDagParamsfrom Pinyin2Hanzi import dagpinyin &#x3D; [&#39;huai&#39;, &#39;an&#39;, &#39;ran&#39;, &#39;qi&#39;]# 构建一个可调用词库字典的实体dagparamsdefault &#x3D; DefaultDagParams()# 利用dag动态规划找到最优解， path_num为返回的候选集个数，默认返回6个，log &#x3D; True&#x2F;False 决定是否进行对数打分，默认为falseresult &#x3D; dag(dagparams, cut_result, path_num&#x3D;2)# 输出结果print(result)&gt;&gt; output:&gt;&gt; [&lt; score&#x3D;0.04097048090243091, path&#x3D;[&#39;怀安&#39;, &#39;燃气&#39;] &gt;, &lt; score&#x3D;0.04097048090243091, path&#x3D;[&#39;淮安&#39;, &#39;燃气&#39;] ] 2.2. 使用前准备我们注意到，这个工具包的输入，拼音是一个分割好的数组，且如果输入的拼音有任何不规范的地方，就会影响整个输出，但在实际应用中，大部分的输入是未拆分的一长串字符，甚至可能会出现错误。所以，前期的数据处理需要做以下工作： 拼写矫正（如需矫正，那么还需要判断是英文还是拼音，是否需要矫正） 拼音分割 实现时间紧张，暂时没有实现拼写矫正，暂时放弃了分析用户输入错误的情况。拼音的分割也是暂时拿了这个大神的代码实现的，但对于一些分割情况应该是有优化的空间的。原理基本是拿到所有的拼音组合情况，构建Trie字典树，进行树匹配。 https://blog.csdn.net/Zh823275484/article/details/87973851 2.3. 实现2.2. 使用前需进行拼音切分","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}]},{"title":"同义词的处理","slug":"chatbot/synony_word","date":"2020-03-08T03:48:08.000Z","updated":"2023-08-11T08:41:36.839Z","comments":true,"path":"chatbot/synony_word/","link":"","permalink":"https://tlylft.github.io/chatbot/synony_word/","excerpt":"","text":"1. python 同义词的替换实现（jieba） https://www.jb51.net/article/179001.htm 方式： 首先将同义词涉及的词汇加入jieba字典中，或提高权重，保证可以被分词识别出来。 构建同义词词典，形成替换对，key为表达的词，val为标准词。 使用jieba进行分词，对于分出来的每个词，进行替换。 123456789101112131415161718192021222324252627282930313233343536import jiebadef replaceSynonymWords(string1): # 1读取同义词表，并生成一个字典。 combine_dict &#x3D; &#123;&#125; # synonymWords.txt是同义词表，每行是一系列同义词，用空格分割 for line in open(&quot;TihuanWords.txt&quot;, &quot;r&quot;, encoding&#x3D;&#39;utf-8&#39;): seperate_word &#x3D; line.strip().split(&quot; &quot;) num &#x3D; len(seperate_word) for i in range(1, num): combine_dict[seperate_word[i]] &#x3D; seperate_word[0] print(seperate_word) print(combine_dict) # 2提升某些词的词频，使其能够被jieba识别出来 jieba.suggest_freq(&quot;年休假&quot;, tune&#x3D;True) # 3将语句切分成单词 seg_list &#x3D; jieba.cut(string1, cut_all&#x3D;False) f &#x3D; &quot;&#x2F;&quot;.join(seg_list).encode(&quot;utf-8&quot;) f &#x3D; f.decode(&quot;utf-8&quot;) print(f) # 4返回同义词替换后的句子 final_sentence &#x3D; &quot; &quot; for word in f.split(&#39;&#x2F;&#39;): if word in combine_dict: word &#x3D; combine_dict[word] final_sentence +&#x3D; word else: final_sentence +&#x3D; word # print final_sentence return final_sentence string1 &#x3D; &#39;年休到底放几天？&#39;print(replaceSynonymWords(string1)) output:12年休&#x2F;到底&#x2F;放&#x2F;几天？年休假到底放几天？ 2. python 同义词的替换实现（replace）有些同义词的替换可能是组合词，如果把它们加到字典的话，可能会影响后面文本相似度匹配的精确度（我暂时想的的办法是1.推荐和文本处理识别模块拆分开部署 2. 推荐和文本处理识别采用不同的分词工具库）。但目前系统没有这么庞大，同义词数据量也较小，所以决定采用第三种方法，效率上不一定可取，但大体满足现阶段需求：构建同义词词典后，遍历词典，逐一对问句进行替换。 3. 哈工大同义词词林 https://lpty-nlp.blog.csdn.net/article/details/80016713","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}]},{"title":"时间文本标准化（日期，区间）","slug":"NLP/NER/time_format","date":"2020-03-07T09:28:58.000Z","updated":"2021-06-11T03:11:47.636Z","comments":true,"path":"NLP/NER/time_format/","link":"","permalink":"https://tlylft.github.io/NLP/NER/time_format/","excerpt":"","text":"Python 日期区间处理 (本周本月上周上月…) https://blog.csdn.net/xiaobuding007/article/details/93721949 复旦Time-NLP优化https://blog.csdn.net/hereiskxm/article/details/51941955https://github.com/shinyke/Time-NLP","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"NER中的特征提取","slug":"NLP/NER/ner_features","date":"2020-03-06T13:11:56.000Z","updated":"2021-06-11T03:10:57.765Z","comments":true,"path":"NLP/NER/ner_features/","link":"","permalink":"https://tlylft.github.io/NLP/NER/ner_features/","excerpt":"","text":"1. 监督学习中的特征工程e.g. The professor Colin roposed a model for NER in 1999. 1.1. Feature Represent Bag of word features 当前次 Colin 前后词 professor, Proposed 前前后后词 The, model Bi-gram (professor,Colin), (Cilin proposed),(The professor),(proposed model) Tri-gram Part-of-speech features 当前词 名词 前后词 n, v 前前后后词 冠词，n n-gram 前缀，后缀 当前词 co, in 前后词 pr, or, pr, ed 前前后后词 … 当前词特性 词长度 含有多少大写字母 是否大写开头 是否包含‘-’ 前面的词是否包含大写 是否包含数字 是否包含特定后缀 ‘my’(特定场景下可以这样设置) etc stemming + 1 中文呢： 拼音，偏旁，声调？ 1.2. Feature EncodingLoc -&gt; one hot[per,geo,loc,…,nothing,..][0,0,1,…,0,0] feature type 分类型 Categorical 男女-&gt; (0,1) (1,0) 表示 :一般用one-hot 连续性 Continuous 身高： 167,178 温度： 27.6,,15 表示 : A. 直接使用： 归一化(0-1) 或 高斯分布(0,1) B. 离散化（场景：银行评分卡）： 会根据数据分布情况去划分binning,150以下用1表示，150-160用2表示 Ordial Feature例如成绩单的等级： ABCDE和连续性的区别在于 95分和90分的差距和90分到85分的差距是差不多的。 但不能说A档到B档的差距和B档到C档的差距是一样的。 Ordinal feature 的层级是有递进关系的，但是interval不一定是规则的（只能了解顺序，但不能量化差别）。 tips: Categorical非常大，也可以考虑feature mergering比如一个特征是城市，城市库里有1000多个城市，但大多数城市都没有出现，数据非常稀疏，会导致效果不好，我们可以按照区域合并，可能只有100个区域。但要根据问题的场景。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"NER","slug":"NER","permalink":"https://tlylft.github.io/tags/NER/"}]},{"title":"信息抽取","slug":"NLP/info_extract/info_extraction","date":"2020-03-05T15:39:03.000Z","updated":"2021-06-11T03:10:03.119Z","comments":true,"path":"NLP/info_extract/info_extraction/","link":"","permalink":"https://tlylft.github.io/NLP/info_extract/info_extraction/","excerpt":"","text":"信息抽取海量文本数据涵盖非常多有价值的信息，但大多数文本不利于计算机的处理和理解。 互联网中超过80%的文本信息是以非结构化的形式存在的，将非结构化的数据转换为有价值的结构化数据，这种技术叫做信息抽取。 抽取的内容：从非结构化或半结构化的文本中，提取出实体，实体属性，实体间关系，事件等信息，形成结构化的内容。 涉及任务：命名实体识别（NER）https://tlylft.github.io/NLP/NER/ner_intro/实体消歧(Entity disambiguation)关系抽取(relationship extraction)事件抽取(event extraction)","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"信息提取","slug":"NLP/信息提取","permalink":"https://tlylft.github.io/categories/NLP/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"信息提取","slug":"信息提取","permalink":"https://tlylft.github.io/tags/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"}]},{"title":"简历结构化","slug":"NLP/info_extract/resume_strcture","date":"2020-03-05T15:39:03.000Z","updated":"2021-06-11T03:10:08.714Z","comments":true,"path":"NLP/info_extract/resume_strcture/","link":"","permalink":"https://tlylft.github.io/NLP/info_extract/resume_strcture/","excerpt":"","text":"BackgroudIf u work in an AI-HR company, once u get a resume, some key information need to be extact. name school graduate year work time skills worked company location 首先，定义实体类别，判断哪些实体是不容易被识别出来的，哪些是可行性比较高的实体。构建知识库： 毕业学校，技能库，公司名字库，地名库","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"信息提取","slug":"NLP/信息提取","permalink":"https://tlylft.github.io/categories/NLP/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"信息提取","slug":"信息提取","permalink":"https://tlylft.github.io/tags/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"}]},{"title":"对话系统现阶段的发展","slug":"chatbot/chatbot_intro","date":"2020-03-05T15:14:32.000Z","updated":"2023-08-11T08:53:28.817Z","comments":true,"path":"chatbot/chatbot_intro/","link":"","permalink":"https://tlylft.github.io/chatbot/chatbot_intro/","excerpt":"","text":"1. 基本还是基于规则做多轮会话，有些可能会用到增强学习，但是目前业界大部分还是使用规则，即便是亚马逊，google等大公司也使用了90% 的规则。 他们会为每一个意图都去设置一个状态机。 2. 步骤：第一步：一定是意图的识别（规则分类+文本分类模型）第二步：针对每个意图，都会有Dialog Management，这里基本都是基于规则的，针对每种情况，先说什么，再说什么。第三步：NER算法，抽取追问或意图的实体。第四步： 填充槽位，调用API查询第五步： NLG,还是基于规则去做的。 3. 其他3.1. 同义词，反义词3.2. 短文本相似度匹配3.3.","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}]},{"title":"CNN卷积神经网络","slug":"deep_learning/CNN","date":"2020-03-04T12:26:59.000Z","updated":"2021-08-23T08:43:17.652Z","comments":true,"path":"deep_learning/CNN/","link":"","permalink":"https://tlylft.github.io/deep_learning/CNN/","excerpt":"","text":"1. 神经网络基础 https://tlylft.github.io/deep_learning/neuron_network/ 浅层神经网络会导致权重矩阵特别的大的情况，训练量比较大，过拟合的风险比较高。 2. CNN 卷积神经网络生理学诺贝尔奖: 人的视觉感光对不同物体不同情况敏感程度（接收到的刺激）是不一样的。比如说光线问题，局部色彩的问题，总得来说导致了我们关注的注意力的聚焦点也不一样。所以导致视网膜图像的情况。视网膜的神经构造也是有很多层状的。也是依据这个，我们把一个个特征或局部区域拆开来看，加上深度的层状，就有了CNN的图像识别。CNN通过局部感受野和权值共享，组合了局部特征，减少了神经网络需要训练的参数。对CNN的理解：把图片不同level的特征进行构建，有很多的参数，导致有很大的自由度，通过复杂的权重调整，进行识别。浅层网络虽然简单，但是容易形成过拟合。所以深度学习的优势不在于参数多，而在于deep,因为有了深度，所以一层一层重造特征，组成了高维的特征，权重调节的低维或高维层级所占的权重。 优点：使用比全连接网络更少的权重，对数据进行基于区域的小规模运算，改善训练参数多少，改善较难收敛的问题，提高模型泛化能力。 以图像为例，传统NN输入层输入的是784个像素点，而CNN传入的是(28*28*3)这个三维结构 卷积层是提取特征，池化层是压缩特征。 提取几次特征后，数据维度变大，进行一次压缩。卷积层和其他神经网络一样，后面加一个RELU函数，池化层没有参数训练。前面的卷积和池化，只是做了特征提取，最后要转换为m分类问题，还要依靠最后一层全连接层。首先将最后一个特征图拉成一个一维的特征向量，长度为n,加上一个输入为n,输出为m的全连接层。特征图的变化： 2.1. 卷积层设定一个3*3*1的卷积核（权重矩阵,filter,kernel），把图像分成不同的小区域，对输入层进行遍历，每个区域相乘后得到一个值，各个区域的值连起来得到一个特征图feature map。其实图像是三维（三通道）数据，设定的卷积核为5*5*3，其实是三个5*5*1分别在三个层/维度下分别计算得到三个特征子图，然后三个子图求和得到一张特征图。 展开计算图（卷积层设置两个卷积核为例，步长为2，卷积后会得到二维的特征图，或者说两个特征图）：两个核可以理解成两种特征提取的方法。可以做很多个卷积层，以第一层为例，每个卷积层有6个5*5*3的卷积核，其中那个3要和输入层的层数对应上，得到了6个子特征图，拼成了一个大小为6的特征图层；就是第一个低维特征。 再向上累加卷积层得到不同程度的特征层。 2.1.1. 参数1：卷积核尺寸和个数 _^: 举个例子： 扔小球，第一次距离设定的圆心的距离是a, 第二次距离圆心的距离是b， 每次扔的距离其实都会有一个概率分布密度，第一次f(x),第二次g(x). 扔两次一共距离相加为3的情况就可以表示为: c=3， 所有a+b=3的情况穷举求和 $\\sum_{a+b=c} f(a)g(b) = \\sum_{a} f(a)g(c-a)$ f(x)为概率密度，g(x)是个卷积 这块说的什么鬼，不可信不可信 图像中，使用一个滑窗，这个滑窗可以叫做一个kernel,filter or feature detector.绿色为原始图像，黄色为滑窗，红色的数字为核的值，通过滑窗相乘相加得到内积和形成了粉色的新的图像。滑窗大小为卷积核大小，卷积核越小，提取越细致，一般3*3不同的卷积核，具有不同滤波器的效果。用深度学习参数训练得到。 卷积核个数：就是前面讲到的，每层最后生成了多少张特征图。 如果有多个卷积层，那么每层的卷积核个数都需要设置。 2.1.2. 参数2：步长步长就是指窗口每次移动多少步。一般设置为1，有时候也会用2.步长比较小的时候，是细粒度的提取特征，得到的特征比较丰富。 2.1.3. 参数3：边缘填充padding由于卷积核按照步长移动进行卷积计算，在边缘会出现划不动的情况，会导致越在边界的数据被作为特征计算的次数越少，在边缘的图像特征会容易被忽略。所以会在边缘补充一圈0，使得边界点不再是边界点。弥补一些边界信息特征缺失，或利用不充分的问题。为什么补充0？ 因为0与卷积核相乘再相加后，对原数据没有任何影响。 same padding 可能会给平面外部补0.valid padding 只会使用平面内的信息，不会超出平面外部。假设，有个28*28的平面，用2*2步长为2的窗口进行卷积或池化。两种方式都会得到14*14的平面。但如果是2*3的平面，用2*2步长为2的窗口进行卷积或池化。same padding 要补一次0，得到1*2的平面valid padding ，得到1*1的平面 文本任务中，会用0补齐所有数据使数据传入大小一致。 2.1.4. 权重参数： 如何理解权值共享假设有100*100的图片，滑窗大小是5*5， 那么在第一层网络层中，有多少训练参数呢？ 是25个w + 1个b，因为如果参数都不同，参数太多了，训练慢而且容易过拟合，所以做了权值共享，每个窗口共享一份权重矩阵。不管图像大小多大，都只与滑窗大小有关。而每个卷积核对应一个偏置参数b 假设有100*100*3的图片，滑窗大小是5*5*3， 那么在第一层网络层中，有多少训练参数呢？ 是75个w + 1个b，每一个通道的权重是不一样的。 假设有100*100*3的图片，用10个滑窗大小是5*5*3的卷积核， 那么在第一层网络层中，有多少训练参数呢？ 是750个w + 10个b，因为加卷积核个数是为了每个卷积核所提取的特征是不同的，而每个卷积核都对应一个偏置参数b. 2.1.5. 输出：特征图尺寸2.2. 池化层 Pooling/subsampling 2.2.1. 权重和池化设置一个池化的filter，取这个窗口的最大或平均值，以此来压缩特征。取最大，可保留最重要的特征，比如人脸的痣。。如果用均值可能就会把痣磨平，美图秀秀基本用的是均值。为啥池化？ 特征压缩。可以看成进一步的特征提取，卷积后的特征图特征还是比较多的，做一次池化，生成另一个size较小的feature map。 池化保持了一定程度的平移不变性，基本保持图像特征元素的位置如果发生了一定改变，也是可以提取到相同的位置特征的。假如三个元素（1，5，3）取max就取到5，如果三个元素向右平移一下变成（0，1，5），那取max之后还是5，具备了平移不变性。大概就是这么个理。 池化层不涉及任何矩阵参数的运算，没有w,b.只是筛选和压缩的作用。实现方式：给一个窗口取最大值，或者平均值，随机取一个值，用的最多的是最大池化。因为比较大的值一般代表比较重要的特征。max-pooling 最大池化只选重要的average/mean-pooling 平均池化逐渐被淘汰了，因为经过试验，发现max比mean基本效果都要好得多。但也有一些应用，比如美图秀秀基本用的是均值。 2.3. 如何理解CNN是一种局部连接的网络其实在这种情况下，就不是之前了解到的全连接网络了，它已经被卷积核的性质，变成了一个particial connections network. 怎么去理解这个particial连接呢？我是这样想的，可以理解是压缩图像，假设输入层x大小为8，如果是全连接网络，就需要一个8*8的权重矩阵W， 然而输出的y,却不一定和这8个x都相关，而只是和他相近的几个x相关，于是这个W就会可能是下图右边那样的稀疏矩阵，那这个本质就是全连接是不必要的，局部连接是更好的选择方式。每向上延展一层，权重的个数就会呈指数增加，pooling/subsampling做的就是选取特征的最大值,为的是更好的保留这个图像的特征。 2.4. 计算过程总结所有矩阵相关的计算过程都是Zero to One 的过程。 一个图片向量或是一个word2vec向量，通过W转换，形成一个一维的数组的过程，这个数组可能代表了各个分类的可能。 CNN卷积的计算，是通过：假设图像大小是 32*32*3， 卷积核大小是5*5*3，通过对图像中每一个5*5*3都与卷积核点乘$w^Tx+b$，得到一个一位数的值,所有的滑窗拼接起来，就形成了一个28*28*1的map.可以通过给定n个卷积核，形成n个map，每一个map都代表着这个图像不同的特点。 这样一步一步下去，卷积核会很多，训练起来消耗比较多，所以引入了pooling的概念，做进一步的特征提取。Stride:可理解为窗口移动步长，之前说的都是窗口逐步移动，我们可以设置Stride = 2, 滑窗每次移动两个位置，这样77的矩阵用33的滑窗横向纵向各移动三次就可以完成，生成一个3*3的output.padding:如果窗口不够，可以在外框补0，可以保持图像的size,为了计算方便的一种技巧。 2.5. 网络层数的问题为什么VGG网络设置到16层，而不是继续加到20层，30层？因为虽然想来层数越多，网络越深，训练效果越好。 但是实际试验现象中并不是这样。因为每一层都是在特征上提取特征，会造成提取的东西越来越模糊，不那么准确。增加的层数会有越来越多学习的不好的层，将整个网络的学习成果拉低了。后来也提出了解决办法：残差网络。在下面介绍。 2.6. 感受野的理解第二个图的绿色感受的是第一个图的绿色部分的特征表示，第三个图的红色感受的是第二个图的红色部分的特征表示，那其实第二个图的红色部分的感受的是第一个图的7*7的区域表示。感受野（filter size小）的作用： 加入的非线性变换多，改变了线性关系，提供了更多组合可能。 训练所需的参数会少 特征提取更细致，避免过拟合。3. 应用3.1. Alexnet 最原始的经典CNN应用12年提出的一个网络结构，是一个八层的网络，5层的卷积和3层全连接。现在看来有很多问题。cons: CONV1:卷积核大小11*11，太大了 LOcal respinse Norm2被证明这一层没有用 3.2. VGG14年提出的网络，改进比较多。A-E代表了发布的几个版本，其中D是应用比较主流的一个版本。16层的网络。比Alexnet效果提升15%左右。pros: 卷积核都是3*3,卷积核比较小，特征提取细致。 层数多，网络结构更深，更好 看特征图的维度，每次做pooling后，特征会压缩1/4，也就会损失一些信息，但VGG在polling后的卷积层，会加倍卷积核个数，将特征图的维度翻倍，将损失的信息弥补回来。 cons: 模型复杂，训练时间很长。以天为单位。3.3. LeNET-5 3.4. resnet残差网络，15年年底提出。解决网络层数增多却降低了模型效果的问题。想法思路是：如果加进的新层没有起到正向效果，就将这一层的影响设置为0.但会导致连接不上下一层，所以采取了 F(x)+x, F(x)做的是决定是否取这一层后的值，x是上一层的结果。这样保证了下一层是有输入的。prons: 保底的网络，保证模型效果不会越来越差。 常用参数50层，101层3.5. 在文本中的分类应用https://tlylft.github.io/NLP/algorithm/TextCNN/","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"}]},{"title":"【读书笔记】我喜欢人生快活的样子 --蔡澜","slug":"reading/Live_A_Cheerful_Life","date":"2020-03-04T11:27:25.000Z","updated":"2023-08-10T12:05:02.839Z","comments":true,"path":"reading/Live_A_Cheerful_Life/","link":"","permalink":"https://tlylft.github.io/reading/Live_A_Cheerful_Life/","excerpt":"","text":"我喜欢人生快活的样子作者：蔡澜 一切都是最好的安排想起大老师在直播时讲的一个故事：《国王与宰相的故事：一切都是最好的安排》, 生活总会给我们很多经历，有时使我愤怒，有时使我不甘，让我怀疑这一切不美好经历的意义，然而诚然，一切的美好的，不愉快的事情，当我时过多年再回首，总会在不经意间对那些难熬的岁月充满了感恩，对一些虚度的美好时光感到一丝悔意。读这本书时，正值国家大规模的疫情爆发期间，现在的我却喜欢“多难兴邦”这个词语，无疑我们遭受的痛苦，国家经受的损失是巨大的，但是正是这样的处境，才能够使更多的人团结起来，让人们去懂得珍惜国泰民安时的生活，让我们的政府积累更多的重大事件处理经验，让我们更清晰的体会到世间的丑恶和美好。生活若给我们苦难，是想让我们成长，未来的某一天，一定会有机会让我们感谢这苦难；生活若给我们安乐，我们便去用心享受这份美好和快乐，懂得珍惜，更要努力，不去辜负生活的这份赐予。无论怎样，一切都是最好的安排。 古时候有个国王，他很喜欢出游，并且经常带着他宠爱的宰相。有一天，他们出去打猎，国王打中了一头狮子，但狮子没有死，突然奋起袭击国王。在众侍卫的救护下，国王仅受了轻伤，断了个小拇指。国王很伤心， 但宰相却说“一切都是最好的安排”。国王很愤怒，把宰相关了起来。一个月后，国王的伤好了，他又想出去玩了。这次，他准备自己一个人出去。他骑马来到 了国界附近的丛林中，舒怀地走在森林的小路上。一群野人突然出现并抓住了国王。他们打算按照当地的风俗把国王当作祭祀供品呈给上天。 就在他们准备将把国王推上祭坛的时候，有人发现国王的小拇指是残缺的，而献给神的礼物怎么能有残缺呢？于是他们放了国王。国王回到皇宫中，下令把宰相请了过来。他对宰相说“我今天才领略到‘一切都是 最好的安排’这句话的意义。不过，爱卿， 我因为小指断掉逃过一劫，你却因此受了一个月的牢狱之灾，这要怎么说呢？”宰相笑了笑，说“陛下，如果我不是在狱中， 依往日惯例，肯定要陪您出行，野人们发现您无法作为祭品的时候，他们就会拿我祭神了。臣还要谢谢陛下的救命之恩呢！”未来的一切都是一个未知数，目前的困难处境一切都是最好的安排。 003 人生的意义，在于一天比一天活得快乐 004 人生识字忧患始书读多了就成了书呆子，最好的办法就是旅行（我理解的旅行是打开心扉和禁锢，走出自己的生活圈，去了解和体会更多的生活方式和人群）。在旅途中，向种种人学习，不管他们的文化程度高低，都有学习的地方。把生活的质量提高，今天活的比昨天高兴快乐，明天又要活的比今天高兴快乐。 007 茶道读这篇时，心情是很复杂的，有迷茫，又觉得些许可笑。自陆羽撰了《茶经》后，茶文化便流传世间，无论日本，台湾，潮州以何种方式进行了延续，它都贯穿了千年文明。我看到身边大部分品茶的人，确实像蔡澜先生书中所描述的一样，茶匙，茶夹，废水缸，闻杯，分盅，样样不落，喝茶求香，追求品质。蔡澜先生似不喜欢这样的品茶方式，他认为茶应该是轻轻松松请客或自用的，想怎么泡就怎么泡，想怎么喝就怎么喝，舒服即是，简单才是茶道，人生也是如此。 我认为蔡澜先生的主张不无道理，但因此我也不觉得那些追求高雅饮茶方式有何不妥，每个人心中都拥有属于自己心中敬仰的茶道，或是严谨，或是像蔡澜先生心中所想的洒脱，只要能将茶用出属于它的韵味，用何种方式又何妨，无非加了一道规矩罢了。 但先生这两句话确是说的毫无争议： 采新茶的香，旧茶的色，中间茶的味，像人生每一个阶段都糅合在一起，无论哪种状态，都是茶，品的都是人生百态。真情流露，就有禅味，有禅味，道即生。 我以为，品茶，品的是生活，平淡的，疾苦的，芬香的…都有它的魅力。 025 做一个贪吃贪知识的人蔡老先生说他好学，但对所有的知识都是“一瓶不满，半瓶晃荡”。看到这里心里不禁偷笑了一下，描述的像极了自己。虽然知道老先生的一瓶不满和自己的不满不在一个层级，但却也是一个好奇而随性的人。无法评论这种做法的对与错，但大体的原则应该是：对事物时刻保持好奇和求知的态度，但也要拥有一两个精进的领域。我很喜欢这句话： 如果一心一意要当什么大家，不享受过程，也枉然。 是的，重要的是，在求知的过程中收获那份豁然开朗的快乐，才是学习的意义。 029 什么才是我们的主人 在制度的条条框框中长大的孩子，最多只是一个循规蹈矩又没什么生活情趣的人。 我一直把自己定位成这样的孩子，但又庆幸内心真实的自己并不是这样的孩子。我喜欢那种突破条条框框的感觉，会让我觉得活得真实，也能把思维代入一个全新的世界。可我好像大多数时候还是一个习惯循规蹈矩的人，太多的规矩和无奈是横在面前很难撼动的。生活还需很大的勇气啊。 036 好诗配好酒 当歌聊自放，对酒交相劝，为我尽一杯，与君发三愿：一愿世清平，二元身强健，三愿临老头，数与君相见。 —白居易 与友人，把酒言欢，抛去身前身后事，长大后这样的日子却难以实现。我还抱着赤子的初心：愿世间太平，愿身体健硕，愿临老，还能与你们来个照面，像20岁的我们，吹着牛皮，世间的喧嚣与欢愉，可都来自于我们呐！ 047 一生浓缩于一日黎明与晚霞，春日与秋月，朝夕变化，四季更替，是否也曾回忆起起若干年前某个时刻的自己，是否意气风发，是否怅然销颓。 “见一对老夫妇晨运，一生便浓缩于一日。”若一生都浓缩为每一个今日，希望自己每日都安排得精彩。 055 烦恼出自我们的贪婪","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"CRF条件随机场","slug":"NLP/algorithm/CRF","date":"2020-02-28T06:17:53.000Z","updated":"2021-06-11T03:06:50.860Z","comments":true,"path":"NLP/algorithm/CRF/","link":"","permalink":"https://tlylft.github.io/NLP/algorithm/CRF/","excerpt":"","text":"1. Conditional Random Fields1.1. Brief intro概率图模型的一种，是典型的判别式模型。CRF 的概率图是无向的，每一个位置的状态和周围相关联的状态都有关。同时，也是一种log-linear model。 方案原理挖掘句子上下文构成特点。模型中可理解为给定位置的窗口，就是上下文位置，来提取特征，不同特征组合可以形成新的特征。满足条件的特征取1，不满足的取0，给CRF，在训练阶段建模标签的转移，推断测试句子的各个位置的标注。 pros: 为一个位置进行标注的过程中，可以利用之前的标注情况，(离散型的输入可)利用Viterbi解码得到最优序列。 HMM 与 CRF 的区别HMM 的概率图是有向的， 即每一个状态都和上一个并只和上一个状态相关。CRF 的概率图是无向的，每一个位置的状态和周围相关联的状态都有关。 1.2. preview马尔科夫随机场1.2.1. Graph modelhttps://tlylft.github.io/NLP/algorithm/graph_theorem/ 1.2.2. log-linear modellog-linear的两个模型： Logistiic Regression 和 CRF表示方法：判别模型的条件概率：$p(y|x;w) = \\frac{exp \\sum_{j=1}^j w_j F_j(x,y)}{z(x,w)}$ $F_j(x,y)$叫做feature function，可以理解成第j个特征，可以是人为方式设定的，$ w_j$是真正的参数，需要去训练估计的，$z(x,w)$是 normalization/Partition function,是为了确保全局的概率之和等于1。 逻辑回归逻辑回归一般处理二分类问题，我们引申到多分类问题解析说明：log-linear model是如何定义和应用的。 假设我们有个三分类问题，预测分类类别为1,2,3.以离散型的输入举例， 所以逻辑回归是一种简化的log-linear模型，只是设置的indicator function导致了每个权重只与自身的输入有关，将序列关联这一层关系隐藏掉了。CRF 1.3. CRF 条件随机场概述 概率表示 通过例子理解公式中变量的意义条件随机场（CRF）模型详解 推导表示given w, x， 求出 y填充u这个分值矩阵，行代表了序列的长度，列代表了每种type的可能（类别）。 参数估计 Estimation of W 可以看看下面的blogNLP —- 条件随机场CRF详解https://blog.csdn.net/weixin_42398658/article/details/84964103CRF(条件随机场)与Viterbi(维特比)算法原理详解https://blog.csdn.net/qq_42189083/article/details/89350890NLP —- 条件随机场CRF（预测算法详解）https://blog.csdn.net/weixin_42398658/article/details/85222113 1.3.1. 线性链条件随机场Linear Chain Conditional Random Fields Comprehensione.g. 小明去年在华为公司工作X = {小,明,去,年,在,华,为,公,司,工,作}期望得到的Y序列：Y = {B-PER, I-PER, B-T, I-T, O, B-ORG, I-ORG, I-ORG, I-ORG, O, O}如何得到呢？首先我们设定一个简单的规则： Y在每个位置的标注只和它直接相关的节点相关。转换为数学公式：P(yi|X,yi-1,yi+1) Z(x)是一个归一化参数，对所有可能的y进行累加 tk 表示从yi-1 到yi状态转移的得分或概率si y这个状态本身的特性vk和 ul 是权重维特比算法可以帮助我们求解一个概率最大的标签序列。","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"NER","slug":"NER","permalink":"https://tlylft.github.io/tags/NER/"}]},{"title":"命名实体识别介绍","slug":"NLP/NER/ner_intro","date":"2020-02-28T02:00:03.000Z","updated":"2021-06-11T03:11:09.901Z","comments":true,"path":"NLP/NER/ner_intro/","link":"","permalink":"https://tlylft.github.io/NLP/NER/ner_intro/","excerpt":"","text":"https://www.cnblogs.com/Determined22/p/7238342.htmlhttps://www.bilibili.com/video/av79514115?from=search&amp;seid=14221634072388770076 1. 概念命名实体识别（Named Entities Recognition, NER） 主要目的是识别语料中的人名、地名、组织名等命名实体。是信息抽取、信息检索、机器翻译、问答系统等NLP技术中必不可少的组成部分。 是NLP中的一个基础任务，指的是文本中具有特定意义或指代性强的实体，从非结构化的文本中抽取上述实体。分类命名实体一般包括三大类：实体类、 时间类、 数字类（时间类和数字类一般可以用正则表达式表示出来）和七小类：人名、地名、 机构名、 时间、 日期、货币、 百分比 评判标准实体边界是否真确实体类型是否正确 中文挑战 英文单词可用空格为一个词的界限，中文不具备 中文一词多义，一字多义，脱离语境无法判断 命名实体中存在嵌套情况,如“北京大学第三医院” 大量简化表达 ， 如 “中科大” 2. 发展历史趋势： 理解语义，准确判断 2.1. 基于规则的NER pattern 规则 {PER}说 ， {xxx大学} cons: 需要大量的语言知识，构建不同的规则，谨慎处理规则间的冲突，费时费力，移植性差。 字典规则 2.2. 传统机器学习方法生成模型HMM,判别模型CRF统计机器学习方法将 NER 视作序列标注任务，利用大规模语料来学习出标注模型，从而对句子的各个位置进行标注。常用的应用到 NER 任务中的模型包括生成式模型HMM、判别式模型CRF等。比较流行的是特征模板+CRF:特征模板通常是人工定义的一些二值特征函数，试图挖掘命名实体内部以及上下文的构成特点。对于句子中的给定位置来说，提特征的位置是一个窗口，即上下文位置。而且，不同的特征模板之间可以进行组合来形成一个新的特征模板。CRF的优点在于其为一个位置进行标注的过程中可以利用到此前已经标注的信息，利用Viterbi解码来得到最优序列。对句子中的各个位置提取特征时，满足条件的特征取值为1，不满足条件的特征取值为0；然后把特征喂给CRF，training阶段建模标签的转移，进而在inference阶段为测试句子的各个位置做标注。 什么是生成式和判别式？？概率模型计算的是变量的概率分布，利用已知变量推断未知变量的分布的过程称为“推断”。生成式模型先学习联合概率分布P(x,y),再求解条件概率密度P(Y|X)判别式模型直接通过训练样本计算条件概率分布P(Y|X)什么是端到端的模型（不一定对）端到端的模型：LSTM-CRF 不需要特征的提取， HMM，CRF需要特征的提取。 2.3. 基于神经网络的NERBi-LSTM-CRF, Lattice LSTM， RNN-CRF, CNN-CRFRNN：随着词向量的出现，将词表示为稠密的向量表示，向量序列输入到RNN中，预测每个位置的标签。pros:是一种端到端的整体过程，不在依赖特征工程，是一种数据驱动的方法。cons: 每个词的标签是一个独立的分类，不能直接利用上文预测的标签（但可以通过隐藏状态传递上文信息），会导致生成标签为非法的（会产生B-PER后面是I-LOC）。 2.4. 近期一些方法attention 模型，迁移学习，半监督学习 3. Programming Point3.1. 技术流程 选择 定义实体种类 构建训练数据 训练数据数据集标注方式BIO数据标注集:B-PER、 I-PER代表人名首字、人名非首字；B-LOC、 I-LOC代表地名首字、地名非首字；B-ORG、 I-ORG代表组织机构名首字、组织机构名非首字；O代表该字不属于命名实体的一部分。BIOSE标注集:B-PER、 I-PER、 E-PER代表人名首字、 人名中间字、人名末尾字；B-LOC、 I-LOC、 E-PER代表地名首字、 地名中间字、地名末尾字；B-ORG、 I-ORG、 E-PER代表组织机构名首字、组织机构名中间字、 组织机构名末尾字；S-X代表单字构成的实体；O代表该字不属于命名实体的一部分。3.2. 评估方法 Precision/Recall F1-Score 3.3. 实现方法 Rule-based 利用规则1.1 正则匹配（电话，数字格式的时间等）1.2 利用定义好的词典 （if word in 词库:） 投票模型 Majority Voting记录一个单词概率最大的实体类型 分类模型3.1 algorithms非时序模型： LR, SVM时序模型： HMM, CRF, LSTM-CRF3.2 features 4. 算法介绍 HMM CRFhttps://tlylft.github.io/NLP/NER/CRF/ BiLSTM-CRF CRF和LSTM在序列标注上的优劣lSTM: RNN系列模型能够捕捉长远的上下文信息,还可以拟合非线性。 但不能学习到输出层的关联性，比如生成的序列B-PER后面一般是I-PERCRF: 不能考虑长远的上下文信息，但是能建模状态之间的转移概率（依赖关系）。 更多考虑的是位置局部特征的线性加权组合，优化的是一个序列，而不是某个时刻的状态。 所就有了Bi-LSTM-CRF模型。 bi-LSTM-CNNs-CRF储备知识： NER，CRF原理和推导，CNN,LSTM 原理https://www.bilibili.com/video/av79514115?from=search&amp;seid=14221634072388770076","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"腾讯智能聊天机器人","slug":"chatbot/tencent_chat","date":"2020-02-27T11:01:15.000Z","updated":"2023-08-11T08:41:25.303Z","comments":true,"path":"chatbot/tencent_chat/","link":"","permalink":"https://tlylft.github.io/chatbot/tencent_chat/","excerpt":"","text":"之前尝试的其他开源接口，有些很不稳定，在腾讯AI开放平台创建了一个应用，发现访问次数是不限制的，只是限制并发，总体稳定性会好很多，而且回复相对于来讲比较正规，适合企业用。 1. 调用tencent-sdk代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# -*- coding: utf-8 -*-&quot;&quot;&quot;@Date : 2021&#x2F;11&#x2F;19 8:31@Author : liufangtong@desc : 腾讯闲聊组件官方api文档：https:&#x2F;&#x2F;cloud.tencent.com&#x2F;document&#x2F;api&#x2F;271&#x2F;39416sdk使用说明：https:&#x2F;&#x2F;cloud.tencent.com&#x2F;document&#x2F;sdk&#x2F;Python查看秘钥： https:&#x2F;&#x2F;console.cloud.tencent.com&#x2F;cam&#x2F;capi调用参考：https:&#x2F;&#x2F;console.cloud.tencent.com&#x2F;api&#x2F;explorer?Product&#x3D;nlp&amp;Version&#x3D;2019-04-08&amp;Action&#x3D;ChatBot&amp;SignVersion&#x3D;&quot;&quot;&quot;# pip install tencentcloud-sdk-python -i https:&#x2F;&#x2F;mirrors.tencent.com&#x2F;pypi&#x2F;simple&#x2F;from tencentcloud.common import credentialfrom tencentcloud.common.profile.client_profile import ClientProfilefrom tencentcloud.common.profile.http_profile import HttpProfilefrom tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKExceptionfrom tencentcloud.nlp.v20190408 import nlp_client, modelsdef tencent_chit_response(self, text): result &#x3D; &#123;&#125; try: Secret_id &#x3D; &#39;AKIDax4ixxxxxxxxxqwo3s4tmFU&#39; Secret_key &#x3D; &#39;B9sLaaKoxxxxxxxxxxxxEwNNF1Yoro&#39; cred &#x3D; credential.Credential(Secret_id, Secret_key) httpProfile &#x3D; HttpProfile() httpProfile.endpoint &#x3D; &quot;nlp.tencentcloudapi.com&quot; clientProfile &#x3D; ClientProfile() clientProfile.httpProfile &#x3D; httpProfile client &#x3D; nlp_client.NlpClient(cred, &quot;ap-guangzhou&quot;, clientProfile) req &#x3D; models.ChatBotRequest() params &#x3D; &#123; &quot;Flag&quot;: 0, &quot;Query&quot;: text &#125; req.from_json_string(json.dumps(params)) resp &#x3D; client.ChatBot(req) logger.debug(&#39;tencent chitchat response: &#123;&#125;&#39;.format(resp.to_json_string())) result[&#39;reply&#39;] &#x3D; resp.Reply.replace(&#39;腾讯&#39;, &#39;&#39;) result[&#39;confidence&#39;] &#x3D; resp.Confidence # except TencentCloudSDKException as err: except Exception as err: logger.error(traceback.format_exc()) result[&#39;reply&#39;] &#x3D; self.component_config.get(&#39;fallback_answer&#39;) result[&#39;confidence&#39;] &#x3D; -1 return result 2. 自生成加密代码直接贴大神代码，时间紧，没时间自己写了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# -*- coding: utf-8 -*-&#39;&#39;&#39;@Date : 2020&#x2F;2&#x2F;27 16:42@Author : liufangtong@desc : 腾讯智能聊天机器人接口&#39;&#39;&#39;import hashlibimport timeimport randomimport stringfrom urllib.parse import quotefrom logger.LoggerHandler import loggerdef curlmd5(src): m &#x3D; hashlib.md5(src.encode(&#39;UTF-8&#39;)) # 将得到的MD5值所有字符转换成大写 return m.hexdigest().upper()def get_params(plus_item): global params # 请求时间戳（秒级），用于防止请求重放（保证签名5分钟有效） t &#x3D; time.time() time_stamp &#x3D; str(int(t)) # 请求随机字符串，用于保证签名不可预测 nonce_str &#x3D; &#39;&#39;.join(random.sample(string.ascii_letters + string.digits, 10)) # 应用标志，这里修改成自己的id和key app_id &#x3D; &#39;xxx&#39; app_key &#x3D; &#39;xxx&#39; params &#x3D; &#123;&#39;app_id&#39;: app_id, &#39;question&#39;: plus_item, &#39;time_stamp&#39;: time_stamp, &#39;nonce_str&#39;: nonce_str, &#39;session&#39;: &#39;10000&#39; &#125; sign_before &#x3D; &#39;&#39; # 要对key排序再拼接 for key in sorted(params): # 键值拼接过程value部分需要URL编码，URL编码算法用大写字母，例如%E8。quote默认大写。 sign_before +&#x3D; &#39;&#123;&#125;&#x3D;&#123;&#125;&amp;&#39;.format(key, quote(params[key], safe&#x3D;&#39;&#39;)) # 将应用密钥以app_key为键名，拼接到字符串sign_before末尾 sign_before +&#x3D; &#39;app_key&#x3D;&#123;&#125;&#39;.format(app_key) # 对字符串sign_before进行MD5运算，得到接口请求签名 sign &#x3D; curlmd5(sign_before) params[&#39;sign&#39;] &#x3D; sign return paramsimport requestsdef tencent_chit_response(question): global payload, r try: # 聊天的API地址 url &#x3D; &quot;https:&#x2F;&#x2F;api.ai.qq.com&#x2F;fcgi-bin&#x2F;nlp&#x2F;nlp_textchat&quot; # 获取请求参数 plus_item &#x3D; question.encode(&#39;utf-8&#39;) payload &#x3D; get_params(plus_item) # r &#x3D; requests.get(url,params&#x3D;payload) r &#x3D; requests.post(url, data&#x3D;payload) answer &#x3D; r.json()[&quot;data&quot;][&quot;answer&quot;] logger.info(&quot;Tencent 闲聊回复：&quot;+ answer) except Exception as e: logger.error(e) answer &#x3D; &#39;小e暂时只会查指标，还不能听懂您的问题哦！&#39; return answer# print(tencent_chit_response(&quot;你好啊&quot;))","categories":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"}]},{"title":"Flask 接口","slug":"python/Flask/flask_response","date":"2020-02-27T10:25:32.000Z","updated":"2021-06-11T03:28:44.996Z","comments":true,"path":"python/Flask/flask_response/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_response/","excerpt":"","text":"1. requestflask 的接收方式第一种：param第二种：form表单第三种：json1234567891011121314151617181920from flask import request@app.route(&#39;&#x2F;test&#39;, methods&#x3D;[&#39;GET&#39;, &#39;POST&#39;])def test(): # 获取 url 参数内容 x &#x3D; request.args.get(&quot;x&quot;) # 获取 form 表单内容 y &#x3D; request.form.get(&quot;y&quot;) # 获取json内容 y2 &#x3D; request.json.get(&quot;y2&quot;) # 获取 http 头部内容 z &#x3D; request.headers.get(&quot;z&quot;) print(&quot;x from url param: &quot;, x) print(&quot;y from form param: &quot;, y) print(&quot;z from headers: &quot;, z) return &quot;test&quot; 后台与前端的交互方式 jsonp（用参数接收数据值）在前端发起请求时将post请求转换为get请求传入后端，参数转换为param,并且带一个callback参数12345678910111213&#x2F;&#x2F; 引用jquery&lt;script src&#x3D;&quot;http:&#x2F;&#x2F;libs.baidu.com&#x2F;jquery&#x2F;1.9.0&#x2F;jquery.js&quot;&gt;&lt;&#x2F;script&gt;&#x2F;&#x2F;get传值，获取jsonp $.ajax(&#123; type: &#39;post&#39;, &#x2F;&#x2F;不重要，post也会转换为get url: &quot;http:&#x2F;&#x2F;127.0.0.1:5000&#x2F;main&#x2F;get_json&#x2F;999&quot;, dataType: &quot;jsonp&quot;, data:&#123;&quot;user&quot;:111&#125;, jsonp: &quot;callback&quot;, success: function (data) &#123; alert(data.hits); &#125; &#125;) post json （用json接收数据值）12345678$.ajax(&#123; type: &#39;post&#39;, url: &#39;&#x2F;chat&#39;, contentType:&quot;application&#x2F;json; charset&#x3D;utf-8&quot;, dataType:&quot;json&quot;, &#x2F;&#x2F;预期服务器返回数据的类型 data:JSON.stringify(&#123;&quot;user&quot;:111&#125;), success: function (r) &#123; console.log(r) param2. response2.1. flask的response方式https://www.jianshu.com/p/a25357f2d930第一种： jsonify 123@app.route(&#39;&#x2F;api&#x2F;v1.0&#x2F;tasks&#39;, methods&#x3D;[&#39;GET&#39;])def get_tasks(): return jsonify(&#123;&#39;tasks&#39;: tasks&#125;) 第二种： 123@app.route(&#39;&#x2F;api&#x2F;v1.0&#x2F;tasks&#39;, methods&#x3D;[&#39;GET&#39;])def get_tasks(): return json.dumps(&#123;&#39;tasks&#39;: tasks&#125;) 第三种： 123@app.route(&#39;&#x2F;api&#x2F;v1.0&#x2F;tasks&#39;, methods&#x3D;[&#39;GET&#39;])def get_tasks(): return Response(json.dumps(&#123;&#39;tasks&#39;: tasks&#125;)) 第一种和第二种返回的Content-Type有区别jsonify能直接编码为utf-8, json.dump()默认为asc-II,要手动调整参数。 2.2. flask 响应接口的封装json.dumps()的方式，封装到response中：12345678910111213141516171819202122232425# -*- coding: utf-8 -*-&#39;&#39;&#39;@Date : 2019&#x2F;12&#x2F;31 9:00@Author : liufangtong@desc : 响应封装&#39;&#39;&#39;from json import dumpsfrom flask import Responseclass ErrorResponse(Response): &#39;&#39;&#39; error response body &#39;&#39;&#39; def __init__(self, err_code, err_desc, err_msg&#x3D;&#39;Failed!&#39;): result &#x3D; dumps(dict(status &#x3D;err_code, status_desc &#x3D; err_desc, msg&#x3D;err_msg),ensure_ascii&#x3D;False) Response.__init__(self, result, mimetype&#x3D;&#39;application&#x2F;json&#39;)class JSONResponse(Response): &#39;&#39;&#39; normal response body &#39;&#39;&#39; def __init__(self, data, msg&#x3D;&#39;success&#39;): result &#x3D; dumps(dict(data&#x3D;data, status&#x3D;0, msg&#x3D;msg),ensure_ascii&#x3D;False) Response.__init__(self, result, mimetype&#x3D;&#39;application&#x2F;json&#39;) 2.3. flask返回中文显示乱码解决方法https://blog.csdn.net/weixin_45372665/article/details/101032144 设置config1app.config[&quot;JSON_AS_ASCII&quot;] &#x3D; False 接口返回的中文字符仍然为\\uxxx的格式，但是用postman会自动转换为中文字符，但是raw文本不是，我理解这样返回给前端是没有问题的，但是如果对方是程序接收会有问题? Flask的响应体本身可以用两种方式实现解决方法1： 使用Flask的jsonify返回结果。1return jsonify(&#123;“login”: “成功2”&#125;) 解决方法2： 继续使用json.dumps(),设置ensure_ascii=Falsehttps://blog.csdn.net/fo11ower/article/details/70062524?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task1234class JSONResponse(Response): def __init__(self, data, msg&#x3D;&#39;success&#39;): result &#x3D; json.dumps(dict(data&#x3D;data, status&#x3D;0, msg&#x3D;msg),ensure_ascii&#x3D;False) Response.__init__(self, result, mimetype&#x3D;&#39;application&#x2F;json&#39;) flask解决请求跨域问题https://blog.csdn.net/ntgxlj/article/details/89021171flask如果直接返回jsonify，使用ajax请求时，ajax会报错：No ‘Access-Control-Allow-Origin’ header is present on the requested，这是ajax跨域访问是一个老问题了，解决方法很多。 方法一： 比较常用的是前端使用JSONP方法，JSONP方法是一种非官方方法，而且这种方法只支持GET方式，不如POST方式安全。即使使用jquery的jsonp方法，type设为POST，也会自动变为GET。（在前端发起请求时将post请求转换为get请求传入后端，参数转换为param） 方法二： 通过设置Access-Control-Allow-Origin来实现跨域访问比较简单。使用CROS,下载flask_cors包pip install flask-cors1234567from flask_cors import *from flask import Flask,jsonifyapp &#x3D; Flask(__name__)CORS(app, supports_credentials&#x3D;True)@app.route(&quot;&#x2F;test&quot;,methods&#x3D;[&quot;POST&quot;])def test(): return jsonify(&#123;&quot;code&quot;:0&#125;)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"python文件读取","slug":"python/python/python_file","date":"2020-02-26T09:33:32.000Z","updated":"2022-05-06T05:31:34.153Z","comments":true,"path":"python/python/python_file/","link":"","permalink":"https://tlylft.github.io/python/python/python_file/","excerpt":"","text":"with模式下结束操作会自动执行f.close()123with open(filename,&#39;w&#39;) as f: f.read() f.write(content) 文件读写模式 读写模式 是否可读 是否可写 文件不存在时 r 是 否 报错 r+ 是 是，覆盖写 报错 w 否 是，清空原内容 创建新文件 w+ 是 是，清空原内容 创建新文件 a 否 是，追加写 创建新文件 a+ 是 是，追加写 创建新文件 7、上述的形态字符串都可以再加一个b字符，如rb、w+b或ab＋等组合，加入b 字符用来告诉函数库打开的文件为二进制文件，而非纯文字文件。不过在POSIX系统，包含Linux都会忽略该字符。 遍历文件夹的文件名123456789101112131415161718# file: all_file.pyimport osdef findAllFile(base): for root, ds, fs in os.walk(base): for f in fs: if f.endswith(&#39;.xls&#39;): fullname &#x3D; os.path.join(root, f) yield fullnamedef main(): base &#x3D; &#39;.&#x2F;base&#x2F;&#39; for i in findAllFile(base): print(i)if __name__ &#x3D;&#x3D; &#39;__main__&#39;: main() 文件合并2追加到1中12with open(&#39;1.csv&#39;,&#39;ab&#39;) as f: f.write(open(&#39;2.csv&#39;,&#39;rb&#39;).read())#将2.csv内容追加到1.csv的后面 文件编码类型判断https://www.jb51.net/article/131129.htm1234567891011121314151617181920212223242526272829303132# 说明：UTF兼容ISO8859-1和ASCII，GB18030兼容GBK，GBK兼容GB2312，GB2312兼容ASCIICODES &#x3D; [&#39;UTF-8&#39;, &#39;UTF-16&#39;, &#39;GB18030&#39;, &#39;BIG5&#39;]# UTF-8 BOM前缀字节UTF_8_BOM &#x3D; b&#39;\\xef\\xbb\\xbf&#39; # 获取文件编码类型def file_encoding(file_path): &quot;&quot;&quot; 获取文件编码类型\\n :param file_path: 文件路径\\n :return: \\n &quot;&quot;&quot; with open(file_path, &#39;rb&#39;) as f: return string_encoding(f.read()) # 获取字符编码类型def string_encoding(b: bytes): &quot;&quot;&quot; 获取字符编码类型\\n :param b: 字节数据\\n :return: \\n &quot;&quot;&quot; # 遍历编码类型 for code in CODES: try: b.decode(encoding&#x3D;code) if &#39;UTF-8&#39; &#x3D;&#x3D; code and b.startswith(UTF_8_BOM): return &#39;UTF-8-SIG&#39; return code except Exception: continue return &#39;未知的字符编码类型&#39; 编码类型转换文件路径相关os模块12345678import os# 合并路径os.path.join(&#39;&#x2F;Users&#x2F;&#39;, &#39;test&#39;) # &#39;&#x2F;Users&#x2F;test&#39;os.path.join(&#39;&#x2F;Users&#x2F;&#39;, &#39;test&#39;, &#39;test&#39;) # &#39;&#x2F;Users&#x2F;test&#x2F;test&#39;# 路径分割os.path.split(&#39;&#x2F;Users&#x2F;test&#x2F;test1&#39;) # (&#39;&#x2F;Users&#x2F;test&#39;, &#39;test1&#39;)os.path.dirname(&#39;&#x2F;Users&#x2F;test&#x2F;test1&#39;) # &#39;&#x2F;Users&#x2F;test&#39;os.path.basename(&#39;&#x2F;Users&#x2F;test&#x2F;test1&#39;) # &#39;test1&#39; pathlib模块name 目录的最后一部分suffix 目录最后一部分的扩展名stem 目录最后一个部分，没有后缀name =stem+suffixsuffixes返回多个扩展名列表with_suffix(suffix)有扩展名则替换，无扩展名则补充扩展名with_name(name)替换目录最后一个部分并返回一个新的路径 1234567from pathlib import Pathp &#x3D; Path(&#39;&#x2F;Users&#x2F;test&#x2F;test1.txt&#39;)p.name # &#39;test1.txt&#39;p.suffixes # &#39;.txt&#39;p.stem # &#39;test1&#39;p.with_suffix(&#39;.py&#39;) # &#39;&#x2F;Users&#x2F;test&#x2F;test1.py&#39;p.with_name(&#39;test2.py&#39;) # &#39;&#x2F;Users&#x2F;test&#x2F;test2.py&#39; 判断方法exists()目录或文件是否存在is_dir()是否是目录，目录返回Trueis_file()是否是普通文件，文件存在返回Trueis_symlin()是否是软链接is_socket()是否是socket文件is_block_device()是否是块设备is_char_device()是否是字符设备is_absolute()是否是绝对路径当所判断的文件存在才能正常判断","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"汉语语言学研究","slug":"NLP/Chinese_language","date":"2020-02-22T02:00:21.000Z","updated":"2021-06-11T03:18:16.337Z","comments":true,"path":"NLP/Chinese_language/","link":"","permalink":"https://tlylft.github.io/NLP/Chinese_language/","excerpt":"","text":"《NLP汉语自然语言处理原理与实践》第二章做中文的自然语言处理，我们需要对研究对象：汉语语言有一个较为深入的认识，才能更好的理解后面各类算法的意义。 汉语属于汉藏语系，与世界各国广泛使用的拼音文字相比，它更加古老和孤立，无论从字符结构或是形式上都显得特立独行。虽然汉语在历史上前后吸收和同化了匈奴、鲜卑、突厥、契丹、满、蒙古、梵语等语言的许多成分，但两千年来，汉语的符号化表示从来没有改变过。 文字符号起源最初的文字符号被称作记事符号，与语言形成于同一时期，起初并不是记录人们语言的所有内容，二十有选择的记录一些重要的内容。随着千百年的发展，才逐渐形成了统一和规范。 字形的发展","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"NLP 简介","slug":"NLP/nlp_intro","date":"2020-02-21T02:00:21.000Z","updated":"2021-06-11T03:16:15.009Z","comments":true,"path":"NLP/nlp_intro/","link":"","permalink":"https://tlylft.github.io/NLP/nlp_intro/","excerpt":"","text":"0. Background算法学习：《自然语言处理算法与实战》这本书将基本的算法的推理和实现，我觉得讲的简短又明白，他的代码很多也是底层手写的，很厉害。 算法可视化：https://github.com/jessevig/bertviz 1. what is NLPNLP = NLU（understanding） + NLG(generation)NLU: udio/text -&gt; meaning 机器翻译，智能客服，智能音箱 NLG: meaning -&gt; audio/text 写新闻，聊天机器人，bi报告生成2. Challenge Multiple ways to express Ambuguity 一词多义 solve: 通过主观概率判断naive method context 上下文认知 bosonnlp演示参考：https://bosonnlp.com/demo#overview-key 3. Application 问答系统 情感分析（股票价格，舆情监控） 特征模型或深度学习 机器翻译 自动摘要 聊天机器人 闲聊型- seq2seq 任务型- 意图识别 信息抽取 结构化文本，知识图谱，NER,Relation extraction 4. representation每种算法都拥有不同的表示特征，算法学习的过程就是训练最好表示的一个过程。比如CNN中，每一层都可以说是对输入数据的一种表示，只是最后output层是更能表达我们意图的一种表示。了解模型算法的表示，可以帮助更好的构建网络和选取算法。一个好的表示：越低维的空间表示，一般是更好的表示，我理解是因为可以更直观的传达出我们想知道的信息。 5. Skills &amp;&amp; difficultPhonetics 声音Morphology 单词分词，POS， NERSyntax 句子句法分析,依存分析semantic 语义 6. task6.1. 词的关键技术6.1.1. 分词工具包只能满足通用性的场景。中文：HanNLPHIT NLPFudan NLPjieba英文：NLTKSpacyStanford Parser 6.1.2. 近义词refer:https://blog.csdn.net/rensihui/article/details/89605517github:https://github.com/yongzhuo/nlp_xiaojiang/blob/master/AugmentText/augment_eda/enhance_eda.py 6.1.3. 词性POS6.1.4. 命名实体识别6.1.4.1. CRF6.1.4.2. others6.2. 句法关键技术6.2.1. 句法分析6.2.2. 依存分析6.3. 语义关键技术6.3.1. 文本相似度6.3.1.1. 词频相似度6.3.1.2. tf-idf6.3.1.3. 语义相似度6.4. 信息提取6.4.1. 词云匹配6.5. 文本分类6.6. robot6.6.1. 问答机器人6.6.2. 任务机器人","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"文本相似度","slug":"NLP/similarity/SimilarityModel","date":"2020-02-21T01:48:42.000Z","updated":"2021-06-11T03:14:07.485Z","comments":true,"path":"NLP/similarity/SimilarityModel/","link":"","permalink":"https://tlylft.github.io/NLP/similarity/SimilarityModel/","excerpt":"","text":"应用及意义文本相似度的意义不仅仅在于计算两句话之间的相近程度，而更重要的是他的应用意义。虽然大部分都是用词袋解决问题，但是决不能限于简单的tf-idf理解。 通常看到的demo，我们只知道它可以应用在文本的相似度计算，但计算相似度都可以做什么呢？ 举个例子： 问答机器人中，训练问答对涵盖了很多问题，当用户问了一个问题，要去问答对中匹配最相近的问题，以此来获取他的答复。（这种情况目前我认为tf-idf就可以解决？？待研究） 任务机器人中，用户传来一个问询，假设用户问了一个kpi指标需要提取槽位信息，用户的话术和我们的指标库的表达一定是不完全一样的，有可能简略，有可能更改表达方式，这属于短文本的问题，如果用户换了表述，词典里没有增加相应的描述，就会让本来就很短的文本的有效信息变得更短，tf-idf 是否还能发挥它的作用？ 文档相似度。 实现方法方法1：无监督，不使用额外的标注数据average word vectors：简单的对句子中的所有词向量取平均，是一种简单有效的方法， 缺点：没有考虑到单词的顺序，只对15个字以内的短句子比较有效，丢掉了词与词间的相关意思，无法更精细的表达句子与句子之间的关系。 tfidf-weighting word vectors：指对句子中的所有词向量根据tfidf权重加权求和，是常用的一种计算sentence embedding的方法，在某些问题上表现很好，相比于简单的对所有词向量求平均，考虑到了tfidf权重，因此句子中更重要的词占得比重就更大。 缺点：没有考虑到单词的顺序 bag of words：这种方法对于短文本效果很差，对于长文本效果一般，通常在科研中用来做baseline。缺点：1.没有考虑到单词的顺序，2.忽略了单词的语义信息。 LDA：计算出一片文档或者句子的主题分布。也常常用于文本分类任务 以smooth inverse frequency[1]（简称SIF)为权重，对所有词的word vector加权平均，最后从中减掉principal component，得到sentence embedding [1] Sanjeev Arora, et al. 2017. A Simple but Tough-to-Beat Baseline for Sentence Embeddings 通过Word Mover’s Distance[2]（简称WMD），直接度量句子之间的相似度 [2] Matt J. Kusner, et al. 2015. From Word Embeddings To Document Distances LSI或LSA：LSI是处理相似度的，基于SVD分解，用于特征降维，LSI求解出来的相似度跟topic相关性很强，而句子结构等信息较少。顺便说下，句子中词的顺序是不会影响LSI相似度结果的。 方法2：有监督，需要额外的标注数据分类任务，例如训练一个CNN的文本分类器[3]，取最后一个hidden layer的输出作为sentence embedding，其实就是取分类器的前几层作为预训练的encoder [3] Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification sentence pair的等价性/等义性判定[4]，这种方法的好处是不仅可以得到sentence embedding，还可以直接学习到距离度量函数里的参数 [4] Jonas Mueller, et al. 2016. Siamese Recurrent Architectures for Learning Sentence Similarity 方法3：DSSM-LSTM，2016年提出用DSSM-LSTM计算任意一对短文本的语义相似性，能够捕捉上下文信息。 方法4：doc2vec（paragraph2vec, sentence embeddings），2014年提出","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"}]},{"title":"git命令","slug":"tools/git","date":"2020-02-13T02:35:44.000Z","updated":"2021-12-27T06:37:03.379Z","comments":true,"path":"tools/git/","link":"","permalink":"https://tlylft.github.io/tools/git/","excerpt":"","text":"https://www.liaoxuefeng.com/wiki/896043488029600/896954074659008 1. 安装12345yum -y install git或者 sudo apt-get install git设置仓库hostsudo su -vi &#x2F;etc&#x2F;hosts 2. 分支2.1. 查看分支12345678910查看本地分支：$ git branch dev master* pre查看远程分支：$ git branch -rorigin&#x2F;HEAD -&gt; origin&#x2F;master origin&#x2F;dev origin&#x2F;master origin&#x2F;pre 2.2. 切换分支1git checkout master 2.3. 创建和删除本地分支123456创建本地分支：$ git branch [name] ----注意新分支创建后不会自动切换为当前分支切换分支：$ git checkout [name]创建新分支并立即切换到新分支：$ git checkout -b [name]基于当前分支的某一个commit号创建分支 $ git checkout -b [name] &lt;commit id&gt;删除分支：$ git branch -d [name] ---- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项 重命名分支1234git branch -m oldName newName ----重命名分支git push --delete origin oldName ----删除远程分支git push origin newName ----将本地分支同步到远程git branch --set-upstream-to origin&#x2F;newName ----设置远程分支关联 2.4. 创建远程新分支第一次创建项目（从零）123456git clone http:&#x2F;&#x2F;gitlab.enn.cn&#x2F;nlp&#x2F;nlp_news.gitcd nlp_newstouch README.mdgit add README.mdgit commit -m &quot;add README&quot;git push -u origin master第一次创建项目（从项目）123456cd existing_foldergit initgit remote add origin http:&#x2F;&#x2F;gitlab.enn.cn&#x2F;nlp&#x2F;nlp_news.gitgit add .git commitgit push -u origin master 12创建远程分支(本地分支push到远程)：$ git push origin [name]删除远程分支：$ git push origin :heads&#x2F;[name] 3. 代码操作3.1. 代码下拉1git clone -b 分支名 仓库地址 3.2. 代码回退（未提交）123456git checkout .# 恢复某个已修改的但未提交的文件（撤销未提交的修改）$ git checkout filename# 批量撤销 $ git checkout *.java #撤销所有java 后缀的文件git checkout . # 撤销所有 3.3. 代码提交12345678910# commit文件$ git add * # 添加文件 *代表全部提交，或输入要提交的指定文件名，空格隔开$ git add file1.txt$ git add file2.txt file3.txt$ git commit -m &quot;init master&quot; # 填写提交备注并提交# commit 指定的文件git commit -o index.html about.html -m &#39;comment&#39; git push origin master # 上传 3.4. 代码回退（已提交,未push）123456git reset [--soft | --mixed | --hard]# --mixed 默认模式，会保留源码,只是将git commit和index 信息回退到了某个版本。 git reset --mixed 等价于 git reset# --soft 保留源码,只回退到commit 信息到某个版本.不涉及index的回退,如果还需要提交,直接commit即可.# --hard 彻底回退，代码删除。源码也会回退到某个版本,commit和index 都回回退到某个版本.(注意,这种方式是改变本地代码仓库源码)git reset HEAD~撤销了commit操作，文件不更改，可重新提交 3.5. 代码回退（已push）123456789git revert撤销某次操作，执行revert命令时要求工作树必须是干净的.此次操作之前和之后的commit和history都会保留，并且把这次撤销作为一次最新的提交revert将代码回滚后，git push把线上的代码更新，不会像reset造成冲突的问题。 * git revert HEAD 撤销前一次 commit * git revert HEAD^ 撤销前前一次 commit * git revert commit-id （比如：fa042ce57ebbe5bb9c8db709f719cec2c58ee7ff）撤销指定的版本，撤销也会作为一次提交进行保存。git revert是提交一个新的版本，将需要revert的版本的内容再反向修改回去，版本会递增，不影响之前提交的内容 12345678git resetgit revert是用一次新的commit来回滚之前的commit，git reset是直接删除指定的commit## --mixed 不删除工作空间改动代码，撤销commit，并且撤销git add . 操作这个为默认参数,git reset --mixed HEAD^ 和 git reset HEAD^ 效果是一样的。## --soft 不删除工作空间改动代码，撤销commit，不撤销git add . ## --hard 删除工作空间改动代码，撤销commit，撤销git add . git reset --hard 139dcfaa558e3276b30b6b2e5cbbb9c00bbdca96 git push -f -u origin develop但要确保别人和服务器的版本不会比你回退的高 4. 标签123456git tag #查看taggit tag v0.0.1 #标记轻量标签git tag -a v1.4 -m &quot;my version 1.4&quot; #附录标签git show v0.0.1git push origin v0.0.1git push origin --tags 5. 分支合并5.1. 合并一个分支到masterdev整体合并到master123git checkout mastergit merge devgit push origin masterpycharm界面合并 5.2. 合并一个commit到master将dev分支下的某个重要修改提前合并到master中，先找到这次提交的commit 82ecb31， 切换到master， pick下这个commit，这时这个commit就到了master下的commit。12git checkout master git cherry-pick 82ecb31再去push（如果push 被reject 的话，原因可能是本地仓库和远程仓库的文件关联不上，需要pull一下，再去push，参考：https://blog.csdn.net/a137151062/article/details/78820806 ）12345(git pullgit pull origin mastergit pull origin master --allow-unrelated-histories)git push origin master 6. 用户端代码、分支、tags迁移到新的GitLab服务器上确保本地代码是最新的并且拥有所有的分支12git pullgit remote prune origin删除本地代码分支与旧Gitlab分支的关联关系1234重命名git remote rename origin old-origin或者删除git remote remove origin本地代码与新的GitLab服务器关联起来1git remote add origin https:&#x2F;&#x2F;gitlab.enncloud.cn&#x2F;tech-middle-platform&#x2F;ai&#x2F;rasa_chatbot.git将本地的所有分支都推送到新的GitLab服务器远程分支1git push -u origin --all将本地的所有tags都推送到新的GitLab服务器远程分支123git push -u origin --tags或者git push --tags切换分支 git checkout dev 删除本地代码与老的GitLab分支之间的关系1git remote remove old-origin 7. git瘦身https://blog.csdn.net/g291976422/article/details/105120681/ 1234567891011121314151617181920nlp_server&#x2F;models&#x2F;address&#x2F;final&#x2F;final.pdoptnlp_server&#x2F;models&#x2F;address&#x2F;final&#x2F;final.pdparamsnlp_server&#x2F;data&#x2F;sgns.renmin.wordgit filter-branch --force --index-filter &#39;git rm -rf --cached --ignore-unmatch nlp_server&#x2F;models&#x2F;address&#x2F;final&#x2F;final.pdopt&#39; --prune-empty --tag-name-filter cat -- --allgit filter-branch --force --index-filter &#39;git rm -rf --cached --ignore-unmatch nlp_server&#x2F;models&#x2F;address&#x2F;final&#x2F;final.pdparams&#39; --prune-empty --tag-name-filter cat -- --allgit filter-branch --force --index-filter &#39;git rm -rf --cached --ignore-unmatch nlp_server&#x2F;data&#x2F;sgns.renmin.word&#39; --prune-empty --tag-name-filter cat -- --all# 真正删除rm -rf .git&#x2F;refs&#x2F;original&#x2F;git reflog expire --expire&#x3D;now --allgit gc --prune&#x3D;nowgit gc --aggressive --prune&#x3D;nowgit push origin --force --all# 让远程仓库变小git remote prune origin","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"git","slug":"git","permalink":"https://tlylft.github.io/tags/git/"}]},{"title":"LINUX权限管理","slug":"linux/access_permission","date":"2020-01-21T10:02:53.000Z","updated":"2022-01-13T05:24:12.360Z","comments":true,"path":"linux/access_permission/","link":"","permalink":"https://tlylft.github.io/linux/access_permission/","excerpt":"","text":"1. linux系统下修改文件夹目录权限-chmod https://www.cnblogs.com/mmx8861/p/9330991.html使用root权限复制到当前用户文件夹下，当前用户有时没有该目录或文件的某些权限，操作：使用root权限chmod命令 修改该文件或文件夹的访问所有者权限 假设我的文件夹在主目录里，地址为 /var/home/dengchao/cc假设我要修改文件权限为777，则在终端输入1chmod 777 &#x2F;var&#x2F;home&#x2F;userid&#x2F;cc 具体的权限(例如777的含意等)在下面解释下：1.777有3位，最高位7是设置文件所有者访问权限，第二位是设置群组访问权限，最低位是设置其他人访问权限。 其中每一位的权限用数字来表示。具体有这些权限： r(Read，读取，权限值为4)：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目 录的权限。 w(Write,写入，权限值为2)：对文件而言，具有新增、修改文件内容的权限；对目录来说，具有删除、移动目录内文件的权限。 x(eXecute，执行，权限值为1)：对文件而言，具有执行文件的权限；对目录了来说该用户具有进入目录的权限。 创建新用户1234su -useradd -m test_userls home -&gt; test_user appadminpasswd test_user #设置密码 2. 为用户增加管理员权限https://blog.csdn.net/nicolewjt/article/details/82454898 root权限的账号 可以先切换到root用户下 su root 也可以登陆有管理员权限的账号后 sudo su - 将hadoop用户加入到root下边1234[root@localhost ~]# sudo visudoroot ALL&#x3D;(ALL) ALLhadoop ALL&#x3D;(ALL) ALL 将访问目录权限全部赋予用户1chown -R [username] &#x2F;usr&#x2F;share&#x2F;webapps&#x2F;[dirname] sudo和su的区别https://mp.weixin.qq.com/s/z127ryX6ueeVf-8FdK07vw su: switch user 切换用户sudo: super user do 超级用户（root 用户）的方式执行命令 susu [username]如果没有加入 - 参数，那么是一种 non-login-shell 的方式，意思是说我现在切换到了 ，但是当前的 shell 还是加载切换之前的那个用户的环境变量以及各种设置。123456ubuntu@VM-0-4-ubuntu:~$ su pptPassword:ppt@VM-0-4-ubuntu:&#x2F;home&#x2F;ubuntu$ whoamipptppt@VM-0-4-ubuntu:&#x2F;home&#x2F;ubuntu$# 环境变量还是用的Ubuntu的su - [username]如果加入了 - 参数，那么是一种 login-shell 的方式，意思是说切换到另一个用户 之后，当前的 shell 会加载 对应的环境变量和各种设置1234ubuntu@VM-0-4-ubuntu:~$ su - pptPassword:ppt@VM-0-4-ubuntu:~$ exit# 环境变量和home目录切换为ppt的 sudo在 Linux 中经常会碰到 Permission denied 这种情况，比如以 ubuntu 用户的身份查看 /etc/shadow 的内容。因为这个文件的内容是只有 root 用户能查看的。 用管理员权限查看1sudo cat &#x2F;etc&#x2F;shadow 一个用户能否使用 sudo 命令，取决于 /etc/sudoers 文件的设置。详细操作见上一个小节。","categories":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"}]},{"title":"文档结构化","slug":"NLP/doc_structure","date":"2020-01-21T04:53:22.000Z","updated":"2021-06-11T03:06:31.598Z","comments":true,"path":"NLP/doc_structure/","link":"","permalink":"https://tlylft.github.io/NLP/doc_structure/","excerpt":"","text":"前期调研病例结构化：https://zhuanlan.zhihu.com/p/35486607 google document AI:https://lawtomated.com/google-document-understanding-a-i-features-screenshots-and-use-cases/ Google 文档结构化笔记产品定位将非结构化数据转变为企业内的结构化数据。原因：企业拥有大量的非结构化数据；非结构化数据呈指数增长；大量价值被锁定在那些非结构化数据中；因为它是非结构化的，所以企业无法有效地访问或分析该内容；结果，花费大量时间和金钱手动将非结构化数据转换为结构化数据。 产品结构结合的技术功能:OCR单/多标签文件分类实体提取知识图谱语义检索自然语言查询使用常见的文件类型，如Word，PDF等文件格式 产品功能及实现01. Wikipedia + DUAI = Knowledge Management知识图谱管理，采用 wiki 48个不同领域主题作为基础知识库。实现知识搜索支持三种查询情况： 关键词搜索（直接搜索，满足用户对一些基础知识查询的需求） 语义匹配 （搜索：最早的蒸汽机） 问答","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"NLP任务","slug":"NLP/nlp_task","date":"2020-01-21T04:47:07.000Z","updated":"2021-06-11T03:16:20.784Z","comments":true,"path":"NLP/nlp_task/","link":"","permalink":"https://tlylft.github.io/NLP/nlp_task/","excerpt":"","text":"https://blog.csdn.net/lz_peter/article/details/81588430 词法分析（Lexical Analysis）:对自然语言进行词汇层面的分析，是NLP基础性工作 分词（Word Segmentation/Tokenization）:对没有明显边界的文本进行切分，得到词序列 新词发现（New Words Identification）:找出文本中具有新形势、新意义或是新用法的词 形态分析（Morphological Analysis）:分析单词的形态组成，包括词干（Sterms）、词根（Roots）、词缀（Prefixes and Suffixes）等 词性标注（Part-of-speech Tagging）:确定文本中每个词的词性。词性包括动词（Verb）、名词（Noun）、代词（pronoun）等 拼写校正（Spelling Correction）:找出拼写错误的词并进行纠正 句子分析（Sentence Analysis）:对自然语言进行句子层面的分析，包括句法分析和其他句子级别的分析任务 组块分析（Chunking）:标出句子中的短语块，例如名词短语（NP），动词短语（VP）等 超级标签标注（Super Tagging）:给每个句子中的每个词标注上超级标签，超级标签是句法树中与该词相关的树形结构 成分句法分析（Constituency Parsing）:分析句子的成分，给出一棵树由终结符和非终结符构成的句法树 依存句法分析（Dependency Parsing）:分析句子中词与词之间的依存关系，给一棵由词语依存关系构成的依存句法树 语言模型（Language Modeling）:对给定的一个句子进行打分，该分数代表句子合理性（流畅度）的程度 语种识别（Language Identification）:给定一段文本，确定该文本属于哪个语种句子边界检测（Sentence Boundary Detection）:给没有明显句子边界的文本加边界 语义分析（Semantic Analysis）:对给定文本进行分析和理解，形成能勾够表达语义的形式化表示或分布式表示 词义消歧（Word Sense Disambiguation）:对有歧义的词，确定其准确的词义 语义角色标注（Semantic Role Labeling）:标注句子中的语义角色类标，语义角色，语义角色包括施事、受事、影响等 抽象语义表示分析（Abstract Meaning Representation Parsing）:AMR是一种抽象语义表示形式，AMR parser把句子解析成AMR结构 一阶谓词逻辑演算（First Order Predicate Calculus）:使用一阶谓词逻辑系统表达语义 框架语义分析（Frame Semantic Parsing）:根据框架语义学的观点，对句子进行语义分析 词汇/句子/段落的向量化表示（Word/Sentence/Paragraph Vector）:研究词汇、句子、段落的向量化方法，向量的性质和应用 信息抽取（Information Extraction）:从无结构文本中抽取结构化的信息 命名实体识别（Named Entity Recognition）:从文本中识别出命名实体，实体一般包括人名、地名、机构名、时间、日期、货币、百分比等 实体消歧（Entity Disambiguation）:确定实体指代的现实世界中的对象术语抽取（Terminology/Giossary Extraction）:从文本中确定术语 共指消解（Coreference Resolution）:确定不同实体的等价描述，包括代词消解和名词消解关系抽取（Relationship Extraction）:确定文本中两个实体之间的关系类型 事件抽取（Event Extraction）:从无结构的文本中抽取结构化事件 情感分析（Sentiment Analysis）:对文本的主观性情绪进行提取 意图识别（Intent Detection）:对话系统中的一个重要模块，对用户给定的对话内容进行分析，识别用户意图 槽位填充（Slot Filling）:对话系统中的一个重要模块，从对话内容中分析出于用户意图相关的有效信息 顶层任务（High-level Tasks）:直接面向普通用户，提供自然语言处理产品服务的系统级任务，会用到多个层面的自然语言处理技术 机器翻译（Machine Translation）:通过计算机自动化的把一种语言翻译成另外一种语言 文本摘要（Text summarization/Simplication）:对较长文本进行内容梗概的提取 问答系统（Question-Answering Systerm）:针对用户提出的问题，系统给出相应的答案 对话系统（Dialogue Systerm）:能够与用户进行聊天对话，从对话中捕获用户的意图，并分析执行 阅读理解（Reading Comprehension）:机器阅读完一篇文章后，给定一些文章相关问题，机器能够回答 自动文章分级（Automatic Essay Grading）:给定一篇文章，对文章的质量进行打分或分级","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"【HIVE系列】03-HIVE运行参数设置","slug":"big_data/hive/hive_param","date":"2020-01-21T03:32:39.000Z","updated":"2023-08-11T08:10:44.312Z","comments":true,"path":"big_data/hive/hive_param/","link":"","permalink":"https://tlylft.github.io/big_data/hive/hive_param/","excerpt":"","text":"参考资料：hive命令行中显示列名字段的配置 1. hive命令行显示字段名服务器集群使用hive命令行输出不显示列名，可读性较差解决方法： 先执行以下命令参数，再执行查询操作12set hive.cli.print.header&#x3D;true; #可能显示表名加字段名set hive.resultset.use.unique.column.names&#x3D;false; # 解决上述问题因为在cli中set配置属性只是当次有效，如果想永久配置的话，将上述命令配置到hive/conf下的配置文件中，或者配置到hiverc文件里，因为每次CLI启动时，在提示符出现之前，Hive会自动在HOME目录下查找名为.hiverc的文件，而且执行这个文件中的所有命令。非常适合做初始化，所以有些关于hive的初始化设置可以配置到家目录下的.hiverc文件里。 2. hive修改执行sql的引擎12set hive.execution.engine&#x3D;spark;set hive.execution.engine&#x3D;mr;","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"hive","slug":"大数据技术/hive","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"hive","slug":"hive","permalink":"https://tlylft.github.io/tags/hive/"}]},{"title":"如何设计一个好的AI项目","slug":"PM/AI_project","date":"2020-01-15T00:43:20.000Z","updated":"2021-03-04T15:53:51.047Z","comments":true,"path":"PM/AI_project/","link":"","permalink":"https://tlylft.github.io/PM/AI_project/","excerpt":"","text":"https://mp.weixin.qq.com/s/WOVVnZYTHCVAVHU6hNQcAQ 读后总结AI项目投入的失败率很高，选择投入是有风险的，所以需要把握风控能力，讲项目落地产生价值。 项目失败的原因： 定位不清晰： 解决了错误的问题，将伪需求当成真需求。 选择了算法解决不了的问题。 实施AI项目的原则： 什么是合适的时机数据的准备是AI切入的时机，没有数据积淀，AI只能空谈。","categories":[{"name":"产品经理","slug":"产品经理","permalink":"https://tlylft.github.io/categories/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/"}],"tags":[{"name":"产品经理","slug":"产品经理","permalink":"https://tlylft.github.io/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/"}]},{"title":"Flask多环境配置","slug":"python/Flask/flask_config","date":"2020-01-11T06:39:00.000Z","updated":"2021-06-11T03:27:38.811Z","comments":true,"path":"python/Flask/flask_config/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_config/","excerpt":"","text":"https://www.jianshu.com/p/f3dba5b5c343 1. flask 实现多环境配置管理可以通过使用创建不同的环境类，创建字典，根据不同的环境情况对应不同的环境类的方式：配置文件：1234567891011121314151617181920# filename: config.py class BaseConfig: DEBUG &#x3D; Falseclass DevConfig(BaseConfig): CRP_URL &#x3D; &#39;xxxx&#39; ... class TestConfig(BaseConfig): CRP_URL &#x3D; &#39;xxxx&#39; ... APP_ENV &#x3D; &#39;dev&#39;configs &#x3D; &#123; &#39;dev&#39;: DevConfig, &#39;test&#39;: TestConfig, &#39;prod&#39;: ProdConfig&#125;conf&#x3D; configs[APP_ENV] 加载文件：1234567891011121314# app.pyfrom flask import Flask, render_templatefrom config.config import configs, APP_ENVfrom route.nlp_route import *from utils.DBUtil import dbimport osapp &#x3D; Flask(__name__,template_folder&#x3D;&quot;templates&quot;,static_folder&#x3D;&#39;static&#39;)# 蓝图管理app.register_blueprint(nlp_route, url_prefix&#x3D;&quot;&#x2F;nlp&quot;)# 引入配置文件中的相关配置app.config.from_object(configs[APP_ENV]) 2. 获取某个配置参数如果需要在项目其他位置中引用某个自定义变量，可以通过以下方式实现：123from config import confCRP_URL &#x3D; conf.CRP_URL 3. 改进为current_app方式获取这种方式，是通过调用current_app 的config属性 flask中提供current_app来标示当前application。相关的config信息在调用create_app()的时候已经对application进行了初始化，在业务代码中不应该再次使用从配置文件中去加载，也不应该和不需要关心当前的配置环境(dev,test,prod) 。而是直接使用已经初始化的create_app. 12345from flask import current_appCRP_URL &#x3D; current_app.config[&#39;CRP_URL&#39;]nginx_ip &#x3D; current_app.config[&#39;nginx_ip&#39;]MONGODB_SCRIPT_PATH &#x3D; current_app.config[&#39;MONGODB_SCRIPT_PATH&#39;] 但是运行会报错，需要在创建app 时配置好current_app，要了解flask的上下文疑问 current_app, g, session, request等相关知识，暂未看明白解决 https://www.zhihu.com/question/56261864","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"Django 用户管理","slug":"python/Django/Django-user-manager","date":"2020-01-10T14:27:55.000Z","updated":"2021-06-11T03:23:13.734Z","comments":true,"path":"python/Django/Django-user-manager/","link":"","permalink":"https://tlylft.github.io/python/Django/Django-user-manager/","excerpt":"","text":"1. 权限验证user = authenticate(username=user_name, password=pass_word)返回一个user对象，验证未通过会返回None123456789101112131415161718192021222324252627from django.contrib.auth import authenticate, login def post(self, request): redirect_to &#x3D; request.GET.get(&#39;next&#39;, &#39;&#x2F;personal&#x2F;&#39;) login_form &#x3D; LoginForm(request.POST) if login_form.is_valid(): user_name &#x3D; request.POST.get(&quot;username&quot;, &quot;&quot;) pass_word &#x3D; request.POST.get(&quot;password&quot;, &quot;&quot;) user &#x3D; authenticate(username&#x3D;user_name, password&#x3D;pass_word) if user is not None: if user.is_active: login(request, user) return HttpResponseRedirect(redirect_to) else: msg &#x3D; &quot;用户未激活！&quot; ret &#x3D; &#123;&quot;msg&quot;: msg, &quot;login_form&quot;: login_form&#125; return render(request, &quot;system&#x2F;users&#x2F;login.html&quot;, ret) else: msg &#x3D; &quot;用户名或密码错误！&quot; ret &#x3D; &#123;&quot;msg&quot;: msg, &quot;login_form&quot;: login_form&#125; return render(request, &quot;system&#x2F;users&#x2F;login.html&quot;, ret) else: msg &#x3D; &quot;用户名和密码不能为空！&quot; ret &#x3D; &#123;&quot;msg&quot;: msg, &quot;login_form&quot;: login_form&#125; return render(request, &quot;system&#x2F;users&#x2F;login.html&quot;, ret) 2. 用户查找 密码重置的例子： https://ruddra.com/posts/implementation-of-forgot-reset-password-feature-in-django/","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Django","slug":"python/Django","permalink":"https://tlylft.github.io/categories/python/Django/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Django","slug":"Django","permalink":"https://tlylft.github.io/tags/Django/"}]},{"title":"深度学习工具库","slug":"deep_learning/DL_libs","date":"2019-12-27T00:57:45.000Z","updated":"2021-06-11T02:55:21.385Z","comments":true,"path":"deep_learning/DL_libs/","link":"","permalink":"https://tlylft.github.io/deep_learning/DL_libs/","excerpt":"","text":"Caffe以表达式、速度和模块化为核心的深度学习框架，早期进行CV模型训练, C++/CUDA架构，支持命令行，python和MATLAB接口代码简单，开发效率高，CNN集成较好，RNN比较麻烦。 第一个主流工业级深度学习工具，适合快速开发工程应用。 运行时都是编译好的C++代码，比python亏啊很多 计算机视觉领域，图像的CNN操作在OPENCV函数库中有良好的表现 配置文件简单，文档齐全 开放性强，可以自定义模型，甚至修改卷积操作 but.. 对递归网络和语言建模的支持性很差","categories":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"}],"tags":[{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"},{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"Flask连接oracle","slug":"python/Flask/flask_oracle","date":"2019-12-23T00:57:45.000Z","updated":"2021-06-11T03:28:27.123Z","comments":true,"path":"python/Flask/flask_oracle/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_oracle/","excerpt":"","text":"环境安装 https://blog.csdn.net/Eric_data/article/details/97638167 安装包12pip install cx_oraclepip install 连接报错：Cannot locate a 64-bit Oracle Client library如果出现这条报错，说明python和oracle客户端还是没有建立连接，下载instant-client， 注意报错是需要64位的library,就要下载64位的instant-client，和python环境保持一致，并且注意版本号，我官网下载了最新的版本还是报错版本号，最终成功的版本是：instant-client 11 x64解压instant-client,需要将扩展包导入到python放包的目录，操作如下：1.找到oracle客户端安装路径，复制三个扩展包，分别为：oci.dll、oraociei11.dll、oraocci11.dll2.找到python的~/lib/site-packages/，粘贴三个扩展包3.重新建立连接即可 解决SQLAlchemy MySQL Oracle 中文执行乱码问题 https://blog.csdn.net/xie_0723/article/details/84901500 在使用SQLAlchemy 操作Oracle数据库时报错：UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position 38-39: ordinal not in range(128) 解决方案：需要设置中文编码， mysql和Oracle的设置方式是不同的。mysql是通过更改连接属性，oracle 是通过更改os配置 Oracle：123import os os.environ[&quot;NLS_LANG&quot;] &#x3D; &quot;GERMAN_GERMANY.UTF8&quot; mysql：1URI &#x3D; f&quot;mysql+pymysql:&#x2F;&#x2F;&#123;USER&#125;:&#123;PASSWORD&#125;@&#123;HOST&#125;:&#123;PORT&#125;&#x2F;&#123;db&#125;?charset&#x3D;utf8&quot; 如果还是不可以，尝试在create_engine 时 添加 encoding12345engine &#x3D; create_engine(URI, convert_unicode&#x3D;False, pool_recycle&#x3D;10, pool_size&#x3D;50, echo&#x3D;True, encoding&#x3D;&#39;utf8&#39;)","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"关键词提取","slug":"NLP/keywords","date":"2019-12-19T14:53:55.000Z","updated":"2021-06-11T03:16:01.542Z","comments":true,"path":"NLP/keywords/","link":"","permalink":"https://tlylft.github.io/NLP/keywords/","excerpt":"","text":"TF-IDF https://blog.csdn.net/asialee_bird/article/details/81486700 Term Frequecy- Inverse Document Frequency cons:TF-IDF 采用文本逆频率 IDF 对 TF 值加权取权值大的作为关键词，但 IDF 的简单结构并不能有效地反映单词的重要程度和特征词的分布情况，使其无法很好地完成对权值调整的功能，所以 TF-IDF 算法的精度并不是很高，尤其是当文本集已经分类的情况下。 在本质上 IDF 是一种试图抑制噪音的加权，并且单纯地认为文本频率小的单词就越重要，文本频率大的单词就越无用。这对于大部分文本信息，并不是完全正确的。IDF 的简单结构并不能使提取的关键词， 十分有效地反映单词的重要程度和特征词的分布情 况，使其无法很好地完成对权值调整的功能。尤其是在同类语料库中，这一方法有很大弊端，往往一些同类文本的关键词被盖。 TF-IDF算法实现简单快速，但是仍有许多不足之处： （1）没有考虑特征词的位置因素对文本的区分度，词条出现在文档的不同位置时，对区分度的贡献大小是不一样的。 （2）按照传统TF-IDF，往往一些生僻词的IDF(反文档频率)会比较高、因此这些生僻词常会被误认为是文档关键词。 （3）传统TF-IDF中的IDF部分只考虑了特征词与它出现的文本数之间的关系，而忽略了特征项在一个类别中不同的类别间的分布情况。 （4）对于文档中出现次数较少的重要人名、地名信息提取效果不佳。 text-rankhttps://zhuanlan.zhihu.com/p/41091116https://www.cnblogs.com/en-heng/p/6124526.html","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"}]},{"title":"python服务部署","slug":"python/env/python_online","date":"2019-12-12T00:57:45.000Z","updated":"2021-06-11T03:27:00.567Z","comments":true,"path":"python/env/python_online/","link":"","permalink":"https://tlylft.github.io/python/env/python_online/","excerpt":"","text":"1. 服务器root登录1sudo su -root 2. 基础环境配置2.1. 安装所需的yum包2.2. python安装 python + 多环境管理 anaconda安装https://www.cnblogs.com/xiao-apple36/p/9052102.html 下载anaconda进入下载页面复制下载链接：https://www.anaconda.com/distribution/wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh 安装bash Anaconda3-4.4.0-Linux-x86_64.sh 增加环境变量1234567vi &#x2F;root&#x2F;.bashrc# added by Anaconda3 4.4.0 installerexport PATH&#x3D;&quot;&#x2F;root&#x2F;anaconda3&#x2F;bin:$PATH&quot;保存后!!!source &#x2F;root&#x2F;.bashrc 2.3. 上传项目项目中所涉及的文件路径地址的斜杠应为左斜杠，双右斜杠在linux中报错。如： path = ‘/data/software/test.txt’不可以是： path = ‘/data/software\\\\\\\\test.txt’2.4. 项目启动 进入文件夹，运行启动文件 1python run.py 如果是多环境管理，可以使用运行python的文件位置 1&#x2F;data&#x2F;anaconda&#x2F;envs&#x2F;name&#x2F;bin&#x2F;python run.py 关闭终端后仍在后台运行 1nohup python run.py&amp;","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}]},{"title":"python 字典操作","slug":"python/python/python_dict","date":"2019-12-08T03:50:55.000Z","updated":"2021-06-11T04:18:02.927Z","comments":true,"path":"python/python/python_dict/","link":"","permalink":"https://tlylft.github.io/python/python/python_dict/","excerpt":"","text":"1. 普通字典1234567d1&#x3D;&#123;&#125;d1[&#39;a&#39;]&#x3D;&#39;A&#39;d1[&#39;b&#39;]&#x3D;&#39;B&#39;d1[&#39;c&#39;]&#x3D;&#39;C&#39;d1[&#39;d&#39;]&#x3D;&#39;D&#39; #此时的d1 &#x3D; &#123;&#39;a&#39;:&#39;A&#39;,&#39;b&#39;:&#39;B&#39;,&#39;c&#39;:&#39;C&#39;,&#39;d&#39;:&#39;D&#39;&#125;for k,v in d1.items(): print k,v 输出结果为无序的 2. 有序的字典123456789import collectionsd1&#x3D;&#123;&#125;d1&#x3D;collections.OrderedDict() #将普通字典转换为有序字典d1[&#39;a&#39;]&#x3D;&#39;A&#39;d1[&#39;b&#39;]&#x3D;&#39;B&#39;d1[&#39;c&#39;]&#x3D;&#39;C&#39;d1[&#39;d&#39;]&#x3D;&#39;D&#39;for k,v in d1.items(): print k,v 如果有序字典中的元素一开始就定义好了，后面没有插入元素这一动作，那么遍历有序字典，其输出结果为空，因为缺少了有序插入这一条件，所以此时有序字典就失去了作用，所以有序字典一般用于动态添加并需要按添加顺序输出的时候。 3. 字典的key值操作3.1. 判断是否存在key如果key不存在，直接获取会报错 3.1.1. 字典情况：1234dic &#x3D; &#123;&#39;a&#39;:1&#125;a &#x3D; dic[&#39;a&#39;] &gt;&gt; a &#x3D; 1b &#x3D; dic[&#39;b&#39;] &gt;&gt; error# 先判断可以是否存在 3.2. 解决办法12345a &#x3D; dic[&#39;a&#39;] if dic.has_key(&#39;a&#39;) else Nonea &#x3D; dic[&#39;a&#39;] if &#39;a&#39; in dic else None # 比haskey速度快a &#x3D; t.get(&#39;a&#39;, default &#x3D; None) # 没有key默认返回None 4. 转换成列表123a &#x3D; &#123;&#39;a&#39;:&#39;A&#39;,&#39;b&#39;:&#39;B&#39;,&#39;c&#39;:&#39;C&#39;,&#39;d&#39;:&#39;D&#39;&#125;key &#x3D; list(a.keys())value &#x3D; list(a.values()) 5. 由列表转换成字典12345678# zip方式key &#x3D; [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;]value &#x3D; [&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;]dict &#x3D; dict(zip(key,value))# 二维数组list &#x3D; [[&#39;燃气&#39;, 0.20], [&#39;燃起&#39;, 0.2024878965897488]]dict &#x3D; dict(list)&gt;&gt; &#123;&#39;燃气&#39;: 0.2&#125; 6. 字典排序6.1. sorted(iterable,key,reverse)返回的是数组类型，不改变原对象的值，需重新赋值iterable:表示可迭代的对象，例如dict.keys(), dict.items()key:是一个函数，用来选择参与排序的元素reverse:默认为False，从小到大排序，reverse=True,表示从大到小排序123456789101112131415dic &#x3D; &#123;&#39;a&#39;:3 , &#39;b&#39;:2 , &#39;c&#39;: 1&#125;# 按key排序dict&#x3D; sorted(dic.iteritems(), key&#x3D;lambda d:d[0], reverse &#x3D; True)# 按value排序dict&#x3D; sorted(dic.iteritems(), key&#x3D;lambda d:d[1], reverse &#x3D; True)&gt;&gt;&gt; a_dic &#x3D; &#123;&#39;a&#39;:&#123;&#39;val&#39;:3&#125;, &#39;b&#39;:&#123;&#39;val&#39;:4&#125;, &#39;c&#39;:&#123;&#39;val&#39;:1&#125;&#125;# 按key排序dict&#x3D; sorted(dic.iteritems(), key&#x3D;lambda d:d[0], reverse &#x3D; True)# 按value排序&gt;&gt;&gt; dict&#x3D; sorted(a_dic.iteritems(), key&#x3D;lambda d:d[1][&#39;val&#39;], reverse &#x3D; True)&gt;&gt;&gt; dict[(&#39;b&#39;, &#123;&#39;val&#39;: 4&#125;), (&#39;a&#39;, &#123;&#39;val&#39;: 3&#125;), (&#39;c&#39;, &#123;&#39;val&#39;: 1&#125;)]","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"python logging日志模块","slug":"python/python/python_logger","date":"2019-12-06T00:57:45.000Z","updated":"2021-06-11T04:18:28.208Z","comments":true,"path":"python/python/python_logger/","link":"","permalink":"https://tlylft.github.io/python/python/python_logger/","excerpt":"","text":"本文介绍两种日志模块的使用，logging为python原生态的日志模块，记录较早，当时存在多线程启用问题。 loguru为后来封装的模块，异常时可以直接抛出traceback,调用方便，推荐使用。 1. loguru1.1. 安装：1pip install loguru 1.2. 使用1.2.1. 参数详解12345678910111213141516def add( self, sink, # sink 一个 file 对象或file路径，可以自动创建文件路径 *, level&#x3D;_defaults.LOGURU_LEVEL, # &#39;INFO&#39;,&#39;DEBUG&#39;,&#39;ERROR&#39; format&#x3D;_defaults.LOGURU_FORMAT, filter&#x3D;_defaults.LOGURU_FILTER, colorize&#x3D;_defaults.LOGURU_COLORIZE, serialize&#x3D;_defaults.LOGURU_SERIALIZE, backtrace&#x3D;_defaults.LOGURU_BACKTRACE, diagnose&#x3D;_defaults.LOGURU_DIAGNOSE, enqueue&#x3D;_defaults.LOGURU_ENQUEUE, catch&#x3D;_defaults.LOGURU_CATCH, **kwargs ): pass 其他参数123encoding&#x3D;&#39;utf-8&#39; # 解决文件存储时中文字符乱码问题，serialize&#x3D;True时不生效。rotation&#x3D;&quot;500 MB&quot; # 文件分区存储retention&#x3D;&#39;10 days&#39; # 保留时长 1.2.2. 基本配置123from loguru import loggerlogger.info(&#39;test&#39;)logger.debug(&#39;this is a debug message&#39;) 1.2.3. 文件存储1logger.add(&#39;runtime.log&#39;, format&#x3D;&quot;&#123;time&#125; &#123;level&#125; &#123;message&#125;&quot;, filter&#x3D;&quot;my_module&quot;, level&#x3D;&quot;INFO&quot;) 1.2.4. 文件分区存储123logger.add(&#39;runtime_&#123;time&#125;.log&#39;, rotation&#x3D;&quot;500 MB&quot;)logger.add(&#39;runtime_&#123;time&#125;.log&#39;, rotation&#x3D;&#39;00:00&#39;，retention&#x3D;&#39;10 days&#39;)logger.add(&#39;runtime_&#123;time&#125;.log&#39;, rotation&#x3D;&#39;1 week&#39;，retention&#x3D;&#39;10 days&#39;) 2. logging模块 https://blog.csdn.net/pansaky/article/details/90710751 2.1. 介绍2.1.1. 日志级别FATAL：致命错误CRITICAL：特别糟糕的事情，如内存耗尽、磁盘空间为空，一般很少使用ERROR：发生错误时，如IO操作失败或者连接问题WARNING：发生很重要的事件，但是并不是错误时，如用户登录密码错误INFO：处理请求或者状态变化等日常事务DEBUG：调试过程中使用DEBUG等级，如算法中每个循环的中间状态 2.1.2. format格式参数%(name)s: Name of the logger (logging channel)%(levelno)s: 打印日志级别的数值%(levelname)s: 打印日志级别名称%(pathname)s: 打印当前执行程序的路径，其实就是sys.argv[0]%(filename)s: 打印当前执行程序名%(module)s Module (name portion of filename)%(funcName)s: 打印日志的当前函数%(lineno)d: 打印日志的当前行号%(created)f Time when the LogRecord was created (time.time() return value)%(asctime)s: 打印日志的时间%(msecs)d Millisecond portion of the creation time%(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time)%(thread)d: 打印线程ID%(threadName)s: 打印线程名称%(process)d: 打印进程ID%(message)s: 打印日志信息 2.2. 基本使用2.2.1. 简单logger的配置使用 默认输出到控制台123456789import logging# 使用basicConfig默认配置到控制台，设置输出级别和输出格式logging.basicConfig(level &#x3D; logging.INFO,format &#x3D; &#39;%(asctime)s - %(filename)s [line:%(lineno)d] %(levelname)s - %(message)s&#39;)# 创建日志记录对象，配置模块名字logger &#x3D; logging.getLogger(__name__)# 开始使用logger.info(&quot;Start print log&quot;)logger.debug(&quot;Do something&quot;)logger.warning(&quot;Something maybe fail.&quot;) 2.2.2. 通过handler控制输出到文件创建一个file_handler,将其加入logger，日志输出到指定文件12345678910111213141516171819202122import logginglogger &#x3D; logging.getLogger(__name__)logger.setLevel(level &#x3D; logging.INFO)# 配置handler, 可以配置多个输出formatter &#x3D; logging.Formatter(&#39;%(asctime)s - %(filename)s [line:%(lineno)d] %(levelname)s - %(message)s&#39;)## 第一个：文件输出handler &#x3D; logging.FileHandler(&quot;log.txt&quot;)handler.setLevel(logging.INFO)handler.setFormatter(formatter)logger.addHandler(handler)## 第二个：控制台输出console &#x3D; logging.StreamHandler()console.setLevel(logging.INFO)console.setFormatter(formatter)logger.addHandler(console) logger.info(&quot;Start print log&quot;)logger.debug(&quot;Do something&quot;)logger.warning(&quot;Something maybe fail.&quot;) 2.2.3. 文件日志分区存储使用handles的TimedRotatingFileHandler模块，设置分区频次和历史数据保留时间123456789101112131415import loggingfrom logging.handlers import TimedRotatingFileHandlerimport relogger &#x3D; logging.getLogger(__name__)logger.setLevel(level&#x3D;logging.INFO)## when和interval设置D和n，每n天一个文件，历史保留60个文件handler &#x3D; TimedRotatingFileHandler(filename&#x3D;&quot;&#x2F;data&#x2F;logs&#x2F;meeting&#x2F;logfile&quot;, when&#x3D;&quot;D&quot;, interval&#x3D;1,backupCount&#x3D;60)# handler.suffix &#x3D; &quot;%Y-%m-%d_%H-%M.log&quot;# handler.extMatch &#x3D; re.compile(r&quot;^\\d&#123;4&#125;-\\d&#123;2&#125;-\\d&#123;2&#125;_\\d&#123;2&#125;-\\d&#123;2&#125;.log$&quot;)formatter &#x3D; logging.Formatter(&#39;%(asctime)s - %(filename)s [line:%(lineno)d] %(levelname)s - %(message)s&#39;)handler.setFormatter(formatter)handler.setLevel(logging.INFO)logger.addHandler(handler) 2.2.4. 多模块使用 2.3. 异常处理：logging 不能支持多进程问题logging写入日志文件时报错：PermissionError: [WinError 32] 另一个程序正在使用此文件，进程无法访问。 2.3.1. 解决一： https://www.jianshu.com/p/d9f18392deec 生成日志文件时用进程号切分：12file_name &#x3D; &#39;.&#x2F;logs&#x2F;&#39; + str(hostname) + &#39;_&#39; + str(os.getpid()) +&#39;.log&#39; # os.getpid()为进程号，防止不同进程直接写入同一个日志文件造成冲突 2.3.2. 解决二： https://www.cnblogs.com/piperck/p/9837637.html这篇文章提供的办法是，仍然继承了logging的源生写法，每次写入日志直接写入到当前日期的日志文件中，但是没有解决interval的问题 2.3.3. 解决三：https://www.jianshu.com/p/ab7fbe6f8f3c这篇文章提供的办法是，每次写入日志直接写入到当前日期的日志文件中，但是没有解决interval的问题","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"词性标注","slug":"NLP/NER/part-of-speech","date":"2019-12-04T05:53:55.000Z","updated":"2021-06-11T03:11:30.887Z","comments":true,"path":"NLP/NER/part-of-speech/","link":"","permalink":"https://tlylft.github.io/NLP/NER/part-of-speech/","excerpt":"","text":"1. 词性标注1.1. 作用 消除歧义 命名实体识别的基础 句法分析的基础 1.2. 存在的问题 同样的单词同样的词性可能也有不同的含义 同样的单词在不同的语境下会有不同的词性 1.3. 训练预料和标注规范 北大计算所词性标注集 宾州词性标注集 Brown Corpus: ENG 87 pos tags C5: ENG 61 POS tags * Penn Treebank: ENG 45 POS tags [使用广泛] 一般来讲pos有八个大类 N noun V verb ADJ adjective ADV adverb P preposition [of,by,to] PRO pronoun [I, me, mine] DET determiner [the,a,that,those]1.4. 词性标注：1.4.1. 使用语法规则进行词性标注 创建词性pattern规则，如名词前多为形容词，则adj + n，大概有1000多个规则，但可能规则间存在冲突，不需要训练预料，但是准确度不高，目前已经不怎么被使用。1.4.2. 使用字典进行词性标注 以高频词性为准，定义字典方式： dict ，准确度80% 1.4.3. 使用n-gram进行标注给定一个词，和前面n个词的词性有关bi-gram : 1.4.4. 应用HMM进行词性标注jieba的词性识别的方式 基本思路： 每个字在词语中都占据一个构词位置（词位），规定四个构词位置：词首 B， 词中 M， 词尾 E， 单独成词 S e.g. 我喜欢吃汉堡包 S B E S B M E 3. 应用CRF进行词性标注","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"NER","slug":"NER","permalink":"https://tlylft.github.io/tags/NER/"}]},{"title":"gensim 使用笔记（一）","slug":"NLP/similarity/gensim_part1","date":"2019-12-04T00:57:45.000Z","updated":"2021-06-11T03:13:49.433Z","comments":true,"path":"NLP/similarity/gensim_part1/","link":"","permalink":"https://tlylft.github.io/NLP/similarity/gensim_part1/","excerpt":"","text":"https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html#sphx-glr-auto-examples-core-run-core-concepts-py 相关概念documentDocument: some text.文本内容1document &#x3D; &quot;Human machine interface for lab abc computer applications&quot; CorpusCorpus: a collection of documents. 预料集1234567891011text_corpus &#x3D; [ &quot;Human machine interface for lab abc computer applications&quot;, &quot;A survey of user opinion of computer system response time&quot;, &quot;The EPS user interface management system&quot;, &quot;System and human system engineering testing of EPS&quot;, &quot;Relation of user perceived response time to error measurement&quot;, &quot;The generation of random binary unordered trees&quot;, &quot;The intersection graph of paths in trees&quot;, &quot;Graph minors IV Widths of trees and well quasi ordering&quot;, &quot;Graph minors A survey&quot;,] vectorVector: a mathematically convenient representation of a document. 文本的数学表示 modelModel: an algorithm for transforming vectors from one representation to another. 通过算法转换后的表示模型 代码实现","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"}]},{"title":"Flask连接mysql","slug":"python/Flask/flask_mysql","date":"2019-12-04T00:57:45.000Z","updated":"2021-08-23T00:55:30.735Z","comments":true,"path":"python/Flask/flask_mysql/","link":"","permalink":"https://tlylft.github.io/python/Flask/flask_mysql/","excerpt":"","text":"https://www.jianshu.com/p/7e32074e4fad 1. 安装数据库的包1pip install flask-sqlalchemy pymysql 2. config 进行数据库连接配置e.g.12345678910DB_URI &#x3D; &#39;mysql+pymysql:&#x2F;&#x2F;&#123;username&#125;:&#123;password&#125;@&#123;server&#125;:&#123;port&#125;&#x2F;&#123;db&#125;?charset&#x3D;utf8&amp;autocommit&#x3D;true&#39;SQLALCHEMY_DATABASE_URI &#x3D; DB_URISQLALCHEMY_COMMIT_TEARDOWN &#x3D; TrueSQLALCHEMY_TRACK_MODIFICATIONS &#x3D; FalseSQLALCHEMY_RECORD_QUERIES &#x3D; TrueSQLALCHEMY_POOL_SIZE &#x3D; 1024SQLALCHEMY_POOL_TIMEOUT &#x3D; 90SQLALCHEMY_POOL_RECYCLE &#x3D; 3 #多少秒后自动回收连接。这对 MySQL 是必要的， 它默认移除闲置多于 8 小时的连接。注意如果 使用了 MySQL ， Flask-SQLALchemy 自动设定这个值为 2 小时。|SQLALCHEMY_MAX_OVERFLOW &#x3D; 1024autocommit=truehttps://zhuanlan.zhihu.com/p/48994990解决报错：错误一：(mysql.connector.errors.OperationalError) MySQL Connection not available.错误二：(sqlalchemy.exc.InvalidRequestError) Can’t reconnect until invalid transaction is rolled backSQLALCHEMY_DATABASE_URI数据库连接地址. Examples:sqlite:////tmp/test.dbmysql://{username}:{password}@{server}:{port}/{db}?charset=utf8mysql+pymysql://{username}:{password}@{server}:{port}/{db}?charset=utf8oracle://{username}:{password}@{server}:{port}/?service_name={service_name}12345678HOSTNAME &#x3D; &#39;10.38.64.57&#39;PORT &#x3D; &#39;3306&#39;DATABASE &#x3D; &#39;robot&#39;USERNAME &#x3D; &#39;robot&#39;PASSWORD &#x3D; &#39;robotrobot&#39;DB_URI &#x3D; &#39;mysql+pymysql:&#x2F;&#x2F;&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;&#x2F;&#123;&#125;?charset&#x3D;utf8&#39;.format( USERNAME, PASSWORD, HOSTNAME, PORT, DATABASE)SQLALCHEMY_DATABASE_URI &#x3D; DB_URI SQLALCHEMY_BINDS多数据源配置1234ORACLE_DB_URL &#x3D; &#39;oracle:&#x2F;&#x2F;&#123;username&#125;:&#123;password&#125;@&#123;server&#125;:&#123;port&#125;&#x2F;?service_name&#x3D;&#123;service_name&#125;&#39;SQLALCHEMY_BINDS &#x3D; &#123; &#39;edata&#39;: ORACLE_DB_URL&#125;SQLALCHEMY_TRACK_MODIFICATIONS 如果设置成 True (默认情况)，Flask-SQLAlchemy 将会追踪对象的修改并且发送信号。这需要额外的内存， 如果不必要的可以禁用它。高版本的SQLALCHEMY 不设置会报错，不需要的情况设置为 False就好。SQLALCHEMY_COMMIT_TEARDOWN = True SQLALCHEMY_RECORD_QUERIES可以用于显式地禁用或者启用查询记录。查询记录 在调试或者测试模式下自动启用。更多信息请参阅 get_debug_queries()。SQLALCHEMY_POOL_SIZE = 1024数据库连接池的大小。默认值 5SQLALCHEMY_POOL_TIMEOUT = 90指定数据库连接池的超时时间。默认是 10SQLALCHEMY_POOL_RECYCLE = 3多少秒后自动回收连接。这对 MySQL 是必要的， 它默认移除闲置多于 8 小时的连接。注意如果 使用了 MySQL ， Flask-SQLALchemy 自动设定 这个值为 2 小时。SQLALCHEMY_MAX_OVERFLOW = 1024控制在连接池达到最大值后可以创建的连接数。当这些额外的 连接回收到连接池后将会被断开和抛弃。 config 文件中配置123DB_URI &#x3D; &#39;mysql+pymysql:&#x2F;&#x2F;&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;&#x2F;&#123;&#125;?charset&#x3D;utf8&#39;.format(USERNAME,PASSWORD,HOSTNAME,PORT,DATABASE)SQLALCHEMY_DATABASE_URI &#x3D; DB_URISQLALCHEMY_COMMIT_TEARDOWN &#x3D; True 或者直接在运行文件中给config赋值12345from flask_sqlalchemy import SQLAlchemyapp.config[&#39;SQLALCHEMY_DATABASE_URI&#39;] &#x3D;&#39;mysql+pymysql:&#x2F;&#x2F;&#123;&#125;:&#123;&#125;@&#123;&#125;:&#123;&#125;&#x2F;&#123;&#125;?charset&#x3D;utf8&#39;.format(USERNAME,PASSWORD,HOSTNAME,PORT,DATABASE)app.config[&#39;SQLALCHEMY_COMMIT_ON_TEARDOWN&#39;] &#x3D; Truedb &#x3D; SQLAlchemy(app) 3. 定义模型 必须有主键，否则会报错。 SQLAlchemy 数据类型和数据库数据类型的对应关系 类型名 MySQL类型 python类型 描述 SmallInteger smallint int 取值范围较小，一般为16位 Integer int int 普通整数，一般32位 BigInteger bigint int/long 不限精度的整数 Float float float 浮点数 Numeric decimal decimal.Decimal 定点数 String varchar str 变长字符串 Text tinytext str 变长字符串，64K,216−1216−1 2^{16}-1216−1=65535bytes Text(65536) mediumtext str 变长字符串，max16M,224−1224−1 2^{24}-1224−1=16777215bytes Text(16777216) longtext str 变长字符串，max32M,232−1232−1 2^{32}-1232−1=4294967295bytes LargeBinary blob str 二进制文件，64K LargeBinary(65536) mediumblob str 二进制，max16M LargeBinary(16777216) longblob str 二进制，max32M PickleType blob 任何python对象 自动使用Pickle序列化，只有blob Unicode varchar unicode 变长字符串 UnicodeText text unicode 变长字符串，64K Boolean tinyint bool 布尔值 Date date datetime.date 日期 Time time date.time 时间 DateTime datetime datetime.datetime 日期和时间 Interval datetime datetime.timedelta 时间间隔 Enum enum str 一组字符串 12345678910111213141516171819202122232425262728293031from app import db# 意图类class User(db.Model): # 定义表名 __tablename__ &#x3D; &#39;users&#39; # 定义列对象 ## 设置主键primary_key，设置自增 autoincrement, 唯一性 unique&#x3D;True, 索引index&#x3D;True id &#x3D; db.Column(db.Integer, autoincrement&#x3D;True, primary_key&#x3D;True ) username &#x3D; db.Column(db.String(64),unique&#x3D;True,index&#x3D;True) role_id &#x3D; db.Column(db.Integer,db.ForeignKey(&#39;roles.id&#39;)) create_time &#x3D; db.Column(db.TIMESTAMP, default&#x3D;datetime.now, comment&#x3D;&#39;创建时间&#39;) update_time &#x3D; db.Column(db.TIMESTAMP, default&#x3D;datetime.now, onupdate&#x3D;datetime.now, comment&#x3D;&#39;更新时间&#39;) #repr()方法显示一个可读字符串，虽然不是完全必要，不过用于调试和测试还是很不错的。 def __repr__(self): return &#39;&lt;Role &#123;&#125;&gt; &#39;.format(self.intent_name)class Role(db.Model): __tablename__ &#x3D; &#39;roles&#39; id &#x3D; db.Column(db.Integer,primary_key&#x3D;True) name &#x3D; db.Column(db.String(64),unique&#x3D;True) users &#x3D; db.relationship(&#39;User&#39;,backref&#x3D;&#39;role&#39;) def __repr__(self): return &#39;&lt;Slots &#123;&#125;&gt;&#39;.format(self.slot_id)#User类中：设置外键role_id &#x3D; db.Column(db.Integer,db.ForeignKey(&#39;roles.id&#39;))# Role类中：设置关系users &#x3D; db.Relationship(&#39;User&#39;,backref&#x3D;&#39;role&#39;) 4. 创建/删除数据库表进入项目目录运行1234# 引入建好的模型类from model.models import *db.create_all()db.drop_all() 5. 增删改查5.1. 插入行5.1.1. 插入单行123user_jim &#x3D; User(username&#x3D;&#39;jim&#39;,role&#x3D;role_admin)db.session.add(user_jim)db.session.commit() 5.1.2. 批量插入例子摘自这里：https://blog.csdn.net/weixin_44777680/article/details/105654220这里有使用建议：https://blog.csdn.net/dongyouyuan/article/details/79236673?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase方式1： 一行一行插入add()，效率最低12345678first_time &#x3D; datetime.utcnow()for i in range(10000): user &#x3D; User(username&#x3D;username + str(i), password&#x3D;password) db.session.add(user) db.session.commit()second_time &#x3D; datetime.utcnow()print((second_time - first_time).total_seconds())# 38.14347s方式2： session.add_all()123objects &#x3D; [User(name&#x3D;&quot;u1&quot;), User(name&#x3D;&quot;u2&quot;), User(name&#x3D;&quot;u3&quot;)]session.add_all(objects)session.commit()方式3：bulk_save_objects批量插入123456789101112second_time &#x3D; datetime.utcnow()db.session.bulk_save_objects( [ User(username&#x3D;username + str(i), password&#x3D;password) for i in range(10000) ])db.session.commit()third_time &#x3D; datetime.utcnow()print((third_time - second_time).total_seconds())# 2.121589s方式4： bulk_insert_mappings批量插入12345678910111213third_time &#x3D; datetime.utcnow()db.session.bulk_insert_mappings( User, [ dict(username&#x3D;&quot;NAME INSERT &quot; + str(i), password&#x3D;password) for i in range(10000) ])db.session.commit()fourth_time &#x3D; datetime.utcnow()print((fourth_time - third_time).total_seconds())# 1.13548s方式5 execute(str_sql_insert) ：12345678910fourth_time &#x3D; datetime.utcnow()db.session.execute( User.__table__.insert(), [&#123;&quot;username&quot;: &#39;Execute NAME &#39; + str(i), &quot;password&quot;: password&#125; for i in range(10000)])db.session.commit()five_time &#x3D; datetime.utcnow()print((five_time - fourth_time).total_seconds())# 0.888822s 5.2. 删除行123user_jim &#x3D; User(username&#x3D;&#39;jim&#39;,role&#x3D;role_admin)db.session.delete(user_jim)db.session.commit() 5.3. 更改行批量插入或更新textal 方式sqlalchemy insert自带方法官方文档给了针对mysql的on_duplicate_key_update操作方式，原理是，对table的insert操作外封了一个on_duplicate_key_update函数，相当于insert后面拼接的内容，该函数有三种提供数据的方式（直接用insert语句的数据；传入定义的字典，传入元组）。 如下链接，结合批量执行的方法，需要传入bindparam参数，所以采用了传入字典的方式，总结如下：https://docs.sqlalchemy.org/en/13/dialects/mysql.html#mysql-insert-on-duplicate-key-update123456789101112131415161718try: # insert操作的内容 insert_stmt &#x3D; insert(NewsArticleKeyword).values( news_id&#x3D; bindparam(&#39;news_id&#39;), order&#x3D; bindparam(&#39;order&#39;),keywords&#x3D; bindparam(&#39;keywords&#39;),weight&#x3D; bindparam(&#39;weight&#39;), status&#x3D; bindparam(&#39;status&#39;)) # update操作的内容 on_duplicate_key_stmt &#x3D; insert_stmt.on_duplicate_key_update( &#123;&quot;keywords&quot;: bindparam(&#39;keywords&#39;), &quot;weight&quot;: bindparam(&#39;weight&#39;),&quot;update_time&quot;: func.current_timestamp()&#125;, ) # 执行批量的更新或插入操作 db.session.execute(on_duplicate_key_stmt,[&#123;&quot;news_id&quot;: news.id, &quot;order&quot;: order, &quot;keywords&quot;: keywords[order][0], &#39;weight&#39;: keywords[order][1], &#39;status&#39;: 1&#125; for order in range(len(keywords))] ) db.session.commit()except SQLAlchemyError as e: db.session.rollback() logger.error(e) 5.4. 查询数据获取多条或一条查询结果加上.all() 或 .one() 不加是查询，加上是获取查询的结果.all() 返回的是满足查询结果的数据list.first() 返回的是满足查询结果的第一条数据.one() 返回的是满足查询结果的第一条数据， 不建议用.one()， 在没有满足查询数据的情况下，one()会因为获取不到而报错，可以采用.limit(1).all()来获取listone_or_none()：跟one()方法类似，但是在结果集中没有数据的时候也不会抛出异常。 5.4.1. 计数12345db.session.query(User).filter(User.name.like(&#39;%ed%&#39;)).count()## 生成的sql语句比较灵活SELECT count(*) AS count_1FROM newsWHERE news.create_time &gt;&#x3D; %(create_time_1)s AND news.create_time &lt; %(create_time_2)s 123456User.query().count()## 生成的sql语句嵌套复杂，一个函数一层嵌套SELECT count(*) AS count_1FROM (SELECT news.news_id AS news_news_id, news.url AS news_urlFROM newsWHERE news.create_time &gt;&#x3D; %(create_time_1)s AND news.create_time &lt; %(create_time_2)s) AS anon_1 5.4.1. 查询所有12345# 对象类方式User.query.all() &gt;&gt; 返回结果：[&lt;User &#39;tom&#39;&gt;, &lt;User &#39;tim&#39;&gt;, &lt;User &#39;sam&#39;&gt;]# session 方式db.session.query(User).all() 5.4.2. 筛选条件https://www.jianshu.com/p/f40a4987891bfilter_by() 和 filter() 的最主要的区别：filter_by() 字段直接用属性名，等于用=， 只接受键值对参数，所以 filter_by() 不支持&gt;&lt;（大于和小于）和 and_、or_查询filter() 字段用类名.属性名，等于用==， 支持&gt;&lt;（大于和小于）和 and_、or_查询 文本方式:SQLAlchemy还提供了使用文本SQL的方式来进行查询，这种方式更加的灵活。而文本SQL要装在一个text()方法中，看以下例子：12from sqlalchemy import textdb.session.query(User).filter(text(&quot;id&lt;244&quot;)).order_by(text(&quot;id&quot;)).all()对象类方式12test3 &#x3D; Intent.query.filter(Intent.intent_name &#x3D;&#x3D; intent).all()test3 &#x3D; Intent.query.filter_by(intent_name &#x3D; intent).all()session 方式123456789101112131415161718192021222324252627from operator import or_, and_, in_# 文本方式# filter_by() # 查询 user 表里面名字等于 Tom 的： db.session.query(User).filter_by(name&#x3D;&#39;Tom&#39;).all() # 查询 user 表里面名字等于 Tom 并且年龄等于 18： db.session.query(User).filter_by(name&#x3D;&#39;Tom&#39;, age&#x3D;18).all() # 比如新的需求，查询 user 表里面名字等于 Tom 或者年龄等于 18 的用户，那么 filter_by() 就满足不了要求了# filter() 查询 user 表里面名字等于 Tom 的： db.session.query(User).filter(User.name &#x3D;&#x3D; &#39;Tom&#39;).all() 查询 user 表里面名字等于 Tom 并且年龄等于 18： db.session.query(User).filter(User.name &#x3D;&#x3D; &#39;Tom&#39;, User.age &#x3D;&#x3D; 18).all() 也可以这样： db.session.query(User).filter(User.name &#x3D;&#x3D; &#39;Tom&#39;）.filter(User.age &#x3D;&#x3D; 18).all() 如果想使用 and 拼接需要用以下方式： db.session.query(User).filter(and_(User.name &#x3D;&#x3D; &#39;Tom&#39;, User.age &#x3D;&#x3D; 18)).all() db.session.query(User).filter(User.name.in_(&#39;abc&#39;, &#39;def)).all() 以下的方式 and 后面的 User.age &#x3D;&#x3D; 18 不会生效： db.session.query(User).filter(User.name &#x3D;&#x3D; &#39;Tom&#39; and User.age &#x3D;&#x3D; 18).all() 查询 user 表里面名字等于 Tom 的或者年龄等于 18： db.session.query(User).filter(or_(User.name &#x3D;&#x3D; &#39;Tom&#39;, User.age &#x3D;&#x3D; 18)).all() 查询 user 表里面名字等于 Tom 的并且年龄大于 18 db.session.query(User).filter(User.name &#x3D;&#x3D; &#39;Tom&#39;, User.age &gt; 18).all() 查询 name 中包含字母 a 的所有数据(模糊查询) db.session.query(User).filter(User.name.like(&#39;%&#123;0&#125;%&#39;.format(&quot;a&quot;))).all() 5.4.3. 关联表1234567# 对象类方式test4 &#x3D; Slots.query.join(Intent, (Slots.slot_id &#x3D;&#x3D; Intent.slot)).filter(Intent.intent_name &#x3D;&#x3D; intent ).all()# session 方式test5 &#x3D; db.session.query(Intent.intent_name,Intent.intent_desc,Slots.slot_id,Slots.type,Slots.ket_word).\\ join(Intent, (Slots.slot_id &#x3D;&#x3D; Intent.slot)).\\ filter(Intent.intent_name &#x3D;&#x3D; intent).all() 5.4.4. 排序12345678910# 对象类方式test4 &#x3D; Slots.query.join(Intent, (Slots.slot_id &#x3D;&#x3D; Intent.slot)).\\ filter(Intent.intent_name &#x3D;&#x3D; intent ).\\ order_by(Intent.slot_sort).all()# session 方式test5 &#x3D; db.session.query(Intent.intent_name,Intent.intent_desc,Slots.slot_id,Slots.type,Slots.ket_word).\\ join(Intent, (Slots.slot_id &#x3D;&#x3D; Intent.slot)).\\ filter(Intent.intent_name &#x3D;&#x3D; intent).\\ order_by(Intent.slot_sort).all() 6. db和主文件循环引用的问题https://www.jianshu.com/p/6103d6a79485https://www.cnblogs.com/zhf123/p/11566831.html问题描述：model引用主文件的db逻辑层引用model的类进行查询route层引用逻辑层实现接口主文件引用route层进行蓝图管理 以上，造成了循环引用，程序无法运行因此，可以将db对象分离出来，单独做一个模块，供其他文件调用，用DBUtil.py表示：1234# DBUtiil.pyfrom flask_sqlalchemy import SQLAlchemydb &#x3D; SQLAlchemy()12345# app.py 主文件from DBUtil import db#没有这个可能导致找不到app的报错： &#39;No application found. Either work inside a view function or push&#39;db.app &#x3D; app db.init_app(app)1234# model.pyfrom DBUtil import dbClass User(db.Model): xxxx 7. 迁移数据库https://www.jianshu.com/p/759c2fdef7d2 异常报错需要回滚才能重连sqlalchemy.exc.InvalidRequestError: Can’t reconnect until invalid transaction is rolled back 在mysql超过wait_timeout后，连接会挂掉，服务就会报错 OperationalError:由于也sqlalchemy关闭了autocommit，隐式使用了事务，还会有错误StatementError: (sqlalchemy.exc.InvalidRequestError) Can’t reconnect until invalid transaction is 错误a是因为mysql的连接到达了wait_timeout, 使用超时的连接就会报错gone away, 错误b是因为连接断开后，事务没有回滚，残留的锁导致后续的查询报错. 解决方案一：打开autocommit sqlalchemy打开autocommit后, 就会停止使用事务，生成的查询语句立即执行, 防止了错误b.1SQLALCHEMY_DATABASE_URI &#x3D; (&#39;mysql+pymysql:&#x2F;&#x2F;username:passwrod@ip:prot&#x2F;database?charset&#x3D;utf8&amp;autocommit&#x3D;true&#39;) 解决方案二： 在所有访问数据库的地方加异常捕获，报异常时rollback1234try: order &#x3D; User.query.filter_by(user_id&#x3D;1).first()except InvalidRequestError: db.session.rollback() 丢连接2013 lost connection to MYSQL server during queryhttps://blog.csdn.net/weixin_39561473/article/details/90213914 连接超时 Mysql请求结果集超过max_allowed_packet 也会出现这样的报错","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"}]},{"title":"python 正则表达式","slug":"python/python/python_match","date":"2019-12-04T00:57:45.000Z","updated":"2021-06-11T04:18:34.576Z","comments":true,"path":"python/python/python_match/","link":"","permalink":"https://tlylft.github.io/python/python/python_match/","excerpt":"","text":"1. 基本介绍1.1. 包引用1import re 1.2. 三种匹配方法的对比 https://blog.csdn.net/weixin_39383896/article/details/99690266 1.2.1. re.match 用法1234re.match语法：re.match(pattern,string,flags&#x3D;0)pattern:表示正则表达式string：要匹配的字符flags：控制匹配的方式 re.match匹配方式：从字符起始位置匹配，若起始位置匹配不成功返回none。即只匹配起始位置 1.2.2. re.search用法re.match 只能在起始位置匹配，而re.search可以扫描整个字符串并返回第一个成功的匹配 1.2.3. re.findall 方法上述两个都只能找到一个匹配结果，而findall可以找到所有满足匹配条件的结果，并以列表的形式返回 1234567891011121314import re string&#x3D;&#39;www.baidu.com&#39;pattern1&#x3D;&#39;www&#39;pattern2&#x3D;&#39;com&#39;m_match1&#x3D;re.match(&#39;www&#39;,string) &gt;&gt;&gt; &lt;re.Match object; span&#x3D;(0, 3), match&#x3D;&#39;www&#39;&gt;m_match1.group() &gt;&gt;&gt; wwwm_match2&#x3D;re.search(&#39;www&#39;,string) &gt;&gt;&gt; &lt;re.Match object; span&#x3D;(0, 3), match&#x3D;&#39;com&#39;&gt;m_match2.group() &gt;&gt;&gt; wwwm_match3&#x3D;re.findall(&#39;www&#39;,string) &gt;&gt;&gt; [&#39;www&#39;]m_match1&#x3D;re.match(&#39;com&#39;,string) &gt;&gt;&gt; Nonem_match2&#x3D;re.search(&#39;com&#39;,string) &gt;&gt;&gt; &lt;re.Match object; span&#x3D;(10, 13), match&#x3D;&#39;com&#39;&gt;m_match3&#x3D;re.findall(&#39;com&#39;,string) &gt;&gt;&gt; [&#39;com&#39;] 2. 匹配个数说明3. 分组匹配3.1. 分组与遍历 （group）match方法：从开始匹配1234567891011121314151617line &#x3D; &quot;Cats are smarter than dogs&quot; matchObj &#x3D; re.match( r&#39;(.*) are (.*?) .*&#39;, line, re.M|re.I) print(matchObj) # 打印匹配的起始位置或Noneif matchObj: print &quot;matchObj.group() : &quot;, matchObj.group() #满足匹配的整个字符串 print &quot;matchObj.group(1) : &quot;, matchObj.group(1) # 字符串里设定的第一个（）里的内容 print &quot;matchObj.group(2) : &quot;, matchObj.group(2) # 字符串里设定的第二个（）里的内容else: print &quot;No match!!&quot;# output:matchObj : (0, 3)或NonematchObj.group() : Cats are smarter than dogsmatchObj.group(1) : CatsmatchObj.group(2) : smarterre.search方法：返回字符串第一个成功的匹配12345678910111213141516line &#x3D; &quot;Cats are smarter than dogs&quot;; searchObj &#x3D; re.search( r&#39;(.*) are (.*?) .*&#39;, line, re.M|re.I) print(searchObj) # 打印匹配的起始位置或Noneif searchObj: print &quot;searchObj.group() : &quot;, searchObj.group() print &quot;searchObj.group(1) : &quot;, searchObj.group(1) print &quot;searchObj.group(2) : &quot;, searchObj.group(2)else: print &quot;Nothing found!!&quot;# output:matchObj.group() : Cats are smarter than dogsmatchObj.group(1) : CatsmatchObj.group(2) : smarter 3.2. 分组后直接以字典方式展示 (?P\\pattern)【例1】：身份证 1102231990xxxxxxxx1234import res &#x3D; &#39;1102231990xxxxxxxx&#39;res &#x3D; re.search(&#39;(?P&lt;province&gt;\\d&#123;3&#125;)(?P&lt;city&gt;\\d&#123;3&#125;)(?P&lt;born_year&gt;\\d&#123;4&#125;)&#39;,s)print(res.groupdict())此分组取出结果为：1&#123;&#39;province&#39;: &#39;110&#39;, &#39;city&#39;: &#39;223&#39;, &#39;born_year&#39;: &#39;1990&#39;&#125;【例2】： 日期 20190101 2019-01-01 2019.01.01 201902123s &#x3D; &#39;20190101&#39;res &#x3D; re.search(&#39;(?P&lt;year&gt;\\d&#123;4&#125;)[.-]*(?P&lt;month&gt;\\d&#123;1,2&#125;)[.-]*(?P&lt;day&gt;\\d&#123;0,2&#125;)&#39;,s)print(res.groupdict())此分组取出结果为：1&#123;&#39;year&#39;: &#39;2019&#39;, &#39;month&#39;: &#39;02&#39;, &#39;day&#39;: &#39;&#39;&#125; 符号说明re? 问号代表了非贪婪方式如 去掉html标签：raw_text = re.sub(r’&lt;.*?&gt;|—retrun—‘, ‘ ‘, text)不加问号的情况，会去掉很多文本，因为会贪婪匹配第一个到最后一个，中间所有的文字都没有了。","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"马尔科夫随机场","slug":"NLP/algorithm/MRF","date":"2019-12-03T14:53:55.000Z","updated":"2021-06-11T03:07:40.558Z","comments":true,"path":"NLP/algorithm/MRF/","link":"","permalink":"https://tlylft.github.io/NLP/algorithm/MRF/","excerpt":"","text":"1. 马尔科夫随机场1.1. 定义在nlp中，一个词可以用一个团表示 1.2. 马尔科夫性个人认为马尔科夫性没有什么特殊的意义，大家只记得马尔科夫性就可以了，即条件独立，当前状态只和前一状态有关。满足以上三者之一的无向图，叫做马尔科夫随机场 2. CRFhttps://tlylft.github.io/NLP/algorithm/CRF/","categories":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"algorithm","slug":"NLP/algorithm","permalink":"https://tlylft.github.io/categories/NLP/algorithm/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"algorithm","slug":"algorithm","permalink":"https://tlylft.github.io/tags/algorithm/"}]},{"title":"python 常用基础操作","slug":"python/python/python-basic","date":"2019-12-02T13:59:55.000Z","updated":"2023-03-30T05:20:49.507Z","comments":true,"path":"python/python/python-basic/","link":"","permalink":"https://tlylft.github.io/python/python/python-basic/","excerpt":"","text":"string123456789101112131415161718192021222324252627# 去除前后空格my_str &#x3D; &quot; welcome to www.tulingxueyuan.com &quot;print(my_str.strip())&gt;&gt; welcome to www.tulingxueyuan.com# 按特定字符串分成元组print(my_str.partition(&#39;to&#39;))&gt;&gt; (&#39; welcome &#39;, &#39;to&#39;, &#39; www.tulingxueyuan.com &#39;)# 多行字符my_str_data &#x3D; &quot;&quot;&quot;今天双双老师啃了三斤猪腿&quot;&quot;&quot;print(my_str_data.splitlines())&gt;&gt; [&#39;今天&#39;, &#39;双双老师&#39;, &#39;啃了三斤猪腿&#39;]# 判断数字和字母my_str &#x3D; &#39;123abc&#39;print(my_str.isalpha()) # falseprint(my_str.isdigit()) # falseprint(my_str.isalnum()) # true# 连接数组join_func &#x3D; &#39;*&#39;str_list &#x3D; [&#39;welcome&#39;, &#39;to&#39;, &#39;changsha&#39;]print(join_func.join(str_list)) 1. 循环的简洁操作 https://www.cnblogs.com/huchong/p/9328687.html 1.1. for … [if]..12345&gt;&gt;&gt; a &#x3D; [12,3,4,6,7,13,21]&gt;&gt;&gt; newList &#x3D; [x for x in a]output : [12,3,4,6,7,13,21]&gt;&gt;&gt; newList2 &#x3D; [x for x in a if x%2 &#x3D;&#x3D; 0]output : [12,4,6] 函数传参1234567891011121314# 当前声明不定长参数的格式def test(a, b, *args, **kwargs): # 不定长参数 *args, **kwargs print(f&#39;&#123;a&#125;, &#123;type(a)&#125;&#39;) print(f&#39;&#123;b&#125;, &#123;type(b)&#125;&#39;) # 如果形式参数已经接收到值之后还多出了一些其他的普通参数 则会被*agrs &#39;全部&#39; 接收 并且类型为一个元组 print(f&#39;&#123;args&#125;, &#123;type(args)&#125;&#39;) print(f&#39;&#123;kwargs&#125;, &#123;type(kwargs)&#125;&#39;) # 默认参数的传递方式会被 **kwargs全部接收 并且打包成字典test(1, 2, 3, 4, 5, 6, name&#x3D;&#39;安娜&#39;, age&#x3D;18)&gt;&gt;&gt;&gt; outputargs &#x3D; (3, 4, 5, 6), &lt;class &#39;tuple&#39;&gt;kwargs &#x3D; &#123;&#39;name&#39;: &#39;安娜&#39;, &#39;age&#39;: 18&#125;, &lt;class &#39;dict&#39;&gt; 1.2. 嵌套的for … [if] ..12345678&gt;&gt;&gt;a &#x3D; [12,3,4,6,7,13,21]&gt;&gt;&gt;b &#x3D; [&#39;a&#39;,&#39;b&#39;,&#39;x&#39;]&gt;&gt;&gt;newList &#x3D; [(x, y) for x in a for y in b]output : [(12,&#39;a&#39;), (12,&#39;b&#39;), (12,&#39;x&#39;), (3,&#39;a&#39;), (3,&#39;b&#39;), (3,&#39;x&#39;), (4,&#39;a&#39;), (4,&#39;b&#39;), (4,&#39;x&#39;), (6,&#39;a&#39;), (6,&#39;b&#39;), (6,&#39;x&#39;), (7,&#39;a&#39;), (7,&#39;b&#39;), (7,&#39;x&#39;), (13,&#39;a&#39;), (13,&#39;b&#39;), (13,&#39;x&#39;), (21,&#39;a&#39;), (21,&#39;b&#39;), (21,&#39;x&#39;)]&gt;&gt;&gt;newList2&#x3D;[(x, y) for x in a for y in b if x%2 &#x3D;&#x3D; 0 and y&lt;&#39;x&#39;]output : [(12,&#39;a&#39;), (12,&#39;b&#39;), (4,&#39;a&#39;), (4,&#39;b&#39;), (6,&#39;a&#39;), (6,&#39;b&#39;)]&gt;&gt; newList3 &#x3D; [(x,y) for x in a if x%2 &#x3D;&#x3D; 0 for y in b]output : [(12,&#39;a&#39;), (12,&#39;b&#39;),(12,&#39;x&#39;), (4,&#39;a&#39;), (4,&#39;b&#39;), (4,&#39;x&#39;), (6,&#39;a&#39;), (6,&#39;b&#39;), (6,&#39;x&#39;)] 2. python的时间操作2.1. 获取当前时间12import datetimecurrent_date &#x3D; datetime.datetime.now().strftime(&#39;%Y-%m-%d&#39;) 2.2. 2.2 时间加减1234now &#x3D; datetime.datetime.now()delta &#x3D; datetime.timedelta(days&#x3D;3)n_days &#x3D; now + deltaprint n_days.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;) 2.3. 2.3 时间与字符串转换123456# 字符串转换成datestr_time &#x3D; &#39;2020-02-24 21:57:30&#39;date_time &#x3D; datetime.datetime.strptime(str_time, &quot;%Y-%m-%d %H:%M:%S&quot;)# 1.把datetime转成字符串def datetime_toString(dt): print(&quot;1.把datetime转成字符串: &quot;, dt.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)) 2.4. 2.4 时间差判断12345678910from datetime import datetimeimport timea &#x3D; datetime.now() #获得当前时间time.sleep(2) #睡眠两秒b &#x3D; datetime.now() # 获取当前时间durn &#x3D; (b-a).seconds #两个时间差，并以秒显示出来print(durn) # &gt;&gt;2durn &#x3D; (b-a).seconds&#x2F;&#x2F;60 #两个时间差，并以分钟显示出来print(durn) 3. python 遍历文件夹当前目录下遍历：12import osfile_list &#x3D; os.listdir(file_path)递归遍历:12345678# 获取目录下所有脚本文件def get_all_path(dirname): result &#x3D; []#所有的文件 for maindir, subdir, file_name_list in os.walk(dirname): for filename in file_name_list: apath &#x3D; os.path.join(maindir, filename)#合并成一个完整路径 result.append(apath) return result 4. 类型转换4.1. 4.1 string 与 json123456789# string 转换成 jsonimport jsonstr &#x3D; &#39;&#123;&quot;accessToken&quot;: &quot;521de21161b23988173e6f7f48f9ee96e28&quot;, &quot;User-Agent&quot;: &quot;Apache-HttpClient&#x2F;4.5.2 (Java&#x2F;1.8.0_131)&quot;&#125;&#39;json &#x3D; json.loads(str)# json 转成stringimport jsonjson &#x3D; &#123;&quot;accessToken&quot;: &quot;521de21161b23988173e6f7f48f9ee96e28&quot;, &quot;User-Agent&quot;: &quot;Apache-HttpClient&#x2F;4.5.2 (Java&#x2F;1.8.0_131)&quot;&#125;str &#x3D; json.dumps(json) 5. 发送接口请求5.1. 5.1 get请求12345678910import requests #请求地址url &#x3D; &quot;https:&#x2F;&#x2F;api.global.net&#x2F;datastore&#x2F;v1&#x2F;tracks&#x2F;&quot;+trackId+&quot;?location&#x3D;12&#125;&quot;#发送get请求response &#x3D; requests.get(url)#获取返回的json数据response.json()# 获取返回的文本格式response.text 如果遇到 certificate verify failed 错误，get方法使用verify=False可以解决1requests.get(url,verify&#x3D;False)https://blog.csdn.net/nirendao/article/details/70214211而root cause是那个被测试站点给出的证书被认为是有问题的，所以需要verify=False去pass这个错误。但是，这样依旧还不够，因为用了verify=False的缘故，每次连接都会有一大段warning信息打印出来，提示连接安全性的问题。在确保安全的情况下，如何disable这段提示信息呢？加上一句话即可：1requests.packages.urllib3.disable_warnings() 5.2. 5.2 post请求12345678910import requestsdata &#x3D; &#123; &quot;name&quot;:&quot;zhaofan&quot;, &quot;age&quot;:23&#125;#发送post请求 response&#x3D;requests.post(&quot;https:&#x2F;&#x2F;api.global.net&#x2F;datastore&#x2F;v1&#x2F;tracks&#x2F;&quot;,data&#x3D;data)#获取返回的json数据response.json() 6. 函数传入指针函数传入或是for循环出的迭代的变量，如果值是数组或是字典类型，一般都是以指针的形式传入，直接改变值可以改变传入前的变量。12345678910111213if __name__ &#x3D;&#x3D; &#39;__main__&#39;: seq &#x3D; [&#123;&#39;k&#39;:1&#125;,&#123;&#39;k&#39;:2&#125;,&#123;&#39;k&#39;:3&#125;] for i, t in enumerate(seq): print(t) t[&#39;k&#39;] &#x3D; 4 print(seq) seq2 &#x3D; [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] for i, t in enumerate(seq2): print(t) t &#x3D; &#39;d&#39; print(seq2)123456789output:&#123;&#39;k&#39;: 1&#125;&#123;&#39;k&#39;: 2&#125;&#123;&#39;k&#39;: 3&#125;[&#123;&#39;k&#39;: 4&#125;, &#123;&#39;k&#39;: 4&#125;, &#123;&#39;k&#39;: 4&#125;]abc[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;] unexpected detail123456a &#x3D; (1,2) # tuplea &#x3D; (1,) # tuplea &#x3D; (1) # element!!!!b&#x3D; [1,2] # listb &#x3D; [1,] # listb &#x3D; [1] # list 7. tricky error:ImportError: cannot import name ‘namedtuple’ from ‘collections’ 不要用关键词命名脚本名！ 不要用关键词命名脚本名！ 不要用关键词命名脚本名！","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"【读书笔记】 叶绍翁诗集","slug":"reading/yeshaoweng","date":"2019-12-01T06:11:10.000Z","updated":"2023-08-10T12:03:16.138Z","comments":true,"path":"reading/yeshaoweng/","link":"","permalink":"https://tlylft.github.io/reading/yeshaoweng/","excerpt":"","text":"叶绍翁叶绍翁，字嗣宗，号靖逸，龙泉（今浙江龙泉）人，祖籍建安（今福建建瓯），南宋中期诗人。江湖派诗人。 叶绍翁原姓李，后因受祖父李颖士牵连，家业中衰，少时即嗣于龙泉叶氏。宋光宗至宋宁宗期间，曾在朝廷做小官，与真德秀过从甚密。他长期隐居钱塘西湖之滨，又与葛天民互相酬唱。 游园不值应怜屐齿印苍苔，小扣柴扉久不开。春色满园关不住，一枝红杏出墙来。 译文：也许是园主担心我的木屐踩坏他那爱惜的青苔，轻轻地敲柴门，久久没有人来开。可是这满园的春色毕竟是关不住的，你看，那儿有一枝粉红色的杏花伸出墙头来。 夜书所见萧萧梧叶送寒声，江上秋风动客情。知有儿童挑促织，夜深篱落一灯明。 译文：瑟瑟的秋风吹动梧桐树叶，送来阵阵寒意，江上吹来秋风，使出门在外的我不禁思念起自己的家乡。家中几个小孩还在兴致勃勃地斗蟋蟀呢！夜深人静了还亮着灯不肯睡眠。 解析： 借景抒情，思乡之情。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"Python IDE","slug":"python/env/python-IDE","date":"2019-11-23T14:27:55.000Z","updated":"2021-12-27T14:09:46.468Z","comments":true,"path":"python/env/python-IDE/","link":"","permalink":"https://tlylft.github.io/python/env/python-IDE/","excerpt":"","text":"几种IDE的介绍https://www.runoob.com/python/python-ide.html Pycharm的安装与配置 pycharm 软件安装https://blog.csdn.net/pdcfighting/article/details/80297499 pycharm 导入第三方包在file—&gt;setting—&gt;project interpreter中https://blog.csdn.net/u014028063/article/details/80423009以下解决了每个项目都需要重新导入包的问题https://blog.csdn.net/weixin_37637399/article/details/81868220 pycharm/idea 前端界面实现实时调试功能IntelliJ IDEA 使用 LiveEdit 插件https://blog.csdn.net/Cindypin/article/details/78657445 pycharm破解","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"pycharm","slug":"pycharm","permalink":"https://tlylft.github.io/tags/pycharm/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}]},{"title":"Python连接kerberos认证的hive和hdfs","slug":"python/env/python-hive-connection","date":"2019-11-23T14:27:55.000Z","updated":"2021-06-11T03:26:57.561Z","comments":true,"path":"python/env/python-hive-connection/","link":"","permalink":"https://tlylft.github.io/python/env/python-hive-connection/","excerpt":"","text":"reference：linux配置步骤：https://blog.csdn.net/u012133034/article/details/100704082报错问题汇总：包版本汇总：https://blog.csdn.net/rav009/article/details/87865093thrift_sasl==0.3.0AttributeError: ‘TSaslClientTransport’ object has no attribute ‘readAll’https://blog.csdn.net/u012965373/article/details/87709077 一、 安装虚拟机开发环境（windows下pykerberos所需的很多基础环境没有找到办法安装，兼容性较差） 所需环境： python 3.7.4 vmware 14 pro centos7镜像： CentOS-7.0-1406-x86_64-DVD.iso 标准安装版 安装centos7虚拟机 https://blog.csdn.net/babyxue/article/details/80970526 win8.1或win10系统使用虚拟机前需在bios中设置开启虚拟化功能 VirtuallizationTechnology = ENable，否则虚拟环境没有64位选项，且会黑屏不能正常使用 只做开发机器，虚拟机网络不需配置固定IP,设置NAT连接即可。 centos安装时，软件安装选择【server with GUI】或者【GNOME desktop】直接是有图形化界面的。如果选择最小安装再安装界面也会有很多坑，比较麻烦 安装anaconda环境 https://www.cnblogs.com/xiao-apple36/p/9052102.html conda配置虚拟环境查看已有环境： conda env list 为项目创建环境： conda create -n your_env_name python=3.7 进入环境（linux是需要source的！！）： Linux: source activate your_env_name 退出环境： source deactivate 安装pycharm https://blog.csdn.net/limingyue0312/article/details/81805826 二、基础环境配置 yum包（需要先装yum包，再装python包，不然会有问题） 1234567yum install openldap-clients -yyum install krb5-workstation krb5-libs -yyum install gcc-c++ python-devel.x86_64 cyrus-sasl-devel.x86_64（c++需要对很多包进行编译）yum install python-devel yum install krb5-devel （没有这个pykerberos是会缺少文件报错的）yum install python-krbVyum install cyrus-sasl-plain cyrus-sasl-devel cyrus-sasl-gssapi python包安装(注意版本号，会不兼容,如果有报错，可能是安装cpython顺序不对，再装一遍cpython) 123456789101112pip install krbcontext&#x3D;&#x3D;0.9pip install thrift&#x3D;&#x3D;0.11.0pip install cpython (thrift-sasl的依赖)pip install thrift-sasl&#x3D;&#x3D;0.3.0pip install thriftpy&#x3D;&#x3D;0.3.9pip install impyla&#x3D;&#x3D;0.14.2.2pip install hdfs[kerberos]pip install pykerberos&#x3D;&#x3D;1.2.1pip install pyhive&#x3D;&#x3D;0.6.1pip install cpythonpip install krbcontext&#x3D;&#x3D;0.9 thrift&#x3D;&#x3D;0.11.0 thrift-sasl&#x3D;&#x3D;0.3.0 thriftpy&#x3D;&#x3D;0.3.9 impyla&#x3D;&#x3D;0.14.2.2 hdfs[kerberos] pykerberos&#x3D;&#x3D;1.2.1 pyhive&#x3D;&#x3D;0.6.1 配置/etc/hosts文件（需要把大数据平台的机器和域名进行配置） 12310.37.147.242 host242.master.dev.cluster.enn.cn host24210.37.147.243 host243.master.dev.cluster.enn.cn host243等等 配置/etc/krb5.conf(具体查看kerberos服务配置中心)把自己的集群的文件覆盖上去 三、代码实现：hive连接：1234567891011121314import osfrom hdfs.ext.kerberos import KerberosClientfrom krbcontext import krbcontextimport pyhivedef get_connection(self): try: print(&#39;getting hive connection to &#123;0&#125;..&#39;.format(self.host)) active_str &#x3D; &#39;kinit -kt &#123;0&#125; &#123;1&#125;&#39;.format(self.keytab_file, self.user) os.system(active_str) with krbContext(using_keytab&#x3D;True, principal&#x3D;self.user, keytab_file&#x3D;self.keytab_file): self.conn &#x3D; connect(host&#x3D;self.host, port&#x3D;self.port, auth&#x3D;&#39;KERBEROS&#39;, kerberos_service_name&#x3D;&quot;hive&quot;) except Exception as e: raise ehdfs连接：12345678910111213import osfrom hdfs.ext.kerberos import KerberosClientfrom krbcontext import krbcontext def _connect(self, host, port, sso_ticket&#x3D;None): try: hdfs_url &#x3D; &#39;http:&#x2F;&#x2F;&#39; + self.host + &#39;:&#39; + self.port active_str &#x3D; &#39;kinit -kt &#123;0&#125; &#123;1&#125;&#39;.format(self.keytab_file, self.user) os.system(active_str) with krbcontext(using_keytab&#x3D;True, keytab_file&#x3D;self.keytab_file, principal&#x3D;self.user): self.client &#x3D; KerberosClient(hdfs_url) except Exception as e: raise e","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"kerberos","slug":"kerberos","permalink":"https://tlylft.github.io/tags/kerberos/"},{"name":"hive","slug":"hive","permalink":"https://tlylft.github.io/tags/hive/"}]},{"title":"Python 安装包报错问题汇总","slug":"python/env/python-package","date":"2019-11-23T14:27:55.000Z","updated":"2021-12-27T14:10:08.715Z","comments":true,"path":"python/env/python-package/","link":"","permalink":"https://tlylft.github.io/python/env/python-package/","excerpt":"","text":"1. 版本冲突1.1. tensorflow 版本冲突1.2. tensorflow-2.2.0 和 numpy-1.17.0https://blog.csdn.net/xinjieyuan/article/details/103738396运行报错1FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy.......解决办法：TensorFlow=2.0.0 numpy=1.16.4TensorFlow=1.14.0 numpy=1.16.0TensorFlow=1.12.0 numpy=1.15.4TensorFlow=1.8.0 numpy=1.14.5或numpy-1.16-0 （试过没起作用） 1.3. pyhive + kerberos 环境下各种安装包版本123456789pip install krbcontext&#x3D;&#x3D;0.9pip install thrift&#x3D;&#x3D;0.11.0pip install cpython (thrift-sasl的依赖)pip install thrift-sasl&#x3D;&#x3D;0.3.0pip install thriftpy&#x3D;&#x3D;0.3.9pip install impyla&#x3D;&#x3D;0.14.2.2pip install hdfs[kerberos]pip install pykerberos&#x3D;&#x3D;1.2.1pip install pyhive&#x3D;0.6.1 2. Flask 安装后丢失ssl模块运行报错1AttributeError: &#39;Nonetype&#39; object has no attribute &#39;SSLContext&#39;解决办法： 以为是少装了ssl包，验证不是 最后在一次又一次的pip install flask中发现有一个warning：1pip is configured with locations that require TLS&#x2F;SSL, however the ssl module in Python is not available 是win10设置环境变量没有把所有的环境加进去。这里找到答案：https://stackoverflow.com/questions/45954528/pip-is-configured-with-locations-that-require-tls-ssl-however-the-ssl-module-in123For Windows 10 if you want use pip in normal cmd, not only in Anaconda prompt. you need add 3 environment paths. like these: D:\\Anaconda3; D:\\Anaconda3\\Scripts; D:\\Anaconda3\\Library\\binmost people only add D:\\Anaconda3\\Scripts; 而且有个问题待考证：之前环境用的是python3.5和3.6版本，启动flask服务没有遇到这个问题，因为项目需要升级到3.7才出现这个问题，可能是python3.7和win10之间无法调用安装的ssl模块。3. pip命令丢失问题描述：在某次执行pip install -upgrade pip 中意外报错后pip被卸载，环境中没有了pip包。 运行报错：1&quot;&#39;D:\\Anaconda3\\Scripts\\pip-script.py&#39; is not present.&quot; 解决办法：使用 easy_install pip命令就能解决。 4. 安装包时出现Microsoft Visual C++ 14.0 is required解决办法：1.到提示网址：https://visualstudio.microsoft.com/download/ 里面下载ALL download &gt; Tools for Visual Studio 2019 &gt; Build Tools for Visual Studio 2019 对应VC++版本安装后继续安装。2.到https://www.lfd.uci.edu/~gohlke/pythonlibs/找到mysqlclient编译包下载对应版本的whl文件：1pip install xxx.whl 5. Django 数据库报错问题描述：django2.2/mysql ImproperlyConfigured: mysqlclient 1.3.13 or newer is required; you have 0.9.3解决办法： https://blog.csdn.net/weixin_33127753/article/details/89100552降低Django版本到 2.1.4","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}]},{"title":"github+hexo 博客搭建","slug":"tools/github-blog","date":"2019-11-23T08:51:55.000Z","updated":"2021-08-23T07:16:42.363Z","comments":true,"path":"tools/github-blog/","link":"","permalink":"https://tlylft.github.io/tools/github-blog/","excerpt":"","text":"https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html https://tlylft.github.io/ 1. 安装nodejs 和 NPM在下载地址安装即可，新版本的nodejs会自动安装npm https://nodejs.org/en/download/ https://www.runoob.com/nodejs/nodejs-install-setup.html 在cmd 验证一下12node --versionnpm -v 2. 安装hexo 并初始化12npm install -g hexo npm install --save hexo-deployer-git (这个要在hexo当前目录下安装) 在电脑的某个地方新建一个名为hexo的文件夹,这个文件夹必须是空的1234$ cd &#x2F;f&#x2F;Workspaces&#x2F;hexo&#x2F;$ hexo init$ hexo g # 生成 ，如果已经有项目，不用生成，直接pull下来到public文件夹下$ hexo s # 启动服务 如果启动有问题 先尝试 hexo clean!!!hexo s是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容 3. 迁移hexo新电脑安装1npm install -g hexo新建hexo目录，进入目录，安装1234567npm installnpm install hexo-deployer-git --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --save#hexo inithexo cleanhexo s将源目录下文件拷贝到新目录下12345_config.yml package.json (这个没有用到) scaffolds&#x2F; (这个没有用到) source&#x2F; themes&#x2F;安装所需模块123456789&#96;&#96;&#96;### 4. 修改主题找到好看的主题：- PURE https:&#x2F;&#x2F;blog.csdn.net&#x2F;zgd826237710&#x2F;article&#x2F;details&#x2F;99671027 - 预览地址：https:&#x2F;&#x2F;blog.cofess.com&#x2F;- 项目地址：https:&#x2F;&#x2F;github.com&#x2F;justpsvm&#x2F;hexo-theme-pure- 安装教程：https:&#x2F;&#x2F;github.com&#x2F;justpsvm&#x2F;hexo-theme-pure 下载这个主题到themes文件夹下$ cd /f/Workspaces/hexo/$ git clone https://github.com/justpsvm/hexo-theme-pure themes/pure1修改_config.yml中的theme: landscape改为theme: pure，然后重新执行hexo g来重新生成。hexo g123456如果出现一些莫名其妙的问题，可以先执行hexo clean来清理一下public的内容，然后再来重新生成和发布。### 5. 上传github在上传代码到github之前，一定要记得先把你以前所有代码下载下来（虽然github有版本管理，但备份一下总是好的），因为从hexo提交代码时会把你以前的所有代码都删掉。 配置_config.yml中有关deploy的部分：deploy: type: git repository: git@github.com:tlylft/tlylft.github.io.git branch: master12&#96;&#96;&#96;hexo d如果报错：Deployer not found: git，是需要安装npm install —save hexo-deployer-git —registry=https://registry.npm.taobao.org 6. 写博客1hexo new &#39;my-first-blog&#39; 你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。 打开markdown文件，完整格式如下：12345678910---title: github+hexo 博客搭建date: 2019-11-24 16:51:55categories:- 一级分类- 二级分类tags: [github,blog]---以下是正文12hexo g --生成hexo d --上传 7. 设置文章路径样式 https://www.cnblogs.com/zhansu/p/9643066.html 默认的文章web路径为：1http:&#x2F;&#x2F;localhost:4000&#x2F;2020&#x2F;01&#x2F;16&#x2F;test-post&#x2F;如果不希望这样展示可以 修改_config.yml 更改默认路径：12permalink: :title&#x2F;# permalink: :year&#x2F;:month&#x2F;:day&#x2F;:title&#x2F; 8. 设置本地图片 https://junhaow.com/2016/07/08/006%20%7C%20%E5%A6%82%E4%BD%95%E5%9C%A8Hexo%E4%B8%AD%E6%97%A0%E7%97%9B%E5%9C%B0%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/ hexo g 后，markdown中引用的本地的图片文件迁移的位置 和 生成的web页面引用的位置不同，导致图片不能正常显示。解决方法：使用hexo-asset-image插件 8.1. 修改_config.yml首先确认_config.yml中有post_asset_folder:true 8.2. 安装hexo-asset-image在Hexo目录，执行1$ npm install https:&#x2F;&#x2F;github.com&#x2F;CodeFalling&#x2F;hexo-asset-image --save 8.3. 生成博文的方式创建md博文会生成一个同名的文件夹，可以存放图片文件做引用，或者手动新建文件和文件夹123456789101112hexo n &quot;new_post.md&quot; 文章名 ├── 图片1.jpg ├── 图片2.jpg └── 图片3.jpg 文章名.mdhexo g public&#x2F;2016&#x2F;07&#x2F;08&#x2F;文章名 ├── index.html ├── 图片1.jpg └── 图片2.jpg 8.4. 解决插件与hexo3.0 不兼容的问题如果hexo g 后生成的图片指向是有io的路径：12update link as:--&gt;&#x2F;.io&#x2F;&#x2F;06&#x2F;01&#x2F;vim&#x2F;1561905818946.pngupdate link as:--&gt;&#x2F;.io&#x2F;&#x2F;06&#x2F;01&#x2F;vim&#x2F;1561905818946.png参考： https://blog.csdn.net/xjm850552586/article/details/84101345 打开文件/node_modules/hexo-asset-image/index.js,修改内容为：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&#39;use strict&#39;;var cheerio &#x3D; require(&#39;cheerio&#39;);&#x2F;&#x2F; http:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;14480345&#x2F;how-to-get-the-nth-occurrence-in-a-stringfunction getPosition(str, m, i) &#123; return str.split(m, i).join(m).length;&#125;var version &#x3D; String(hexo.version).split(&#39;.&#39;);hexo.extend.filter.register(&#39;after_post_render&#39;, function(data)&#123; var config &#x3D; hexo.config; if(config.post_asset_folder)&#123; var link &#x3D; data.permalink; if(version.length &gt; 0 &amp;&amp; Number(version[0]) &#x3D;&#x3D; 3) var beginPos &#x3D; getPosition(link, &#39;&#x2F;&#39;, 1) + 1; else var beginPos &#x3D; getPosition(link, &#39;&#x2F;&#39;, 3) + 1; &#x2F;&#x2F; In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;...&#x2F;about&#x2F;index.html&quot;. var endPos &#x3D; link.lastIndexOf(&#39;&#x2F;&#39;) + 1; link &#x3D; link.substring(beginPos, endPos); var toprocess &#x3D; [&#39;excerpt&#39;, &#39;more&#39;, &#39;content&#39;]; for(var i &#x3D; 0; i &lt; toprocess.length; i++)&#123; var key &#x3D; toprocess[i]; var $ &#x3D; cheerio.load(data[key], &#123; ignoreWhitespace: false, xmlMode: false, lowerCaseTags: false, decodeEntities: false &#125;); $(&#39;img&#39;).each(function()&#123; if ($(this).attr(&#39;src&#39;))&#123; &#x2F;&#x2F; For windows style path, we replace &#39;\\&#39; to &#39;&#x2F;&#39;. var src &#x3D; $(this).attr(&#39;src&#39;).replace(&#39;\\\\&#39;, &#39;&#x2F;&#39;); if(!&#x2F;http[s]*.*|\\&#x2F;\\&#x2F;.*&#x2F;.test(src) &amp;&amp; !&#x2F;^\\s*\\&#x2F;&#x2F;.test(src)) &#123; &#x2F;&#x2F; For &quot;about&quot; page, the first part of &quot;src&quot; can&#39;t be removed. &#x2F;&#x2F; In addition, to support multi-level local directory. var linkArray &#x3D; link.split(&#39;&#x2F;&#39;).filter(function(elem)&#123; return elem !&#x3D; &#39;&#39;; &#125;); var srcArray &#x3D; src.split(&#39;&#x2F;&#39;).filter(function(elem)&#123; return elem !&#x3D; &#39;&#39; &amp;&amp; elem !&#x3D; &#39;.&#39;; &#125;); if(srcArray.length &gt; 1) srcArray.shift(); src &#x3D; srcArray.join(&#39;&#x2F;&#39;); $(this).attr(&#39;src&#39;, config.root + link + src); console.info&amp;&amp;console.info(&quot;update link as:--&gt;&quot;+config.root + link + src); &#125; &#125;else&#123; console.info&amp;&amp;console.info(&quot;no src attr, skipped...&quot;); console.info&amp;&amp;console.info($(this)); &#125; &#125;); data[key] &#x3D; $.html(); &#125; &#125;&#125;); 8.5. markdown 在hexo渲染中支持数学公式 https://www.cnblogs.com/zhyantao/p/10424874.html1234567891011121314151617181920212223242526271. 安装npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save2. 修改：打开node_modules&#x2F;hexo-renderer-kramed&#x2F;lib&#x2F;renderer.js，将formatText(text)方法改成：&#x2F;&#x2F; Change inline math rulefunction formatText(text) &#123; return text;&#125;3. 安装npm uninstall hexo-math --savenpm install hexo-renderer-mathjax --save4. 修改：a.打开node_modules&#x2F;hexo-renderer-mathjax&#x2F;mathjax.html，将 &lt;script&gt; 改为：&lt;script src&#x3D;&quot;https:&#x2F;&#x2F;cdnjs.cloudflare.com&#x2F;ajax&#x2F;libs&#x2F;mathjax&#x2F;2.7.1&#x2F;MathJax.js?config&#x3D;TeX-MML-AM_CHTML&quot;&gt;&lt;&#x2F;script&gt;b. 打开node_modules&#x2F;kramed&#x2F;lib&#x2F;rules&#x2F;inline.js:将11行：escape: &#x2F;^\\\\([\\\\&#96;*&#123;&#125;\\[\\]()#$+\\-.!_&gt;])&#x2F;,改为：escape: &#x2F;^\\\\([&#96;*\\[\\]()# +\\-.!_&gt;])&#x2F;,将20行:em: &#x2F;^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)&#x2F;,改为：em: &#x2F;^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)&#x2F;,5. 开启公式支持在home&#x2F;_config.yml，中添加如下内容mathjax: enable: true 8.6. 增加评论和浏览数功能https://www.jianshu.com/p/15a100aa0efe 8.7. 设置文章顺序新版hexo已支持_config.yml配置1234index_generator: path: &#39;&#39; per_page: 10 order_by: -updatefile header 增加update属性，top属性也可设置置顶文章，top 定义的值越大，越靠前12345678910---title: rasa policydate: 2020-12-21 13:29:23update: 2020-12-21 13:29:23top: 1categories: - chatbot- rasatags: [chatbot, rasa]--- 8.8. 设置首页显示更新时间 新增archive style： themes\\landscape\\source\\css_partial\\archive.styl1234567.archive-article-update color: color-grey text-decoration: none font-size: 0.85em line-height: 1em margin-bottom: 0.5em display: block 新增style ：themes\\landscape\\source\\css_partial\\article.styl123.article-update @extend $block-caption float: left 新建展示文件themes\\pure\\layout_partial\\post\\update.ejs123&lt;span class&#x3D;&quot;article-update&quot;&gt; &lt;time datetime&#x3D;&quot;&lt;%&#x3D; date_xml(post.update) %&gt;&quot; itemprop&#x3D;&quot;datePublished&quot;&gt;update: &lt;%&#x3D; date(post.update, date_format) %&gt;&lt;&#x2F;time&gt;&lt;&#x2F;span&gt; 修改主页文章列表底部展示列表内容file:themes\\pure\\layout_partial\\archive-post.ejs12345678&lt;p class&#x3D;&quot;article-meta&quot;&gt; &lt;%- partial(&#39;post&#x2F;category&#39;) %&gt; &lt;%- partial(&#39;post&#x2F;date&#39;, &#123;class_name: &#39;article-date&#39;, date_format: &#39;yy-MM-DD&#39;&#125;) %&gt; &lt;%- partial(&#39;post&#x2F;update&#39;, &#123;class_name: &#39;article-update&#39;, date_format: &#39;yy-MM-DD&#39;&#125;) %&gt; &lt;!-- &lt;%- partial(&#39;post&#x2F;tag&#39;) %&gt; &lt;span class&#x3D;&quot;post-comment&quot;&gt;&lt;i class&#x3D;&quot;icon icon-comment&quot;&gt;&lt;&#x2F;i&gt; &lt;a href&#x3D;&quot;&lt;%- url_for(post.path) %&gt;#comments&quot; class&#x3D;&quot;article-comment-link&quot;&gt;&lt;%&#x3D; __(&#39;article.comments&#39;) %&gt;&lt;&#x2F;a&gt;&lt;&#x2F;span&gt; &lt;%- partial(&#39;post&#x2F;wordcount&#39;) %&gt; --&gt;&lt;&#x2F;p&gt;","categories":[{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"}],"tags":[{"name":"github","slug":"github","permalink":"https://tlylft.github.io/tags/github/"},{"name":"blog","slug":"blog","permalink":"https://tlylft.github.io/tags/blog/"}]},{"title":"pandas数据读写","slug":"python/pandas/pandas-file-operation","date":"2019-11-10T14:27:55.000Z","updated":"2022-11-04T09:01:01.657Z","comments":true,"path":"python/pandas/pandas-file-operation/","link":"","permalink":"https://tlylft.github.io/python/pandas/pandas-file-operation/","excerpt":"","text":"数据类型Series1sr1 &#x3D; pd.Series([1,2,3,4],index&#x3D;[101,102,103,104]) 1. csv文件读写https://blog.csdn.net/tz_zs/article/details/81137998 1.1 读入csv文件1.2 写入csv或文本文件df.to_csv() 所有参数：1234567891011121314151617181920DataFrame.to_csv( path_or_buf&#x3D;None, sep&#x3D;&#39;, &#39;, na_rep&#x3D;&#39;&#39;, float_format&#x3D;None, columns&#x3D;None, header&#x3D;True, index&#x3D;True, index_label&#x3D;None, mode&#x3D;&#39;w&#39;, encoding&#x3D;None, compression&#x3D;None, quoting&#x3D;None, quotechar&#x3D;&#39;&quot;&#39;, line_terminator&#x3D;&#39;\\n&#39;, chunksize&#x3D;None, tupleize_cols&#x3D;None, date_format&#x3D;None, doublequote&#x3D;True, escapechar&#x3D;None, decimal&#x3D;&#39;.&#39;)参数： path_or_buf : 文件路径，如果没有指定则将会直接返回字符串的 json sep : 输出文件的字段分隔符，默认为 “,” na_rep : 用于替换空数据的字符串，默认为’’ float_format : 设置浮点数的格式（几位小数点） columns : 要写的列 header : 是否保存列名，默认为 True ，保存 index : 是否保存索引，默认为 True ，保存 index_label : 索引的列标签名 mode : w a 1df.to_csv(&#39;.&#x2F;oneTouch&#x2F;dict.txt&#39;, sep &#x3D; &#39; &#39;, columns &#x3D; [&#39;a&#39;,&#39;pos&#39;],index&#x3D;False, header &#x3D; False, encoding &#x3D; &#39;utf-8_sig&#39; ) df.to_csv()出现中文乱码的解决办法:只需在后面加上 encoding=’utf-8_sig’ 2. excel文件读写2.1 读入excel文件12345678910111213141516# 方法一：默认读取第一个表单df=pd.read_excel('lemon.xlsx')# 这个会直接默认读取到这个Excel的第一个表单data=df.head()# 默认读取前5行的数据# 方法二：通过指定表单名的方式来读取df=pd.read_excel('lemon.xlsx',sheet_name='student') # 可以通过sheet_name来指定读取的表单data=df.head() # 默认读取前5行的数据# 方法三：通过表单索引来指定要访问的表单，0表示第一个表单# 也可以采用表单名和索引的双重方式来定位表单# 也可以同时定位多个表单，方式都罗列如下所示df=pd.read_excel('lemon.xlsx',sheet_name=['python','student']) # 可以通过表单名同时指定多个# df=pd.read_excel('lemon.xlsx',sheet_name=0) # 可以通过表单索引来指定读取的表单# df=pd.read_excel('lemon.xlsx',sheet_name=['python',1]) # 可以混合的方式来指定# df=pd.read_excel('lemon.xlsx',sheet_name=[1,2]) # 可以通过索引 同时指定多个data=df.values # 获取所有的数据，注意这里不能用head()方法哦~ 2.2 写入excel文件 https://www.cnblogs.com/sxinfo/p/11723338.html函数解析：1234567891011121314151617181920DataFrame.to_excel(excel_writer, sheet_name&#x3D;&#39;Sheet1&#39;, na_rep&#x3D;&#39;&#39;, float_format&#x3D;None, columns&#x3D;None, header&#x3D;True, index&#x3D;True, index_label&#x3D;None, startrow&#x3D;0, startcol&#x3D;0, engine&#x3D;None, merge_cells&#x3D;True, encoding&#x3D;None, inf_rep&#x3D;&#39;inf&#39;, verbose&#x3D;True, freeze_panes&#x3D;None) excel_writer : 字符串或ExcelWriter 对象，文件路径或现有的ExcelWritersheet_name :字符串,默认“Sheet1”，将包含DataFrame的表的名称。na_rep : 字符串,默认‘ ’，缺失数据表示方式float_format : 字符串,默认None，格式化浮点数的字符串columns : 序列,可选，要编写的列header : 布尔或字符串列表，默认为Ture。写出列名。如果给定字符串列表，则假定它是列名称的别名。index :布尔,默认的Ture，写行名（索引）index_label : 字符串或序列，默认为None。如果需要，可以使用索引列的列标签。如果没有给出，标题和索引为true，则使用索引名称。如果数据文件使用多索引，则需使用序列。startrow :左上角的单元格行来转储数据框startcol :左上角的单元格列转储数据帧engine : 字符串,默认没有使用写引擎 - 您也可以通过选项io.excel.xlsx.writer，io.excel.xls.writer和io.excel.xlsm.writer进行设置。merge_cells : 布尔,默认为Ture编码生成的excel文件。 只有xlwt需要，其他编写者本地支持unicode。inf_rep : 字符串,默认“正”无穷大的表示(在Excel中不存在无穷大的本地表示)freeze_panes : 整数的元组(长度2)，默认为None。指定要冻结的基于1的最底部行和最右边的列 直接写入：1df.to_excel(‘grade.xlsx’) 在一个excel文件里面写入多个sheet 需要定义writer，否则每次写入会覆盖之前的文件。(写入文件时，每个writer都会覆盖原文件，如果需要在原文件追加内容，需要用xlutils包做copy操作)12345writer &#x3D; pd.ExcelWriter(filepath)model_df.to_excel(excel_writer&#x3D;writer,sheet_name&#x3D;&#39;建模作业&#39;)sqoop_df.to_excel(excel_writer&#x3D;writer, sheet_name&#x3D;&#39;推数作业&#39;)writer.save()writer.close() 向一个sheet写入多行无规则的数据1234567891011121314151617def write_excel(): f &#x3D; openpyxl.Workbook() sheet1 &#x3D; f.create_sheet(&#39;核心&#39;,index&#x3D;0) #写第一行 row0 &#x3D; [&quot;代码&quot;,&quot;名称&quot;,&quot;价格&quot;,&quot;数量&quot;] sheet1.append(row0) list1 &#x3D; [&quot;【市场概况】：&quot;] sheet1.append(list1) list2 &#x3D; [&quot;AA：&quot;, a ,&quot;BB：&quot;, b] sheet1.append(list2) f.save(&#39;test.xlsx&#39;)write_excel()","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"pandas","slug":"python/pandas","permalink":"https://tlylft.github.io/categories/python/pandas/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"pandas","slug":"pandas","permalink":"https://tlylft.github.io/tags/pandas/"}]},{"title":"pandas笔记目录","slug":"python/pandas/pandas-index","date":"2019-11-10T12:27:55.000Z","updated":"2021-06-11T04:17:23.976Z","comments":true,"path":"python/pandas/pandas-index/","link":"","permalink":"https://tlylft.github.io/python/pandas/pandas-index/","excerpt":"","text":"1. 数据读入和导出https://tlylft.github.io/2019/11/10/python/pandas/pandas-file-operation/ 2. 索引的设置和更改3. 数据的增删改查https://tlylft.github.io/2019/11/09/python/pandas/pandas-data-operation/","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"pandas","slug":"python/pandas","permalink":"https://tlylft.github.io/categories/python/pandas/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"pandas","slug":"pandas","permalink":"https://tlylft.github.io/tags/pandas/"}]},{"title":"dataframe的增删改查","slug":"python/pandas/pandas-data-operation","date":"2019-11-09T12:27:55.000Z","updated":"2023-07-19T16:18:56.865Z","comments":true,"path":"python/pandas/pandas-data-operation/","link":"","permalink":"https://tlylft.github.io/python/pandas/pandas-data-operation/","excerpt":"","text":"1. 创建dataframe1234567df &#x3D; pd.DataFrame(&#123;&quot;a&quot;:[1,2,3],&quot;b&quot;:[4,5,6]&#125;, index&#x3D;[101,102,103])df.desc()# 修改类型df[&#39;s_date&#39;] &#x3D; df[&#39;s_date&#39;].astype(&#39;datetime64&#39;)#重命名dataframe.rename(columns &#x3D; &#123;&quot;old1&quot;: &quot;new1&quot;, &quot;old2&quot;:&quot;new2&quot;&#125;, inplace&#x3D;True) 2. 数据增加2.1. 增加一列123456789# add with default value df[&#39;e&#39;] &#x3D; &#39;abc&#39;df.loc[&#39;e&#39;] &#x3D; &#39;abc&#39;# 组合两列文本df[&#39;new_col&#39;] &#x3D; df[&#39;text1&#39;] + df[&#39;text2&#39;]df[&#39;new_col&#39;] &#x3D; df[&#39;year&#39;].astype(str) + df[&#39;text2&#39;]# applydf[&#39;daygas_final&#39;] &#x3D; df[&#39;daygas&#39;].apply(lambda x: np.nan if (x &gt; 30000 or x &lt; 0) else x)df.loc[:, &#39;daygas_final&#39;] &#x3D; df[&#39;daygas&#39;].apply(lambda x: np.nan if (x &gt; 30000 or x &lt; 0) else x) 分组组内不同列用不同函数123456group &#x3D; df.groupby([&#39;gender&#39;])df1 &#x3D; group.agg(&#123;&#39;math&#39;:np.mean, &#39;chinese&#39;:np.std&#125;).reset_index()print(df1)gender math chinese man 115 12.727922woman 125 12.727922 2.2. 增加一行或多行12345678910111213141516# l. locdf.loc[len(df)] &#x3D; [col1,col2]# 2. append # 采用append函数，进行叠加，可以避免上面的相同index造成的替换问题。# 采用 append 的方法速度上比较快，而且可以避免index的错误。import pandas as pdfrom numpy.random import randintdf &#x3D; pd.DataFrame(columns&#x3D;(&#39;lib&#39;, &#39;qty1&#39;, &#39;qty2&#39;))for i in range(5): s &#x3D; pd.Series(&#123;&#39;lib&#39;:randint(-1,1), &#39;qty1&#39;:randint(-1,1), &#39;qty2&#39;:randint(-1,1)&#125;) # 这里 Series 必须是 dict-like 类型 df &#x3D; df.append(s, ignore_index&#x3D;True) # 这里必须选择ignore_index&#x3D;True 或者给 Series 一个index值 #也可以直接填写字典格式进去 df &#x3D; df.append(&#123;col1:value1, col2:value2&#125;, ignore_index&#x3D;True) 3. 数据删除3.1. 删除列12colsToDrop &#x3D; [&#39;a&#39;]df.drop(colsToDrop, axis&#x3D;1) 3.2. 删除一行drop 只能使用名称索引删除，drop返回一个新对象，不对原对象进行修改,如果需要修改原对象，设置inplace参数或者重新赋值123# 按索引删除 df.drop(102) # 不对原对象进行修改df.drop(102, inplace&#x3D;True) #对原对象进行修改 3.3. 删除摸个条件下的数据4. 数据更改123456# 按索引修改df.loc[101] &#x3D; 666# 按下标修改df.iloc[2:4] &#x3D; [33,44]# 按逻辑索引修改符合条件的值df.loc[(df&gt;10)&amp;(df&lt;100&gt;)] &#x3D; 0 5. 数据查询5.1. 按列查询假设df有a, b, c ,d 四列数据1234567891011121314# 选取一列df[&#39;a&#39;]# 选取多列## 通过名字选取df1 &#x3D; df[[&#39;a&#39;,&#39;c&#39;]] # df[[&#39;a&#39;,&#39;b&#39;]] produces a copy## 通过位置选取a,b两列，从0计数df1 &#x3D; df.iloc[:,0:2]df1 &#x3D; df.iloc[0,0:2].copy() # To avoid the case where changing df1 also changes df## 通过位置选取b,c,d 三列df1 &#x3D; df.iloc[:,1:4]df1 &#x3D; df.loc[:, &#39;b&#39;:&#39;d&#39;]df1 &#x3D; df[[&#39;b&#39;, &#39;c&#39;, &#39;d&#39;]] 5.2. 查询行数据5.2.1. 按位置查询12df_rows &#x3D; 1df.loc[df_rows] 5.2.2. 条件查询 使用逻辑运算符号&lt;、&gt;等进行筛选123# 进行逻辑判断# 用true false进行标记，逻辑判断的结果可以作为筛选的依据data[data[&#39;p_change&#39;] &gt; 2] 使用|、&amp;完成复合的逻辑12# 完成一个符合逻辑判断， p_change &gt; 2, open &gt; 15data[(data[&#39;p_change&#39;] &gt; 2) &amp; (data[&#39;open&#39;] &gt; 15)] isin()123# 可以指定值进行一个判断，从而进行筛选操作data[data[&#39;turnover&#39;].isin([4.19])]data.head(10) 自定义运算函数123# 进行apply函数运算data[[&#39;open&#39;, &#39;close&#39;]].apply(lambda x: x.max() - x.min(), axis&#x3D;0)data[[&#39;open&#39;, &#39;close&#39;]].apply(lambda x: x.max() - x.min(), axis&#x3D;1) nan判断查询isnan(), notna()12data[np.isnan(data[&#39;p_change&#39;])]data[dadta[&#39;p_change].notna()] 5.3. 查询某个数据1df.loc[行号, 列名] 6. 分组查询https://www.jb51.net/article/188649.htm1234567891011# 分组最大值# 方式1df_groupby &#x3D; df.groupby(by&#x3D;&#39;year&#39;, as_index&#x3D;False).max()df_groupby &#x3D; df.groupby(by&#x3D;&#39;year&#39;, as_index&#x3D;False).sum()df_groupby &#x3D; df.groupby(by&#x3D;&#39;year&#39;, as_index&#x3D;False).cumsum() # 累计求和df_groupby &#x3D; df.groupby(by&#x3D;[&#39;year&#39;, &#39;name&#39;], as_index&#x3D;False).max()# 方式2 &#123;‘行名&#x2F;列名’：‘函数名’&#125;df_groupby &#x3D; df.groupby([&#39;Fruits&#39;]).agg(&#123;&quot;Numbers&quot;:&quot;sum&quot;&#125;)df_groupby &#x3D; df_groupby.reset_index()# 方式三： 一个字段多个聚合df &#x3D; df.groupby([&#39;partner&#39;, &#39;partner_txt&#39;, &#39;s_date&#39;])[&#39;daygas&#39;].agg([np.sum, np.count_nonzero]).reset_index() 数据补全 7. dataframe性质7.1. 判空1df.empty 无数据返回true 7.2. 转换numpy1np_list &#x3D; np.array(df) 转换为list1list &#x3D; np.array(df).tolist() 7.3. 转换dict/json123456789101112dict &#x3D; df.to_dict(orient&#x3D;&#39;records&#39;)&gt;&gt; [&#123;&quot;工号&quot;:&quot;A0001&quot;,&quot;姓名&quot;:&quot;张三&quot;&#125;,&#123;&quot;工号&quot;:&quot;A0002&quot;,&quot;姓名&quot;:&quot;李四&quot;&#125;]dict &#x3D; df.to_dict(orient&#x3D;&#39;index&#39;)&gt;&gt; &#123;&quot;row 1&quot;:&#123;&quot;工号&quot;:&quot;A0001&quot;,&quot;姓名&quot;:&quot;张三&quot;&#125;,&quot;row 2&quot;:&#123;&quot;工号&quot;:&quot;A0002&quot;,&quot;姓名&quot;:&quot;李四&quot;&#125;&#125;dict &#x3D; df.to_dict(orient&#x3D;&#39;columns&#39;)&gt;&gt; &#123;&quot;工号&quot;:&#123;&quot;row 1&quot;:&quot;A0001&quot;,&quot;row 2&quot;:&quot;A0002&quot;&#125;,&quot;姓名&quot;:&#123;&quot;row 1&quot;:&quot;张三&quot;,&quot;row 2&quot;:&quot;李四&quot;&#125;&#125;dict &#x3D; df.to_dict(orient&#x3D;&#39;split&#39;)&gt;&gt; &#123;&quot;columns&quot;:[&quot;工号&quot;,&quot;姓名&quot;],&quot;index&quot;:[&quot;row 1&quot;,&quot;row 2&quot;],&quot;data&quot;:[[&quot;A0001&quot;,&quot;张三&quot;],[&quot;A0002&quot;,&quot;李四&quot;]]&#125;dict &#x3D; df.to_dict(orient&#x3D;&#39;records&#39;)&gt;&gt; [&#123;&quot;工号&quot;:&quot;A0001&quot;,&quot;姓名&quot;:&quot;张三&quot;&#125;,&#123;&quot;工号&quot;:&quot;A0002&quot;,&quot;姓名&quot;:&quot;李四&quot;&#125;]# 转成json是一样的","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"pandas","slug":"python/pandas","permalink":"https://tlylft.github.io/categories/python/pandas/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"pandas","slug":"pandas","permalink":"https://tlylft.github.io/tags/pandas/"}]},{"title":"numpy","slug":"python/python/python_numpy","date":"2019-09-20T02:50:43.000Z","updated":"2023-01-20T13:41:01.936Z","comments":true,"path":"python/python/python_numpy/","link":"","permalink":"https://tlylft.github.io/python/python/python_numpy/","excerpt":"","text":"notebook笔记生成1import numpy as np 1. numpy introarray 数组结构是numpy的核心数组创建元素的类型可以不同，但numpy中的数组元素类型必须是相同的，如果创建时不同，它就会自动统一为“字符串”&gt;“浮点型”&gt; “整型” 1. 1 可表示向量和矩阵12345678# array 数组结构是numpy的核心， 可表示向量和矩阵vector = np.array([5,10,15,20])vector1 = np.array([5,'a',15,20])matrix = np.array([[5,10,15],[20,25,30],[35,40,45]])print(\"vector style：\\n\",vector.dtype, \"\\n\",vector)print(\"vector1 style：\\n\",vector1.dtype, \"\\n\",vector1)print(\"matrix style：\\n\", matrix) vector style： int32 [ 5 10 15 20] vector1 style： &lt;U11 [&#39;5&#39; &#39;a&#39; &#39;15&#39; &#39;20&#39;] matrix style： [[ 5 10 15] [20 25 30] [35 40 45]] 1.2 初始化数组 zeros ones eye diag arange linspace123456789101112131415161718print(np.array([5,10,15,20])) print( np.arange(15)) print( \"初始化零矩阵数组：\\n\", np.zeros(15)) print( \"初始化零矩阵矩阵：\\n\", np.zeros((3,4)))print( \"初始化1矩阵数组：\\n\", np.ones(15)) print( \"初始化1矩阵矩阵：\\n\", np.ones((3,4)))print( \"初始化1矩阵数组（规定格式为int）：\\n\", np.ones((3,4), dtype=np.int32))print( \"初始化对角线矩阵np.eye((4)：\\n\", np.eye((4)))print( \"初始化对角线矩阵np.diag(2,3,4,6)：\\n\", np.diag((2,3,4,6)))print( \"初始化序列数组：\\n\",np.arange(15)) print( \"初始化等差序列数组（开始，结尾，间隔）不包含终值：\\n\",np.arange(1, 10, 2)) print( \"初始化等差序列数组（开始，结尾，个数）默认包含终值：\\n\", np.linspace(1, 10, 5))print( \"初始化等差序列数组（开始，结尾，个数）默认不包含终值：\\n\", np.linspace(1, 10, 5, endpoint = False))print( \"初始化等比序列数组（开始（10的1次方），结尾（10的5次方），个数）默认包含终值：\\n\", np.logspace(1, 5, 5))print( \"初始化序列矩阵：\\n\",np.arange(15).reshape(3,5)) print( \"初始化序列矩阵（开始，结尾，间隔）：\\n\",np.arange(14,30,2).reshape(2,4)) print( \"初始化随机数组：\\n\",np.random.random((3))) print( \"初始化随机矩阵：\\n\",np.random.random((3,5))) [ 5 10 15 20] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] 初始化零矩阵数组： [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 初始化零矩阵矩阵： [[0. 0. 0. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]] 初始化1矩阵数组： [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 初始化1矩阵矩阵： [[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] 初始化1矩阵数组（规定格式为int）： [[1 1 1 1] [1 1 1 1] [1 1 1 1]] 初始化对角线矩阵np.eye((4)： [[1. 0. 0. 0.] [0. 1. 0. 0.] [0. 0. 1. 0.] [0. 0. 0. 1.]] 初始化对角线矩阵np.diag(2,3,4,6)： [[2 0 0 0] [0 3 0 0] [0 0 4 0] [0 0 0 6]] 初始化序列数组： [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] 初始化等差序列数组（开始，结尾，间隔）不包含终值： [1 3 5 7 9] 初始化等差序列数组（开始，结尾，个数）默认包含终值： [ 1. 3.25 5.5 7.75 10. ] 初始化等差序列数组（开始，结尾，个数）默认不包含终值： [1. 2.8 4.6 6.4 8.2] 初始化等比序列数组（开始（10的1次方），结尾（10的5次方），个数）默认包含终值： [1.e+01 1.e+02 1.e+03 1.e+04 1.e+05] 初始化序列矩阵： [[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14]] 初始化序列矩阵（开始，结尾，间隔）： [[14 16 18 20] [22 24 26 28]] 初始化随机数组： [0.80601192 0.05946332 0.86242638] 初始化随机矩阵： [[0.91668918 0.60699718 0.33048596 0.57706866 0.81791635] [0.18732739 0.02276459 0.37137314 0.11513707 0.77960908] [0.62706401 0.12196409 0.69217366 0.2778243 0.12321069]] 1.3 生成随机数 random rand randn randintn借鉴了random模块，做了一些优化 123456789101112131415161718192021import randomprint(random.random()) # 随机生成0-1之间的一个数print(random.randint(2,4))#随机生成2,4(含)之间的一个数print(random.choice(['a','b','c']))print(\"****** numpy ramdom 0-1之间**********\") print(np.random.random()) # 随机生成0-1之间的一个数print(np.random.random(10)) # 随机生成0-1之间的一个长度为10 的数组print(np.random.random((2,3))) # 随机生成0-1之间的一个维度为3*4 的数组print(\"****** numpy rand 0-1之间**********\") print(np.random.rand(2,3,4))#随机生成0-1之间的一个维度为2*3*4 的数组print(np.random.rand(2,3))#随机生成0-1之间的一个维度为2*3 的数组print(\"****** numpy randn 正态分布**********\") print(np.random.randn(2,3,4))#随机生成满足正态分布的一个维度为2*3*4 的数组print(np.random.randn(2,3))#随机生成满足正态分布的一个维度为2*3 的数组print(\"****** numpy randintn 整数**********\") print(np.random.randint(2,5, size=(3,4)))#随机生成2-5之间的整数，维度为3*4 的数组print(np.random.choice(['a','b','c'],2, replace=False))print(np.random.choice(['a','b','c'],(2,3))) 0.044834346624626376 4 a ****** numpy ramdom 0-1之间********** 0.864350048272003 [0.65748403 0.33285943 0.18710013 0.09902238 0.18116909 0.81149327 0.97833833 0.31165887 0.62881737 0.91470069] [[0.07839733 0.2633746 0.82457737] [0.67352118 0.27438417 0.5792902 ]] ****** numpy rand 0-1之间********** [[[0.38377744 0.31448772 0.62029243 0.2962354 ] [0.11900535 0.40831462 0.44684615 0.96365478] [0.70716223 0.27679105 0.73314883 0.99528842]] [[0.54205298 0.5377321 0.25215674 0.74957155] [0.63997497 0.49793333 0.56001219 0.84472098] [0.19525733 0.2394554 0.24217443 0.27579085]]] [[0.86340602 0.14459479 0.84265716] [0.69997434 0.00479376 0.30847902]] ****** numpy randn 正态分布********** [[[-2.25748187 1.85943236 0.8404757 2.7647975 ] [ 0.85889078 -0.0589001 0.3945796 0.01385911] [ 0.91828937 0.33109734 0.70731845 -1.14395811]] [[ 0.74687225 -0.52241361 -1.18731666 -0.86005084] [ 0.11590988 -1.71853916 1.2170654 -1.51387923] [ 0.53244296 -0.27353471 2.17443133 -0.54941748]]] [[-0.28654672 -0.08486647 -2.18025425] [-0.34210686 2.8129446 -0.61966614]] ****** numpy randintn 整数********** [[3 2 3 2] [2 3 2 3] [3 4 3 4]] [&#39;a&#39; &#39;c&#39;] [[&#39;a&#39; &#39;c&#39; &#39;b&#39;] [&#39;c&#39; &#39;a&#39; &#39;b&#39;]] 1.4 查看/重塑数组形态 shape size ndim reshape ravel flatten123456# 可以查看数组形态print(\"vector shape：\",vector.shape)print(\"vector size：\",vector.size)print(\"matrix shape：\",matrix.shape)print(\"matrix size：\",matrix.size)print(\"matrix dim：\",matrix.ndim) vector shape： (4,) vector size： 4 matrix shape： (3, 3) matrix size： 9 matrix dim： 2 123456789101112131415# 重塑数组形态a = np.arange(15)# 还原为matrix## shape更改的是原对象# a.shape(3,5)## reshape是返回了一个新对象，原对象不做更改b = a.reshape(3,5)# 还原为vectorc = b.ravel()print(\"原矩阵：\", a)print(\"原矩阵reshape后：\\n\", b)print(\"ravel还原为vector：\", c)print('flatten按行展平：',b.flatten('C'))print('flatten按列展平：',b.flatten('F')) 原矩阵： [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] 原矩阵reshape后： [[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14]] ravel还原为vector： [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] flatten按行展平： [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14] flatten按列展平： [ 0 5 10 1 6 11 2 7 12 3 8 13 4 9 14] 1.5 数组中的每个数值都要是一样的数据类型12345678910# 数组中的每个数值都要是一样的数据类型num1 = np.array([1,2,3])print(\"[1,2,3] 数组类型为：\", num1.dtype)num2 = np.array([1,2,3.0])print(\"[1,2,3.0] 数组类型为：\",num2.dtype)# 数据类型的转换str_vector = np.array([\"1\",\"2\",\"3\"])print(\"['1','2','3'] 数组类型为：\", str_vector.dtype)float_vec = str_vector.astype(float)print(\"['1','2','3']转换后 数组类型为：\", float_vec.dtype) [1,2,3] 数组类型为： int32 [1,2,3.0] 数组类型为： float64 [&#39;1&#39;,&#39;2&#39;,&#39;3&#39;] 数组类型为： &lt;U1 [&#39;1&#39;,&#39;2&#39;,&#39;3&#39;]转换后 数组类型为： float64 无法识别非数字型的值， 将会用nan值替代填充 2. 文件读取数据用的并不多，通常会用pandas读取，返回值应该不是一个np数组（待验证），因为string类型可以被展示。 1# data = np.genfromtxt(\"filename,txt\", delimiter=\",\", dtype=str, skip_header=1) 3. 数据选取(根据位置)3.1 一维数组的切片通过传递位置索引 12345678# 通过切片选取vector = np.array([5,10,15,20])print(vector[3])print(vector[0:3])print(vector[3:])print(vector[-1])print(vector[::2]) # 每n个取一个print(vector[:]) 20 [ 5 10 15] [20] 20 [ 5 15] [ 5 10 15 20] 12345# 通过下标列表选取a = np.array(['a','b','c'])b = np.array([1,2])print(b)print(a[b]) [1 2] [&#39;b&#39; &#39;c&#39;] 传递一组位置索引12345678import numpy as npa = np.array(['a','b','c'])b = [0,2]print(a[b])&gt; output:['a' 'c']b = [0,2,2]print(a[b])&gt; output:['a' 'c' 'c'] 3.2 多维数组的切片123456789101112131415161718matrix = np.array([[5,10,15],[20,25,30],[35,40,45]])# 取一个值 索引的两种方式print(matrix[0][1])print(matrix[0,1])# 取某几列print(matrix[1:2,0:2])# 取某几行print(matrix[0:2,:])# 取某部分的矩阵print(matrix[1:,1:])print(matrix[matrix.argmax(axis=0),range(matrix.shape[1])])# 两个中括号的取值方式print(\"*************两个中括号的取值方式***************\")print(matrix[0][1])print(matrix[1][0:2])print(matrix[1:2][0:2]) # 这样是不支持的，我理解第一个中括号里只支持唯一的idx，不支持区间，否则后面的中括号不生效 10 10 [[20 25]] [[ 5 10 15] [20 25 30]] [[25 30] [40 45]] [35 40 45] *************两个中括号的取值方式*************** 10 [20 25] [[20 25 30]] 1type(matrix) numpy.ndarray 4. 数据运算4.1. 数据比较（逻辑运算）1234vector = np.array([5,10,15,20])print(vector == 10)# 数据筛选（根据值）print(vector[vector==10]) [False True False False] [10] 123456matrix = np.array([[5,10,15],[20,25,30],[35,40,45]])print(matrix == 25)# 数据筛选（根据值）print(matrix[matrix==25])print(matrix[:,1] ==25)print(matrix[matrix[:,1] ==25,:]) [[False False False] [False True False] [False False False]] [25] [False True False] [[20 25 30]] 1234# 与或运算vector = np.array([5,10,15,20])print((vector == 10) &amp; (vector ==5))print((vector == 10) | (vector ==5)) [False False False False] [ True True False False] 4.2. 聚合运算（最小，最大，求和，平均）1234567vector = np.array([5,10,15,20])print(\"最小值为：\",vector.min())print(\"最大值为：\",vector.max())print(\"求和：\",vector.sum())print(\"求和忽略nan值：\",vector.nansum()) # nan值取值为0print(\"平均值：\", vector.mean())print(\"平均值忽略nan值：\", vector.nanmean()) 最小值为： 5 最大值为： 20 求和： 50 平均值： 12.5 1234567matrix = np.array([[5,10,15],[20,25,30],[35,40,45]])print(\"矩阵最小值：\", matrix.min())print(\"矩阵按维度最小值（行）：\", matrix.min(axis =1))print(\"矩阵按维度最小值（列）：\", matrix.min(axis =0))print(\"矩阵求和：\", matrix.sum())print(\"矩阵按维度求和（行）：\", matrix.sum(axis =1))print(\"矩阵按维度求和（列）：\", matrix.sum(axis =0)) 矩阵最小值： 5 矩阵按维度最小值（行）： [ 5 20 35] 矩阵按维度最小值（列）： [ 5 10 15] 矩阵求和： 225 矩阵按维度求和（行）： [ 30 75 120] 矩阵按维度求和（列）： [60 75 90] 4.3 基础运算1234567891011vector = np.array([5,10,15,20])print(\"+1：\",vector+1)print(\"-1：\",vector-1)print(\"*2：\",vector*2)print(\"/2：\",vector/2)print(\"平方：\",vector**2)print(\"==5：\",vector==5)print(\"&gt;5：\",vector&gt;5)print(\"np.exp(B)：\\n\",np.exp(vector))print(\"开根号 np.sqrt()\\n：\",np.sqrt(vector))print(\"向下取整 np.floor()\\n：\",np.floor(np.sqrt(vector))) +1： [ 6 11 16 21] -1： [ 4 9 14 19] *2： [10 20 30 40] /2： [ 2.5 5. 7.5 10. ] 平方： [ 25 100 225 400] ==5： [ True False False False] &gt;5： [False True True True] np.exp(B)： [1.48413159e+02 2.20264658e+04 3.26901737e+06 4.85165195e+08] 开根号 np.sqrt() ： [2.23606798 3.16227766 3.87298335 4.47213595] 向下取整 np.floor() ： [2. 3. 3. 4.] 12345678910111213141516A = np.array([[1,1],[0,1]])B = np.array([[2,0],[3,4]])C = np.array([1,2])print(\"=======单独运算======\")print(\"+1：\\n\",A+1)print(\"-1：\\n\",A-1)print(\"*2：\\n\",A*2)print(\"/2：\\n\",A/2)print(\"平方：\",A**2)print(\"==1：\",A==1)print(\"&gt;0：\",A&gt;0)print(\"A+C:\\n\",A+C)print(\"np.exp(B)：\\n\",np.exp(B))print(\"np.sqrt(B)\\n：\",np.sqrt(B))print(\"每行最大值的索引 argmax:\\n\", B.argmax(axis=1))print(\"每列最大值的索引 argmax:\\n\", B.argmax(axis=0)) =======单独运算====== +1： [[2 2] [1 2]] -1： [[ 0 0] [-1 0]] *2： [[2 2] [0 2]] /2： [[0.5 0.5] [0. 0.5]] 平方： [[1 1] [0 1]] ==1： [[ True True] [False True]] &gt;0： [[ True True] [False True]] A+C: [[2 3] [1 3]] np.exp(B)： [[ 7.3890561 1. ] [20.08553692 54.59815003]] np.sqrt(B) ： [[1.41421356 0. ] [1.73205081 2. ]] 每行最大值的索引 argmax: [0 1] 每列最大值的索引 argmax: [1 1] 4.4 组合运算123456789101112131415161718192021A = np.array([[1,1],[0,1]])B = np.array([[2,0],[3,4]])C = [[1,1]] print(\"=======组合运算======\")print(\"A-C:\", A-C)print(\"对应位置相乘（内积）：A*B\\n\" , A*B)print(\"对应位置相乘（内积）：A multiply B\\n\" , np.multiply(A,B))print(\"点乘：A dot B\\n\" , A.dot(B))print(\"点乘：A dot B\\n\" , np.dot(A,B))print(\"=======拼接运算======\")print(\"上下拼接（用于特征拼接）：\\n\" , np.vstack((A,B)))print(np.concatenate((A,B),axis=0))print(\"左右拼接：\\n\" , np.hstack((A,B)))print(np.concatenate((A,B),axis=1))print(\"=======切分运算======\")a = np.floor(10*np.random.random((2,12)))print(\"切分矩阵：\\n\",a)print(\"按列切分(平均切分)：\\n\" , np.hsplit(a,3))print(\"按列切分(指定列位置切分)：\\n\" , np.hsplit(a,(3,4)))print(\"按行切分(平均切分)：\\n\" , np.vsplit(a,1)) =======组合运算====== A-C: [[ 0 0] [-1 0]] 对应位置相乘（内积）：A*B [[2 0] [0 4]] 对应位置相乘（内积）：A multiply B [[2 0] [0 4]] 点乘：A dot B [[5 4] [3 4]] 点乘：A dot B [[5 4] [3 4]] =======拼接运算====== 上下拼接（用于特征拼接）： [[1 1] [0 1] [2 0] [3 4]] [[1 1] [0 1] [2 0] [3 4]] 左右拼接： [[1 1 2 0] [0 1 3 4]] [[1 1 2 0] [0 1 3 4]] =======切分运算====== 切分矩阵： [[9. 6. 1. 8. 4. 7. 6. 7. 9. 0. 5. 1.] [6. 7. 7. 7. 6. 3. 5. 1. 1. 0. 4. 2.]] 按列切分(平均切分)： [array([[9., 6., 1., 8.], [6., 7., 7., 7.]]), array([[4., 7., 6., 7.], [6., 3., 5., 1.]]), array([[9., 0., 5., 1.], [1., 0., 4., 2.]])] 按列切分(指定列位置切分)： [array([[9., 6., 1.], [6., 7., 7.]]), array([[8.], [7.]]), array([[4., 7., 6., 7., 9., 0., 5., 1.], [6., 3., 5., 1., 1., 0., 4., 2.]])] 按行切分(平均切分)： [array([[9., 6., 1., 8., 4., 7., 6., 7., 9., 0., 5., 1.], [6., 7., 7., 7., 6., 3., 5., 1., 1., 0., 4., 2.]])] 5. 复制12345678910111213141516171819202122a = np.array([[1,1],[0,1]])# 指向同一个对象b = aprint(\"b == a :\", b is a)print(\"a 的 id:\", id(a))print(\"b 的 id:\", id(b))b[0,0] = 2print(a)# 浅复制，创建一个新数组赋值，指向不同对象，但是数据是共用的# 不推荐使用c= a.view()print(\"d == a :\", c is a)print(\"c 的 id:\", id(c))c[0,0] = 3print(a)# complete赋值, 完全拷贝，不指向任何共用空间的初始化d = a.copy()print(\"d == a :\", d is a)print(\"d 的 id:\", id(d))d[0,0] = 4print(a) b == a : True a 的 id: 1728210115360 b 的 id: 1728210115360 [[2 1] [0 1]] d == a : False c 的 id: 1728209969920 [[3 1] [0 1]] d == a : False d 的 id: 1727820260496 [[3 1] [0 1]] 6. 填充https://www.icode9.com/content-1-1202504.html可以将数组array按指定的方法填充成指定的形状。1numpy.pad(array,pad_width,mode,**kwargs)array：表示N维数组pad_width：每个轴边缘填充的数值。mode:表示填充方法。constant：常数填充，constant_values=(x,y)表示前面用x填充，后面用y填充，无constant_values参数时默认填充0 一维数组填充12345678910import numpy as nparray_one = np.array([1,2,3,4,5])#（1,3）:在该数组前面填充1位，后面填充3位; 默认填充0extend_one1 = np.pad(array_one, (1,3))print(extend_one1) &gt;&gt; [0,1,2,3,4,5,0,0,0]# constant_values=(9,8) 表示前面填充1位9，后面填充3位8extend_one2 = np.pad(array_one, (1,3),'constant', constant_values=(9,8))print(extend_one2)&gt;&gt; [9,1,2,3,4,5,8,8,8]二维数组填充123456789101112131415161718192021import numpy as nparray_one = np.array([[1,1,1],[2,2,2],[3,3,3]])\"\"\"((1,1),(2,2))表示在二维数组array第一维（此处便是行）前面填充1行，最后面填充1行； 在二维数组array第二维（此处便是列）前面填充2列，最后面填充2列constant_values=(0,4) 表示前面填充0，后面填充4\"\"\"extend_two = np.pad(array_two,((1,1),(2,2)),'constant', constant_values=(0,4)) print(array_two)print(extend_two)&gt;&gt; array_two[[1,1,1],[2,2,2],[3,3,3]]&gt;&gt; extend_two[[0,0,0,0,0,4,4],[0,0,1,1,1,4,4],[0,0,2,2,2,4,4],[0,0,3,3,3,4,4],[0,0,4,4,4,4,4]] 应用查找连续的012345678910111213141516171819import numpy as npdef zero_runs(a): # Create an array that is 1 where a is 0, and pad each end with an extra 0. iszero &#x3D; np.concatenate(([0], np.equal(a, 0).view(np.int8), [0])) absdiff &#x3D; np.abs(np.diff(iszero)) # Runs start and end where absdiff is 1. ranges &#x3D; np.where(absdiff &#x3D;&#x3D; 1)[0].reshape(-1, 2) return rangesIn [236]: a &#x3D; [1, 2, 3, 0, 0, 0, 0, 0, 0, 4, 5, 6, 0, 0, 0, 0, 9, 8, 7, 0, 10, 11]In [237]: runs &#x3D; zero_runs(a)In [238]: runsOut[238]: array([[ 3, 9], [12, 16], [19, 20]])","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"numpy","slug":"numpy","permalink":"https://tlylft.github.io/tags/numpy/"}]},{"title":"Django 建表语句参数","slug":"python/Django/Django-mysql-args","date":"2019-09-10T14:27:55.000Z","updated":"2021-06-11T03:20:43.812Z","comments":true,"path":"python/Django/Django-mysql-args/","link":"","permalink":"https://tlylft.github.io/python/Django/Django-mysql-args/","excerpt":"","text":"https://blog.csdn.net/weixin_43430036/article/details/84174704https://www.cnblogs.com/Blaxon/p/4415246.html 1. 格式字段名 = model.type(attribute)interger 不需要设置长度12user_id &#x3D; models.IntegerField(primary_key &#x3D; True)user_name &#x3D; models.CharField(max_length&#x3D;200) 2. 设置主键1user_id &#x3D; models.IntegerField(primary_key &#x3D; True) primary_key = True 设置主键，如果没有设置django创建表时会自动加上:12id &#x3D; meta.AutoField(&#39;ID&#39;, primary_key&#x3D;True)primary_key&#x3D;True implies blank&#x3D;False, null&#x3D;False and unique&#x3D;True. Only one primary key is allowed on an object. 3. 设置缺省值1default &#x3D; &#39;&#39; 4. 加当前日期时间12create_time &#x3D; models.DateTimeField(auto_now_add&#x3D;True)update_time &#x3D; models.DateTimeField(auto_now&#x3D;True) modelField，DateTimeField和DateField和TimeField存储的内容分别对应着datetime(),date(),time()三个对象。 auto_now=True，字段保存时会自动保存当前时间，但要注意每次对其实例执行save()的时候都会将当前时间保存，也就是不能再手动给它存非当前时间的值。 auto_now_add=True，字段在实例第一次保存的时候会保存当前时间，不管你在这里是否对其赋值。但是之后的save()是可以手动赋值的。也就是新实例化一个model，想手动存其他时间，就需要对该实例save()之后赋值然后再save()。","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Django","slug":"python/Django","permalink":"https://tlylft.github.io/categories/python/Django/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Django","slug":"Django","permalink":"https://tlylft.github.io/tags/Django/"}]},{"title":"Django 模型：pycharm中django框架连接mysql数据库","slug":"python/Django/Django-mysql","date":"2019-09-10T14:27:55.000Z","updated":"2021-06-11T03:23:07.052Z","comments":true,"path":"python/Django/Django-mysql/","link":"","permalink":"https://tlylft.github.io/python/Django/Django-mysql/","excerpt":"","text":"reference :https://blog.csdn.net/lw_wishes/article/details/82633130https://www.runoob.com/django/django-model.html 1. 下载安装pymysql模块12pip install pymysqlsudo pip install mysqlclient 2. 导入库在项目的init文件中编写下列代码： 123# 导入pymysql模块import pymysqlpymysql.install_as_MySQLdb() 这样整个项目都能使用pymysql，就不用再每个文件都导入pymyqsl 3. 数据库配置我们在项目的 settings.py 文件中找到 DATABASES 配置项，将其信息修改为：HelloWorld/HelloWorld/settings.py:12345678910DATABASES &#x3D; &#123; &#39;default&#39;: &#123; &#39;ENGINE&#39;: &#39;django.db.backends.mysql&#39;, # 或者使用 mysql.connector.django &#39;NAME&#39;: &#39;test&#39;, &#39;USER&#39;: &#39;test&#39;, &#39;PASSWORD&#39;: &#39;test123&#39;, &#39;HOST&#39;:&#39;localhost&#39;, &#39;PORT&#39;:&#39;3306&#39;, &#125;&#125;这里添加了中文注释，所以你需要在 HelloWorld/settings.py 文件头部添加 # -- coding: UTF-8 --。 上面包含数据库名称和用户的信息，它们与 MySQL 中对应数据库和用户的设置相同。Django 根据这一设置，与 MySQL 中相应的数据库和用户连接起来。 4. 定义模型创建 APP Django规定，如果要使用模型，必须要创建一个app。我们使用以下命令创建一个 TestModel 的 app:1django-admin startapp TestModel目录结构如下： HelloWorld|— TestModel| |— init.py| |— admin.py| |— models.py| |— tests.py| `— views.py 我们修改 TestModel/models.py 文件，代码如下： HelloWorld/TestModel/models.py: 文件代码：123456789101112131415161718# models.pyfrom django.db import models class Test(models.Model): name &#x3D; models.CharField(max_length&#x3D;20)以上的类名代表了数据库表名，且继承了models.Model，类里面的字段代表数据表中的字段(name)，数据类型则由CharField（相当于varchar）、DateField（相当于datetime）， max_length 参数限定长度。接下来在settings.py中找到INSTALLED_APPS这一项，如下：INSTALLED_APPS &#x3D; ( &#39;django.contrib.admin&#39;, &#39;django.contrib.auth&#39;, &#39;django.contrib.contenttypes&#39;, &#39;django.contrib.sessions&#39;, &#39;django.contrib.messages&#39;, &#39;django.contrib.staticfiles&#39;, &#39;TestModel&#39;, # 添加此项)在命令行中运行：1234$ python manage.py migrate # 创建表结构$ python manage.py makemigrations TestModel # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate TestModel # 创建表结构 看到几行 “Creating table…” 的字样，你的数据表就创建好了。 Creating tables ………Creating table TestModel_test #我们自定义的表……表名组成结构为：应用名_类名（如：TestModel_test）。 注意：尽管我们没有在models给表设置主键，但是Django会自动添加一个id作为主键。 未完待续 https://www.runoob.com/django/django-model.html 5. 表结构重建https://blog.csdn.net/hang916/article/details/80197871 先到数据库把表删掉：drop table 注释django中对应的Model 执行以下命令：12python manage.py makemigrations python manage.py migrate --fake去掉注释重新迁移12python manage.py makemigrations python manage.py migrate 6. 删除APPhttps://blog.csdn.net/huochen1994/article/details/52680067 6.1. 删除 models.py无论是删除一个单独的model还是删除整个App,都需要首先删除models.py文件中的模型。 确认没有其他文件引用models.py中的类。迁移或者删除你的数据库，Django提供了简便的方法方便用户删除某App下的所有数据(Django 1.7)。 ./manage.py migrate your_app_name zero1删除models.py中的数据模型。 6.1.1. 删除App再次确认其他App中没有引用此App的文件删除整个App文件夹在settings.py的Installed Apps中移除该app。在urls.py中移除该App相关内容。","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"Django","slug":"python/Django","permalink":"https://tlylft.github.io/categories/python/Django/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Django","slug":"Django","permalink":"https://tlylft.github.io/tags/Django/"}]},{"title":"python 类","slug":"python/python/python_class","date":"2019-09-02T14:27:55.000Z","updated":"2021-08-19T11:08:41.348Z","comments":true,"path":"python/python/python_class/","link":"","permalink":"https://tlylft.github.io/python/python/python_class/","excerpt":"","text":"1. 类特殊成员方法https://www.cnblogs.com/xiangsikai/p/7827021.html__init__ 构造方法，通过类创建对象时，自动触发执行__doc__ 打印类的描述信息12345678class Foo: &quot;&quot;&quot; 描述类信息，这是用于看片的神奇 &quot;&quot;&quot; def func(self): pass print(Foo.__doc__)#输出：类的描述信息__module__ 表示当前操作的对象在那个模块__class__ 表示当前操作的对象的类是什么12345from lib.aa import Cobj &#x3D; C()print(obj.__module__) # 输出 lib.aa，即：输出模块print(obj.__class__) # 输出 lib.aa.C，即：输出类 __call__:对象后面加括号，触发执行123456789101112#注：构造方法的执行是由创建对象触发的，即：对象 &#x3D; 类名() ；而对于 __call__ 方法的执行是由对象后加括号触发的，即：对象() 或者 类()()class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): print &#39;__call__&#39; obj &#x3D; Foo() # 执行 __init__obj() # 执行 __call__ 2. 类变量class JustCounter: __secretCount = 0 # 私有变量 publicCount = 0 # 公开变量 def count(self): self.__secretCount += 1 self.publicCount += 1 JustCounter.publicCount += 1 JustCounter.__secretCount += 1 print (self.__secretCount) print (self.publicCount ) def getsecretCount(): print(JustCounter.__secretCount) counter = JustCounter() counter.count() counter.count() &gt;&gt;&gt;1 &gt;&gt;&gt;1 &gt;&gt;&gt;2 &gt;&gt;&gt;2 counter1 = JustCounter() counter1.count() counter1.count() &gt;&gt;&gt;3 &gt;&gt;&gt;3 &gt;&gt;&gt;4 &gt;&gt;&gt;4 JustCounter.getsecretCount() counter1.publicCount &gt;&gt;&gt;4 &gt;&gt;&gt;4 在创建类的时候，JustCounter类本身为类创建了两个变量，__secretCount私有计数器和publicCount公共计数器， 可以为创建的实例服务。 在创建实例counter的时候，因为没有指定变量的值，所以从JustCounter类将默认值0，0直接赋值copy给了这个实例 在counter进行了两次count函数操作后， counter.secretCount = 2 counter.publicCount = 2 JustCounter.publicCount = 2 JustCounter.secretCount = 2 这时，类变量的值已经被更改为2 在创建实例counter1的时候，因为没有指定变量的值，所以从JustCounter类中已经被改变的默认值2，2直接赋值copy给了这个实例 在counter1进行了两次count函数操作后， counter1.secretCount = 2 counte1r.publicCount = 2 JustCounter.publicCount = 4 JustCounter.secretCount = 4 3. @classmethod 和 @staticmethod12345678910111213141516171819202122232425262728293031323334class test: class_name &#x3D; &quot;test&quot; def __init__(self, name): self.class_name &#x3D; name def my_print(self, value): print(value + &quot; &quot; +self.class_name) @staticmethod def my_static_print(val): print(val) @classmethod def my_class_print(cls, val): print(val +&quot; &quot;+ cls.class_name)if __name__ &#x3D;&#x3D; &quot;__main__&quot;: my_test &#x3D; test(&quot;xxx&quot;) test.my_static_print(&quot;static print&quot;) test.my_class_print(&quot;class print&quot;) my_test.my_static_print(&quot;static print&quot;) my_test.my_class_print(&quot;class print&quot;) my_test.my_print(&quot;my_print&quot;)output:static printclass print teststatic printclass print testmy_print xxx 成员方法： 不需要加注解 需要传入self变量表示实例信息 可以访问和实例相关的属性 类方法： 需要加入注解@classmethod 需要传入cls参数表示类信息 可以访问和类相关（不和实例相关)的属性 静态方法： 需要加入注解@staticmethod 不需传入额外的参数 不需要访问和类相关的属性或数据","categories":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"}]},{"title":"【HIVE系列】04-HIVE SQL编译原理","slug":"big_data/hive/hive-compile","date":"2019-01-21T09:10:45.000Z","updated":"2023-08-11T08:24:17.787Z","comments":true,"path":"big_data/hive/hive-compile/","link":"","permalink":"https://tlylft.github.io/big_data/hive/hive-compile/","excerpt":"","text":"https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html MapReduce实现基本SQL操作的原理JOIN操作原理1select u.name, o.orderid from order o join user u on o.uid &#x3D; u.uid; 在map的输出value中为不同表的数据打上tag标记，在reduce阶段根据tag判断数据来源。MapReduce的过程如下（这里只是说明最基本的Join的实现，还有其他的实现方式） GROUP BY实现原理1select rank, isonline, count(*) from city group by rank, isonline; 将GroupBy的字段组合为map的输出key值，利用MapReduce的排序，在reduce阶段保存LastKey区分不同的key。MapReduce的过程如下（当然这里只是说明Reduce端的非Hash聚合过程） Distinct的实现原理单个distinct1select dealid, count(distinct uid) num from order group by dealid; 当只有一个distinct字段时，如果不考虑Map阶段的Hash GroupBy，只需要将GroupBy字段和Distinct字段组合为map输出key，利用mapreduce的排序，同时将GroupBy字段作为reduce的key，在reduce阶段保存LastKey即可完成去重 多个distinct1select dealid, count(distinct uid), count(distinct date) from order group by dealid; 实现方式有两种： （1）如果仍然按照上面一个distinct字段的方法，即下图这种实现方式，无法跟据uid和date分别排序，也就无法通过LastKey去重，仍然需要在reduce阶段在内存中通过Hash去重（2）第二种实现方式，可以对所有的distinct字段编号，每行数据生成n行数据，那么相同字段就会分别排序，这时只需要在reduce阶段记录LastKey即可去重。 这种实现方式很好的利用了MapReduce的排序，节省了reduce阶段去重的内存消耗，但是缺点是增加了shuffle的数据量。 需要注意的是，在生成reduce value时，除第一个distinct字段所在行需要保留value值，其余distinct数据行value字段均可为空。","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"hive","slug":"大数据技术/hive","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"hive","slug":"hive","permalink":"https://tlylft.github.io/tags/hive/"}]},{"title":"【HIVE系列】02-HIVE 高级操作","slug":"big_data/hive/hive-senior","date":"2018-11-15T09:10:45.000Z","updated":"2023-08-11T08:05:02.489Z","comments":true,"path":"big_data/hive/hive-senior/","link":"","permalink":"https://tlylft.github.io/big_data/hive/hive-senior/","excerpt":"","text":"1. 窗口函数 http://blog.csdn.net/Abysscarry/article/details/81408265 1.1. over(partition by xx) 和 group by 的区别-- 聚合函数，操作后每个b只有一条数据,值为总的求和值 sum(a) group by b -- 执行后保留b的每一条数据，值为总的求和值 sum(a) over (partition by b) -- 执行后保留b的每一条数据，值为：按照c排序,从起点到当前行，对a进行累加值 sum(a) over (partition by b order by c) -- 执行后保留b的每一条数据，值为：按照c排序,从起点到当前行，对a进行累加值 SUM(a) OVER(PARTITION BY b ORDER BY c ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) -- 执行后保留b的每一条数据，值为：按照c排序,从当前行+往前3行，a的合计值 SUM(a) OVER(PARTITION BY b ORDER BY c ROWS BETWEEN 3 PRECEDING AND CURRENT ROW) -- 执行后保留b的每一条数据，值为：按照c排序,当前行+往前3行+往后1行，a的合计值 SUM(a) OVER(PARTITION BY b ORDER BY c ROWS BETWEEN 3 PRECEDING AND 1 FOLLOWING) -- 执行后保留b的每一条数据，值为：按照c排序,当前行+往后所有行，a的合计值 SUM(a) OVER(PARTITION BY b ORDER BY c ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) 1.2. over(partition by xx order by )1.3. row_number()、rank()、dense_rank() 的区别--row_number() 顺序排序 select name,course,row_number() over(partition by course order by score desc) rank from student; --rank() 跳跃排序，如果有两个第一级别时，接下来是第三级别 select name,course,rank() over(partition by course order by score desc) rank from student; --dense_rank() 连续排序，如果有两个第一级别时，接下来是第二级别 select name,course,dense_rank() over(partition by course order by score desc) rank from student; 1.4 count(distinct ) over的实现方式count(distinct ) over(partition by order by) -- 会报错，可以替换成 size(collect_set() over(partition by order by)) 2. 对日期进行补全2.1. 日期补全参考链接：https://stackoverflow.com/questions/45278300/how-to-generate-date-series-in-hive-creating-table 123456789select zqid, compname, kpi_id, date_add(t.StartDate,pe.i) as count_datefrom (-- 准备出每条数据补全后的最大日期和最小日期SELECT zqid, compname, kpi_id, min(count_date) as startDate, max(count_date) as endDate from model_ennenergy_icome.icome_kpi_002_xajt_basict group by zqid, compname, kpi_id) tlateral view posexplode(split(space(datediff(t.EndDate,t.StartDate)),&#39; &#39;)) pe as i,x; 2.2. 月份补全1234567drop table if exists dev_ennenergy_ccs.ccs_bus_balance_info_basic_full_h;create table dev_ennenergy_ccs.ccs_bus_balance_info_basic_full_h asselect basic.*, from_unixtime(unix_timestamp(add_months(concat(minmonth,&#39;-01&#39;),pe.i),&#39;yyyy-MM-dd&#39;),&#39;yyyyMM&#39;) as calmonth-- 需要准备出每条数据补全后的最大月份和最小月份from dev_ennenergy_ccs.ccs_bus_balance_info_basic_h basiclateral view posexplode(split(space(cast(months_between(concat(if(maxmonth&gt;from_unixtime(unix_timestamp(),&#39;yyyy-MM&#39;),from_unixtime(unix_timestamp(),&#39;yyyy-MM&#39;),maxmonth) ,&#39;-01&#39;),concat(minmonth,&#39;-01&#39;)) as int)),&#39; &#39;)) pe as i,x; 3. 对多个字段求最大，最小值3.1. 准备数据12insert into table test2 values(5,1,3,8,6);insert into table test2 values(6,2,5,11,9); a b c d e5 1 3 8 66 2 5 11 9 3.2. 用数组进行排序1select sort_array(array(a,b,c,d,e)) from test2; [1,3,5,6,8][2,5,6,9,11] 3.3. 取最大最小值123456-- 取最大值最小值select arr[0] as min_val, arr[4] as max_val from( select sort_array(array(a,b,c,d,e)) arr from test2)a; min_val &emsp; max_val1 &emsp; &emsp; &emsp; 82 &emsp; &emsp; &emsp; 11","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"hive","slug":"大数据技术/hive","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"hive","slug":"hive","permalink":"https://tlylft.github.io/tags/hive/"}]},{"title":"【HIVE系列】01-HIVE 常用操作","slug":"big_data/hive/hive-basic","date":"2018-11-13T12:20:31.000Z","updated":"2023-08-11T08:05:31.779Z","comments":true,"path":"big_data/hive/hive-basic/","link":"","permalink":"https://tlylft.github.io/big_data/hive/hive-basic/","excerpt":"","text":"参考资料：https://blog.csdn.net/wisgood/article/details/17376393http://ju.outofmemory.cn/entry/176408 1. 数据库操作（增删改查）1.1. 创建表 create table page_view ( page_id bigint comment &#39;页面ID&#39;, page_name string comment &#39;页面名称&#39;, page_url string comment &#39;页面URL&#39; ) comment &#39;页面视图&#39; partitioned by (ds string comment &#39;当前时间，用于分区字段&#39;) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\\001&#39; stored as rcfile location &#39;/user/hive/test&#39;; 1.2. 数据加载与插入1.2.1. 文件导入数据hive&gt; load data local inpath &#39;xiong.txt&#39; into table table_name; 1.2.2. 其他表导入create table table_name as select * from a left join b on a.1=b.1 2. 字符类型转换Hive也包括 隐式转换（implicit conversions）和显式转换（explicitly conversions）。 Hive在需要的时候将会对numeric类型的数据进行隐式转换。比如我们对两个不同数据类型的数字进行比较，假如一个数据类型是INT型，另一个 是SMALLINT类型，那么SMALLINT类型的数据将会被隐式转换地转换为INT类型，这个到底和Java中的一样；但是我们不能隐式地将一个INT类型的数据转换成SMALLINT或TINYINT类型的数据，这将会返回错误，除非你使用了CAST操作。 任何整数类型都可以隐式地转换成一个范围更大的类型。TINYINT,SMALLINT,INT,BIGINT,FLOAT和STRING都可以隐式 地转换成DOUBLE；是的你没看出，STRING也可以隐式地转换成DOUBLE！但是BOOLEAN类型不能转换为其他任何数据类型！ 我们可以用CAST来显式的将一个类型的数据转换成另一个数据类型。 3. 字符串操作3.1. 文本替换regexp_replace(&#39;2016-06-05 00:00:00.0&#39;, &#39;-&#39;, &#39;&#39;) --第二个参数为正则表达式 translate(description,&#39;\\\\t&#39;,&#39;&#39;) -- 3.2. 字符串拼接3.2.1. 拼接函数concat(STRING|BINARY a, STRING|BINARY b…) select concat(&#39;abc&#39;,&#39;def&#39;,&#39;gh&#39;,123) abcdefgh123 concat_ws(STRING sep, STRING a, STRING b…) concat_ws(STRING sep, Array) 和concat()一样，将多个字符串连接成一个字符串，但是可以一次性指定分隔符～（concat_ws就是concat with separator） 语法：concat_ws(separator, str1, str2, …) 说明：第一个参数指定分隔符。需要注意的是分隔符不能为null，如果为null，则返回结果为null。 select concat_ws(&#39;abc&#39;,&#39;def&#39;,&#39;gh&#39;) defabcgh 3.2.2. 分组拼接group_concat( [distinct] 要连接的字段 [order by 排序字段 asc/desc ] [separator ‘分隔符’] ) select userid,bankid,group_concat(cast(creditlimit as string)) from vdm_fin.cc_user_bill_0724 group by userid,bankid limit 100; concat_ws(‘|’, collect_set(str)) hive 实现相同功能（只返回不重复的值）： SELECT id, concat_ws(&#39;|&#39;, collect_set(str)) FROM t GROUP BY id; 3.3. 字符串补全3.3.1.4. 时间计算4.1. 获取当前时间及格式转换from_unixtime(bigint unixtime[, string format]) select from_unixtime(unix_timestamp()) --获取当前时间 select from_unixtime(unix_timestamp(), &#39;yyyyMMdd HH:mm:ss&#39;) --获取当前时间，限定格式 select from_unixtime(unix_timestamp(&#39;2013-01-01 10:10:10&#39;), &#39;yyyyMMdd&#39;) --转换格式 select from_unixtime(unix_timestamp(&#39;2013-01-01&#39;, &#39;yyyy-MM-dd&#39;), &#39;yyyyMMdd&#39;) select to_date(’2011-12-08 10:03:01′) from dual; --转成日期格式 2011-12-08 -- 获取年月日 select year(’2011-12-08 10:03:01′) from dual; 2011 select month(’2011-08-08′) from dual; 8 select day(’2011-12-08 10:03:01′) from dual; 10 --获取时分秒 select hour(’2011-12-08 10:03:01′) from dual; 8 select minute(’2011-12-08 10:03:01′) from dual; 3 select second(’2011-12-08 10:03:01′) from dual; 1 -- 获取周数 select weekofyear(’2011-12-08 10:03:01′) from dual; 49 4.2. 日期运算--日期比较函数: datediff --语法: datediff(string enddate, string startdate) --返回值: int --说明:返回结束日期减去开始日期的天数。 select datediff(&#39;2012-12-08&#39;,&#39;2012-05-09&#39;) ; 213 --日期增加函数: date_add --语法: date_add(string startdate, int days) --返回值: string --说明:返回开始日期startdate增加days天后的日期。 select date_add(&#39;2012-12-08&#39;,10); 2012-12-18 --日期减少函数: date_sub --语法: date_sub (string startdate, int days) --返回值: string --说明:返回开始日期startdate减少days天后的日期。 select date_sub(&#39;2012-12-08&#39;,10); 2012-11-28 4.3. 计算时间差-- 方法一：时间戳的差值直接按照单位换算 select post_date, gqdate, (unix_timestamp(post_date) - unix_timestamp(gqdate))/60 diff_min, (unix_timestamp(post_date) - unix_timestamp(gqdate)) diff_second from testdata limit 10; -- 方法二：计算小时差 (hour(from_unixtime(unix_timestamp(),&#39;yyyy-MM-dd HH:mm:ss&#39;))-hour(create_time)+(datediff(from_unixtime(unix_timestamp(),&#39;yyyy-MM-dd HH:mm:ss&#39;), create_time))*24) as hour_dValue --计算日期差 datediff(date1, date2) 4.4. 时间加减5. 数值处理5.1. 保留小数5.2. 取整函数5.2.1. 四舍五入取整 roundround(double a)返回值: BIGINT说明:返回double类型的整数值部分（遵循四舍五入） select round(3.1415926); 3 hive&gt; select round(3.5); 4 5.2.2. 向下取整 floorselect floor(3.1415926); 3 5.2.3. 向上取整函数: ceil/ceilinghive&gt; select ceil(3.1415926) from lxw_dual; 4 hive&gt; select ceiling(3.1415926) from lxw_dual; 4 5.3. 指定精度5.3.1. round(double a, int d)注：发现小数位用round(col1,2)在hue不起作用 5.3.2. 强制转换 cast小数位： CAST(zl_30 AS DECIMAL(20,2)) 5.3.3. 保留固定位数的精度转换format_number(3.4, 2) &gt; 3.40(String)","categories":[{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"hive","slug":"大数据技术/hive","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/hive/"}],"tags":[{"name":"hive","slug":"hive","permalink":"https://tlylft.github.io/tags/hive/"}]},{"title":"代价函数","slug":"machine_learning/cost_function","date":"2018-11-03T00:57:45.000Z","updated":"2020-07-21T01:35:32.623Z","comments":true,"path":"machine_learning/cost_function/","link":"","permalink":"https://tlylft.github.io/machine_learning/cost_function/","excerpt":"","text":"https://www.cnblogs.com/go-ahead-wsg/p/12346744.html 二次代价函数一般在回归模型使用二次代价函数假设我们激活函数输出的值目标是收敛到1，A点离目标较远，梯度较大，权值调整比较大。B点为0.98离目标比较近，梯度比较小，权值调整比较小，调整方案合理。 假设我们激活函数输出的值目标是收敛到0，A点离目标较远，梯度较大，权值调整比较大。B点为0.98离目标比较远，梯度比较小，权值调整比较小，调整方案不合理，B点要经过非常长的时间才会收敛到0，而且B点很可能成为不收敛的点。 交叉墒代价函数(cross-entropy)一般在分类的任务中使用交叉熵t和y相差越远，E的值越大。上边就是求导的推导过程，从最后的式子可以看出：权值w和偏执值b的调整与σ′(z)无关，另外，梯度公式中的σ(z)−y表示输出值与实际值放入误差。所以当误差越大时，梯度就越大，参数w和b的调整就越快，训练的速度也就越快。 总结：当输出神经元是线性的，那么二次代价函数就是一种合适的选择。如果输出神经元是S型函数，那么比较适合交叉墒代价函数。 对数似然代价函数（log-likelihood cost）对数似然函数常用来作为softmax回归的代价函数，如果输出层神经元是sigmoid函数，可以使用交叉墒代价函数。而深度学习中更普遍的做法是将softmax作为最后一层，此时常用的代价函数是对数似然代价函数。 对数似然代价函数与softmax的组合和交叉墒与sigmoid函数的组合非常相似。对数似然代价函数在二分类时可以化简为交叉墒代价函数的形式。 在TensorFlow中用： tf.nn.sigmoid_cross_entropy_with_logits()来表示跟sigmoid搭配使用的交叉墒。 tf.nn.softmax_cross_entropy_with_logits()来表示跟softmax搭配使用的交叉墒。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"集成模型","slug":"machine_learning/ensemble","date":"2017-12-31T00:57:45.000Z","updated":"2021-01-13T07:37:09.501Z","comments":true,"path":"machine_learning/ensemble/","link":"","permalink":"https://tlylft.github.io/machine_learning/ensemble/","excerpt":"","text":"1. 集成模型1.1. Bagging and BoostingBaggingLeverages unstable base learners that are weak because of overfitting.每个模型都是专家，集成了这些容易过拟合的模型。 Bagging的思想比较简单，即每一次从原始数据中根据均匀概率分布有放回的抽取和原始数据大小相同的样本集合，样本点可能出现重复，然后对每一次产生的训练集构造一个分类器，再对分类器进行组合。 BoostingLeverage stable base learners that weak because underfitting.每个模型都是一般的人（只要模型准确率大于随机猜测即可），集成了很多欠拟合的模型。 boosting的每一次抽样的样本分布都是不一样的。每一次迭代，都根据上一次迭代的结果，增加被错误分类的样本的权重，使得模型能在之后的迭代中更加注意到难以分类的样本，这是一个不断学习的过程，也是一个不断提升的过程，这也就是boosting思想的本质所在。迭代之后，将每次迭代的基分类器进行集成。那么如何进行样本权重的调整和分类器的集成是我们需要考虑的关键问题。 对比Bagging 减小方差Boosting 减小偏差 1.2. 随机森林 random forest是一种bagging的集成模型。通过选取不同的数据集和不同的特征，将多个模型结合起来，使得模型的泛化能力更好。选取不同的数据集构造树选取不同的特征构造树选取不同的数据和特征构造树最后用voting选取最优结果 第一，从原始的数据集中采取有放回的抽样（bootstrap），构造子数据集，子数据集的数据量是和原始数据集相同的。不同子数据集的元素可以重复，同一个子数据集中的元素也可以重复。第二，利用子数据集来构建子决策树，将这个数据放到每个子决策树中，每个子决策树输出一个结果。最后，如果有了新的数据需要通过随机森林得到分类结果，就可以通过对子决策树的判断结果的投票，得到随机森林的输出结果了。如下图，假设随机森林中有3棵子决策树，2棵子树的分类结果是A类，1棵子树的分类结果是B类，那么随机森林的分类结果就是A类。 1.3. adaboost一般分类模型 算法步骤：通过调整弱样本的权重，和 每个弱分类器的权重 达到增强的效果。 获取到数据集 X, y 初始化训练数据的权值分布 初始化每个样本的权值为平均值 1/N 遍历每个分类器 m = 1,2,3,4…,M a) 使用具有权值分布$D_m$的训练样本进行学习，得到基本分类器 $G_m(x): X -&gt;\\{-1,+1\\}$ b) 计算分类器的分类误差率 分错记为1，划分正确记为0，乘以权重为权值分布的权重。得到的就是所有分错的样本权重和 c) 计算分类器的系数（模型的权重，和误差率有关） $公式=log(1-e_m) - loge_m$,所以分类误差越小，系数越大，分类误差越大，系数越小 d) 更新训练数据的权重分布（和每次的效果有关） 1.4. GBDT 梯度提升树 gradient boosting decision tree一般回归模型 1.4.1. 回归提升树将前一颗树和gold standard的误差MSE作为下一棵树的损失函数，训练的是残差。（因为每次训练的就是残差，所以提升树最后就是把每棵树得到的结果都进行相加就可以了） 1.4.2. 梯度提升树GBDT的理解回归提升树学习的是残差，梯度提升树学习的是梯度方向原理：泰勒展开式 1.5. xgboost在gdbt的基础上加了一个对树的惩罚， loss function进行了泰勒的二阶展开，避免了叶节点过多，深度过深，叶节点的值过于边缘化 XGBoost相较于GBDT的提升： https://zhuanlan.zhihu.com/p/1485882751：对损失函数的泰勒展开由一阶导变为使用一二阶导，下降方向更清晰，速度更快；2：在gdbt的基础上加了一个对树的惩罚：添加了正则项，防止过拟合；3：支持特征粒度预排序，一次排序，全局使用，减少排序时间消耗（需存储，空间换时间）；4：支持直方图近似算法，根据数据分布确定划分点，将连续数据进行分桶，统计桶内的一二阶导数，进行存储，不再存储所有数据的一二阶导数，减少存储所需要的空间；5：支持加权分位数算法，在大数据寻找有效分位点时很有效；6：支持缺失值处理，自动学习分类方向；7：优化cache命中（针对预排序算法）；8：支持列采样（类似随机森林）。 Xgboost原文理解 1.6. lightGBMA highly efficiency gradient boosting decision tree在保证accuracy的前提下，对GBDT做了优化，运行速度更加高效。 dbdt的不足： 对每个特征的每个取值都进行了遍历，复杂度高lightgbm的改进 https://zhuanlan.zhihu.com/p/1485882751：支持类别特征，无需one-hot编码；2：采用叶节点分裂而非层分裂，学习精度更高；3：Gradient-based One-Side Sampling-GOSS（基于梯度的单边采样），对海量学习数据，根据其梯度，筛除绝大部分的小梯度样本，减少了样本行的计算（几乎无更新作用），保持精度的同时加快速度；4：EFB（独立特征合并），针对海量稀疏数据，根据数据间的冲突度（如cos夹角，0101和1010的冲突很小，因为非零位不相同，非零位不相同的占比越高，冲突度越少），对冲突度小的特征进行合并，变稀疏矩阵为稠密矩阵，减少特征维度，减少特征列的计算资源；5：在直方图加速算法中，支持直方图减法，对下一层样本的直方图绘制，减少时间（右孩子直方图=父节点直方图-左孩子直方图）。 无痛看懂LightGBM原文","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"激活函数","slug":"machine_learning/activate_function","date":"2017-12-15T07:54:41.000Z","updated":"2021-06-11T03:02:19.190Z","comments":true,"path":"machine_learning/activate_function/","link":"","permalink":"https://tlylft.github.io/machine_learning/activate_function/","excerpt":"","text":"why activate function? 使线性结果非线性化我们得到的输出是y= wx+b,但在现实中很多事物发展并不是完全线性的，使用非线性函数做激活函数可以掰弯线性关系。 how to use?神经网络只有两三层时，任何的激活函数差别不大。神经网络有多层时，会产生梯度爆炸，梯度消失的问题。 卷积神经网络：推荐RELU 循环神经网络：RELU tanh what does it have?1. sigmoid functionsigmoid函数也叫 Logistic 函数，用于隐层神经元输出的激活函数（表示是否将这个输入激活的权重），取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。 为什么用于二分类，我的理解： 它的输出为0-1的分布，可以把线性问题转换为概率问题 它的曲线相对来讲更加两级化，把数据更强的用趋近于边界的数值（0,1）表示， 更好的适用于分类问题。问题：值越接近两边，梯度约等于0，发生梯度消失问题，梯度就没办法更新了，后来为了解决这个问题，引进了RELU激活函数。2. RELUmax(0,x)为了解决梯度消失的问题。3. softmax3.1. 简单说明是sigmoid函数的升级版，在多分类问题中，通常会使用softmax函数作为网络输出层的激活函数。因为做了归一化，数值可以参考为概率值或置信度。 Softmax解决这样一个问题：我有一个向量，想用数学方法把向量中的所有元素归一化为一个概率分布。也就是说，该向量中的元素在[0,1]范围内，且所有元素的和为1。 Softmax就是这个数学方法，本质上是一个函数。 假设我们有一个k维向量z，我们想把它转换为一个k维向量 ， 使其所有元素的范围是[0,1]且所有元素的和为1，函数表达式是：$softmax(x)_i = {e^{x_i} \\over \\sum_j{e^{x_j}}}$  也就是说， 内的每一个元素是对z内的对应元素求指数，再除以所有元素求指数后的和。所以Softmax函数也叫做归一化指数函数（normalized exponential function） 3.2. 数学理解解释下公式里各个运算的作用：在上一层神经层运算后，得到的类别数值分数的差异并不是很大，如3.2和5.1，但得分函数里，虽然数值差异很小，但可能对类别划分情况就产生了很大的影响。为了让差异更明显，做了一次指数次幂的运算，使得差异变大，如24.5和164.0。做归一化，是为了映射到0-1的范围区间上，可以理解为概率表示，表示类别的可能性。加一层负的log函数，这个意义并不是激活函数的一部分，而是针对应该被划分的正确类别，为这个样本计算损失函数。比如现在是只猫，但是被认为是猫的可能为0.13，在log函数中距离0很近，做一层log,会认为损失很大。 3.3. 例子","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"正则化惩罚项","slug":"machine_learning/regularization_penalty","date":"2017-12-04T06:29:33.000Z","updated":"2020-08-03T06:07:09.008Z","comments":true,"path":"machine_learning/regularization_penalty/","link":"","permalink":"https://tlylft.github.io/machine_learning/regularization_penalty/","excerpt":"","text":"https://www.cnblogs.com/jianxinzhou/p/4083921.html 1. 背景在机器学习里，如果我们只拿到原始数据作为特征，通常结果会是一条直线（如图一），发生欠拟合的情况。这样我们经常会对feature设置一些高维度特征（二次项），去更好的拟合一个曲线趋势（如图二），但如果数据量不够，往往又会发生过拟合的现象。过拟合会导致在测试集中，误差较大。（这个时候预测曲线的浮动差异是比较大的，我们希望它的浮动型较小）为了解决这种高维特征导致的过拟合现象，可以引入正则化惩罚项，去将高维特征的权重参数降低。提高模型的泛化能力。 2. 解决过拟合2.1. 数据准备：增大训练数据集https://tlylft.github.io/machine_learning/sample_imbalance/ 2.2. 训练过程中：early stopping在训练模型时，往往会设置一个比较大的迭代次数。 early stopping 采用提前结束训练的策略来防止过拟合。一般提前结束的策略：记录到目前为止最好的accuracy， 当连续n=10个epoch没有达到最佳的accuracy时，就认为可以停止迭代了。 2.3. 减少特征数量选取相对重要的特征，或是将多种特征组合降维。 2.4. 深度学习：神经网络中的dropout过拟合问题，除了用l1,l2惩罚项，还可以用dropout.正则化的原理是减小每个神经元的权重，但保留每个神经元， dropout的原理是随机选择一部分神经元（0.4-0.6之间的drop率） 2.5. 正则化很多特征都会对预测结果产生一些影响，但多了又容易发生过拟合，每个特征变量都是有一定意义的，又不希望删掉某个变量，为了优化拟合曲线，引入正则化概念，通过正则化均值，降低一些特征变量的权重值。 3. 正则化理解将代价函数 加上一个参数正则惩罚项，一方面使代价函数越来越小，另一方面使feature的权重参数越来越小。L1会导致一部分参数值等于0，L2会使所有参数都衰减趋近于0. 4. 惩罚力度正则化惩罚力度越大，减弱过拟合，泛化能力越强。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"机器学习基础概念","slug":"machine_learning/basic","date":"2017-12-04T00:57:45.000Z","updated":"2021-07-03T05:35:48.278Z","comments":true,"path":"machine_learning/basic/","link":"","permalink":"https://tlylft.github.io/machine_learning/basic/","excerpt":"","text":"1. 什么是机器学习Field of study that gives computers the ability to learn without being explicitly programmed.让机器帮助我们去发现一些新的规则。所以机器学习的核心是，从数据中自动学出规律，而不是一个人拍脑袋定出来的。可以简单地理解为归纳总结。而且通过机器归纳出来的规律有可能很多是我们之前都没有想到的。 1.1. 深度学习 vs 机器学习深度学习是机器学习的一个分支subfield.深度学习是受到了人类大脑认知的启发，设计出神经网络的结果的一类算法。 如何理解deep?有什么好处？简单来讲，深度可以理解成我们把很多简单的模型叠加在了一起，这自然就能得到一个有深度的模型。举个例子，比如我们把一个神经网络叠加成多层结构的时候，得到的是深度神经网络； 当我们把一个高斯混合模型叠加在一起的时候就得到了深度高斯混合模型； 当我们把SVM叠加在一起的时候就得到了深度SVM模型。由此可见，这样的一个框架可以应用在很多不同种类的模型上。 这样的模型会有更强大的表达能力(capacity)， 具备层次表示能力(hierarhical representation)， 具有全局泛化能力(global generalization)，迁移学习能力(transfer learning)等等。 1.2. 有监督学习和无监督学习区别就是先验知识的训练数据，有没有样本标签。有监督学习：数据既有特征，又有标签，通过已知的标签学习标签的规律，x到y的映射关系。无监督学习：数据没有标签，寻找x的特征或者规律。对于无监督算法来讲，它的实际场景主要还是以聚类分析为主，其中最经典的聚类算法叫做 K-means，也是一个极其简单的算法。 另外，聚类分析方法经常用在营销过程当中。 在工业界应用里主要还是以监督学习为主。 1.3. 回归 分类 聚类 回归： 预测数据为连续性数值，比如温度，年龄，身高 分类： 预测数据为类别型数值，并且分类已知，比如男或女，好或坏 聚类： 预测数据为类别型数值，并且分类未知 1.4. 测试数据和训练数据训练数据用来训练模型，测试数据的作用是用来评估模型。 建模流程收集数据：数据非常重要，收集足够多和有效的数据。跳过特征工程的方法，叫做端到端的模型 基本术语数据集dataset样本sample特征feature 通用概念决策边界什么又是决策边界呢？其实我们每天都做各式各样的决策，比如我的决策是：当华为Mate降价到2000元的时候购买一个。对于这个问题，我的决策边界是2000元，也就是大于2000元的时候我不会购买，但小于2000元时我会选择购买，类似的生活中的例子很多。60分考试及格，那么60就是一个决策边界。 泛化能力决策边界在训练数据上的表现是最好的，但这不代表在测试数据或未来数据上表现最好。这里涉及到了一个很重要的概念，叫做模型的泛化能力，可以简单理解成“它在新的环境中的适应能力”，当然这个环境需要跟已有的环境类似才行。 交叉验证 2. 应用场景2.1. 农业2.2. 教育拍照识题，自动批改作业， 课堂面部表情检测， 规划学习路径，推送学习内容 2.3. 医疗病情演变，问诊，早期病情预警，影像诊断。由于医疗领域本身的敏感性，搜集数据是摆在眼前的一大难题，解决数据问题或许会成为这个领域的突破口。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"样本不均衡问题","slug":"machine_learning/sample_imbalance","date":"2017-12-03T07:54:41.000Z","updated":"2020-08-02T10:52:55.019Z","comments":true,"path":"machine_learning/sample_imbalance/","link":"","permalink":"https://tlylft.github.io/machine_learning/sample_imbalance/","excerpt":"","text":"样本不均衡0的样本有28w，1的样本有几百个。模型训练会有误判。 过采样原理：使得两个样本同样多。对样本少的类别做数据生成。 数值型数据生成：SMOTE算法，用数值维度表示样本数量少的类别的各个样本点，每个样本计算与其他样本的距离，实现方式： 1234pip install imblearnfrom imblearn.over_sampling import SMOTEoversampler &#x3D; SMOTE(random_state&#x3D;0)os_features, os_labels &#x3D; oversampler.fit_sample(features_train, labels_train) 下采样原理：使得两个样本同样少。取最小的数值，让所有类别都是大概那么多的样本量。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"决策树","slug":"machine_learning/DT","date":"2017-12-03T00:57:45.000Z","updated":"2021-02-08T04:50:12.556Z","comments":true,"path":"machine_learning/DT/","link":"","permalink":"https://tlylft.github.io/machine_learning/DT/","excerpt":"","text":"1. 算法原理1.1. 决策树介绍是树模型， 从根节点开始一步一步决策到叶子节点。利用分类算法生成可读性的规则。既可以做分类也可以做回归。有两种树：分类树和回归树。 Pros:1、推理过程容易理解，决策推理过程可以表示成If Then形式；2、推理过程完全依赖于属性变量的取值特点；3、可自动忽略目标变量没有贡献的属性变量，也为判断属性变量的重要性，减少变量的数目提供参考。 1.2. 树的组成根节点：第一个选择点非叶子节点与分支： 中间过程叶子节点： 最终的决策结果 节点：相当于在数据中切分开，作为划分的依据，越多的特征切分越细致，但并不是节点越多越好（过拟合），所以需要适当裁剪 训练阶段： 构造树（从根节点选择特征，两个问题：1。如何选择，2.如何切分） 测试阶段： 根据构造出的树模型按照顺序执行就好了 难点在训练阶段 1.3. 如何构造决策树（决定特征的决策顺序）1.3.1. 信息熵：表示随机变量的不确定性的度量（物体的混乱程度），分布的混乱程度越大，表示信息的不确定性就越大，熵值越大。用二分类来说，如果两个分类的概率都是0.5，那么就不能明确物品属于分类1的事实，呈现的情况就很模糊，信息的不确定性就越大，看下图曲线，这个时候熵值是最大的。举个例子：一个人在商场闲逛，买到a商品的概率 商场里只有a商品[a,a,a,a,a,a,a,a,a,a]这种情况，确定性高，选择就很稳定 商场只买a,b两个商品[a,a,a,a,a,b,b,b,b,b]这种情况，确定性较高，选择基本稳定 商场只卖a,b两个商品，但是a更多。[a,a,a,a,a,a,a,a,b,b]这种情况，确定性会比第二种高一些 杂货市场买很多商品[a,b,c,d,e,f,g,h,i,a]类别太多，不确定性大，熵值大 1.3.2. 信息增益：https://www.cnblogs.com/muzixi/p/6566803.html特征A对训练数据集D的信息增益g(D,A),定义为集合D的经验煽H(D) 与特征A 给定条件下D 的经验条件煽H(D|A) 之差$g(D,A) = H(D) - H(D|A)$理解：（1）H(D) ：$C_k$表示每个类别k的样本数，$D$表示样本总数，相除就是$P_k$（2）H(D|A)：条件熵，$D_i$表示每个特征值i的样本数，相除代表在该特征的概率分布，$H(D_i)$表示包含这个特征值数据集的熵。值越大代表信息不确定性越强。如果A表示年龄这个特征，$D_i$表示青年，中年，老年的样本数，${D_1}\\over|D|$表示青年这个值在年龄特征中的概率，理解为权重。$H(D_1)$表示包含青年这个特征值数据集的熵。（3）增益：当前数据分布的信息熵，减去特征A的条件熵。我们想找出能够明确信息的一个特征，那这个特征的条件熵就应该越小，那么增益就应该越大。例子 $H(D) = -{9\\over15}log_2 -{6\\over15}log_2 = 0.971$ $A_1$表示年龄这个特征，$D_i$表示青年，中年，老年的样本数，${D_1}\\over|D|$表示青年这个值在年龄特征中的概率，理解为权重。$H(D_1)$表示包含青年这个特征值数据集的熵。$A_2$表示有工作这个特征，$D_i$表示是和否的样本数为5和10，${D_2}\\over|D|$表示否这个值在有工作特征中的概率，理解为权重为10/15。$H(D_2)$表示包含否这个特征值数据集的熵（这个数据集一共10条数，4个类别为是，6个类别为否）。$g(D,A_4) = 0.971-0.608=0.362$缺点：信息增益偏向取值较多的特征原因：当特征的取值较多时，根据此特征划分更容易得到纯度更高的子集，因此划分之后的熵更低，由于划分前的熵是一定的，因此信息增益更大，因此信息增益比较 偏向取值较多的特征。 1.4. 信息增益比https://blog.csdn.net/m0_38024592/article/details/82317369信息增益表述的是信息熵和条件熵之间的差值,假如我们想用Day来做为特征(当然实际上一般人也不会傻到用Day用做特征)，显然，每一天都可以将样本分开，也就是形成了一颗叶子数量为14，深度只有两层的树。这种样本分隔的结果就是计算出来的H(D|Day)=0,那么g(D,Day)=0.9403，这特征可真是够“好”的！不过显然这种特征对于样本的分隔没有任何意义。类似的情况还有人们的身份证号、信用卡号、学号等等特征。那么导致这样的偏差的原因是什么呢？从上面的例子应该能够感受出来，原因就是该特征可以选取的值过多。解决办法自然就想到了如何能够对树分支过多的情况进行惩罚，这样就引入了下面的公式，属性A的内部信息缺点：信息增益比偏向取值较少的特征原因：当特征A的类型取值较少时HA(D)的值较小，因此其倒数较大，因而信息增益比较大。因而偏向取值较少的特征。基于以上缺点，并不是直接选择信息增益率最大的特征，而是现在候选特征中找出信息增益高于平均水平的特征，然后在这些特征中再选择信息增益率最高的特征。 2. 实现的算法决策树是机器学习中的经典算法，分别由三个经典算法实现：ID3，C4.5，CART，这三个算法最明显的区别就是对于特征选择的策略不同，不过目的只有一个：使当前数据集的混乱程度降低。具体来说，ID3使用的信息增益，C4.5使用的信息增益比，CART使用的Gini指数（基尼指数）ID3树可以根据特征类别是多叉树，但CART树是二叉树。 2.1. ID3ID3 算法的核心是在决策树各个结点上应用信息增益准则选择特征，递归地构建决策树。 2.2. C4.5为什么C4.5要用信息增益比https://blog.csdn.net/m0_38024592/article/details/82317369 2.3. cart 回归树（classification and regression trees）• 目标变量是类别的 —- 分类树• 目标变量是连续的 —- 回归树cart树的生成是递归构建二叉决策树的过程，对回归树用平方误差最小化准则，对分类树用基尼指数（Gini index) 最小化准则，进行特征选择，生成二叉树。 2.3.1. 分类树基尼指数：分类问题中，假设有$K $个类，样本点属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为: $Gini(p)=\\sum_{k=1}^K{p_k(1-p_k)}=1-\\sum_{k=1}^K{p_k^2}$对于给定的样本集合D，其基尼指数为: $Gini(p)=1-\\sum_{k=1}^K{({|C_k|\\over |D|})^2 }$ 对于特征A 是否取某一可能值α ，使得样本集合D被分割成D1 和D2 两部分 $Gini(D,A)= {|D_1|\\over|D|}Gini(D_1) + {|D_2|\\over |D|}Gini(D_2)$ 2.3.2. 回归树2.4. 剪枝2.5. 随机森林选取不同的数据集构造树选取不同的特征构造树选取不同的数据和特征构造树最后用voting选取最优结果","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"逻辑回归","slug":"machine_learning/logistic_regression","date":"2017-12-02T07:54:41.000Z","updated":"2021-04-20T07:10:08.141Z","comments":true,"path":"machine_learning/logistic_regression/","link":"","permalink":"https://tlylft.github.io/machine_learning/logistic_regression/","excerpt":"","text":"https://blog.csdn.net/u011734144/article/details/79717470 Logistic regression原理：线性回归的函数，加了一层sigmoid函数, 将线性问题转换为类别的概率问题，适用于二分类场景。 breif intro线性回归解决的是线性拟合问题（数值类，连续的）逻辑回归解决的是分类问题，非0即1，经典的二分类算法。 首选的分类算法是逻辑回归，有些问题没有那么复杂，一般优先用逻辑回归实验。可解释性强。 逻辑回归的边界： 可以是非线性的。 sigmoid函数一般分类问题用它解决。为什么？我的理解： 它的输出为0-1的分布，可以把线性问题转换为概率问题 它的曲线相对来讲更加两级化，把数据更强的用趋近于边界的数值（0,1）表示， 更好的适用于分类问题。 公式推导推导过程：预测函数是线性回归加上一层sigmoid函数。因为是分类任务，认为P(y = 0) + P(y = 1) = 1整合的过程并不是推导出来的，而是因为只有这样表示，才能在y=0和y=1时还原成分类任务的表示。 求解过程和逻辑回归一样，用似然函数， 对数似然转换成加法问题。引入负号，将求最大值问题转换成求最小值问题。（为啥要转换？我的理解：因为一般损失函数都是指定义一个函数使损失最小，应该是为了满足这个通用的理解吧，在逻辑回归里，去掉常量后的式子已经是个最小值问题了，所以不用转换。） 求导的意义是，找到这个参数调整的方向。沿着这个方向，去更新一定的步长。迭代上万次，就可以得到我们想要的参数。 延伸多分类问题，会使用softmax函数， 其实是在sigmoid函数上加了一个类别权重。 实现1234from sklearn.linear_model import LogisticRegressionlr &#x3D; LogisticRegression(C &#x3D; best_c, penalty &#x3D; &#39;l1&#39;)lr.fit(X_train, y_train)y_pred &#x3D; lr.predict(x_test) 阈值设定12thresholds &#x3D; 0.7lr.predict_proba() 类别划分的阈值不同，对分类结果准确度的影响：","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"KNN K近邻算法","slug":"machine_learning/KNN","date":"2017-12-02T00:27:58.000Z","updated":"2021-08-30T12:08:11.544Z","comments":true,"path":"machine_learning/KNN/","link":"","permalink":"https://tlylft.github.io/machine_learning/KNN/","excerpt":"","text":"1. KNN给定一个预测目标，接下来计算预测预测目标和所有样本之间的距离或者相似度，然后选择距离最近的前K个样本，然后通过这些样本来投票决策。 K值对结果的影响（决策边界）：随着K值的增加，决策边界会变得更加平滑。决策边界的平滑也意味着模型的稳定性。这个其实很好理解，平时工作当中多个人共同决策要比一个人决策会大概率上减少犯错误。但稳定不代表，这个模型就会越准确。 一般对于二分类问题来说，把K设置为奇数是容易防止平局的现象。但对于多分类来说，设置为奇数未必一定能够防平局。 KNN的交叉验证在KNN里，通过交叉验证，我们即可以得出最合适的K值。它的核心思想是把一些可能的K逐个去尝试一遍，然后选出效果最好的K值。KNN 特征缩放在我们使用欧氏距离这样通过距离表述样本关系的情况中，如KNN,K-means等，如果数据点中其中某一个维度的值较大，表现的距离差在这个维度上也会很大，就会使得其他维度的特征影响不明显（起不到作用），所以需要特征缩放进行标准化操作，也就是把特征映射到类似的量纲空间，目的是不让某些特征的影响变得太大。 总结 KNN是一个极其简单的算法，训练过程是一种memory-Base/Instace-Based的算法。 适合用在低维空间（因为核心是计算距离，就要把每个维度都跑起来，）时间复杂度是O(N*D) 在训练过程中不需要做任何事情（选参数），时间消耗很小。 预测过程需要循环所有的样本数据，复杂度线性依赖于样本个数，所以应用在大数据（千万级）中，预测时是有瓶颈的。解决方法：减少数据量，使用KD-Tree,使用近似算法1.1. sklean 实现https://scikit-learn.org/stable/modules/neighbors.html#neighbors函数介绍12sklearn.neighbors.KNeighborsClassifier(n_neighbors&#x3D;5, weights&#x3D;’uniform’, algorithm&#x3D;’auto’, leaf_size&#x3D;30, p&#x3D;2, metric&#x3D;’minkowski’, metric_params&#x3D;None, n_jobs&#x3D;None, **kwargs) n_neighbors临近的节点数量，默认值是5 weights权重，默认值是uniform， uniform：表示每个数据点的权重是相同的； distance：离一个簇中心越近的点，权重越高； callable：用户定义的函数，用于表示每个数据点的权重 algorithm auto：根据值选择最合适的算法 ball_tree：使用BallTree kd_tree：KDTree brute：使用Brute-Force查找 leaf_sizeleaf_size传递给BallTree或者KDTree，表示构造树的大小，用于影响模型构建的速度和树需要的内存数量，最佳值是根据数据来确定的，默认值是30。 p，metric，metric_parasp参数用于设置Minkowski 距离的Power参数，当p=1时，等价于manhattan距离；当p=2等价于euclidean距离，当p&gt;2时，就是Minkowski 距离。metric参数：设置计算距离的方法metric_paras：传递给计算距离方法的参数 n_jobs并发执行的job数量，用于查找邻近的数据点。默认值1，选取-1占据CPU比重会减小，但运行速度也会变慢，所有的core都会运行。 代码实现sklearn123456789101112131415161718192021from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_split# 加载数据集iris_dataset&#x3D;load_iris()# 拆分训练数据x_train,x_test,y_train,y_test&#x3D;train_test_split(iris_dataset[&#39;data&#39;],iris_dataset[&#39;target&#39;],random_state&#x3D;0)# 定义分类器from sklearn.neighbors import KNeighborsClassifierknn &#x3D; KNeighborsClassifier(n_neighbors&#x3D;3)knn.fit(x_train, y_train)# 评估模型assess_model_socre&#x3D;knn.score(x_test,y_test)print(&#39;Test set score:&#123;:2f&#125;&#39;.format(assess_model_socre))# 预测新的数据x_new&#x3D;np.array([[5, 2.9, 1, 0.2]])prediction&#x3D; knn.predict(x_new)print(&quot;prediction :&#123;0&#125; ,classifier:&#123;1&#125;&quot;.format(prediction,iris_dataset[&quot;target_names&quot;][prediction])) 手写代码实现收获：投票器，Counter的用法numpy切片运算和排序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from sklearn import datasetsfrom collections import Counter # 为了做投票from sklearn.model_selection import train_test_splitimport numpy as np# 导入iris数据iris &#x3D; datasets.load_iris()X &#x3D; iris.datay &#x3D; iris.targetX_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, random_state&#x3D;2003)def euc_dis(instance1, instance2): &quot;&quot;&quot; 计算两个样本instance1和instance2之间的欧式距离 instance1: 第一个样本， array型 instance2: 第二个样本， array型 &quot;&quot;&quot; # TODO dist &#x3D; np.sqrt(np.sum(np.square(instance1-instance2))) # dist &#x3D; np.linalg.norm(instance1-instance2) return dist def knn_classify(X, y, testInstance, k): &quot;&quot;&quot; 给定一个测试数据testInstance, 通过KNN算法来预测它的标签。 X: 训练数据的特征 y: 训练数据的标签 testInstance: 测试数据，这里假定一个测试数据 array型 k: 选择多少个neighbors? &quot;&quot;&quot; # TODO 返回testInstance的预测标签 &#x3D; &#123;0,1,2&#125; dist_list &#x3D; np.sqrt(np.sum(np.square(X-testInstance),axis &#x3D; 1)) top_k_idx &#x3D; dist_list.argsort()[0:k] top_k_label &#x3D; [y[idx] for idx in top_k_idx] count &#x3D; Counter(top_k_label) return count.most_common(1)[0][0]# 预测结果。predictions &#x3D; [knn_classify(X_train, y_train, data, 3) for data in X_test]correct &#x3D; np.count_nonzero((predictions&#x3D;&#x3D;y_test)&#x3D;&#x3D;True)print (&quot;Accuracy is: %.3f&quot; %(correct&#x2F;len(X_test)))&gt;&gt;Accuracy is: 0.921 实现决策边界1234567891011121314151617181920212223242526272829303132333435363738import matplotlib.pyplot as pltimport numpy as npfrom itertools import productfrom sklearn.neighbors import KNeighborsClassifier# 生成一些随机样本n_points &#x3D; 100X1 &#x3D; np.random.multivariate_normal([1,50], [[1,0],[0,10]], n_points)X2 &#x3D; np.random.multivariate_normal([2,50], [[1,0],[0,10]], n_points)X &#x3D; np.concatenate([X1,X2])y &#x3D; np.array([0]*n_points + [1]*n_points)print (X.shape, y.shape)# KNN模型的训练过程clfs &#x3D; []neighbors &#x3D; [1,3,5,9,11,13,15,17,19]for i in range(len(neighbors)): clfs.append(KNeighborsClassifier(n_neighbors&#x3D;neighbors[i]).fit(X,y))# 可视化结果x_min, x_max &#x3D; X[:, 0].min() - 1, X[:, 0].max() + 1y_min, y_max &#x3D; X[:, 1].min() - 1, X[:, 1].max() + 1xx, yy &#x3D; np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))f, axarr &#x3D; plt.subplots(3,3, sharex&#x3D;&#39;col&#39;, sharey&#x3D;&#39;row&#39;, figsize&#x3D;(15, 12))for idx, clf, tt in zip(product([0, 1, 2], [0, 1, 2]), clfs, [&#39;KNN (k&#x3D;%d)&#39;%k for k in neighbors]): Z &#x3D; clf.predict(np.c_[xx.ravel(), yy.ravel()]) Z &#x3D; Z.reshape(xx.shape) axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha&#x3D;0.4) axarr[idx[0], idx[1]].scatter(X[:, 0], X[:, 1], c&#x3D;y, s&#x3D;20, edgecolor&#x3D;&#39;k&#39;) axarr[idx[0], idx[1]].set_title(tt) plt.show() 虽然决策边界平滑会使得模型变得更加稳定，但稳定不代表模型的准确率更高。这就类似于我们投资股票，我们如果寻求特别的稳定，就意味着最终的收益会很少，但至少抗风险能力会很强。所以一般都会平衡风险和收益，从而选择最合适的平衡点。 sample解决回归问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import pandas as pdimport matplotlibimport matplotlib.pyplot as pltimport numpy as npimport seaborn as sns#读取数据df &#x3D; pd.read_csv(&#39;&#x2F;home&#x2F;anaconda&#x2F;data&#x2F;RGZNXLY&#x2F;ch4&#x2F;data.csv&#39;)df # data frame# 特征处理# 把颜色独热编码df_colors &#x3D; df[&#39;Color&#39;].str.get_dummies().add_prefix(&#39;Color: &#39;)# 把类型独热编码df_type &#x3D; df[&#39;Type&#39;].apply(str).str.get_dummies().add_prefix(&#39;Type: &#39;)# 添加独热编码数据列df &#x3D; pd.concat([df, df_colors, df_type], axis&#x3D;1)# 去除独热编码对应的原始列df &#x3D; df.drop([&#39;Brand&#39;, &#39;Type&#39;, &#39;Color&#39;], axis&#x3D;1)df# 数据转换matrix &#x3D; df.corr()f, ax &#x3D; plt.subplots(figsize&#x3D;(8, 6))sns.heatmap(matrix, square&#x3D;True)plt.title(&#39;Car Price Variables&#39;)# 忽略警告信息import warningswarnings.filterwarnings(&quot;ignore&quot;)from sklearn.neighbors import KNeighborsRegressorfrom sklearn.model_selection import train_test_splitfrom sklearn import preprocessingfrom sklearn.preprocessing import StandardScalerimport numpy as np# 先将标签取出y &#x3D; df[&#39;Ask Price&#39;].values.reshape(-1, 1)# 删除标签列作为特征数据X &#x3D; df.drop([&#39;Ask Price&#39;], axis&#x3D;1)X_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, test_size&#x3D;0.3, random_state&#x3D;41)X_normalizer &#x3D; StandardScaler() # N(0,1)# 将需要归一化处理的三个列值替换为处理后的X_train.loc[:,[&#39;Construction Year&#39;, &#39;Days Until MOT&#39;, &#39;Odometer&#39;]] &#x3D; X_normalizer.fit_transform(X_train[[&#39;Construction Year&#39;, &#39;Days Until MOT&#39;, &#39;Odometer&#39;]])X_test.loc[:,[&#39;Construction Year&#39;, &#39;Days Until MOT&#39;, &#39;Odometer&#39;]] &#x3D; X_normalizer.transform(X_test[[&#39;Construction Year&#39;, &#39;Days Until MOT&#39;, &#39;Odometer&#39;]])y_normalizer &#x3D; StandardScaler()y_train &#x3D; y_normalizer.fit_transform(y_train)y_test &#x3D; y_normalizer.transform(y_test)knn &#x3D; KNeighborsRegressor(n_neighbors&#x3D;2)knn.fit(X_train, y_train.ravel())#Now we can predict prices:y_pred &#x3D; knn.predict(X_test)y_pred_inv &#x3D; y_normalizer.inverse_transform(y_pred)y_test_inv &#x3D; y_normalizer.inverse_transform(y_test)# Build a plotplt.scatter(y_pred_inv, y_test_inv)plt.xlabel(&#39;Prediction&#39;)plt.ylabel(&#39;Real value&#39;)# Now add the perfect prediction linediagonal &#x3D; np.linspace(500, 1500, 100)plt.plot(diagonal, diagonal, &#39;-r&#39;)plt.xlabel(&#39;Predicted ask price&#39;)plt.ylabel(&#39;Ask price&#39;)plt.show()print(y_pred_inv)knn 提升KNN搜索效率有很多方法，但没有完美解决方案 从每一个类别里选出具有代表性的样本。我们从每一个类别中选出了3个具有代表性的样本。在之后的预测阶段，我们只需要计算跟这些样本之间的距离就可以了。 使用近似KNN算法这种算法仍然是KNN，但是在搜索的过程会做一些近似运算来提升效率，但同时也会牺牲一些准确率。可以参考以下链接：https://www.cs.umd.edu/~mount/ANN/ 使用KD树来加速搜索速度，但一般只适合用在低维的空间。时间复杂度：一般O(logN)最坏：O(N) 我们可以把KD树看作是一种数据结构，而且这种数据结构把样本按照区域重新做了组织，这样的好处是一个区域里的样本互相离得比较近。假如之后来了一个新的预测样本，这时候我们首先来判定这个预测样本所在的区域，而且离它最近的样本很有可能就在这个区域里面。如何构建kd树按区域自定义划分，一般取中间，一般在子节点区域小于三个样本数停止。新样本来了以后，按照kd树搜索，得到最可能在的区域，这个区域里离他最近的点我们认为就是样本集里离他最近的节点。但并不能保证距离最短的点一定会落在跟预测样本同一个区域。 为了保证能够找到全局最近的点，我们需要适当去检索其他区域里的点，这个过程也叫作Backtracking。 和维度的关系随着特征维度的增加，搜索的时间复杂度会指数级增加。 这就意味着我们其实没有办法把KD树用在高维的空间里。KD树的应用地图搜索，最近的饭店 带权重的KNN有时候选取了K值，采用投票机制的结果不一定准确，如下图。所以采取离得最近的点权重更大的方式，最后做了加权平均。","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]},{"title":"线性回归","slug":"machine_learning/LR","date":"2017-12-01T07:54:41.000Z","updated":"2021-02-21T05:36:06.591Z","comments":true,"path":"machine_learning/LR/","link":"","permalink":"https://tlylft.github.io/machine_learning/LR/","excerpt":"","text":"1. 问题理解 2. 线性拟合为了可以训练到$\\theta_0$,我们一般会额外设置x0 ,增加x0列，这列都是1，与$\\theta_0$相乘。 3. 误差的概念真实值和预测值之间肯定是有差异的，这个差异用$\\varepsilon$表示。 所以 真实的值 会等于预测曲线拟合出的值 加上 一个偏差 $y = \\theta^{T} X^{(i)} + \\varepsilon $ 我们认为误差是独立并且具有相同的分布，并且服从均值为0 方差为$\\theta^2$的高斯分布。 为什么独立：每个样本间是没有关系的，才能同时满足一种自然界通用规则，有了关系，会相互影响。为什么同分布：换了一个环境，那么分布，误差，这些东西都会有变化，就不太满足一个通用的规则了。所以比如气量预测，针对不同的地区，会单独做不同的模型，通俗理解上是因为他们的影响条件不同，数学上理解，他们的情况分布会不同。因为误差服从正态（高斯）分布，所以对于样本 $x_i$ 预测的值也服从高斯分布。 4. 似然函数与目标函数 似然函数的理解：用样本去估计我们的参数值，用数据找出（推出）参数（规则）是什么。极大似然估计：一个函数，使得成为真实值的概率越大越好。目标函数 为什么引入似然函数？因为首先，需要做一些训练的表示，使得预测和真实越接近越好。似然函数通过误差的正态分布，可以表示这种问题。表达了预测值成为真实值的可能性。这个可能性越大越好。为什么进行log变换？转换成加法，将问题和运算简单化。为什么目标函数越小越好？我们想要预测和真实越接近越好，那么就是误差越小越好，误差越小，正态分布的概率越大。 那么就是希望似然估计的值越大越好，化简后有个负号，所以是希望后面的公式越小越好。 5. 目标函数求解因为是求最小值的问题， 求偏导，导数等于0的位置就是最小值点。（通常会把求最大值问题转换为求最小值问题。好求？）一元线性问题求解：多元线性回归矩阵表示： 6. 梯度下降沿着目标方向（偏导方向），一步一步迭代的走。 多个参数需要训练，就针对每个参数在各自的维度方向做偏导。 目标函数是对所有样品偏差的一个平均值。 6.1. 三种梯度下降方法：批量梯度下降损失函数为所有样本的偏差求和，计算速度和样本数成正比，综合考虑所有样本的偏差，准确性高，但训练速度慢。随机梯度下降每次随便找一个样本进行更新，训练速度快，但收敛方向可能是错的,收敛不一定快。mini-batch 小批量梯度下降（GOOD)综合了前面两种方法，批量更新。目前用的比较多，但并不意味着一定适用于每种场景。一般选择2的倍数，32,64,128，要根据内存和效率情况调整，但是尽量能多大就多大，越大稳定程度越高。 6.2. 学习率的选择学习率会对结果产生很大的影响，一般选取0.01如果学习曲线飞了，再调整小一些。找到合适的学习率后， 可以在训练过程中，随着迭代的次数，在迭代过程中不断再减小学习率。（比如，0-1w的数据，用0.01， 第1w-2w的数据用0.005..） 123456789101112131415161718192021222324252627# 创建数据集，把数据写入到numpy数组import numpy as np # 引用numpy库，主要用来做科学计算import matplotlib.pyplot as plt # 引用matplotlib库，主要用来画图data &#x3D; np.array([[152,51],[156,53],[160,54],[164,55], [168,57],[172,60],[176,62],[180,65], [184,69],[188,72]])# 打印大小x, y &#x3D; data[:,0], data[:,1]print (x.shape, y.shape)# 1. 手动实现一个线性回归算法，具体推导细节参考上图# TODO: 实现w和b参数， 这里w是斜率， b是偏移量x_mean &#x3D; x.mean()y_mean &#x3D; y.mean()xy_mean &#x3D; (x*y).mean()x2_mean &#x3D; (x**2).mean()# print(x_mean,y_mean,xy_mean,x2_mean)w &#x3D; (xy_mean -x_mean*y_mean)&#x2F;(x2_mean-x_mean**2)b &#x3D; y_mean -w*x_meanprint (&quot;通过手动实现的线性回归模型参数: %.5f %.5f&quot;%(w,b))# 2. 使用sklearn来实现线性回归模型, 可以用来比较一下跟手动实现的结果from sklearn.linear_model import LinearRegressionmodel &#x3D; LinearRegression().fit(x.reshape(-1,1),y)print (&quot;基于sklearn的线性回归模型参数：%.5f %.5f&quot;%(model.coef_, model.intercept_))","categories":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"}]}],"categories":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/categories/LLM/"},{"name":"transformer","slug":"LLM/transformer","permalink":"https://tlylft.github.io/categories/LLM/transformer/"},{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/categories/tools/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/categories/machine-learning/"},{"name":"time series","slug":"machine-learning/time-series","permalink":"https://tlylft.github.io/categories/machine-learning/time-series/"},{"name":"爬虫","slug":"爬虫","permalink":"https://tlylft.github.io/categories/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"https://tlylft.github.io/categories/python/"},{"name":"python","slug":"python/python","permalink":"https://tlylft.github.io/categories/python/python/"},{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/categories/Leecode/"},{"name":"pandas","slug":"python/pandas","permalink":"https://tlylft.github.io/categories/python/pandas/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/categories/deep-learning/"},{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/categories/cv/"},{"name":"pointcloud","slug":"cv/pointcloud","permalink":"https://tlylft.github.io/categories/cv/pointcloud/"},{"name":"segmentation","slug":"cv/segmentation","permalink":"https://tlylft.github.io/categories/cv/segmentation/"},{"name":"matplotlib","slug":"python/matplotlib","permalink":"https://tlylft.github.io/categories/python/matplotlib/"},{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/categories/pytorch/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/categories/knowledge-graph/"},{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/categories/NLP/"},{"name":"信息提取","slug":"NLP/信息提取","permalink":"https://tlylft.github.io/categories/NLP/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"},{"name":"math","slug":"math","permalink":"https://tlylft.github.io/categories/math/"},{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/categories/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"bert","slug":"NLP/bert","permalink":"https://tlylft.github.io/categories/NLP/bert/"},{"name":"similarity","slug":"NLP/similarity","permalink":"https://tlylft.github.io/categories/NLP/similarity/"},{"name":"前端","slug":"前端","permalink":"https://tlylft.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"大数据技术","slug":"大数据技术","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"mysql","slug":"大数据技术/mysql","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/mysql/"},{"name":"kafka","slug":"大数据技术/kafka","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/kafka/"},{"name":"corrector","slug":"NLP/corrector","permalink":"https://tlylft.github.io/categories/NLP/corrector/"},{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/categories/linux/"},{"name":"环境搭建","slug":"python/环境搭建","permalink":"https://tlylft.github.io/categories/python/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"algorithm","slug":"NLP/algorithm","permalink":"https://tlylft.github.io/categories/NLP/algorithm/"},{"name":"sensitive","slug":"NLP/sensitive","permalink":"https://tlylft.github.io/categories/NLP/sensitive/"},{"name":"NER","slug":"NLP/NER","permalink":"https://tlylft.github.io/categories/NLP/NER/"},{"name":"kubernetes","slug":"tools/kubernetes","permalink":"https://tlylft.github.io/categories/tools/kubernetes/"},{"name":"segment","slug":"NLP/segment","permalink":"https://tlylft.github.io/categories/NLP/segment/"},{"name":"Flask","slug":"python/Flask","permalink":"https://tlylft.github.io/categories/python/Flask/"},{"name":"ftp","slug":"tools/ftp","permalink":"https://tlylft.github.io/categories/tools/ftp/"},{"name":"label","slug":"NLP/label","permalink":"https://tlylft.github.io/categories/NLP/label/"},{"name":"k8s","slug":"tools/k8s","permalink":"https://tlylft.github.io/categories/tools/k8s/"},{"name":"autoML","slug":"machine-learning/autoML","permalink":"https://tlylft.github.io/categories/machine-learning/autoML/"},{"name":"paper","slug":"tools/paper","permalink":"https://tlylft.github.io/categories/tools/paper/"},{"name":"word2vec","slug":"NLP/word2vec","permalink":"https://tlylft.github.io/categories/NLP/word2vec/"},{"name":"tensorflow","slug":"tensorflow","permalink":"https://tlylft.github.io/categories/tensorflow/"},{"name":"keras","slug":"python/keras","permalink":"https://tlylft.github.io/categories/python/keras/"},{"name":"hive","slug":"大数据技术/hive","permalink":"https://tlylft.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/hive/"},{"name":"产品经理","slug":"产品经理","permalink":"https://tlylft.github.io/categories/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/"},{"name":"Django","slug":"python/Django","permalink":"https://tlylft.github.io/categories/python/Django/"}],"tags":[{"name":"LLM","slug":"LLM","permalink":"https://tlylft.github.io/tags/LLM/"},{"name":"强化学习","slug":"强化学习","permalink":"https://tlylft.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"tools","slug":"tools","permalink":"https://tlylft.github.io/tags/tools/"},{"name":"time series","slug":"time-series","permalink":"https://tlylft.github.io/tags/time-series/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://tlylft.github.io/tags/machine-learning/"},{"name":"爬虫","slug":"爬虫","permalink":"https://tlylft.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"python","slug":"python","permalink":"https://tlylft.github.io/tags/python/"},{"name":"Leecode","slug":"Leecode","permalink":"https://tlylft.github.io/tags/Leecode/"},{"name":"pandas","slug":"pandas","permalink":"https://tlylft.github.io/tags/pandas/"},{"name":"deep learning","slug":"deep-learning","permalink":"https://tlylft.github.io/tags/deep-learning/"},{"name":"pointcloud","slug":"pointcloud","permalink":"https://tlylft.github.io/tags/pointcloud/"},{"name":"cv","slug":"cv","permalink":"https://tlylft.github.io/tags/cv/"},{"name":"segmentation","slug":"segmentation","permalink":"https://tlylft.github.io/tags/segmentation/"},{"name":"pytorch","slug":"pytorch","permalink":"https://tlylft.github.io/tags/pytorch/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://tlylft.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://tlylft.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"knowledge graph","slug":"knowledge-graph","permalink":"https://tlylft.github.io/tags/knowledge-graph/"},{"name":"NLP","slug":"NLP","permalink":"https://tlylft.github.io/tags/NLP/"},{"name":"信息提取","slug":"信息提取","permalink":"https://tlylft.github.io/tags/%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/"},{"name":"math","slug":"math","permalink":"https://tlylft.github.io/tags/math/"},{"name":"对话系统","slug":"对话系统","permalink":"https://tlylft.github.io/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/"},{"name":"RASA","slug":"RASA","permalink":"https://tlylft.github.io/tags/RASA/"},{"name":"bert","slug":"bert","permalink":"https://tlylft.github.io/tags/bert/"},{"name":"bert4keras","slug":"bert4keras","permalink":"https://tlylft.github.io/tags/bert4keras/"},{"name":"similarity","slug":"similarity","permalink":"https://tlylft.github.io/tags/similarity/"},{"name":"vp","slug":"vp","permalink":"https://tlylft.github.io/tags/vp/"},{"name":"ppt","slug":"ppt","permalink":"https://tlylft.github.io/tags/ppt/"},{"name":"kafka","slug":"kafka","permalink":"https://tlylft.github.io/tags/kafka/"},{"name":"neo4j","slug":"neo4j","permalink":"https://tlylft.github.io/tags/neo4j/"},{"name":"corrector","slug":"corrector","permalink":"https://tlylft.github.io/tags/corrector/"},{"name":"linux","slug":"linux","permalink":"https://tlylft.github.io/tags/linux/"},{"name":"tensorflow","slug":"tensorflow","permalink":"https://tlylft.github.io/tags/tensorflow/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tlylft.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"paddle","slug":"paddle","permalink":"https://tlylft.github.io/tags/paddle/"},{"name":"mysql","slug":"mysql","permalink":"https://tlylft.github.io/tags/mysql/"},{"name":"algorithm","slug":"algorithm","permalink":"https://tlylft.github.io/tags/algorithm/"},{"name":"sensitive","slug":"sensitive","permalink":"https://tlylft.github.io/tags/sensitive/"},{"name":"NER","slug":"NER","permalink":"https://tlylft.github.io/tags/NER/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://tlylft.github.io/tags/kubernetes/"},{"name":"matplotlib","slug":"matplotlib","permalink":"https://tlylft.github.io/tags/matplotlib/"},{"name":"nlp","slug":"nlp","permalink":"https://tlylft.github.io/tags/nlp/"},{"name":"segment","slug":"segment","permalink":"https://tlylft.github.io/tags/segment/"},{"name":"pycharm","slug":"pycharm","permalink":"https://tlylft.github.io/tags/pycharm/"},{"name":"Flask","slug":"Flask","permalink":"https://tlylft.github.io/tags/Flask/"},{"name":"label","slug":"label","permalink":"https://tlylft.github.io/tags/label/"},{"name":"doccano","slug":"doccano","permalink":"https://tlylft.github.io/tags/doccano/"},{"name":"k8s","slug":"k8s","permalink":"https://tlylft.github.io/tags/k8s/"},{"name":"docker","slug":"docker","permalink":"https://tlylft.github.io/tags/docker/"},{"name":"anaconda","slug":"anaconda","permalink":"https://tlylft.github.io/tags/anaconda/"},{"name":"autoML","slug":"autoML","permalink":"https://tlylft.github.io/tags/autoML/"},{"name":"kubeflow","slug":"kubeflow","permalink":"https://tlylft.github.io/tags/kubeflow/"},{"name":"Docker","slug":"Docker","permalink":"https://tlylft.github.io/tags/Docker/"},{"name":"word2vec","slug":"word2vec","permalink":"https://tlylft.github.io/tags/word2vec/"},{"name":"navicat","slug":"navicat","permalink":"https://tlylft.github.io/tags/navicat/"},{"name":"keras","slug":"keras","permalink":"https://tlylft.github.io/tags/keras/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://tlylft.github.io/tags/Anaconda/"},{"name":"git","slug":"git","permalink":"https://tlylft.github.io/tags/git/"},{"name":"hive","slug":"hive","permalink":"https://tlylft.github.io/tags/hive/"},{"name":"产品经理","slug":"产品经理","permalink":"https://tlylft.github.io/tags/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/"},{"name":"Django","slug":"Django","permalink":"https://tlylft.github.io/tags/Django/"},{"name":"kerberos","slug":"kerberos","permalink":"https://tlylft.github.io/tags/kerberos/"},{"name":"github","slug":"github","permalink":"https://tlylft.github.io/tags/github/"},{"name":"blog","slug":"blog","permalink":"https://tlylft.github.io/tags/blog/"},{"name":"numpy","slug":"numpy","permalink":"https://tlylft.github.io/tags/numpy/"}]}